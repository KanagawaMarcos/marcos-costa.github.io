<html><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8" /><link href="style.css" rel="stylesheet" type="text/css" /><title>Python Machine Learning - Second Edition</title></head><body><div id="calibre_link-85" class="calibre"><div class="book" title="Python Machine Learning Second Edition" id="calibre_link-663"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-664"><a id="calibre_link-665" class="calibre1"></a>
<span class="strong"><strong class="calibre2">Python Machine Learning Second Edition</strong></span>
</h1></div></div><hr class="calibre3" /></div></div></div>

<div id="calibre_link-199" class="calibre">
    <div class="book">
      <h1 class="calibre4" id="calibre_link-666">Table of Contents</h1>
      <div class="book">
        <a href="#calibre_link-200" class="calibre1">Python Machine Learning Second Edition</a>
      </div>
      <div class="book">
        <a href="#calibre_link-201" class="calibre1">Credits</a>
      </div>
      <div class="book">
        <a href="#calibre_link-202" class="calibre1">About the Authors</a>
      </div>
      <div class="book">
        <a href="#calibre_link-203" class="calibre1">About the Reviewers</a>
      </div>
      <div class="book">
        <a href="#calibre_link-204" class="calibre1">www.PacktPub.com</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-205" class="calibre1">eBooks, discount offers, and more</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-206" class="calibre1">Why subscribe?</a>
      </div>
      <div class="book">
        <a href="#calibre_link-207" class="calibre1">Customer Feedback</a>
      </div>
      <div class="book">
        <a href="#calibre_link-208" class="calibre1">Preface</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-209" class="calibre1">What this book covers</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-210" class="calibre1">What you need for this book</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-211" class="calibre1">Who this book is for</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-212" class="calibre1">Conventions</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-213" class="calibre1">Reader feedback</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-214" class="calibre1">Customer support</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-215" class="calibre1">Downloading the example code</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-216" class="calibre1">Downloading the color images of this book</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-217" class="calibre1">Errata</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-218" class="calibre1">Piracy</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-219" class="calibre1">Questions</a>
      </div>
      <div class="book">
        <a href="#calibre_link-17" class="calibre1">1. Giving Computers the Ability to Learn from Data</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-220" class="calibre1">Building intelligent machines to transform data into knowledge</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-70" class="calibre1">The three different types of machine learning</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-221" class="calibre1">Making predictions about the future with supervised learning</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-222" class="calibre1">Classification for predicting class labels</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-223" class="calibre1">Regression for predicting continuous outcomes</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-224" class="calibre1">Solving interactive problems with reinforcement learning</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-225" class="calibre1">Discovering hidden structures with unsupervised learning</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-226" class="calibre1">Finding subgroups with clustering</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-227" class="calibre1">Dimensionality reduction for data compression</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-228" class="calibre1">Introduction to the basic terminology and notations</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-229" class="calibre1">A roadmap for building machine learning systems</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-230" class="calibre1">Preprocessing &ndash; getting data into shape</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-231" class="calibre1">Training and selecting a predictive model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-232" class="calibre1">Evaluating models and predicting unseen data instances</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-15" class="calibre1">Using Python for machine learning</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-233" class="calibre1">Installing Python and packages from the Python Package Index</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-234" class="calibre1">Using the Anaconda Python distribution and package manager</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-235" class="calibre1">Packages for scientific computing, data science, and machine learning</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-236" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-19" class="calibre1">2. Training Simple Machine Learning Algorithms for Classification</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-237" class="calibre1">Artificial neurons &ndash; a brief glimpse into the early history of machine learning</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-238" class="calibre1">The formal definition of an artificial neuron</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-239" class="calibre1">The perceptron learning rule</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-52" class="calibre1">Implementing a perceptron learning algorithm in Python</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-240" class="calibre1">An object-oriented perceptron API</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-241" class="calibre1">Training a perceptron model on the Iris dataset</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-6" class="calibre1">Adaptive linear neurons and the convergence of learning</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-242" class="calibre1">Minimizing cost functions with gradient descent</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-243" class="calibre1">Implementing Adaline in Python</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-244" class="calibre1">Improving gradient descent through feature scaling</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-245" class="calibre1">Large-scale machine learning and stochastic gradient descent</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-246" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-30" class="calibre1">3. A Tour of Machine Learning Classifiers Using scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-247" class="calibre1">Choosing a classification algorithm</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-7" class="calibre1">First steps with scikit-learn &ndash; training a perceptron</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-8" class="calibre1">Modeling class probabilities via logistic regression</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-248" class="calibre1">Logistic regression intuition and conditional probabilities</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-249" class="calibre1">Learning the weights of the logistic cost function</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-250" class="calibre1">Converting an Adaline implementation into an algorithm for logistic regression</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-251" class="calibre1">Training a logistic regression model with scikit-learn</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-252" class="calibre1">Tackling overfitting via regularization</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-253" class="calibre1">Maximum margin classification with support vector machines</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-254" class="calibre1">Maximum margin intuition</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-255" class="calibre1">Dealing with a nonlinearly separable case using slack variables</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-256" class="calibre1">Alternative implementations in scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-84" class="calibre1">Solving nonlinear problems using a kernel SVM</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-257" class="calibre1">Kernel methods for linearly inseparable data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-258" class="calibre1">Using the kernel trick to find separating hyperplanes in high-dimensional space</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-71" class="calibre1">Decision tree learning</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-259" class="calibre1">Maximizing information gain &ndash; getting the most bang for your buck</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-260" class="calibre1">Building a decision tree</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-261" class="calibre1">Combining multiple decision trees via random forests</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-81" class="calibre1">K-nearest neighbors &ndash; a lazy learning algorithm</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-262" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-36" class="calibre1">4. Building Good Training Sets &ndash; Data Preprocessing</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-263" class="calibre1">Dealing with missing data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-264" class="calibre1">Identifying missing values in tabular data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-265" class="calibre1">Eliminating samples or features with missing values</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-266" class="calibre1">Imputing missing values</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-267" class="calibre1">Understanding the scikit-learn estimator API</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-68" class="calibre1">Handling categorical data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-268" class="calibre1">Nominal and ordinal features</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-269" class="calibre1">Creating an example dataset</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-270" class="calibre1">Mapping ordinal features</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-271" class="calibre1">Encoding class labels</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-272" class="calibre1">Performing one-hot encoding on nominal features</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-107" class="calibre1">Partitioning a dataset into separate training and test sets</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-161" class="calibre1">Bringing features onto the same scale</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-82" class="calibre1">Selecting meaningful features</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-273" class="calibre1">L1 and L2 regularization as penalties against model complexity</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-274" class="calibre1">A geometric interpretation of L2 regularization</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-275" class="calibre1">Sparse solutions with L1 regularization</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-276" class="calibre1">Sequential feature selection algorithms</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-160" class="calibre1">Assessing feature importance with random forests</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-277" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-26" class="calibre1">5. Compressing Data via Dimensionality Reduction</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-278" class="calibre1">Unsupervised dimensionality reduction via principal component analysis</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-279" class="calibre1">The main steps behind principal component analysis</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-280" class="calibre1">Extracting the principal components step by step</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-281" class="calibre1">Total and explained variance</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-282" class="calibre1">Feature transformation</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-283" class="calibre1">Principal component analysis in scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-162" class="calibre1">Supervised data compression via linear discriminant analysis</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-284" class="calibre1">Principal component analysis versus linear discriminant analysis</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-285" class="calibre1">The inner workings of linear discriminant analysis</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-286" class="calibre1">Computing the scatter matrices</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-287" class="calibre1">Selecting linear discriminants for the new feature subspace</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-288" class="calibre1">Projecting samples onto the new feature space</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-289" class="calibre1">LDA via scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-11" class="calibre1">Using kernel principal component analysis for nonlinear mappings</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-290" class="calibre1">Kernel functions and the kernel trick</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-291" class="calibre1">Implementing a kernel principal component analysis in Python</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-292" class="calibre1">Example 1 &ndash; separating half-moon shapes</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-293" class="calibre1">Example 2 &ndash; separating concentric circles</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-294" class="calibre1">Projecting new data points</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-295" class="calibre1">Kernel principal component analysis in scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-296" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-37" class="calibre1">6. Learning Best Practices for Model Evaluation and Hyperparameter Tuning</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-297" class="calibre1">Streamlining workflows with pipelines</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-298" class="calibre1">Loading the Breast Cancer Wisconsin dataset</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-299" class="calibre1">Combining transformers and estimators in a pipeline</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-300" class="calibre1">Using k-fold cross-validation to assess model performance</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-301" class="calibre1">The holdout method</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-302" class="calibre1">K-fold cross-validation</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-14" class="calibre1">Debugging algorithms with learning and validation curves</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-303" class="calibre1">Diagnosing bias and variance problems with learning curves</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-304" class="calibre1">Addressing over- and underfitting with validation curves</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-13" class="calibre1">Fine-tuning machine learning models via grid search</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-305" class="calibre1">Tuning hyperparameters via grid search</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-306" class="calibre1">Algorithm selection with nested cross-validation</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-2" class="calibre1">Looking at different performance evaluation metrics</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-307" class="calibre1">Reading a confusion matrix</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-308" class="calibre1">Optimizing the precision and recall of a classification model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-309" class="calibre1">Plotting a receiver operating characteristic</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-310" class="calibre1">Scoring metrics for multiclass classification</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-72" class="calibre1">Dealing with class imbalance</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-311" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-38" class="calibre1">7. Combining Different Models for Ensemble Learning</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-312" class="calibre1">Learning with ensembles</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-50" class="calibre1">Combining classifiers via majority vote</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-313" class="calibre1">Implementing a simple majority vote classifier</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-314" class="calibre1">Using the majority voting principle to make predictions</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-315" class="calibre1">Evaluating and tuning the ensemble classifier</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-51" class="calibre1">Bagging &ndash; building an ensemble of classifiers from bootstrap samples</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-316" class="calibre1">Bagging in a nutshell</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-317" class="calibre1">Applying bagging to classify samples in the Wine dataset</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-5" class="calibre1">Leveraging weak learners via adaptive boosting</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-318" class="calibre1">How boosting works</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-319" class="calibre1">Applying AdaBoost using scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-320" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-39" class="calibre1">8. Applying Machine Learning to Sentiment Analysis</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-321" class="calibre1">Preparing the IMDb movie review data for text processing</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-322" class="calibre1">Obtaining the movie review dataset</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-323" class="calibre1">Preprocessing the movie dataset into more convenient format</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-49" class="calibre1">Introducing the bag-of-words model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-324" class="calibre1">Transforming words into feature vectors</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-325" class="calibre1">Assessing word relevancy via term frequency-inverse document frequency</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-326" class="calibre1">Cleaning text data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-327" class="calibre1">Processing documents into tokens</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-110" class="calibre1">Training a logistic regression model for document classification</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-328" class="calibre1">Working with bigger data &ndash; online algorithms and out-of-core learning</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-144" class="calibre1">Topic modeling with Latent Dirichlet Allocation</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-329" class="calibre1">Decomposing text documents with LDA</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-330" class="calibre1">LDA with scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-331" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-40" class="calibre1">9. Embedding a Machine Learning Model into a Web Application</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-332" class="calibre1">Serializing fitted scikit-learn estimators</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-108" class="calibre1">Setting up an SQLite database for data storage</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-67" class="calibre1">Developing a web application with Flask</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-333" class="calibre1">Our first Flask web application</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-334" class="calibre1">Form validation and rendering</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-335" class="calibre1">Setting up the directory structure</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-336" class="calibre1">Implementing a macro using the Jinja2 templating engine</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-337" class="calibre1">Adding style via CSS</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-338" class="calibre1">Creating the result page</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-339" class="calibre1">Turning the movie review classifier into a web application</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-340" class="calibre1">Files and folders &ndash; looking at the directory tree</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-341" class="calibre1">Implementing the main application as app.py</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-342" class="calibre1">Setting up the review form</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-343" class="calibre1">Creating a results page template</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-344" class="calibre1">Deploying the web application to a public server</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-345" class="calibre1">Creating a PythonAnywhere account</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-346" class="calibre1">Uploading the movie classifier application</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-347" class="calibre1">Updating the movie classifier</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-348" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-41" class="calibre1">10. Predicting Continuous Target Variables with Regression Analysis</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-349" class="calibre1">Introducing linear regression</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-350" class="calibre1">Simple linear regression</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-351" class="calibre1">Multiple linear regression</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-80" class="calibre1">Exploring the Housing dataset</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-352" class="calibre1">Loading the Housing dataset into a data frame</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-353" class="calibre1">Visualizing the important characteristics of a dataset</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-354" class="calibre1">Looking at relationships using a correlation matrix</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-9" class="calibre1">Implementing an ordinary least squares linear regression model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-355" class="calibre1">Solving regression for regression parameters with gradient descent</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-356" class="calibre1">Estimating coefficient of a regression model via scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-357" class="calibre1">Fitting a robust regression model using RANSAC</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-73" class="calibre1">Evaluating the performance of linear regression models</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-141" class="calibre1">Using regularized methods for regression</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-83" class="calibre1">Turning a linear regression model into a curve &ndash; polynomial regression</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-358" class="calibre1">Adding polynomial terms using scikit-learn</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-359" class="calibre1">Modeling nonlinear relationships in the Housing dataset</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-109" class="calibre1">Dealing with nonlinear relationships using random forests</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-360" class="calibre1">Decision tree regression</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-361" class="calibre1">Random forest regression</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-362" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-42" class="calibre1">11. Working with Unlabeled Data &ndash; Clustering Analysis</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-363" class="calibre1">Grouping objects by similarity using k-means</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-364" class="calibre1">K-means clustering using scikit-learn</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-365" class="calibre1">A smarter way of placing the initial cluster centroids using k-means++</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-366" class="calibre1">Hard versus soft clustering</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-367" class="calibre1">Using the elbow method to find the optimal number of clusters</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-368" class="calibre1">Quantifying the quality of clustering via silhouette plots</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-12" class="calibre1">Organizing clusters as a hierarchical tree</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-369" class="calibre1">Grouping clusters in bottom-up fashion</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-370" class="calibre1">Performing hierarchical clustering on a distance matrix</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-371" class="calibre1">Attaching dendrograms to a heat map</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-372" class="calibre1">Applying agglomerative clustering via scikit-learn</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-53" class="calibre1">Locating regions of high density via DBSCAN</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-373" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-10" class="calibre1">12. Implementing a Multilayer Artificial Neural Network from Scratch</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-374" class="calibre1">Modeling complex functions with artificial neural networks</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-375" class="calibre1">Single-layer neural network recap</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-376" class="calibre1">Introducing the multilayer neural network architecture</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-377" class="calibre1">Activating a neural network via forward propagation</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-143" class="calibre1">Classifying handwritten digits</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-378" class="calibre1">Obtaining the MNIST dataset</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-379" class="calibre1">Implementing a multilayer perceptron</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-18" class="calibre1">Training an artificial neural network</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-380" class="calibre1">Computing the logistic cost function</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-381" class="calibre1">Developing your intuition for backpropagation</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-382" class="calibre1">Training neural networks via backpropagation</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-78" class="calibre1">About the convergence in neural networks</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-182" class="calibre1">A few last words about the neural network implementation</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-383" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-16" class="calibre1">13. Parallelizing Neural Network Training with TensorFlow</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-384" class="calibre1">TensorFlow and training performance</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-385" class="calibre1">What is TensorFlow?</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-386" class="calibre1">How we will learn TensorFlow</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-387" class="calibre1">First steps with TensorFlow</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-388" class="calibre1">Working with array structures</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-389" class="calibre1">Developing a simple model with the low-level TensorFlow API</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-76" class="calibre1">Training neural networks efficiently with high-level TensorFlow APIs</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-390" class="calibre1">Building multilayer neural networks using TensorFlow's Layers API</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-391" class="calibre1">Developing a multilayer neural network with Keras</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-3" class="calibre1">Choosing activation functions for multilayer networks</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-392" class="calibre1">Logistic function recap</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-393" class="calibre1">Estimating class probabilities in multiclass classification via the softmax function</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-394" class="calibre1">Broadening the output spectrum using a hyperbolic tangent</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-395" class="calibre1">Rectified linear unit activation</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-396" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-43" class="calibre1">14. Going Deeper &ndash; The Mechanics of TensorFlow</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-397" class="calibre1">Key features of TensorFlow</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-398" class="calibre1">TensorFlow ranks and tensors</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-399" class="calibre1">How to get the rank and shape of a tensor</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-75" class="calibre1">Understanding TensorFlow's computation graphs</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-400" class="calibre1">Placeholders in TensorFlow</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-401" class="calibre1">Defining placeholders</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-402" class="calibre1">Feeding placeholders with data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-403" class="calibre1">Defining placeholders for data arrays with varying batchsizes</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-34" class="calibre1">Variables in TensorFlow</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-404" class="calibre1">Defining variables</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-405" class="calibre1">Initializing variables</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-406" class="calibre1">Variable scope</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-407" class="calibre1">Reusing variables</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-408" class="calibre1">Building a regression model</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-409" class="calibre1">Executing objects in a TensorFlow graph using their names</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-410" class="calibre1">Saving and restoring a model in TensorFlow</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-411" class="calibre1">Transforming Tensors as multidimensional data arrays</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-77" class="calibre1">Utilizing control flow mechanics in building graphs</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-181" class="calibre1">Visualizing the graph with TensorBoard</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-412" class="calibre1">Extending your TensorBoard experience</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-413" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-20" class="calibre1">15. Classifying Images with Deep Convolutional Neural Networks</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-414" class="calibre1">Building blocks of convolutional neural networks</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-415" class="calibre1">Understanding CNNs and learning feature hierarchies</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-416" class="calibre1">Performing discrete convolutions</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-417" class="calibre1">Performing a discrete convolution in one dimension</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-418" class="calibre1">The effect of zero-padding in a convolution</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-419" class="calibre1">Determining the size of the convolution output</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-420" class="calibre1">Performing a discrete convolution in 2D</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-421" class="calibre1">Subsampling</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-74" class="calibre1">Putting everything together to build a CNN</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-422" class="calibre1">Working with multiple input or color channels</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-423" class="calibre1">Regularizing a neural network with dropout</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-79" class="calibre1">Implementing a deep convolutional neural network using TensorFlow</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-424" class="calibre1">The multilayer CNN architecture</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-425" class="calibre1">Loading and preprocessing the data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-426" class="calibre1">Implementing a CNN in the TensorFlow low-level API</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-427" class="calibre1">Implementing a CNN in the TensorFlow Layers API</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-428" class="calibre1">Summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-44" class="calibre1">16. Modeling Sequential Data Using Recurrent Neural Networks</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-429" class="calibre1">Introducing sequential data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-430" class="calibre1">Modeling sequential data &ndash; order matters</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-431" class="calibre1">Representing sequences</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-432" class="calibre1">The different categories of sequence modeling</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-4" class="calibre1">RNNs for modeling sequences</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-433" class="calibre1">Understanding the structure and flow of an RNN</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-434" class="calibre1">Computing activations in an RNN</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-435" class="calibre1">The challenges of learning long-range interactions</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-436" class="calibre1">LSTM units</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-437" class="calibre1">Implementing a multilayer RNN for sequence modeling in TensorFlow</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-142" class="calibre1">Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-438" class="calibre1">Preparing the data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-439" class="calibre1">Embedding</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-440" class="calibre1">Building an RNN model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-441" class="calibre1">The SentimentRNN class constructor</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-442" class="calibre1">The build method</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-443" class="calibre1">Step 1 &ndash; defining multilayer RNN cells</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-444" class="calibre1">Step 2 &ndash; defining the initial states for the RNN cells</a>
      </div>
      <div class="calibre7">
        <a href="#calibre_link-445" class="calibre1">Step 3 &ndash; creating the RNN using the RNN cells and their states</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-446" class="calibre1">The train method</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-447" class="calibre1">The predict method</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-448" class="calibre1">Instantiating the SentimentRNN class</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-449" class="calibre1">Training and optimizing the sentiment analysis RNN model</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-69" class="calibre1">Project two &ndash; implementing an RNN for character-level language modeling in TensorFlow</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-450" class="calibre1">Preparing the data</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-451" class="calibre1">Building a character-level RNN model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-452" class="calibre1">The constructor</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-453" class="calibre1">The build method</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-454" class="calibre1">The train method</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-455" class="calibre1">The sample method</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-456" class="calibre1">Creating and training the CharRNN Model</a>
      </div>
      <div class="calibre6">
        <a href="#calibre_link-457" class="calibre1">The CharRNN model in the sampling mode</a>
      </div>
      <div class="calibre5">
        <a href="#calibre_link-458" class="calibre1">Chapter and book summary</a>
      </div>
      <div class="book">
        <a href="#calibre_link-459" class="calibre1">Index</a>
      </div>
    </div>
  </div>

<div id="calibre_link-490" class="calibre"><div class="book" title="Python Machine Learning Second Edition"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-667"><a id="calibre_link-668" class="calibre1"></a>
<span class="strong"><strong class="calibre2">Python Machine Learning Second Edition</strong></span>
</h1></div></div><hr class="calibre3" /></div></div></div>

<div id="calibre_link-92" class="calibre"><div class="book" title="Python Machine Learning Second Edition" id="calibre_link-200"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-669"><a id="calibre_link-670" class="calibre1"></a>Python Machine Learning Second Edition</h1></div></div></div><p class="calibre8">Copyright Â© 2017 Packt Publishing</p><p class="calibre8">All rights reserved. No part of this book may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, without the prior written permission of the publisher, except in the case of brief quotations embedded in critical articles or reviews.</p><p class="calibre8">Every effort has been made in the preparation of this book to ensure the accuracy of the information presented. However, the information contained in this book is sold without warranty, either express or implied. Neither the authors, nor Packt Publishing, and its dealers and distributors will be held liable for any damages caused or alleged to be caused directly or indirectly by this book.</p><p class="calibre8">Packt Publishing has endeavored to provide trademark information about all of the companies and products mentioned in this book by the appropriate use of capitals. However, Packt Publishing cannot guarantee the accuracy of this information.</p><p class="calibre8">First published: September 2015</p><p class="calibre8">Second edition: September 2017</p><p class="calibre8">Production reference: 1120917</p><p class="calibre8">Published by Packt Publishing Ltd.</p><p class="calibre8">Livery Place</p><p class="calibre8">35 Livery Street</p><p class="calibre8">Birmingham B3 2PB, UK.</p><p class="calibre8">ISBN 978-1-78712-593-3</p><p class="calibre8">
<a class="calibre1" href="http://www.packtpub.com">www.packtpub.com</a>
</p></div></div>

<div id="calibre_link-100" class="calibre"><div class="book" title="Credits" id="calibre_link-201"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-671"><a id="calibre_link-672" class="calibre1"></a>Credits</h1></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Authors</strong></span>
</p><p class="calibre8">Sebastian Raschka</p><p class="calibre8">Vahid Mirjalili</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Reviewers</strong></span>
</p><p class="calibre8">Jared Huffman</p><p class="calibre8">Huai-En, Sun (Ryan Sun)</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Acquisition Editor</strong></span>
</p><p class="calibre8">Frank Pohlmann</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Content Development Editor</strong></span>
</p><p class="calibre8">Chris Nelson</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Project Editor</strong></span>
</p><p class="calibre8">Monika Sangwan</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Technical Editors</strong></span>
</p><p class="calibre8">Bhagyashree Rai</p><p class="calibre8">Nidhisha Shetty</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Copy Editor</strong></span>
</p><p class="calibre8">Safis Editing</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Project Coordinator</strong></span>
</p><p class="calibre8">Suzanne Coutinho</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Proofreader</strong></span>
</p><p class="calibre8">Safis Editing</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Indexer</strong></span>
</p><p class="calibre8">Tejal Daruwale Soni</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Graphics</strong></span>
</p><p class="calibre8">Kirk D'Penha</p><p class="calibre8">
<span class="strong"><strong class="calibre2">Production Coordinator</strong></span>
</p><p class="calibre8">Arvindkumar Gupta</p></div></div>

<div id="calibre_link-112" class="calibre"><div class="book" title="About the Authors" id="calibre_link-202"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-673"><a id="calibre_link-674" class="calibre1"></a>About the Authors</h1></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Sebastian Raschka</strong></span>, the author of the bestselling book, <span class="strong"><em class="calibre9">Python Machine Learning</em></span>, has many years of experience with coding in Python, and he has given several seminars on the practical applications of data science, machine learning, and deep learning including a machine learning tutorial at SciPy&mdash;the leading conference for scientific computing in Python.</p><p class="calibre8">While Sebastian's academic research projects are mainly centered around problem-solving in computational biology, he loves to write and talk about data science, machine learning, and Python in general, and he is motivated to help people develop data-driven solutions without necessarily requiring a machine learning background.</p><p class="calibre8">His work and contributions have recently been recognized by the departmental outstanding graduate student award 2016-2017 as well as the ACM Computing Reviewsâ Best of 2016 award. In his free time, Sebastian loves to contribute to open source projects, and the methods that he has implemented are now successfully used in machine learning competitions, such as Kaggle.</p><div class="book"><div class="book"><p class="calibre8"></p><p class="calibre8">I would like to take this opportunity to thank the great Python community and developers of open source packages who helped me create the perfect environment for scientific research and data science. Also, I want to thank my parents who always encouraged and supported me in pursuing the path and career that I was so passionate about.</p><p class="calibre8">Special thanks to the core developers of scikit-learn. As a contributor to this project, I had the pleasure to work with great people who are not only very knowledgeable when it comes to machine learning but are also excellent programmers.</p><p class="calibre8">Lastly, I'd like to thank Elie Kawerk, who volunteered to review the book and provided valuable feedback on the new chapters.</p></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Vahid Mirjalili</strong></span> obtained his PhD in mechanical engineering working on novel methods for large-scale, computational simulations of molecular structures. Currently, he is focusing his research efforts on applications of machine learning in various computer vision projects at the department of computer science and engineering at Michigan State University.</p><p class="calibre8">Vahid picked Python as his number-one choice of programming language, and throughout his academic and research career he has gained tremendous experience with coding in Python. He taught Python programming to the engineering class at Michigan State University, which gave him a chance to help students understand different data structures and develop efficient code in Python.</p><p class="calibre8">While Vahid's broad research interests focus on deep learning and computer vision applications, he is especially interested in leveraging deep learning techniques to extend privacy in biometric data such as face images so that information is not revealed beyond what users intend to reveal. Furthermore, he also collaborates with a team of engineers working on self-driving cars, where he designs neural network models for the fusion of multispectral images for pedestrian detection.</p><div class="book"><div class="book"><p class="calibre8"></p><p class="calibre8">I would like to thank my PhD advisor, Dr. Arun Ross, for giving me the opportunity to work on novel problems in his research lab. I also like to thank Dr. Vishnu Boddeti for inspiring my interests in deep learning and demystifying its core concepts.</p></div></div></div></div>

<div id="calibre_link-568" class="calibre"><div class="book" title="About the Reviewers" id="calibre_link-203"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-675"><a id="calibre_link-676" class="calibre1"></a>About the Reviewers</h1></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Jared Huffman</strong></span> is an entrepreneur, gamer, storyteller, machine learning fanatic, and database aficionado. He has dedicated the past 10 years to developing software and analyzing data. His previous work has spanned a variety of topics, including network security, financial systems, and business intelligence, as well as web services, developer tools, and business strategy. Most recently, he was the founder of the data science team at Minecraft, with a focus on big data and machine learning. When not working, you can typically find him gaming or enjoying the beautiful Pacific Northwest with friends and family.</p><div class="book"><div class="book"><p class="calibre8"></p><p class="calibre8">I'd like to thank Packt for giving me the opportunity to work on such a great book, my wife for the constant encouragement, and my daughter for sleeping through most of the late nights while I was reviewing and debugging code.</p></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Huai-En, Sun (Ryan Sun)</strong></span> holds a master's degree in statistics from the National Chiao Tung University. He is currently working as a data scientist for analyzing the production line at PEGATRON. Machine learning and deep learning are his main areas of research.</p></div></div>

<div id="calibre_link-118" class="calibre">
<div id="calibre_link-677" class="calibre10"></div><div class="book" title="www.PacktPub.com" id="calibre_link-204"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-678"><a id="calibre_link-679" class="calibre1"></a>www.PacktPub.com</h1></div></div></div></div></div>

<div id="calibre_link-125" class="calibre">
<div class="book" title="www.PacktPub.com" id="calibre_link-680">
<div class="book" title="eBooks, discount offers, and more"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-681"><a id="calibre_link-205" class="calibre1"></a>eBooks, discount offers, and more</h1></div></div></div><p class="calibre8">Did you know that Packt offers eBook versions of every book published, with PDF and ePub files available? You can upgrade to the eBook version at <a class="calibre1" href="http://www.PacktPub.com">www.PacktPub.com</a> and as a print book customer, you are entitled to a discount on the eBook copy. Get in touch with us at <code class="email">&lt;<a class="calibre1" href="mailto:customercare@packtpub.com">customercare@packtpub.com</a>&gt;</code> for more details.</p><p class="calibre8">At <a class="calibre1" href="http://www.PacktPub.com">www.PacktPub.com</a>, you can also read a collection of free technical articles, sign up for a range of free newsletters and receive exclusive discounts and offers on Packt books and eBooks.</p><div class="mediaobject"><img src="images/00491.jpeg" alt="eBooks, discount offers, and more" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
<a class="calibre1" href="https://www.packtpub.com/mapt">https://www.packtpub.com/mapt</a></p><p class="calibre8">Get the most in-demand software skills with Mapt. Mapt gives you full access to all Packt books and video courses, as well as industry-leading tools to help you plan your personal development and advance your career.</p></div></div></div>

<div id="calibre_link-134" class="calibre">
<div class="book" title="www.PacktPub.com" id="calibre_link-682">
<div class="book" title="eBooks, discount offers, and more">
<div class="book" title="Why subscribe?"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-683"><a id="calibre_link-206" class="calibre1"></a>Why subscribe?</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">Fully searchable across every book published by Packt</li><li class="listitem">Copy and paste, print, and bookmark content</li><li class="listitem">On demand and accessible via a web browser</li></ul></div></div></div></div></div>

<div id="calibre_link-145" class="calibre"><div class="book" title="Customer Feedback" id="calibre_link-207"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-684"><a id="calibre_link-685" class="calibre1"></a>Customer Feedback</h1></div></div></div><p class="calibre8">Thanks for purchasing this Packt book. At Packt, quality is at the heart of our editorial process. To help us improve, please leave us an honest review on this book's Amazon page at <a class="calibre1" href="https://www.amazon.com/dp/1787125939">https://www.amazon.com/dp/1787125939</a>.</p><p class="calibre8">If you'd like to join our team of regular reviewers, you can email us at <code class="email">customerreviews@packtpub.com</code>. We award our regular reviewers with free eBooks and videos in exchange for their valuable feedback. Help us be relentless in improving our products!</p></div></div>

<div id="calibre_link-659" class="calibre">
<div id="calibre_link-686" class="calibre10"></div><div class="book" title="Preface"><div class="book" id="calibre_link-208"><div class="book"><div class="book"><h1 class="title" id="calibre_link-687"><a id="calibre_link-688" class="calibre1"></a>Preface</h1></div></div></div><p class="calibre8">Through exposure to the news and social media, you are probably aware of the fact that machine learning has become one of the most exciting technologies of our time and age. Large companies, such as Google, Facebook, Apple, Amazon, and IBM, heavily invest in machine learning research and applications for good reasons. While it may seem that machine learning has become the buzzword of our time and age, it is certainly not a fad. This exciting field opens the way to new possibilities and has become indispensable to our daily lives. This is evident in talking to the voice assistant on our smartphones, recommending the right product for our customers, preventing credit card fraud, filtering out spam from our email inboxes, detecting and diagnosing medical diseases, the list goes on and on.</p><p class="calibre8">If you want to become a machine learning practitioner, a better problem solver, or maybe even consider a career in machine learning research, then this book is for you. However, for a novice, the theoretical concepts behind machine learning can be quite overwhelming. Many practical books have been published in recent years that will help you get started in machine learning by implementing powerful learning algorithms.</p><p class="calibre8">Getting exposed to practical code examples and working through example applications of machine learning are a great way to dive into this field. Concrete examples help illustrate the broader concepts by putting the learned material directly into action. However, remember that with great power comes great responsibility! In addition to offering a hands-on experience with machine learning using the Python programming languages and Python-based machine learning libraries, this book introduces the mathematical concepts behind machine learning algorithms, which is essential for using machine learning successfully. Thus, this book is different from a purely practical book; it is a book that discusses the necessary details regarding machine learning concepts and offers intuitive yet informative explanations of how machine learning algorithms work, how to use them, and most importantly, how to avoid the most common pitfalls.</p><p class="calibre8">Currently, if you type "machine learning" as a search term in Google Scholar, it returns an overwhelmingly large number of publications&mdash;1,800,000. Of course, we cannot discuss the nitty-gritty of all the different algorithms and applications that have emerged in the last 60 years. However, in this book, we will embark on an exciting journey that covers all the essential topics and concepts to give you a head start in this field. If you find that your thirst for knowledge is not satisfied, this book references many useful resources that can be used to follow up on the essential breakthroughs in this field. </p><p class="calibre8">If you have already studied machine learning theory in detail, this book will show you how to put your knowledge into practice. If you have used machine learning techniques before and want to gain more insight into how machine learning actually works, this book is for you. Don't worry if you are completely new to the machine learning field; you have even more reason to be excited. Here is a promise that machine learning will change the way you think about the problems you want to solve and will show you how to tackle them by unlocking the power of data. </p><p class="calibre8">Before we dive deeper into the machine learning field, let's answer your most important question, "Why Python?" The answer is simple: it is powerful yet very accessible. Python has become the most popular programming language for data science because it allows us to forget about the tedious parts of programming and offers us an environment where we can quickly jot down our ideas and put concepts directly into action. </p><p class="calibre8">We, the authors, can truly say that the study of machine learning has made us better scientists, thinkers, and problem solvers. In this book, we want to share this knowledge with you. Knowledge is gained by learning. The key is our enthusiasm, and the real mastery of skills can only be achieved by practice. The road ahead may be bumpy on occasions and some topics may be more challenging than others, but we hope that you will embrace this opportunity and focus on the reward. Remember that we are on this journey together, and throughout this book, we will add many powerful techniques to your arsenal that will help us solve even the toughest problems the data-driven way. </p><div class="book" title="What this book covers"><div class="book"><div class="book"><div class="book"><div class="book" id="calibre_link-689"></div>
</div></div></div></div></div></div>

<div id="calibre_link-35" class="calibre">
<div id="calibre_link-690" class="calibre10"></div><div class="book" title="Preface">
<div class="book" title="What this book covers">
<div class="book">
<div class="book">
<div class="book">
<h1 class="title" id="calibre_link-691"><a id="calibre_link-209" class="calibre1"></a>What this book covers</h1></div></div></div><p class="calibre8">
<a class="calibre1" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" href="#calibre_link-17">Chapter 1</a>
<span class="strong"><em class="calibre9">, Giving Computers the Ability to Learn from Data</em></span>, introduces you to the main subareas of machine learning in order to tackle various problem tasks. In addition, it discusses the essential steps for creating a typical machine learning model by building a pipeline that will guide us through the following chapters.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>
<span class="strong"><em class="calibre9">, Training Simple Machine Learning Algorithms for Classification</em></span>, goes back to the origins of machine learning and introduces binary perceptron classifiers and adaptive linear neurons. This chapter is a gentle introduction to the fundamentals of pattern classification and focuses on the interplay of optimization algorithms and machine learning.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>
<span class="strong"><em class="calibre9">, A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, describes the essential machine learning algorithms for classification and provides practical examples using one of the most popular and comprehensive open source machine learning libraries: scikit-learn. </p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>
<span class="strong"><em class="calibre9">, Building Good Training Sets &ndash; Data Preprocessing</em></span>, discusses how to deal with the most common problems in unprocessed datasets, such as missing data. It also discusses several approaches to identify the most informative features in datasets and teaches you how to prepare variables of different types as proper input for machine learning algorithms.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>
<span class="strong"><em class="calibre9">, Compressing Data via Dimensionality Reduction</em></span>, describes the essential techniques to reduce the number of features in a dataset to smaller sets while retaining most of their useful and discriminatory information. It discusses the standard approach to dimensionality reduction via principal component analysis and compares it to supervised and nonlinear transformation techniques. </p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>
<span class="strong"><em class="calibre9">, Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, discusses the dos and don'ts for estimating the performances of predictive models. Moreover, it discusses different metrics for measuring the performance of our models and techniques to fine-tune machine learning algorithms. </p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 7.Â Combining Different Models for Ensemble Learning" href="#calibre_link-38">Chapter 7</a>
<span class="strong"><em class="calibre9">, Combining Different Models for Ensemble Learning</em></span>, introduces you to the different concepts of combining multiple learning algorithms effectively. It teaches you how to build ensembles of experts to overcome the weaknesses of individual learners, resulting in more accurate and reliable predictions. </p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>
<span class="strong"><em class="calibre9">, Applying Machine Learning to Sentiment Analysis</em></span>, discusses the essential steps to transform textual data into meaningful representations for machine learning algorithms to predict the opinions of people based on their writing. </p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application" href="#calibre_link-40">Chapter 9</a>
<span class="strong"><em class="calibre9">, Embedding a Machine Learning Model into a Web Application</em></span>, continues with the predictive model from the previous chapter and walks you through the essential steps of developing web applications with embedded machine learning models.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" href="#calibre_link-41">Chapter 10</a>
<span class="strong"><em class="calibre9">, Predicting Continuous Target Variables with Regression Analysis</em></span>, discusses the essential techniques for modeling linear relationships between target and response variables to make predictions on a continuous scale. After introducing different linear models, it also talks about polynomial regression and tree-based approaches. </p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis" href="#calibre_link-42">Chapter 11</a>
<span class="strong"><em class="calibre9">, Working with Unlabeled Data &ndash; Clustering Analysis,</em></span> shifts the focus to a different subarea of machine learning, unsupervised learning. We apply algorithms from three fundamental families of clustering algorithms to find groups of objects that share a certain degree of similarity.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>
<span class="strong"><em class="calibre9">, Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, extends the concept of gradient-based optimization, which we first introduced in <span class="strong"><em class="calibre9">Chapter 2, Training Simple Machine Learning Algorithms for Classification</em></span>, to build powerful, multilayer neural networks based on the popular backpropagation algorithm in Python.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>
<span class="strong"><em class="calibre9">, Parallelizing Neural Network Training with TensorFlow</em></span>, builds upon the knowledge from the previous chapter to provide you with a practical guide for training neural networks more efficiently. The focus of this chapter is on TensorFlow, an open source Python library that allows us to utilize multiple cores of modern GPUs.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span>, covers TensorFlow in greater detail explaining its core concepts of computational graphs and sessions. In addition, this chapter covers topics such as saving and visualizing neural network graphs, which will come in very handy during the remaining chapters of this book.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks" href="#calibre_link-20">Chapter 15</a>
<span class="strong"><em class="calibre9">, Classifying Images with Deep Convolutional Neural Networks</em></span>, discusses deep neural network architectures that have become the new standard in computer vision and image recognition fields&mdash;convolutional neural networks. This chapter will discuss the main concepts between convolutional layers as a feature extractor and apply convolutional neural network architectures to an image classification task to achieve almost perfect classification accuracy.</p><p class="calibre8">
<a class="calibre1" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" href="#calibre_link-44">Chapter 16</a>
<span class="strong"><em class="calibre9">, Modeling Sequential Data Using Recurrent Neural Networks</em></span>, introduces another popular neural network architecture for deep learning that is especially well suited for working with sequential data and time series data. In this chapter, we will apply different recurrent neural network architectures to text data. We will start with a sentiment analysis task as a warm-up exercise and will learn how to generate entirely new text.</p></div></div></div>

<div id="calibre_link-62" class="calibre"><div class="book" title="What you need for this book" id="calibre_link-210"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-692"><a id="calibre_link-693" class="calibre1"></a>What you need for this book</h1></div></div></div><p class="calibre8">The execution of the code examples provided in this book requires an installation of Python 3.6.0 or newer on macOS, Linux, or Microsoft Windows. We will make frequent use of Python's essential libraries for scientific computing throughout this book, including SciPy, NumPy, scikit-learn, Matplotlib, and pandas.</p><p class="calibre8">The first chapter will provide you with instructions and useful tips to set up your Python environment and these core libraries. We will add additional libraries to our repertoire; moreover, installation instructions are provided in the respective chapters: the NLTK library for natural language processing (<a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span>), the Flask web framework (<a class="calibre1" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application" href="#calibre_link-40">Chapter 9</a>, <span class="strong"><em class="calibre9">Embedding a Machine Learning Algorithm into a Web Application</em></span>), the Seaborn library for statistical data visualization (<a class="calibre1" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" href="#calibre_link-41">Chapter 10</a>, <span class="strong"><em class="calibre9">Predicting Continuous Target Variables with Regression Analysis</em></span>), and TensorFlow for efficient neural network training on graphical processing units (<span class="strong"><em class="calibre9">Chapters 13 to 16</em></span>).</p></div></div>

<div id="calibre_link-102" class="calibre"><div class="book" title="Who this book is for" id="calibre_link-211"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-694"><a id="calibre_link-695" class="calibre1"></a>Who this book is for</h1></div></div></div><p class="calibre8">If you want to find out how to use Python to start answering critical questions of your data, pick up <span class="strong"><em class="calibre9">Python Machine Learning, Second Edition</em></span>&mdash;whether you want to start from scratch or extend your data science knowledge, this is an essential and unmissable resource.</p></div></div>

<div id="calibre_link-136" class="calibre"><div class="book" title="Conventions" id="calibre_link-212"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-696"><a id="calibre_link-697" class="calibre1"></a>Conventions</h1></div></div></div><p class="calibre8">In this book, you will find a number of text styles that distinguish between different kinds of information. Here are some examples of these styles and an explanation of their meaning. </p><p class="calibre8">Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "Using the <code class="email">out_file=None</code> setting, we directly assigned the dot data to a <code class="email">dot_data</code> variable, instead of writing an intermediate <code class="email">tree.dot</code> file to disk."</p><p class="calibre8">A block of code is set as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; knn = KNeighborsClassifier(n_neighbors=5, p=2,
...                            metric='minkowski')
&gt;&gt;&gt; knn.fit(X_train_std, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined_std, y_combined, 
...                       classifier=knn, test_idx=range(105,150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Any command-line input or output is written as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip3 install graphviz</strong></span>
</pre></div><p class="calibre8">
<span class="strong"><strong class="calibre2">New terms</strong></span> and <span class="strong"><strong class="calibre2">important words</strong></span> are shown in bold. Words that you see on the screen, for example, in menus or dialog boxes, appear in the text like this: "After we click on the <span class="strong"><strong class="calibre2">Dashboard</strong></span> button in the top-right corner, we have access to the control panel shown at the top of the page."</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-698" class="calibre1"></a>Note</h3><p class="calibre8">Warnings or important notes appear in a box like this.</p></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-699" class="calibre1"></a>Tip</h3><p class="calibre8">Tips and tricks appear like this.</p></div></div></div>

<div id="calibre_link-165" class="calibre"><div class="book" title="Reader feedback" id="calibre_link-213"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-700"><a id="calibre_link-701" class="calibre1"></a>Reader feedback</h1></div></div></div><p class="calibre8">Feedback from our readers is always welcome. Let us know what you think about this book&mdash;what you liked or disliked. Reader feedback is important for us as it helps us develop titles that you will really get the most out of.</p><p class="calibre8">To send us general feedback, simply email <code class="email">&lt;<a class="calibre1" href="mailto:feedback@packtpub.com">feedback@packtpub.com</a>&gt;</code>, and mention the book's title in the subject of your message.</p><p class="calibre8">If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, see our author guide at <a class="calibre1" href="http://www.packtpub.com/authors">www.packtpub.com/authors</a>.</p></div></div>

<div id="calibre_link-175" class="calibre">
<div id="calibre_link-702" class="calibre10"></div><div class="book" title="Customer support" id="calibre_link-214"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-703"><a id="calibre_link-704" class="calibre1"></a>Customer support</h1></div></div></div><p class="calibre8">Now that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.</p></div></div>

<div id="calibre_link-462" class="calibre">
<div class="book" title="Customer support" id="calibre_link-705">
<div class="book" title="Downloading the example code"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-706"><a id="calibre_link-215" class="calibre1"></a>Downloading the example code</h2></div></div></div><p class="calibre8">You can download the example code files for this book from your account at <a class="calibre1" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="calibre1" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files emailed directly to you.</p><p class="calibre8">You can download the code files by following these steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Log in or register to our website using your email address and password.</li><li class="listitem" value="2">Hover the mouse pointer on the <span class="strong"><strong class="calibre2">SUPPORT</strong></span> tab at the top.</li><li class="listitem" value="3">Click on <span class="strong"><strong class="calibre2">Code Downloads &amp; Errata</strong></span>.</li><li class="listitem" value="4">Enter the name of the book in the <span class="strong"><strong class="calibre2">Search</strong></span> box.</li><li class="listitem" value="5">Select the book for which you're looking to download the code files.</li><li class="listitem" value="6">Choose from the drop-down menu where you purchased this book from.</li><li class="listitem" value="7">Click on <span class="strong"><strong class="calibre2">Code Download</strong></span>.</li></ol><div class="calibre13"></div></div><p class="calibre8">You can also download the code files by clicking on the <span class="strong"><strong class="calibre2">Code Files button</strong></span> on the book's web page at the Packt Publishing website. This page can be accessed by entering the book's name in the <span class="strong"><strong class="calibre2">Search</strong></span> box. Please note that you need to be logged in to your Packt account.</p><p class="calibre8">Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p><div class="book"><ul class="itemizedlist"><li class="listitem">WinRAR / 7-Zip for Windows</li><li class="listitem">Zipeg / iZip / UnRarX for Mac</li><li class="listitem">7-Zip / PeaZip for Linux</li></ul></div><p class="calibre8">The code bundle for the book is also hosted on GitHub at <a class="calibre1" href="https://github.com/PacktPublishing/Python-Machine-Learning-Second-Edition">https://github.com/PacktPublishing/Python-Machine-Learning-Second-Edition</a>. We also have other code bundles from our rich catalog of books and videos available at <a class="calibre1" href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!
</p></div></div></div>

<div id="calibre_link-493" class="calibre">
<div class="book" title="Customer support" id="calibre_link-707">
<div class="book" title="Downloading the color images of this book"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-708"><a id="calibre_link-216" class="calibre1"></a>Downloading the color images of this book</h2></div></div></div><p class="calibre8">We also provide you with a PDF file that has color images of the screenshots/diagrams used in this book. The color images will help you better understand the changes in the output. You can download this file from <a class="calibre1" href="http://www.packtpub.com/sites/default/files/downloads/PythonMachineLearningSecondEdition_ColorImages.pdf">http://www.packtpub.com/sites/default/files/downloads/PythonMachineLearningSecondEdition_ColorImages.pdf</a>. In addition, lower resolution color images are embedded in the code notebooks of this book that come bundled with the example code files.</p></div></div></div>

<div id="calibre_link-183" class="calibre">
<div class="book" title="Customer support" id="calibre_link-709">
<div class="book" title="Errata"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-710"><a id="calibre_link-217" class="calibre1"></a>Errata</h2></div></div></div><p class="calibre8">Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you find a mistake in one of our books&mdash;maybe a mistake in the text or the code&mdash;we would be grateful if you could report this to us. By doing so, you can save other readers from frustration and help us improve subsequent versions of this book. If you find any errata, please report them by visiting <a class="calibre1" href="http://www.packtpub.com/submit-errata">http://www.packtpub.com/submit-errata</a>, selecting your book, clicking on the <span class="strong"><strong class="calibre2">Errata Submission Form</strong></span> link, and entering the details of your errata. Once your errata are verified, your submission will be accepted and the errata will be uploaded to our website or added to any list of existing errata under the Errata section of that title.</p><p class="calibre8">To view the previously submitted errata, go to <a class="calibre1" href="https://www.packtpub.com/books/content/support">https://www.packtpub.com/books/content/support</a> and enter the name of the book in the search field. The required information will appear under the <span class="strong"><strong class="calibre2">Errata</strong></span> section.</p></div></div></div>

<div id="calibre_link-528" class="calibre">
<div class="book" title="Customer support" id="calibre_link-711">
<div class="book" title="Piracy"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-712"><a id="calibre_link-218" class="calibre1"></a>Piracy</h2></div></div></div><p class="calibre8">Piracy of copyrighted material on the Internet is an ongoing problem across all media. At Packt, we take the protection of our copyright and licenses very seriously. If you come across any illegal copies of our works in any form on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy.</p><p class="calibre8">Please contact us at <code class="email">&lt;<a class="calibre1" href="mailto:copyright@packtpub.com">copyright@packtpub.com</a>&gt;</code> with a link to the suspected pirated material.</p><p class="calibre8">We appreciate your help in protecting our authors and our ability to bring you valuable content.</p></div></div></div>

<div id="calibre_link-189" class="calibre">
<div class="book" title="Customer support" id="calibre_link-713">
<div class="book" title="Questions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-714"><a id="calibre_link-219" class="calibre1"></a>Questions</h2></div></div></div><p class="calibre8">If you have a problem with any aspect of this book, you can contact us at <code class="email">&lt;<a class="calibre1" href="mailto:questions@packtpub.com">questions@packtpub.com</a>&gt;</code>, and we will do our best to address the problem.</p></div></div></div>

<div id="calibre_link-570" class="calibre">
<div id="calibre_link-715" class="calibre10"></div><div class="book" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" id="calibre_link-17"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-716"><a id="calibre_link-717" class="calibre1"></a>Chapter&nbsp;1.&nbsp;Giving Computers the Ability to Learn from Data</h1></div></div></div><p class="calibre8">In my opinion, <span class="strong"><strong class="calibre2">machine learning</strong></span>, the<a id="calibre_link-718" class="calibre1"></a> application and science of algorithms that make sense of data, is the most exciting field of all the computer sciences! We are living in an age where data comes in abundance; using self-learning algorithms from the field of machine learning, we can turn this data into knowledge. Thanks to the many powerful open source libraries that have been developed in recent years, there has probably never been a better time to break into the machine learning field and learn how to utilize powerful algorithms to spot patterns in data and make predictions about future events.</p><p class="calibre8">In this chapter, you will learn about the main concepts and different types of machine learning. Together with a basic introduction to the relevant terminology, we will lay the groundwork for successfully using machine learning techniques for practical problem solving.</p><p class="calibre8">In this chapter, we will cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">The general concepts of machine learning</li><li class="listitem">The three types of learning and basic terminology</li><li class="listitem">The building blocks for successfully designing machine learning systems</li><li class="listitem">Installing and setting up Python for data analysis and machine learning</li></ul></div></div></div>

<div id="calibre_link-196" class="calibre">
<div class="book" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" id="calibre_link-719">
<div class="book" title="Building intelligent machines to transform data into knowledge"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-720"><a id="calibre_link-220" class="calibre1"></a>Building intelligent machines to transform data into knowledge</h1></div></div></div><p class="calibre8">In<a id="calibre_link-721" class="calibre1"></a> this age of modern technology, there is one resource that we have in abundance: a large amount of structured and unstructured data. In the second half of the twentieth century, machine learning evolved as a subfield of <a id="calibre_link-722" class="calibre1"></a>
<span class="strong"><strong class="calibre2">Artificial Intelligence</strong></span> (<span class="strong"><strong class="calibre2">AI</strong></span>) that involved self-learning algorithms that derived knowledge from data in order to make predictions. Instead of requiring humans to manually derive rules and build models from<a id="calibre_link-723" class="calibre1"></a> analyzing large amounts of data, machine learning offers a more efficient alternative for capturing the knowledge in data to gradually improve the performance of predictive models and make data-driven decisions. Not only is machine learning becoming increasingly important in computer science research, but it also plays an ever greater role in our everyday lives. Thanks to machine learning, we enjoy robust email spam filters, convenient text and voice recognition software, reliable web search engines, challenging chess-playing programs, and, hopefully soon, safe and efficient self-driving cars.</p></div></div></div>

<div id="calibre_link-468" class="calibre">
<div id="calibre_link-724" class="calibre10"></div><div class="book" title="The three different types of machine learning"><div class="book" id="calibre_link-70"><div class="book"><div class="book"><h1 class="title" id="calibre_link-725"><a id="calibre_link-726" class="calibre1"></a>The three different types of machine learning</h1></div></div></div><p class="calibre8">In this section, we will <a id="calibre_link-727" class="calibre1"></a>take a look at the three types of <a id="calibre_link-728" class="calibre1"></a>machine learning: <span class="strong"><strong class="calibre2">supervised learning</strong></span>, <span class="strong"><strong class="calibre2">unsupervised learning</strong></span>, and <span class="strong"><strong class="calibre2">reinforcement learning</strong></span>. We will learn about the<a id="calibre_link-729" class="calibre1"></a> fundamental differences between the three different<a id="calibre_link-730" class="calibre1"></a> learning types and, using conceptual examples, we will develop an intuition for the practical problem domains where these can be applied:</p><div class="mediaobject"><img src="images/00498.jpeg" alt="The three different types of machine learning" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-472" class="calibre">
<div class="book" title="The three different types of machine learning">
<div class="book" title="Making predictions about the future with supervised learning"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-731"><a id="calibre_link-221" class="calibre1"></a>Making predictions about the future with supervised learning</h2></div></div></div><p class="calibre8">The main goal in <a id="calibre_link-732" class="calibre1"></a>supervised learning is to learn a model from labeled training data that allows us to make predictions about unseen or future data. Here, the term <span class="strong"><strong class="calibre2">supervised</strong></span> refers to a set of samples where the desired output signals (labels) are already known.</p><div class="mediaobject"><img src="images/00508.jpeg" alt="Making predictions about the future with supervised learning" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Considering the example of email spam filtering, we can train a model using a supervised machine learning algorithm on a corpus of labeled emails, emails that are correctly marked as spam or not-spam, to predict whether a new email belongs to either of the two categories. A supervised learning task with discrete class labels, such as in the previous email spam filtering example, is also called <a id="calibre_link-733" class="calibre1"></a>a <span class="strong"><strong class="calibre2">classification task</strong></span>. Another subcategory of supervised learning<a id="calibre_link-734" class="calibre1"></a> is <span class="strong"><strong class="calibre2">regression</strong></span>, where the outcome signal is a continuous value:</p><div class="book" title="Classification for predicting class labels"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-222" class="calibre1"></a>Classification for predicting class labels</h3></div></div></div><p class="calibre8">Classification is a<a id="calibre_link-735" class="calibre1"></a> subcategory of supervised learning where the goal is to predict the categorical class labels of new instances, based on past observations. Those class labels are discrete, unordered values that can be understood as the group memberships of the instances. The previously mentioned example of email spam detection represents a typical example of a binary classification task, where the machine learning algorithm learns a set of rules in order to distinguish between two possible classes: spam and non-spam emails.</p><p class="calibre8">However, the set of <a id="calibre_link-736" class="calibre1"></a>class labels does not have to be of a binary nature. The predictive model learned by a supervised learning algorithm can assign any class label that was presented in the training dataset to a new, unlabeled instance. A typical<a id="calibre_link-737" class="calibre1"></a> example of a <span class="strong"><strong class="calibre2">multiclass classification</strong></span> task is handwritten character recognition. Here, we could collect a training dataset that consists of multiple handwritten examples of each letter in the alphabet. Now, if a user provides a new handwritten character via an input device, our predictive model will be able to predict the correct letter in the alphabet with certain accuracy. However, our machine learning system would be unable to correctly recognize any of the digits zero to nine, for example, if they were not part of our training dataset.</p><p class="calibre8">The following figure illustrates the concept of a binary classification task given 30 training samples; 15 training samples are labeled as negative class (minus signs) and 15 training samples are labeled as positive class (plus signs). In this scenario, our dataset is two-dimensional, which means that each sample has two values associated with it: <span class="strong"><img src="images/00519.jpeg" alt="Classification for predicting class labels" class="calibre14" /></span> and <span class="strong"><img src="images/00531.jpeg" alt="Classification for predicting class labels" class="calibre14" /></span>. Now, we can use a supervised machine learning algorithm to learn a rule&mdash;the decision boundary represented as a dashed line&mdash;that can separate those two classes and classify new data into each of those two categories given its <span class="strong"><img src="images/00519.jpeg" alt="Classification for predicting class labels" class="calibre14" /></span> and <span class="strong"><img src="images/00531.jpeg" alt="Classification for predicting class labels" class="calibre14" /></span> values:</p><div class="mediaobject"><img src="images/00542.jpeg" alt="Classification for predicting class labels" class="calibre11" /></div><p class="calibre12"> </p></div><div class="book" title="Regression for predicting continuous outcomes"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-223" class="calibre1"></a>Regression for predicting continuous outcomes</h3></div></div></div><p class="calibre8">We learned in the <a id="calibre_link-738" class="calibre1"></a>previous section that the task of classification is to assign categorical, unordered labels to instances. A second type of supervised learning is the prediction of continuous outcomes, which is also <a id="calibre_link-739" class="calibre1"></a>called <span class="strong"><strong class="calibre2">regression analysis</strong></span>. In regression analysis, we are given a number of predictor (<span class="strong"><strong class="calibre2">explanatory</strong></span>) variables and a continuous response variable (<span class="strong"><strong class="calibre2">outcome</strong></span> or <span class="strong"><strong class="calibre2">target</strong></span>), and we try to find a relationship between those variables that allows us to predict an outcome.</p><p class="calibre8">For example, let's assume that we are interested in predicting the math SAT scores of our students. If there is a relationship between the time spent studying for the test and the final scores, we could use it as training data to learn a model that uses the study time to predict the test scores of future students who are planning to take this test.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-740" class="calibre1"></a>Note</h3><p class="calibre8">The term <span class="strong"><em class="calibre9">regression</em></span> was devised by Francis Galton in his article <span class="strong"><em class="calibre9">Regression towards Mediocrity in Hereditary Stature</em></span> in 1886. Galton described the biological phenomenon that the variance of height in a population does not increase over time. He observed that the height of parents is not passed on to their children, but instead the children's height is regressing towards the population mean.</p></div><p class="calibre8">The following<a id="calibre_link-741" class="calibre1"></a> figure illustrates the concept of linear regression. Given a predictor variable <span class="strong"><em class="calibre9">x</em></span> and a response variable <span class="strong"><em class="calibre9">y</em></span>, we fit a straight line to this data that<a id="calibre_link-742" class="calibre1"></a> minimizes the distance&mdash;most commonly the average squared distance&mdash;between the sample points and the fitted line. We can now use the intercept and slope learned from this data to predict the outcome variable of new data:</p><div class="mediaobject"><img src="images/00549.jpeg" alt="Regression for predicting continuous outcomes" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-477" class="calibre">
<div class="book" title="The three different types of machine learning">
<div class="book" title="Solving interactive problems with reinforcement learning"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-743"><a id="calibre_link-224" class="calibre1"></a>Solving interactive problems with reinforcement learning</h2></div></div></div><p class="calibre8">Another type of machine learning <a id="calibre_link-744" class="calibre1"></a>is <span class="strong"><strong class="calibre2">reinforcement learning</strong></span>. In reinforcement<a id="calibre_link-745" class="calibre1"></a> learning, the <a id="calibre_link-746" class="calibre1"></a>goal is to develop a system (<span class="strong"><strong class="calibre2">agent</strong></span>) that improves its performance based on interactions with the environment. Since the information about the current state of the environment typically also includes a so-<a id="calibre_link-747" class="calibre1"></a>called <span class="strong"><strong class="calibre2">reward signal</strong></span>, we can think of reinforcement learning as a field related to supervised learning. However, in reinforcement learning this feedback is not the correct ground truth label or value, but a measure of how well the action was measured by a reward function. Through its interaction with the environment, an agent can then use reinforcement learning to learn a series of actions that maximizes this reward via an exploratory trial-and-error approach or deliberative planning.</p><p class="calibre8">A popular <a id="calibre_link-748" class="calibre1"></a>example of reinforcement<a id="calibre_link-749" class="calibre1"></a> learning is a chess engine. Here, the agent decides upon a series of moves depending on the state of the board (the environment), and the reward can be defined as <span class="strong"><strong class="calibre2">win</strong></span> or <span class="strong"><strong class="calibre2">lose</strong></span> at the end of the game:</p><div class="mediaobject"><img src="images/00562.jpeg" alt="Solving interactive problems with reinforcement learning" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">There are many different subtypes of reinforcement learning. However, a general scheme is that the agent in reinforcement learning tries to maximize the reward by a series of interactions with the environment. Each state can be associated with a positive or negative reward, and a reward can be defined as accomplishing an overall goal, such as winning or losing a game of chess. For instance, in chess the outcome of each move can be thought of as a different state of the environment. To explore the chess example further, let's think of visiting certain locations on the chess board as being associated with a positive event&mdash;for instance, removing an opponent's chess piece from the board or threatening the queen. Other positions, however, are associated with a negative event, such as losing a chess piece to the opponent in the following turn. Now, not every turn results in the removal of a chess piece, and reinforcement learning is concerned with learning the series of steps by maximizing a reward based on immediate and delayed feedback.</p><p class="calibre8">While this section provides a basic overview of reinforcement learning, please note that applications of reinforcement learning are beyond the scope of this book, which primarily focusses on classification, regression analysis, and clustering.</p></div></div></div>

<div id="calibre_link-661" class="calibre">
<div class="book" title="The three different types of machine learning">
<div class="book" title="Discovering hidden structures with unsupervised learning"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-750"><a id="calibre_link-225" class="calibre1"></a>Discovering hidden structures with unsupervised learning</h2></div></div></div><p class="calibre8">In<a id="calibre_link-751" class="calibre1"></a> supervised<a id="calibre_link-752" class="calibre1"></a> learning, we know the right answer beforehand when we train our model, and in reinforcement learning, we define a measure of reward for particular actions by the agent. In unsupervised learning, however, we are dealing with unlabeled data or data of unknown structure. Using unsupervised learning techniques, we are able to explore the structure of our data to extract meaningful information without the guidance of a known outcome variable or reward function.</p><div class="book" title="Finding subgroups with clustering"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-226" class="calibre1"></a>Finding subgroups with clustering</h3></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Clustering</strong></span> is an <a id="calibre_link-753" class="calibre1"></a>exploratory data analysis technique that allows us to organize a pile of <a id="calibre_link-754" class="calibre1"></a>information into meaningful<a id="calibre_link-755" class="calibre1"></a> subgroups (<span class="strong"><strong class="calibre2">clusters</strong></span>) without having any prior knowledge of their group <a id="calibre_link-756" class="calibre1"></a>memberships. Each cluster that arises during the analysis defines a group of objects that share a certain degree of similarity but are more dissimilar to objects in other clusters, which is why clustering is also sometimes <a id="calibre_link-757" class="calibre1"></a>called <span class="strong"><strong class="calibre2">unsupervised classification</strong></span>. Clustering is a great technique for structuring information and deriving meaningful relationships from data. For example, it allows marketers to discover customer groups based on their interests, in order to develop distinct marketing programs.</p><p class="calibre8">The following figure illustrates how clustering can be applied to organizing unlabeled data into three distinct groups based on the similarity of their features <span class="strong"><img src="images/00519.jpeg" alt="Finding subgroups with clustering" class="calibre14" /></span> and <span class="strong"><img src="images/00531.jpeg" alt="Finding subgroups with clustering" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00576.jpeg" alt="Finding subgroups with clustering" class="calibre11" /></div><p class="calibre12"> </p></div><div class="book" title="Dimensionality reduction for data compression"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-227" class="calibre1"></a>Dimensionality reduction for data compression</h3></div></div></div><p class="calibre8">Another subfield of unsupervised <a id="calibre_link-758" class="calibre1"></a>learning is <span class="strong"><strong class="calibre2">dimensionality reduction</strong></span>. Often we are working with data of high dimensionality&mdash;each observation comes with a high number of measurements&mdash;that can present a challenge for limited storage space and the computational performance of machine learning algorithms. Unsupervised <a id="calibre_link-759" class="calibre1"></a>dimensionality reduction is a commonly used approach in feature preprocessing to remove noise from data, which can also degrade the predictive performance of certain algorithms, and compress the data onto a smaller dimensional subspace while retaining most of the relevant information.</p><p class="calibre8">Sometimes, dimensionality reduction can also be useful for visualizing data, for example, a high-dimensional feature set can be projected onto one-, two-, or three-dimensional feature spaces in order to visualize it via 3D or 2D scatterplots or histograms. The following figure shows an example where nonlinear dimensionality reduction was applied to compress a 3D Swiss Roll onto a new 2D feature subspace:</p><div class="mediaobject"><img src="images/00589.jpeg" alt="Dimensionality reduction for data compression" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-487" class="calibre"><div class="book" title="Introduction to the basic terminology and notations" id="calibre_link-228"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-760"><a id="calibre_link-761" class="calibre1"></a>Introduction to the basic terminology and notations</h1></div></div></div><p class="calibre8">Now that we have discussed the three broad categories of machine<a id="calibre_link-762" class="calibre1"></a> learning&mdash;supervised, unsupervised, and reinforcement learning&mdash;let us have a look at the basic<a id="calibre_link-763" class="calibre1"></a> terminology that we will be using throughout the book. The following table depicts an excerpt of the Iris dataset, which is a classic example in the field of machine learning. The Iris dataset contains the measurements of 150 Iris flowers from three different species&mdash;Setosa, Versicolor, and Virginica. Here, each flower sample represents one row in our dataset, and the flower measurements in centimeters are stored as columns, which we also call the <span class="strong"><strong class="calibre2">features</strong></span> of the dataset:</p><div class="mediaobject"><img src="images/00597.jpeg" alt="Introduction to the basic terminology and notations" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To keep the<a id="calibre_link-764" class="calibre1"></a> notation and implementation simple yet efficient, we <a id="calibre_link-765" class="calibre1"></a>will make use of some of the basics of linear algebra. In the following chapters, we will use a matrix and vector notation to refer to our data. We will follow the common convention to represent each sample as a separate row in a feature matrix <span class="strong"><strong class="calibre2">X</strong></span>, where each feature is stored as a separate column.</p><p class="calibre8">The Iris dataset consisting of 150 samples and four features can then be written as a <span class="strong"><img src="images/00609.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span> matrix <span class="strong"><img src="images/00622.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00657.jpeg" alt="Introduction to the basic terminology and notations" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-766" class="calibre1"></a>Note</h3><p class="calibre8">For the rest of this book, unless noted otherwise, we will use the superscript <span class="strong"><em class="calibre9">i</em></span> to refer to the <span class="strong"><em class="calibre9">i</em></span>th training sample, and the subscript <span class="strong"><em class="calibre9">j</em></span> to refer to the <span class="strong"><em class="calibre9">j</em></span>th dimension of the training dataset.</p><p class="calibre8">We use lowercase, bold-face letters to refer to vectors <span class="strong"><img src="images/00673.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span> and uppercase, bold-face letters to refer to matrices <span class="strong"><img src="images/00691.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span>. To refer to single elements in a vector or matrix, we write the letters in italics (<span class="strong"><img src="images/00699.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span> or <span class="strong"><img src="images/00710.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span> , respectively).</p><p class="calibre8">For example, <span class="strong"><img src="images/00720.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span> refers to the first dimension of flower sample 150, the <span class="strong"><em class="calibre9">sepal length</em></span>. Thus, each row in this feature matrix represents one flower instance and can be written as a four-dimensional row vector <span class="strong"><img src="images/00732.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span>:</p><div class="mediaobject1"><img src="images/00740.jpeg" alt="Introduction to the basic terminology and notations" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">And each feature dimension is a 150-dimensional column vector <span class="strong"><img src="images/00753.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span>. For example:</p><div class="mediaobject1"><img src="images/00768.jpeg" alt="Introduction to the basic terminology and notations" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similarly, we store the target variables (here, class labels) as a 150-dimensional column vector:
<span class="strong"><img src="images/00779.jpeg" alt="Introduction to the basic terminology and notations" class="calibre14" /></span>
</p></div></div></div>

<div id="calibre_link-500" class="calibre">
<div id="calibre_link-767" class="calibre10"></div><div class="book" title="A roadmap for building machine learning systems" id="calibre_link-229"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-768"><a id="calibre_link-769" class="calibre1"></a>A roadmap for building machine learning systems</h1></div></div></div><p class="calibre8">In previous sections, we <a id="calibre_link-770" class="calibre1"></a>discussed the basic concepts of machine learning and the three different types of learning. In this section, we will discuss the other important parts of a machine learning system accompanying the learning algorithm. The following diagram shows a typical workflow for using machine learning in predictive modeling, which we will discuss in the following subsections:</p><div class="mediaobject"><img src="images/00788.jpeg" alt="A roadmap for building machine learning systems" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-505" class="calibre">
<div class="book" title="A roadmap for building machine learning systems" id="calibre_link-771">
<div class="book" title="Preprocessing â getting data into shape"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-772"><a id="calibre_link-230" class="calibre1"></a>Preprocessing &ndash; getting data into shape</h2></div></div></div><p class="calibre8">Let's begin with discussing the roadmap for building machine learning systems. Raw data rarely comes in the<a id="calibre_link-773" class="calibre1"></a> form and shape that is necessary for the optimal performance of a learning algorithm. Thus, the preprocessing of the data is one of the most crucial steps in any machine learning application. If we take the Iris flower dataset from the previous section as an example, we can think of the raw data as a series of flower images from which we want to extract meaningful features. Useful features could be the color, the hue, the intensity of the flowers, the height, and the flower lengths and widths. Many machine learning algorithms also require that the selected features are on the same scale for optimal performance, which is often achieved by transforming the features in the range [0, 1] or a standard normal distribution with zero mean and unit variance, as we will see in later chapters.</p><p class="calibre8">Some of the selected features may be highly correlated and therefore redundant to a certain degree. In those cases, dimensionality reduction techniques are useful for compressing the features onto a lower dimensional subspace. Reducing the dimensionality of our feature space has the advantage that less storage space is required, and the learning algorithm can run much faster. In certain cases, dimensionality reduction can also improve the predictive performance of a model if the dataset contains a large number of irrelevant features (or noise), that is, if the dataset has a low signal-to-noise ratio.</p><p class="calibre8">To determine whether our machine learning algorithm not only performs well on the training set but also generalizes well to new data, we also want to randomly divide the dataset into a separate training and test set. We use the training set to train and optimize our machine learning model, while we keep the test set until the very end to evaluate the final model.</p></div></div></div>

<div id="calibre_link-605" class="calibre">
<div class="book" title="A roadmap for building machine learning systems" id="calibre_link-774">
<div class="book" title="Training and selecting a predictive model"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-775"><a id="calibre_link-231" class="calibre1"></a>Training and selecting a predictive model</h2></div></div></div><p class="calibre8">As we will see in <a id="calibre_link-776" class="calibre1"></a>later chapters, many different machine learning algorithms<a id="calibre_link-777" class="calibre1"></a> have been developed to solve different problem tasks. An important point that can be summarized from David Wolpert's famous <span class="strong"><em class="calibre9">No free lunch theorems</em></span> is that we can't get learning "for free" (<span class="strong"><em class="calibre9">The Lack of A Priori Distinctions Between Learning Algorithms</em></span>, D.H. Wolpert 1996; <span class="strong"><em class="calibre9">No free lunch theorems for optimization</em></span>, D.H. Wolpert and W.G. Macready, 1997). Intuitively, we can relate this concept to the popular saying, <span class="strong"><em class="calibre9">I suppose it is tempting, if the only tool you have is a hammer, to treat everything as if it were a nail</em></span> (Abraham Maslow, 1966). For example, each classification algorithm has its inherent biases, and no single classification model enjoys superiority if we don't make any assumptions about the task. In practice, it is therefore essential to compare at least a handful of different algorithms in order to train and select the best performing model. But before we can compare different models, we first have to decide upon a metric to measure performance. One commonly used metric is classification accuracy, which is defined as the proportion of correctly classified instances.</p><p class="calibre8">One legitimate question to ask is this: <span class="strong"><em class="calibre9">how do we know which model performs well on the final test dataset and real-world data if we don't use this test set for the model selection, but keep it for the final model evaluation?</em></span> In order to address the issue embedded in this question, different cross-validation techniques can be used where the training dataset is further divided into training and validation subsets in order to estimate the generalization performance of the model. Finally, we also cannot expect that the default parameters of the different learning algorithms provided by software libraries are optimal for our specific problem task. Therefore, we will make frequent use of hyperparameter optimization techniques that help us to fine-tune the performance of our model in later chapters. Intuitively, we can think of those hyperparameters as parameters that are not learned from the data but represent the knobs of a model that we can turn to improve its performance. This will become much clearer in later chapters when we see actual examples.</p></div></div></div>

<div id="calibre_link-620" class="calibre">
<div class="book" title="A roadmap for building machine learning systems" id="calibre_link-778">
<div class="book" title="Evaluating models and predicting unseen data instances"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-779"><a id="calibre_link-232" class="calibre1"></a>Evaluating models and predicting unseen data instances</h2></div></div></div><p class="calibre8">After we have selected a <a id="calibre_link-780" class="calibre1"></a>model that has been fitted on the training dataset, we can use the test <a id="calibre_link-781" class="calibre1"></a>dataset to estimate how well it performs on this unseen data to estimate the generalization error. If we are satisfied with its performance, we can now use this model to predict new, future data. It is important to note that the parameters for the previously mentioned procedures, such as feature scaling and dimensionality reduction, are solely obtained from the training dataset, and the same parameters are later reapplied to transform the test dataset, as well as any new data samples&mdash;the performance measured on the test data may be overly optimistic otherwise.</p></div></div></div>

<div id="calibre_link-21" class="calibre">
<div id="calibre_link-782" class="calibre10"></div><div class="book" title="Using Python for machine learning" id="calibre_link-15"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-783"><a id="calibre_link-784" class="calibre1"></a>Using Python for machine learning</h1></div></div></div><p class="calibre8">Python is <a id="calibre_link-785" class="calibre1"></a>one of the most popular programming languages for data science and therefore enjoys a large number of useful add-on libraries developed by its great developer and and open-source community.</p><p class="calibre8">Although the<a id="calibre_link-786" class="calibre1"></a> performance of interpreted languages, such as Python, for <a id="calibre_link-787" class="calibre1"></a>computation-intensive tasks is inferior to lower-level programming languages, extension libraries such as NumPy and SciPy have been developed that build upon lower-layer Fortran and C implementations for fast and vectorized operations on multidimensional arrays.</p><p class="calibre8">For machine learning programming tasks, we will mostly refer to the scikit-learn library, which is currently one of the most popular and accessible open source machine learning libraries.</p></div></div>

<div id="calibre_link-519" class="calibre">
<div class="book" title="Using Python for machine learning" id="calibre_link-788">
<div class="book" title="Installing Python and packages from the Python Package Index"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-789"><a id="calibre_link-233" class="calibre1"></a>Installing Python and packages from the Python Package Index</h2></div></div></div><p class="calibre8">Python is available for all three major operating systems&mdash;Microsoft Windows, macOS, and Linux&mdash;and the installer, as well as the documentation, can be downloaded from the official Python<a id="calibre_link-790" class="calibre1"></a> website: <a class="calibre1" href="https://www.python.org">https://www.python.org</a>.</p><p class="calibre8">This book is written for Python<a id="calibre_link-791" class="calibre1"></a> version 3.5.2 or higher, and it is recommended you use the most recent version of Python 3 that is currently available, although most of the code examples may also be compatible with Python 2.7.13 or higher. If you decide to use Python 2.7 to execute the code examples, please make sure that you know about the major differences between the two Python versions. A good summary of the differences between Python 3.5 and 2.7 can be <a id="calibre_link-792" class="calibre1"></a>found at <a class="calibre1" href="https://wiki.python.org/moin/Python2orPython3">https://wiki.python.org/moin/Python2orPython3</a>.</p><p class="calibre8">The additional packages that we will be using throughout this book can be installed via the <code class="email">pip</code> installer program, which has been part of the Python standard library since Python 3.3. More<a id="calibre_link-793" class="calibre1"></a> information about <code class="email">pip</code> can be found at <a class="calibre1" href="https://docs.python.org/3/installing/index.html">https://docs.python.org/3/installing/index.html</a>.</p><p class="calibre8">After we have successfully<a id="calibre_link-794" class="calibre1"></a> installed Python, we can<a id="calibre_link-795" class="calibre1"></a> execute <code class="email">pip</code> from the Terminal to install additional Python packages:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip install SomePackage</strong></span>
</pre></div><p class="calibre8">Already installed packages can be updated via the <code class="email">--upgrade</code> flag:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip install SomePackage --upgrade</strong></span>
</pre></div></div></div></div>

<div id="calibre_link-521" class="calibre">
<div class="book" title="Using Python for machine learning" id="calibre_link-796">
<div class="book" title="Using the Anaconda Python distribution and package manager"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-797"><a id="calibre_link-234" class="calibre1"></a>Using the Anaconda Python distribution and package manager</h2></div></div></div><p class="calibre8">A highly recommended <a id="calibre_link-798" class="calibre1"></a>alternative Python distribution for scientific computing is Anaconda by Continuum Analytics. Anaconda is a free&mdash;including for commercial use&mdash;enterprise-ready Python distribution that bundles all the essential Python packages for data science, math, and engineering in one user-friendly cross-platform distribution. The Anaconda installer<a id="calibre_link-799" class="calibre1"></a> can be downloaded at <a class="calibre1" href="http://continuum.io/downloads">http://continuum.io/downloads</a>, and an Anaconda<a id="calibre_link-800" class="calibre1"></a> quick-start guide is available at <a class="calibre1" href="https://conda.io/docs/test-drive.html">https://conda.io/docs/test-drive.html</a>.</p><p class="calibre8">After successfully installing Anaconda, we can install new Python packages using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">conda install SomePackage</strong></span>
</pre></div><p class="calibre8">Existing packages can be updated using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">conda update SomePackage</strong></span>
</pre></div></div></div></div>

<div id="calibre_link-552" class="calibre">
<div class="book" title="Using Python for machine learning" id="calibre_link-801">
<div class="book" title="Packages for scientific computing, data science, and machine learning"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-802"><a id="calibre_link-235" class="calibre1"></a>Packages for scientific computing, data science, and machine learning</h2></div></div></div><p class="calibre8">Throughout this book, we<a id="calibre_link-803" class="calibre1"></a> will mainly use NumPy's multidimensional arrays to<a id="calibre_link-804" class="calibre1"></a> store and manipulate data. Occasionally, we will <a id="calibre_link-805" class="calibre1"></a>make use of pandas, which is a library built on top of NumPy that provides additional higher-level data manipulation tools that make working with tabular data even more convenient. To augment our learning experience and visualize quantitative data, which is often extremely useful to intuitively make sense of it, we will use the very customizable Matplotlib library.</p><p class="calibre8">The version numbers of the major Python packages that were used for writing this book are mentioned in the following list. Please make sure that the version numbers of your installed packages are equal to, or<a id="calibre_link-806" class="calibre1"></a> greater than, those <a id="calibre_link-807" class="calibre1"></a>version numbers to ensure the <a id="calibre_link-808" class="calibre1"></a>code examples run correctly:</p><div class="book"><ul class="itemizedlist"><li class="listitem">NumPy 1.12.1</li><li class="listitem">SciPy 0.19.0</li><li class="listitem">scikit-learn 0.18.1</li><li class="listitem">Matplotlib 2.0.2</li><li class="listitem">pandas 0.20.1</li></ul></div></div></div></div>

<div id="calibre_link-580" class="calibre"><div class="book" title="Summary" id="calibre_link-236"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-809"><a id="calibre_link-810" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, we explored machine learning at a very high level and familiarized ourselves with the big picture and major concepts that we are going to explore in the following chapters in more detail. We learned that supervised learning is composed of two important subfields: classification and regression. While classification models allow us to categorize objects into known classes, we can use regression analysis to predict the continuous outcomes of target variables. Unsupervised learning not only offers useful techniques for discovering structures in unlabeled data, but it can also be useful for data compression in feature preprocessing steps. We briefly went over the typical roadmap for applying machine learning to problem tasks, which we will use as a foundation for deeper discussions and hands-on examples in the following chapters. Eventually, we set up our Python environment and installed and updated the required packages to get ready to see machine learning in action.</p><p class="calibre8">Later in this book, in addition to machine learning itself, we will also introduce different techniques to preprocess our dataset, which will help us to get the best performance out of different machine learning algorithms. While we will cover classification algorithms quite extensively throughout the book, we will also explore different techniques for regression analysis and clustering.</p><p class="calibre8">We have an exciting journey ahead, covering many powerful techniques in the vast field of machine learning. However, we will approach machine learning one step at a time, building upon our knowledge gradually throughout the chapters of this book. In the following chapter, we will start this journey by implementing one of the earliest machine learning algorithms for classification, which will prepare us for <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, where we cover more advanced machine learning algorithms using the scikit-learn open source machine learning library.</p></div></div>

<div id="calibre_link-530" class="calibre">
<div id="calibre_link-811" class="calibre10"></div><div class="book" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification"><div class="book" id="calibre_link-19"><div class="book"><div class="book"><h1 class="title" id="calibre_link-812"><a id="calibre_link-813" class="calibre1"></a>Chapter&nbsp;2.&nbsp;Training Simple Machine Learning Algorithms for Classification</h1></div></div></div><p class="calibre8">In this chapter, we will make use of two of the first algorithmically described machine learning algorithms for classification, the perceptron and adaptive linear neurons. We will start by implementing a perceptron step by step in Python and training it to classify different flower species in the Iris dataset. This will help us understand the concept of machine learning algorithms for classification and how they can be efficiently implemented in Python.</p><p class="calibre8">Discussing the basics of optimization using adaptive linear neurons will then lay the groundwork for using more powerful classifiers via the scikit-learn machine learning library in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>.</p><p class="calibre8">The topics that we will cover in this chapter are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Building an intuition for machine learning algorithms</li><li class="listitem">Using pandas, NumPy, and Matplotlib to read in, process, and visualize data</li><li class="listitem">Implementing linear classification algorithms in Python</li></ul></div></div></div>

<div id="calibre_link-534" class="calibre">
<div class="book" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification">
<div class="book" title="Artificial neurons â a brief glimpse into the early history of machine learning"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-814"><a id="calibre_link-237" class="calibre1"></a>Artificial neurons &ndash; a brief glimpse into the early history of machine learning</h1></div></div></div><p class="calibre8">Before we discuss the<a id="calibre_link-815" class="calibre1"></a> perceptron and related algorithms in more detail, let us take a brief tour through the early beginnings of machine learning. Trying to understand how the biological brain works, in order to design AI, Warren McCullock and Walter Pitts published the first concept of a simplified brain cell, the<a id="calibre_link-816" class="calibre1"></a> so-called <span class="strong"><strong class="calibre2">McCullock-Pitts</strong></span> (<span class="strong"><strong class="calibre2">MCP</strong></span>) neuron, in 1943 (<span class="strong"><em class="calibre9">A Logical Calculus of the Ideas Immanent in Nervous Activity</em></span>, <span class="strong"><em class="calibre9">W. S. McCulloch</em></span> and <span class="strong"><em class="calibre9">W. Pitts</em></span>, <span class="strong"><em class="calibre9">Bulletin of Mathematical Biophysics</em></span>, 5(4): 115-133, <span class="strong"><em class="calibre9">1943</em></span>). Neurons are interconnected nerve<a id="calibre_link-817" class="calibre1"></a> cells in the brain that are involved in the processing and transmitting of chemical and electrical signals, which is illustrated in the following figure:</p><div class="mediaobject"><img src="images/00798.jpeg" alt="Artificial neurons â a brief glimpse into the early history of machine learning" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">McCullock and Pitts <a id="calibre_link-818" class="calibre1"></a>described such a nerve cell as a simple logic gate with binary outputs; multiple signals arrive at the dendrites, are then integrated into the cell body, and, if the accumulated signal exceeds a certain threshold, an output signal is generated that will be passed on by the axon.</p><p class="calibre8">Only a few years later, Frank Rosenblatt published the first concept of the perceptron learning rule based on the MCP neuron model (<span class="strong"><em class="calibre9">The Perceptron: A Perceiving and Recognizing Automaton</em></span>, <span class="strong"><em class="calibre9">F. Rosenblatt</em></span>, <span class="strong"><em class="calibre9">Cornell Aeronautical Laboratory</em></span>, <span class="strong"><em class="calibre9">1957</em></span>). With his perceptron rule, Rosenblatt proposed an algorithm that would automatically learn the optimal weight coefficients that are then multiplied with the input features in order to make the decision of whether a neuron fires or not. In the context of supervised learning and classification, such an algorithm could then be used to predict if a sample belongs to one class or the other.</p></div></div></div>

<div id="calibre_link-536" class="calibre">
<div class="book" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification">
<div class="book" title="Artificial neurons â a brief glimpse into the early history of machine learning">
<div class="book" title="The formal definition of an artificial neuron"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-819"><a id="calibre_link-238" class="calibre1"></a>The formal definition of an artificial neuron</h2></div></div></div><p class="calibre8">More formally, we can put the idea<a id="calibre_link-820" class="calibre1"></a> behind <span class="strong"><strong class="calibre2">artificial neurons</strong></span> into the context of a binary classification task where we refer to our two classes as 1 (positive class) and -1 (negative class) for simplicity. We can then define a decision function (<span class="strong"><img src="images/00815.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span>) that takes a linear combination of certain input values <span class="strong"><strong class="calibre2">x</strong></span> and a corresponding weight vector <span class="strong"><strong class="calibre2">w</strong></span>, where z is the so-called net input <span class="strong"><img src="images/00828.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00839.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, if the net input of a particular <a id="calibre_link-821" class="calibre1"></a>sample <span class="strong"><img src="images/00850.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span> is greater than a defined threshold <span class="strong"><img src="images/00866.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span>, we predict class <span class="strong"><em class="calibre9">1</em></span>, and class <span class="strong"><em class="calibre9">-1</em></span> otherwise. In the perceptron algorithm, the decision function <span class="strong"><img src="images/00879.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span> is a variant<a id="calibre_link-822" class="calibre1"></a> of a <span class="strong"><strong class="calibre2">unit step function</strong></span>:</p><div class="mediaobject"><img src="images/00899.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">For simplicity, we can bring the threshold <span class="strong"><img src="images/00866.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span> to the left side of the equation and define a weight-zero as <span class="strong"><img src="images/00907.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span> and <span class="strong"><img src="images/00920.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span> so that we write z in a more compact form:</p><div class="mediaobject"><img src="images/00939.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">And:</p><div class="mediaobject"><img src="images/00954.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In machine learning literature, the negative threshold, or weight, <span class="strong"><img src="images/00907.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span>, is usually called the<a id="calibre_link-823" class="calibre1"></a> <span class="strong"><strong class="calibre2">bias unit</strong></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-824" class="calibre1"></a>Note</h3><p class="calibre8">In the following sections, we will often make use of basic notations from linear algebra. For example, we will abbreviate the sum of the products of the values in <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">w</strong></span> using a vector dot product, whereas superscript <span class="strong"><em class="calibre9"><sup class="calibre15">T</sup></em></span> stands for<a id="calibre_link-825" class="calibre1"></a> <span class="strong"><strong class="calibre2">transpose</strong></span>, which is an operation that transforms a column vector into a row vector and vice versa:</p><div class="mediaobject1"><img src="images/00633.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">For example:</p><div class="mediaobject1"><img src="images/00647.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Furthermore, the transpose operation can also be applied to matrices to reflect it over its diagonal, for example:</p><div class="mediaobject1"><img src="images/00470.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In this book, we will only use very basic concepts from linear algebra; however, if you need a quick refresher, please take a look at Zico Kolter's excellent <span class="strong"><em class="calibre9">Linear Algebra Review and Reference</em></span>, which is <a id="calibre_link-826" class="calibre1"></a>freely available at <a class="calibre1" href="http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf">http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf</a>.</p></div><p class="calibre8">The following figure illustrates how the net input <span class="strong"><img src="images/00492.jpeg" alt="The formal definition of an artificial neuron" class="calibre14" /></span> is squashed into a binary output (<code class="email">-1</code> or <code class="email">1</code>) by the decision function of the perceptron (left subfigure) and how it can be used to discriminate between two linearly separable classes (right subfigure):</p><div class="mediaobject"><img src="images/00499.jpeg" alt="The formal definition of an artificial neuron" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-538" class="calibre">
<div class="book" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification">
<div class="book" title="Artificial neurons â a brief glimpse into the early history of machine learning">
<div class="book" title="The perceptron learning rule"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-827"><a id="calibre_link-239" class="calibre1"></a>The perceptron learning rule</h2></div></div></div><p class="calibre8">The whole idea behind the MCP<a id="calibre_link-828" class="calibre1"></a> neuron and Rosenblatt's <span class="strong"><em class="calibre9">thresholded</em></span> perceptron model is to use a reductionist approach to mimic how a single neuron in the brain works: it either <span class="strong"><em class="calibre9">fires</em></span> or it doesn't. Thus, Rosenblatt's initial perceptron rule is fairly simple and can be summarized by the following steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Initialize the weights to 0 or small random numbers.</li><li class="listitem" value="2">
For each training sample <span class="strong"><img src="images/00850.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>:
a. Compute the output value <span class="strong"><img src="images/00509.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>.
b. Update the weights.</li></ol><div class="calibre13"></div></div><p class="calibre8">Here, the output value is the class<a id="calibre_link-829" class="calibre1"></a> label predicted by the unit step function that we defined earlier, and the simultaneous update of each weight <span class="strong"><img src="images/00520.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> in the weight vector <span class="strong"><strong class="calibre2">w</strong></span> can be more formally written as:</p><div class="mediaobject"><img src="images/00532.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The value of <span class="strong"><img src="images/00543.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>, which is used to update the weight <span class="strong"><img src="images/00520.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>, is calculated by the perceptron learning rule:</p><div class="mediaobject"><img src="images/00550.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Where <span class="strong"><img src="images/00563.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> is the <span class="strong"><strong class="calibre2">learning rate</strong></span> (typically a constant between 0.0 and 1.0), <span class="strong"><img src="images/00575.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> is the <span class="strong"><strong class="calibre2">true class label</strong></span> of<a id="calibre_link-830" class="calibre1"></a> the <span class="strong"><em class="calibre9">i</em></span>th <a id="calibre_link-831" class="calibre1"></a>training sample, and <span class="strong"><img src="images/00590.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> is the <span class="strong"><strong class="calibre2">predicted class label</strong></span>. It is<a id="calibre_link-832" class="calibre1"></a> important to note that all weights in the weight vector are being updated simultaneously, which means that we don't recompute the <span class="strong"><img src="images/00590.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> before all of the weights <span class="strong"><img src="images/00543.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> are updated. Concretely, for a two-dimensional dataset, we would write the update as:</p><div class="mediaobject"><img src="images/00598.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00610.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00621.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Before we implement the <a id="calibre_link-833" class="calibre1"></a>perceptron rule in Python, let us make a simple thought experiment to illustrate how beautifully simple this learning rule really is. In the two scenarios where the perceptron predicts the class label correctly, the weights remain unchanged:</p><div class="mediaobject"><img src="images/00634.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00648.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, in the case of a wrong prediction, the weights are being pushed towards the direction of the positive or negative target class:</p><div class="mediaobject"><img src="images/00658.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00672.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To get a better intuition for the <a id="calibre_link-834" class="calibre1"></a>multiplicative factor <span class="strong"><img src="images/00328.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>, let us go through another simple example, where:</p><div class="mediaobject"><img src="images/00700.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's assume that <span class="strong"><img src="images/00711.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>, and we misclassify this sample as <span class="strong"><em class="calibre9">-1</em></span>. In this case, we would increase the corresponding weight by 1 so that the net input <span class="strong"><img src="images/00719.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> would be more positive the next time we encounter this sample, and thus be more likely to be above the threshold of the unit step function to classify the sample as <span class="strong"><em class="calibre9">+1</em></span>:</p><div class="mediaobject"><img src="images/00731.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The weight update is proportional to the value of <span class="strong"><img src="images/00328.jpeg" alt="The perceptron learning rule" class="calibre14" /></span>. For example, if we have another sample <span class="strong"><img src="images/00741.jpeg" alt="The perceptron learning rule" class="calibre14" /></span> that is incorrectly classified as <span class="strong"><em class="calibre9">-1</em></span>, we'd push the decision boundary by an even larger extent to classify this sample correctly the next time:</p><div class="mediaobject"><img src="images/00754.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">It is important to note that the convergence of the perceptron is only guaranteed if the two classes are linearly separable and the<a id="calibre_link-835" class="calibre1"></a> learning rate is sufficiently small. If the two classes can't be separated by a linear decision boundary, we can set a maximum number of passes over the training dataset (<span class="strong"><strong class="calibre2">epochs</strong></span>) and/or a threshold for the number of tolerated misclassifications&mdash;the perceptron would never stop updating the weights otherwise:</p><div class="mediaobject"><img src="images/00767.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-836" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Downloading the example code</strong></span>
</p><p class="calibre8">If you bought this book directly from Packt, you can download the example code files from your account at <a class="calibre1" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can download all code examples and datasets directly from <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition">https://github.com/rasbt/python-machine-learning-book-2nd-edition</a>.</p></div><p class="calibre8">Now, before we jump into the<a id="calibre_link-837" class="calibre1"></a> implementation in the next section, let us summarize what we just learned in a simple diagram that illustrates the general concept of the perceptron:</p><div class="mediaobject"><img src="images/00778.jpeg" alt="The perceptron learning rule" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The preceding diagram illustrates how the perceptron receives the inputs of a sample <span class="strong"><strong class="calibre2">x</strong></span> and combines them with the weights <span class="strong"><strong class="calibre2">w</strong></span> to compute the net input. The net input is then passed on to the threshold function, which generates a binary output <code class="email">-1</code> or <code class="email">+1</code>&mdash;the predicted class label of the sample. During the learning phase, this output is used to calculate the error of the prediction and update the weights.</p></div></div></div></div>

<div id="calibre_link-541" class="calibre">
<div id="calibre_link-838" class="calibre10"></div><div class="book" title="Implementing a perceptron learning algorithm in Python"><div class="book" id="calibre_link-52"><div class="book"><div class="book"><h1 class="title" id="calibre_link-839"><a id="calibre_link-840" class="calibre1"></a>Implementing a perceptron learning algorithm in Python</h1></div></div></div><p class="calibre8">In the previous section, we learned <a id="calibre_link-841" class="calibre1"></a>how the Rosenblatt's <a id="calibre_link-842" class="calibre1"></a>perceptron rule works; let us now go ahead and implement it in Python, and apply it to the Iris dataset that we introduced in <a class="calibre1" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" href="#calibre_link-17">Chapter 1</a>, <span class="strong"><em class="calibre9">Giving Computers the Ability to Learn from Data</em></span>.</p></div></div>

<div id="calibre_link-547" class="calibre">
<div class="book" title="Implementing a perceptron learning algorithm in Python">
<div class="book" title="An object-oriented perceptron API"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-843"><a id="calibre_link-240" class="calibre1"></a>An object-oriented perceptron API</h2></div></div></div><p class="calibre8">We will take an object-oriented<a id="calibre_link-844" class="calibre1"></a> approach to define the perceptron interface as a Python class, which allows us to initialize new <code class="email">Perceptron</code> objects that can learn from data via a <code class="email">fit</code> method, and make predictions via a separate <code class="email">predict</code> method. As a convention, we append an underscore (<code class="email">_</code>) to attributes that are not being created upon the<a id="calibre_link-845" class="calibre1"></a> initialization of the object but by calling the object's other<a id="calibre_link-846" class="calibre1"></a> methods, for <a id="calibre_link-847" class="calibre1"></a>example, <code class="email">self.w_</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-848" class="calibre1"></a>Note</h3><p class="calibre8">If you are not yet familiar with Python's scientific libraries or need a refresher, please see the following resources:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">NumPy</strong></span>: <a class="calibre1" href="https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf">https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf</a></li><li class="listitem"><span class="strong"><strong class="calibre2">pandas</strong></span>: <a class="calibre1" href="https://pandas.pydata.org/pandas-docs/stable/10min.html">https://pandas.pydata.org/pandas-docs/stable/10min.html</a></li><li class="listitem"><span class="strong"><strong class="calibre2">Matplotlib</strong></span>: <a class="calibre1" href="http://matplotlib.org/users/beginner.html">http://matplotlib.org/users/beginner.html</a></li></ul></div></div><p class="calibre8">The following is the implementation of a perceptron:</p><div class="informalexample"><pre class="programlisting">import numpy as np

class Perceptron(object):
    """Perceptron classifier.

    Parameters
    ------------
    eta : float
      Learning rate (between 0.0 and 1.0)
    n_iter : int
      Passes over the training dataset.
    random_state : int
      Random number generator seed for random weight
      initialization.

    Attributes
    -----------
    w_ : 1d-array
      Weights after fitting.
    errors_ : list
      Number of misclassifications (updates) in each epoch.

    """
    def __init__(self, eta=0.01, n_iter=50, random_state=1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state

    def fit(self, X, y):
        """Fit training data.

        Parameters
        ----------
        X : {array-like}, shape = [n_samples, n_features]
          Training vectors, where n_samples is the number of 
          samples and
          n_features is the number of features.
        y : array-like, shape = [n_samples]
          Target values.

        Returns
        -------
        self : object

        """
        rgen = np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc=0.0, scale=0.01, 
                              size=1 + X.shape[1])
        self.errors_ = []

        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.w_[1:] += update * xi
                self.w_[0] += update
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self

    def net_input(self, X):
        """Calculate net input"""
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def predict(self, X):
        """Return class label after unit step"""
        return np.where(self.net_input(X) &gt;= 0.0, 1, -1)</pre></div><p class="calibre8">Using this perceptron <a id="calibre_link-849" class="calibre1"></a>implementation, we can now initialize new <code class="email">Perceptron</code> objects with a given learning rate <code class="email">eta</code> and <code class="email">n_iter</code>, which is the number of epochs (passes over the training set). Via the <code class="email">fit</code> method, we initialize the weights in <code class="email">self.w_</code> to a vector <span class="strong"><img src="images/00789.jpeg" alt="An object-oriented perceptron API" class="calibre14" /></span>, where <span class="strong"><em class="calibre9">m</em></span> stands for the number of dimensions (features) in the dataset, where we add <span class="strong"><em class="calibre9">1</em></span> for the first element in this vector that represents the bias unit. Remember that the first element in this vector, <code class="email">self.w_[0]</code>, represents the so-called bias unit that we discussed earlier.</p><p class="calibre8">Also notice that this vector contains small random numbers drawn from a normal distribution with standard deviation <code class="email">0.01</code> via <code class="email">rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])</code>, where <code class="email">rgen</code> is a NumPy random number generator that we seeded with a user-specified random seed so that we can reproduce previous results if desired.</p><p class="calibre8">Now, the reason we don't initialize the weights to zero is that the learning rate <span class="strong"><img src="images/00563.jpeg" alt="An object-oriented perceptron API" class="calibre14" /></span> (<code class="email">eta</code>) only has an effect on the classification outcome if the weights are initialized to non-zero values. If all the weights are initialized to zero, the learning rate parameter <code class="email">eta</code> affects only the scale of the weight vector, not the direction. If you are familiar with trigonometry, consider a vector <span class="strong"><img src="images/00799.jpeg" alt="An object-oriented perceptron API" class="calibre14" /></span>, where the angle between <span class="strong"><img src="images/00816.jpeg" alt="An object-oriented perceptron API" class="calibre14" /></span> and a vector <span class="strong"><img src="images/00827.jpeg" alt="An object-oriented perceptron API" class="calibre14" /></span>  would be exactly zero, as demonstrated by the following code snippet:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; v1 = np.array([1, 2, 3])
&gt;&gt;&gt; v2 = 0.5 * v1
&gt;&gt;&gt; np.arccos(v1.dot(v2) / (np.linalg.norm(v1) * 
...           np.linalg.norm(v2)))
0.0</pre></div><p class="calibre8">Here, <code class="email">np.arccos</code> is the trigonometric inverse cosine and <code class="email">np.linalg.norm</code> is a function that computes the length of a vector. (The reason why we have drawn the random numbers from a random<a id="calibre_link-850" class="calibre1"></a> normal distribution&mdash;for example, instead from a uniform distribution&mdash;and why we used a standard deviation of <code class="email">0.01</code> was arbitrary; remember, we are just interested in small random values to avoid the properties of all-zero vectors as discussed earlier.)</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-851" class="calibre1"></a>Note</h3><p class="calibre8">NumPy indexing for one-dimensional arrays works similarly to Python lists using the square-bracket (<code class="email">[]</code>) notation. For two-dimensional arrays, the first indexer refers to the row number and the second indexer to the column number. For example, we would use <code class="email">X[2, 3]</code> to select the third row and fourth column of a two-dimensional array <code class="email">X</code>.</p></div><p class="calibre8">After the weights have been initialized, the <code class="email">fit</code> method loops over all individual samples in the training set and updates the weights according to the perceptron learning rule that we discussed in the previous section. The class labels are predicted by the <code class="email">predict</code> method, which is called in the <code class="email">fit</code> method to predict the class label for the weight update, but <code class="email">predict</code> can also be used to predict the class labels of new data after we have fitted our model. Furthermore, we also collect the number of misclassifications during each epoch in the <code class="email">self.errors_</code> list so that we can later analyze how well our perceptron performed during the training. The <code class="email">np.dot</code> function that is used in the <code class="email">net_input</code> method simply calculates the vector dot product <span class="strong"><img src="images/00838.jpeg" alt="An object-oriented perceptron API" class="calibre14" /></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-852" class="calibre1"></a>Note</h3><p class="calibre8">Instead of using NumPy to calculate the vector dot product between two arrays <code class="email">a</code> and <code class="email">b</code> via <code class="email">a.dot(b)</code> or <code class="email">np.dot(a, b)</code>, we could also perform the calculation in pure Python via <code class="email">sum([j * j for i, j in zip(a, b)])</code>. However, the advantage of using NumPy over classic Python <code class="email">for</code> loop structures is that its arithmetic operations are vectorized. <span class="strong"><strong class="calibre2">Vectorization</strong></span> means that an elemental arithmetic operation is<a id="calibre_link-853" class="calibre1"></a> automatically applied to all elements in an array. By formulating our arithmetic operations as a sequence of instructions on an array, rather than performing a set of operations for each element at the time, we can make better use of our modern CPU architectures with <span class="strong"><strong class="calibre2">Single Instruction, Multiple Data</strong></span> (<span class="strong"><strong class="calibre2">SIMD</strong></span>) support. Furthermore, NumPy <a id="calibre_link-854" class="calibre1"></a>uses highly optimized linear algebra libraries such as <span class="strong"><strong class="calibre2">Basic Linear Algebra Subprograms</strong></span> (<span class="strong"><strong class="calibre2">BLAS</strong></span>) <a id="calibre_link-855" class="calibre1"></a>and <span class="strong"><strong class="calibre2">Linear Algebra Package</strong></span> (<span class="strong"><strong class="calibre2">LAPACK</strong></span>) that<a id="calibre_link-856" class="calibre1"></a> have been written in C or Fortran. Lastly, NumPy also allows us to write our code in a more compact and intuitive way using the basics of linear algebra, such as vector and matrix dot products.</p></div></div></div></div>

<div id="calibre_link-551" class="calibre">
<div class="book" title="Implementing a perceptron learning algorithm in Python">
<div class="book" title="Training a perceptron model on the Iris dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-857"><a id="calibre_link-241" class="calibre1"></a>Training a perceptron model on the Iris dataset</h2></div></div></div><p class="calibre8">To test our perceptron<a id="calibre_link-858" class="calibre1"></a> implementation, we will load the two flower<a id="calibre_link-859" class="calibre1"></a> classes Setosa and Versicolor from the Iris dataset. Although the perceptron rule is not restricted to two dimensions, we will only consider the two features sepal length and petal length for visualization purposes. Also, we only chose the two flower classes Setosa and Versicolor for practical reasons. However, the perceptron algorithm can be extended to multi-class classification&mdash;for<a id="calibre_link-860" class="calibre1"></a> example, the <span class="strong"><strong class="calibre2">One-versus-All</strong></span> (<span class="strong"><strong class="calibre2">OvA</strong></span>) technique.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-861" class="calibre1"></a>Note</h3><p class="calibre8">OvA, or sometimes also<a id="calibre_link-862" class="calibre1"></a> called <span class="strong"><strong class="calibre2">One-versus-Rest</strong></span> (<span class="strong"><strong class="calibre2">OvR</strong></span>), is a technique that allows us to extend a binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the samples from all other classes are considered negative classes. If we were to classify a new data sample, we would use our <span class="strong"><em class="calibre9">n</em></span> classifiers, where <span class="strong"><em class="calibre9">n</em></span> is the number of class labels, and assign the class label with the highest confidence to the particular sample. In the case of the perceptron, we would use OvA to choose the class label that is associated with the largest absolute net input value.</p></div><p class="calibre8">First, we will use the <code class="email">pandas</code> library to load the Iris dataset directly from the <span class="strong"><em class="calibre9">UCI Machine Learning Repository</em></span> into a <code class="email">DataFrame</code> object and print the last five lines via the <code class="email">tail</code> method to check the data was loaded correctly:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv('https://archive.ics.uci.edu/ml/'
...                  'machine-learning-databases/iris/iris.data',
...                  header=None)
&gt;&gt;&gt; df.tail()</pre></div><div class="mediaobject"><img src="images/00851.jpeg" alt="Training a perceptron model on the Iris dataset" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-863" class="calibre1"></a>Note</h3><p class="calibre8">You can find a copy of the Iris dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the UCI server at <a class="calibre1" href="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data">https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data</a> is temporarily unavailable. For instance, to load the Iris dataset from a local directory, you can replace this line:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('https://archive.ics.uci.edu/ml/'
        'machine-learning-databases/iris/iris.data', 
        header=None)</pre></div><p class="calibre8">Replace it with this:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('your/local/path/to/iris.data', 
                 header=None)</pre></div></div><p class="calibre8">Next, we extract the<a id="calibre_link-864" class="calibre1"></a> first 100 class labels that correspond to<a id="calibre_link-865" class="calibre1"></a> the 50 <code class="email">Iris-setosa</code> and 50 <code class="email">Iris-versicolor</code> flowers, and convert the class labels into the two integer class labels <code class="email">1</code> (<code class="email">versicolor</code>) and <code class="email">-1</code> (<code class="email">setosa</code>) that we assign to a vector <code class="email">y</code>, where the values method of a pandas <code class="email">DataFrame</code> yields the corresponding NumPy representation.</p><p class="calibre8">Similarly, we extract the first feature column (sepal length) and the third feature column (petal length) of those 100 training samples and assign them to a feature matrix <code class="email">X</code>, which we can visualize via a two-dimensional scatter plot:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; # select setosa and versicolor
&gt;&gt;&gt; y = df.iloc[0:100, 4].values
&gt;&gt;&gt; y = np.where(y == 'Iris-setosa', -1, 1)

&gt;&gt;&gt; # extract sepal length and petal length
&gt;&gt;&gt; X = df.iloc[0:100, [0, 2]].values

&gt;&gt;&gt; # plot data
&gt;&gt;&gt; plt.scatter(X[:50, 0], X[:50, 1],
...             color='red', marker='o', label='setosa')
&gt;&gt;&gt; plt.scatter(X[50:100, 0], X[50:100, 1],
...             color='blue', marker='x', label='versicolor')
&gt;&gt;&gt; plt.xlabel('sepal length [cm]')
&gt;&gt;&gt; plt.ylabel('petal length [cm]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the <a id="calibre_link-866" class="calibre1"></a>preceding code example, we should now see<a id="calibre_link-867" class="calibre1"></a> the following scatterplot:</p><div class="mediaobject"><img src="images/00865.jpeg" alt="Training a perceptron model on the Iris dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The preceding scatterplot shows the distribution of flower samples in the Iris dataset along the two feature axes, petal length and sepal length. In this two-dimensional feature subspace, we can see that a linear decision boundary should be sufficient to separate Setosa from Versicolor flowers. Thus, a linear classifier such as the perceptron should be able to classify the flowers in this dataset perfectly.</p><p class="calibre8">Now, it's time to train our perceptron algorithm on the Iris data subset that we just extracted. Also, we will plot the misclassification error for each epoch to check whether the algorithm <a id="calibre_link-868" class="calibre1"></a>converged and found a decision boundary that <a id="calibre_link-869" class="calibre1"></a>separates the two Iris flower classes:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ppn = Perceptron(eta=0.1, n_iter=10)
&gt;&gt;&gt; ppn.fit(X, y)
&gt;&gt;&gt; plt.plot(range(1, len(ppn.errors_) + 1), 
...          ppn.errors_, marker='o')
&gt;&gt;&gt; plt.xlabel('Epochs')
&gt;&gt;&gt; plt.ylabel('Number of updates')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the preceding code, we should see the plot of the misclassification errors versus the number of epochs, as shown here:</p><div class="mediaobject"><img src="images/00898.jpeg" alt="Training a perceptron model on the Iris dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see in the preceding plot, our perceptron converged after the sixth epoch and should now be able to classify the training samples perfectly. Let us implement a small<a id="calibre_link-870" class="calibre1"></a> convenience function to visualize the <a id="calibre_link-871" class="calibre1"></a>decision boundaries for two-dimensional datasets:</p><div class="informalexample"><pre class="programlisting">from matplotlib.colors import ListedColormap

def plot_decision_regions(X, y, classifier, resolution=0.02):

    # setup marker generator and color map
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])

    # plot the decision surface
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))
    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    Z = Z.reshape(xx1.shape)
    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())

    # plot class samples
    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(x=X[y == cl, 0],
                    y=X[y == cl, 1],
                    alpha=0.8,
                    c=colors[idx],
                    marker=markers[idx],
                    label=cl,
                    edgecolor='black')</pre></div><p class="calibre8">First, we define a number of <code class="email">colors</code> and <code class="email">markers</code> and create a colormap from the list of colors via <code class="email">ListedColormap</code>. Then, we determine the minimum and maximum values for the two features and use those feature vectors to create a pair of grid arrays <code class="email">xx1</code> and <code class="email">xx2</code> via the NumPy <code class="email">meshgrid</code> function. Since we trained our perceptron classifier on two feature dimensions, we need to flatten the grid arrays and create a matrix that has the same number of columns as the Iris training subset so that we can use the <code class="email">predict</code> method to predict the class labels <code class="email">Z</code> of the corresponding grid points.</p><p class="calibre8">After reshaping the predicted class labels <code class="email">Z</code> into a grid with the same dimensions as <code class="email">xx1</code> and <code class="email">xx2</code>, we can now draw a contour plot via Matplotlib's <code class="email">contourf</code> function, which maps the different decision regions to different colors for each predicted class in the grid array:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plot_decision_regions(X, y, classifier=ppn)
&gt;&gt;&gt; plt.xlabel('sepal length [cm]')
&gt;&gt;&gt; plt.ylabel('petal length [cm]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the <a id="calibre_link-872" class="calibre1"></a>preceding code example, we should now see a <a id="calibre_link-873" class="calibre1"></a>plot of the decision regions, as shown in the following figure:</p><div class="mediaobject"><img src="images/00908.jpeg" alt="Training a perceptron model on the Iris dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see in the plot, the perceptron learned a decision boundary that is able to classify all flower samples in the Iris training subset perfectly.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-874" class="calibre1"></a>Note</h3><p class="calibre8">Although the perceptron classified the two Iris flower classes perfectly, convergence is one of the biggest problems of the perceptron. Frank Rosenblatt proved mathematically that the perceptron learning rule converges if the two classes can be separated by a linear hyperplane. However, if classes cannot be separated perfectly by such a linear decision boundary, the weights will never stop updating unless we set a maximum number of epochs.</p></div></div></div></div>

<div id="calibre_link-115" class="calibre">
<div id="calibre_link-875" class="calibre10"></div><div class="book" title="Adaptive linear neurons and the convergence of learning"><div class="book" id="calibre_link-6"><div class="book"><div class="book"><h1 class="title" id="calibre_link-876"><a id="calibre_link-877" class="calibre1"></a>Adaptive linear neurons and the convergence of learning</h1></div></div></div><p class="calibre8">In this section, we will take a look at another type of single-layer neural network: <span class="strong"><strong class="calibre2">ADAptive LInear NEuron</strong></span> (<span class="strong"><strong class="calibre2">Adaline</strong></span>). Adaline<a id="calibre_link-878" class="calibre1"></a> was published by Bernard Widrow and his doctoral student Tedd Hoff, only a few years after Frank Rosenblatt's perceptron algorithm, and can be considered as an improvement on the latter. (Refer to <span class="strong"><em class="calibre9">An Adaptive</em></span> <span class="strong"><em class="calibre9">"Adaline" Neuron Using Chemical "Memistors"</em></span>, <span class="strong"><em class="calibre9">Technical Report Number 1553-2</em></span>, <span class="strong"><em class="calibre9">B. Widrow and others</em></span>, <span class="strong"><em class="calibre9">Stanford Electron Labs</em></span>, Stanford, CA, <span class="strong"><em class="calibre9">October 1960</em></span>).</p><p class="calibre8">The Adaline algorithm is particularly interesting because it illustrates the key concepts of defining and minimizing continuous cost functions. This lays the groundwork for understanding more advanced machine learning algorithms for classification, such as logistic regression, support vector machines, and regression models, which we will discuss in future chapters.</p><p class="calibre8">The key difference between the Adaline rule (also known as the <span class="strong"><em class="calibre9">Widrow-Hoff rule</em></span>) and Rosenblatt's perceptron is that the weights are updated based on a linear activation function rather than a unit step function like in the perceptron. In Adaline, this linear activation function <span class="strong"><img src="images/00919.jpeg" alt="Adaptive linear neurons and the convergence of learning" class="calibre14" /></span> is simply the identity function of the net input, so that:</p><div class="mediaobject"><img src="images/00940.jpeg" alt="Adaptive linear neurons and the convergence of learning" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">While the linear activation function is used for learning the weights, we still use a threshold function to make the final prediction, which is similar to the unit step function that we have seen earlier. The main differences between the perceptron and Adaline algorithm are highlighted in the following figure:</p><div class="mediaobject"><img src="images/00955.jpeg" alt="Adaptive linear neurons and the convergence of learning" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The illustration shows that the <a id="calibre_link-879" class="calibre1"></a>Adaline algorithm compares the true class labels with the linear activation function's continuous valued output to compute the model error and update the weights. In contrast, the perceptron compares the true class labels to the predicted class labels.</p></div></div>

<div id="calibre_link-557" class="calibre">
<div class="book" title="Adaptive linear neurons and the convergence of learning">
<div class="book" title="Minimizing cost functions with gradient descent"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-880"><a id="calibre_link-242" class="calibre1"></a>Minimizing cost functions with gradient descent</h2></div></div></div><p class="calibre8">One of the key ingredients <a id="calibre_link-881" class="calibre1"></a>of supervised machine learning<a id="calibre_link-882" class="calibre1"></a> algorithms is a defined <span class="strong"><strong class="calibre2">objective function</strong></span>
<a id="calibre_link-883" class="calibre1"></a> that is to be optimized during the learning process. This objective function is often a cost function that we want to minimize. In the case of Adaline, we can define the cost function <span class="strong"><img src="images/00461.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> to learn the weights as the <span class="strong"><strong class="calibre2">Sum of Squared Errors</strong></span> (<span class="strong"><strong class="calibre2">SSE</strong></span>) between<a id="calibre_link-884" class="calibre1"></a> the calculated outcome and the true class label:</p><div class="mediaobject"><img src="images/00471.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The term <span class="strong"><img src="images/00880.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> is just added for our convenience, which will make it easier to derive the gradient, as we will see in the following paragraphs. The main advantage of this continuous linear activation function, in contrast to the unit step function, is that the cost function becomes differentiable. Another nice property of this cost function is that it is convex; thus, we can use a <a id="calibre_link-885" class="calibre1"></a>simple yet powerful optimization<a id="calibre_link-886" class="calibre1"></a> algorithm called <span class="strong"><strong class="calibre2">gradient descent</strong></span>
<a id="calibre_link-887" class="calibre1"></a> to find the weights that minimize our cost function to classify the samples in the Iris dataset.</p><p class="calibre8">As illustrated in the following figure, we can describe the main idea behind gradient descent as <span class="strong"><em class="calibre9">climbing down a hill</em></span> until a local or global cost minimum is reached. In each iteration, we take a step in the opposite direction of the gradient where the step size is determined by the value of the learning rate, as well as the slope of the gradient:</p><div class="mediaobject"><img src="images/00034.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Using gradient descent, we can now update the weights by taking a step in the opposite direction of the gradient <span class="strong"><img src="images/00045.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> of our cost function <span class="strong"><img src="images/00054.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00060.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Where the weight change <span class="strong"><img src="images/00075.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> is defined as the negative gradient multiplied by the learning rate <span class="strong"><img src="images/00563.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00089.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To compute the gradient<a id="calibre_link-888" class="calibre1"></a> of the cost function, we need to compute<a id="calibre_link-889" class="calibre1"></a> the partial derivative of the cost function with respect to each weight <span class="strong"><img src="images/00520.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00103.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">So that we can write the update of weight <span class="strong"><img src="images/00520.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> as:</p><div class="mediaobject"><img src="images/00109.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since we update all weights simultaneously, our Adaline learning rule becomes:</p><div class="mediaobject"><img src="images/00122.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-890" class="calibre1"></a>Note</h3><p class="calibre8">For those who are <a id="calibre_link-891" class="calibre1"></a>familiar with calculus, the <a id="calibre_link-892" class="calibre1"></a>partial derivative of the SSE cost function with respect to the <span class="strong"><em class="calibre9">j</em></span>th weight can be obtained as follows:</p><div class="mediaobject1"><img src="images/00130.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00147.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00158.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00678.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00179.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00194.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre11" /></div><p class="calibre12"> </p></div><p class="calibre8">Although the Adaline<a id="calibre_link-893" class="calibre1"></a> learning rule looks identical to the<a id="calibre_link-894" class="calibre1"></a> perceptron rule, we should note that the <span class="strong"><img src="images/00206.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> with <span class="strong"><img src="images/00929.jpeg" alt="Minimizing cost functions with gradient descent" class="calibre14" /></span> is a real number and not an integer class label. Furthermore, the weight update is calculated based on all samples in the training set (instead of updating the weights incrementally after each sample), which is why this approach is <a id="calibre_link-895" class="calibre1"></a>also referred to as <span class="strong"><strong class="calibre2">batch gradient descent</strong></span>.</p></div></div></div>

<div id="calibre_link-563" class="calibre">
<div class="book" title="Adaptive linear neurons and the convergence of learning">
<div class="book" title="Implementing Adaline in Python"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-896"><a id="calibre_link-243" class="calibre1"></a>Implementing Adaline in Python</h2></div></div></div><p class="calibre8">Since the perceptron rule and <a id="calibre_link-897" class="calibre1"></a>Adaline are very similar, we will take the perceptron<a id="calibre_link-898" class="calibre1"></a> implementation that we defined earlier and change the <code class="email">fit</code> method so that the weights are updated by minimizing the cost function via gradient descent:</p><div class="informalexample"><pre class="programlisting">class AdalineGD(object):
    """ADAptive LInear NEuron classifier.

    Parameters
    ------------
    eta : float
      Learning rate (between 0.0 and 1.0)
    n_iter : int
      Passes over the training dataset.
    random_state : int
      Random number generator seed for random weight
      initialization.


    Attributes
    -----------
    w_ : 1d-array
      Weights after fitting.
    cost_ : list
      Sum-of-squares cost function value in each epoch.

    """
    def __init__(self, eta=0.01, n_iter=50, random_state=1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state

    def fit(self, X, y):
        """ Fit training data.

        Parameters
        ----------
        X : {array-like}, shape = [n_samples, n_features]
          Training vectors, where n_samples is the number of
          samples and
          n_features is the number of features.
        y : array-like, shape = [n_samples]
          Target values.

        Returns
        -------
        self : object

        """
        rgen = np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc=0.0, scale=0.01, 
                              size=1 + X.shape[1])
        self.cost_ = []

        for i in range(self.n_iter):
            net_input = self.net_input(X)
            output = self.activation(net_input)
            errors = (y - output)
            self.w_[1:] += self.eta * X.T.dot(errors)
            self.w_[0] += self.eta * errors.sum()
            cost = (errors**2).sum() / 2.0
            self.cost_.append(cost)
        return self

    def net_input(self, X):
        """Calculate net input"""
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def activation(self, X):
        """Compute linear activation"""
        return X

    def predict(self, X):
        """Return class label after unit step"""
        return np.where(self.activation(self.net_input(X)) 
                        &gt;= 0.0, 1, -1)</pre></div><p class="calibre8">Instead of updating the<a id="calibre_link-899" class="calibre1"></a> weights after evaluating each individual <a id="calibre_link-900" class="calibre1"></a>training sample, as in the perceptron, we calculate the gradient based on the whole training dataset via <code class="email">self.eta * errors.sum()</code> for the bias unit (zero-weight) and via <code class="email">self.eta * X.T.dot(errors)</code> for the weights 1 to <span class="strong"><em class="calibre9">m</em></span> where <code class="email">X.T.dot(errors)</code> is a matrix-vector multiplication between our feature matrix and the error vector.</p><p class="calibre8">Please note that the <code class="email">activation</code> method has no effect in the code since it is simply an identity function. Here, we added the activation function (computed via the <code class="email">activation</code> method) to illustrate how information flows through a single layer neural network: features from the input data, net input, activation, and output. In the next chapter, we will learn about a logistic regression classifier that uses a non-identity, nonlinear activation function. We will see that a logistic regression model is closely related to Adaline with the only difference being its activation and cost function.</p><p class="calibre8">Now, similar to the previous perceptron implementation, we collect the cost values in a <code class="email">self.cost_</code> list to check whether the algorithm converged after training.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-901" class="calibre1"></a>Note</h3><p class="calibre8">Performing a matrix-vector multiplication is similar to calculating a vector dot-product where each row in the matrix is treated as a single row vector. This vectorized approach represents a more compact notation and results in a more efficient computation using NumPy. For example:</p><div class="mediaobject1"><img src="images/00018.jpeg" alt="Implementing Adaline in Python" class="calibre11" /></div><p class="calibre12"> </p></div><p class="calibre8">In practice, it often requires<a id="calibre_link-902" class="calibre1"></a> some experimentation to find a good <a id="calibre_link-903" class="calibre1"></a>learning rate <span class="strong"><img src="images/00563.jpeg" alt="Implementing Adaline in Python" class="calibre14" /></span> for optimal convergence. So, let's choose two different learning rates, <span class="strong"><img src="images/00233.jpeg" alt="Implementing Adaline in Python" class="calibre14" /></span> and <span class="strong"><img src="images/00242.jpeg" alt="Implementing Adaline in Python" class="calibre14" /></span>, to start with and plot the cost functions versus the number of epochs to see how well the Adaline implementation learns from the training data.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-904" class="calibre1"></a>Note</h3><p class="calibre8">The learning rate <span class="strong"><img src="images/00563.jpeg" alt="Implementing Adaline in Python" class="calibre14" /></span> (<code class="email">eta</code>), as well as the number of epochs (<code class="email">n_iter)</code>, are the so-called hyperparameters of the perceptron and Adaline learning algorithms. In <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we will take a look at different techniques to automatically find the values of different hyperparameters that yield optimal performance of the classification model.</p></div><p class="calibre8">Let us now plot the cost against the number of epochs for the two different learning rates:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))

&gt;&gt;&gt; ada1 = AdalineGD(n_iter=10, eta=0.01).fit(X, y)
&gt;&gt;&gt; ax[0].plot(range(1, len(ada1.cost_) + 1), 
...            np.log10(ada1.cost_), marker='o')
&gt;&gt;&gt; ax[0].set_xlabel('Epochs')
&gt;&gt;&gt; ax[0].set_ylabel('log(Sum-squared-error)')
&gt;&gt;&gt; ax[0].set_title('Adaline - Learning rate 0.01')

&gt;&gt;&gt; ada2 = AdalineGD(n_iter=10, eta=0.0001).fit(X, y)
&gt;&gt;&gt; ax[1].plot(range(1, len(ada2.cost_) + 1), 
...            ada2.cost_, marker='o')
&gt;&gt;&gt; ax[1].set_xlabel('Epochs')
&gt;&gt;&gt; ax[1].set_ylabel('Sum-squared-error')
&gt;&gt;&gt; ax[1].set_title('Adaline - Learning rate 0.0001')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting <a id="calibre_link-905" class="calibre1"></a>cost-function plots, we encountered two different<a id="calibre_link-906" class="calibre1"></a> types of problem. The left chart shows what could happen if we choose a learning rate that is too large. Instead of minimizing the cost function, the error becomes larger in every epoch, because we <span class="strong"><em class="calibre9">overshoot</em></span> the global minimum. On the other hand, we can see that the cost decreases on the right plot, but the chosen learning rate <span class="strong"><img src="images/00242.jpeg" alt="Implementing Adaline in Python" class="calibre14" /></span> is so small that the algorithm would require a very large number of epochs to converge to the global cost minimum:</p><div class="mediaobject"><img src="images/00259.jpeg" alt="Implementing Adaline in Python" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The following figure illustrates what might happen if we change the value of a particular weight parameter to minimize the cost function <span class="strong"><img src="images/00461.jpeg" alt="Implementing Adaline in Python" class="calibre14" /></span>. The left subfigure illustrates the case of a well-chosen learning rate, where the cost decreases gradually, moving in the direction of the global minimum. The subfigure on the right, however, illustrates what happens if we choose a learning rate that is too large&mdash;we overshoot the global minimum:</p><div class="mediaobject"><img src="images/00269.jpeg" alt="Implementing Adaline in Python" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-574" class="calibre">
<div class="book" title="Adaptive linear neurons and the convergence of learning">
<div class="book" title="Improving gradient descent through feature scaling"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-907"><a id="calibre_link-244" class="calibre1"></a>Improving gradient descent through feature scaling</h2></div></div></div><p class="calibre8">Many machine learning algorithms<a id="calibre_link-908" class="calibre1"></a> that we will encounter <a id="calibre_link-909" class="calibre1"></a>throughout this book require some sort of feature scaling for optimal performance, which we will discuss in more detail in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span> and <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing.</em></span>
</p><p class="calibre8">Gradient descent is one of the many algorithms that benefit from feature scaling. In this section, we will use a feature scaling method<a id="calibre_link-910" class="calibre1"></a> called <span class="strong"><strong class="calibre2">standardization</strong></span>, which gives our data the property of a standard normal distribution, which helps gradient descent learning to converge more quickly. Standardization shifts the mean of each feature so that it is centered at zero and each feature has a standard deviation of 1. For instance, to standardize the <span class="strong"><em class="calibre9">j</em></span>th feature, we can simply subtract the sample mean <span class="strong"><img src="images/00283.jpeg" alt="Improving gradient descent through feature scaling" class="calibre14" /></span> from every training sample and divide it by its standard deviation <span class="strong"><img src="images/00291.jpeg" alt="Improving gradient descent through feature scaling" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00300.jpeg" alt="Improving gradient descent through feature scaling" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00311.jpeg" alt="Improving gradient descent through feature scaling" class="calibre14" /></span> is a vector consisting of the <span class="strong"><em class="calibre9">j</em></span>th feature values of all training samples <span class="strong"><em class="calibre9">n</em></span>, and this standardization technique is applied to each feature <span class="strong"><em class="calibre9">j</em></span> in our dataset.</p><p class="calibre8">One of the reasons why standardization helps with gradient descent learning is that the optimizer has to go through fewer steps to find a good or optimal solution (the global cost minimum), as illustrated in the following figure, where the subfigures represent the cost surface as a function of two model weights in a two-dimensional classification problem:</p><div class="mediaobject"><img src="images/00320.jpeg" alt="Improving gradient descent through feature scaling" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Standardization can easily <a id="calibre_link-911" class="calibre1"></a>be achieved using the built-in <a id="calibre_link-912" class="calibre1"></a>NumPy methods <code class="email">mean</code> and <code class="email">std</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_std = np.copy(X)
&gt;&gt;&gt; X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
&gt;&gt;&gt; X_std[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()</pre></div><p class="calibre8">After standardization, we will train Adaline again and see that it now converges after a small number of epochs using a learning rate <span class="strong"><img src="images/00332.jpeg" alt="Improving gradient descent through feature scaling" class="calibre14" /></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ada = AdalineGD(n_iter=15, eta=0.01)
&gt;&gt;&gt; ada.fit(X_std, y)

&gt;&gt;&gt; plot_decision_regions(X_std, y, classifier=ada)
&gt;&gt;&gt; plt.title('Adaline - Gradient Descent')
&gt;&gt;&gt; plt.xlabel('sepal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal length [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()

&gt;&gt;&gt; plt.plot(range(1, len(ada.cost_) + 1), ada.cost_, marker='o')
&gt;&gt;&gt; plt.xlabel('Epochs')
&gt;&gt;&gt; plt.ylabel('Sum-squared-error')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing this code, we <a id="calibre_link-913" class="calibre1"></a>should see a figure of the decision <a id="calibre_link-914" class="calibre1"></a>regions as well as a plot of the declining cost, as shown in the following figure:</p><div class="mediaobject"><img src="images/00345.jpeg" alt="Improving gradient descent through feature scaling" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see in the plots, Adaline has now converged after training on the standardized features using a learning rate <span class="strong"><img src="images/00332.jpeg" alt="Improving gradient descent through feature scaling" class="calibre14" /></span>. However, note that the SSE remains non-zero even though all samples were classified correctly.</p></div></div></div>

<div id="calibre_link-579" class="calibre">
<div class="book" title="Adaptive linear neurons and the convergence of learning">
<div class="book" title="Large-scale machine learning and stochastic gradient descent"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-915"><a id="calibre_link-245" class="calibre1"></a>Large-scale machine learning and stochastic gradient descent</h2></div></div></div><p class="calibre8">In the previous section, we <a id="calibre_link-916" class="calibre1"></a>learned how to minimize a cost function by <a id="calibre_link-917" class="calibre1"></a>taking a step in the opposite direction of a cost gradient that is calculated from the whole training set; this is why this approach is sometimes also referred to as <span class="strong"><strong class="calibre2">batch gradient descent</strong></span>. Now imagine we have a very large dataset with millions of <a id="calibre_link-918" class="calibre1"></a>data points, which is not uncommon in many machine learning applications. Running batch gradient descent can be computationally quite costly in such scenarios since we need to reevaluate the whole training dataset each time we take one step towards the global minimum.</p><p class="calibre8">A popular alternative to the batch gradient descent <a id="calibre_link-919" class="calibre1"></a>algorithm is <span class="strong"><strong class="calibre2">stochastic gradient descent</strong></span>, sometimes also called iterative or online gradient descent. Instead of updating the weights based on the sum of the accumulated errors over all samples <span class="strong"><img src="images/00850.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00353.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We update the weights incrementally for each training sample:</p><div class="mediaobject"><img src="images/00360.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although stochastic gradient descent can be considered as an approximation of gradient descent, it typically reaches convergence much faster because of the more frequent weight updates. Since each gradient is calculated based on a single training example, the error surface is noisier than in gradient descent, which can also have the advantage that stochastic gradient descent can escape shallow local minima more readily if we are working with nonlinear cost functions, as we will see later in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>. To obtain satisfying results via stochastic gradient descent, it is important to present it training data in a random order; also, we want to shuffle the training set for every epoch to prevent cycles.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-920" class="calibre1"></a>Note</h3><p class="calibre8">In stochastic gradient descent implementations, the fixed learning rate <span class="strong"><img src="images/00563.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre14" /></span> is often replaced by an adaptive learning rate that decreases over time, for example:</p><div class="mediaobject1"><img src="images/00372.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Where <span class="strong"><img src="images/00861.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre14" /></span> and <span class="strong"><img src="images/00932.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre14" /></span> are constants. We shall note that stochastic gradient descent does not reach the global minimum, but an area very close to it. And using an adaptive learning rate, we can achieve further annealing to the cost minimum.</p></div><p class="calibre8">Another advantage of stochastic gradient descent is that we can use it for <span class="strong"><strong class="calibre2">online learning</strong></span>. In <a id="calibre_link-921" class="calibre1"></a>online learning, our model is trained on the fly as new training data arrives. This is especially useful if we are accumulating large amounts of data, for example, customer data in web applications. Using online learning, the system can immediately adapt to changes and the training data can be discarded after updating the model if storage space is an issue.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-922" class="calibre1"></a>Note</h3><p class="calibre8">A compromise between batch gradient descent and stochastic gradient descent is so-called <span class="strong"><strong class="calibre2">mini-batch learning</strong></span>. Mini-batch learning <a id="calibre_link-923" class="calibre1"></a>can be understood as applying batch gradient descent to smaller subsets of the training data, for example, 32 samples at a time. The advantage over batch gradient descent is that convergence is reached faster via mini-batches because of the more frequent weight updates. Furthermore, mini-batch learning allows us to replace the <code class="email">for</code> loop over the training samples in stochastic gradient descent with vectorized operations, which can further improve the computational efficiency of our learning algorithm.</p></div><p class="calibre8">Since we already implemented the Adaline learning rule using gradient descent, we only need to make a few adjustments to modify the learning algorithm to update the weights via stochastic gradient descent. Inside the <code class="email">fit</code> method, we will now update the weights after each training sample. Furthermore, we will implement an additional <code class="email">partial_fit</code> method, which does not reinitialize the weights, for online learning. In order to check whether our algorithm converged after training, we will calculate the cost as the average cost of the training samples in each epoch. Furthermore, we will add an option to shuffle the training data before each epoch to avoid repetitive cycles when we are optimizing the cost function; via the <code class="email">random_state</code> parameter, we allow the specification of a random seed for reproducibility:</p><div class="informalexample"><pre class="programlisting">class AdalineSGD(object):
    """ADAptive LInear NEuron classifier.

    Parameters
    ------------
    eta : float
      Learning rate (between 0.0 and 1.0)
    n_iter : int
      Passes over the training dataset.
    shuffle : bool (default: True)
      Shuffles training data every epoch if True 
      to prevent cycles.
    random_state : int
      Random number generator seed for random weight
      initialization.


    Attributes
    -----------
    w_ : 1d-array
      Weights after fitting.
    cost_ : list
      Sum-of-squares cost function value averaged over all
      training samples in each epoch.

        
    """
    def __init__(self, eta=0.01, n_iter=10, 
                 shuffle=True, random_state=None):
        self.eta = eta
        self.n_iter = n_iter
        self.w_initialized = False
        self.shuffle = shuffle
        self.random_state = random_state
        
    def fit(self, X, y):
        """ Fit training data.

        Parameters
        ----------
        X : {array-like}, shape = [n_samples, n_features]
          Training vectors, where n_samples is the number 
          of samples and
          n_features is the number of features.
        y : array-like, shape = [n_samples]
          Target values.

        Returns
        -------
        self : object

        """
        self._initialize_weights(X.shape[1])
        self.cost_ = []
        for i in range(self.n_iter):
            if self.shuffle:
                X, y = self._shuffle(X, y)
            cost = []
            for xi, target in zip(X, y):
                cost.append(self._update_weights(xi, target))
            avg_cost = sum(cost) / len(y)
            self.cost_.append(avg_cost)
        return self

    def partial_fit(self, X, y):
        """Fit training data without reinitializing the weights"""
        if not self.w_initialized:
            self._initialize_weights(X.shape[1])
        if y.ravel().shape[0] &gt; 1:
            for xi, target in zip(X, y):
                self._update_weights(xi, target)
        else:
            self._update_weights(X, y)
        return self

    def _shuffle(self, X, y):
        """Shuffle training data"""
        r = self.rgen.permutation(len(y))
        return X[r], y[r]
    
    def _initialize_weights(self, m):
        """Initialize weights to small random numbers"""
        self.rgen = np.random.RandomState(self.random_state)
        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, 
                                   size=1 + m)
        self.w_initialized = True
        
    def _update_weights(self, xi, target):
        """Apply Adaline learning rule to update the weights"""
        output = self.activation(self.net_input(xi))
        error = (target - output)
        self.w_[1:] += self.eta * xi.dot(error)
        self.w_[0] += self.eta * error
        cost = 0.5 * error**2
        return cost
    
    def net_input(self, X):
        """Calculate net input"""
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def activation(self, X):
        """Compute linear activation"""
        return X

    def predict(self, X):
        """Return class label after unit step"""
        return np.where(self.activation(self.net_input(X)) 
                        &gt;= 0.0, 1, -1)</pre></div><p class="calibre8">The <code class="email">_shuffle</code> method that we are now using in the <code class="email">AdalineSGD</code> classifier works as follows: via the <code class="email">permutation</code> function in <code class="email">np.random</code>, we generate a random sequence of unique numbers in the range 0 to 100. Those numbers can then be used as indices to shuffle our feature matrix and class label vector.</p><p class="calibre8">We can then use the <code class="email">fit</code> method to train the <code class="email">AdalineSGD</code> classifier and use our <code class="email">plot_decision_regions</code> to plot our training results:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ada = AdalineSGD(n_iter=15, eta=0.01, random_state=1)
&gt;&gt;&gt; ada.fit(X_std, y)

&gt;&gt;&gt; plot_decision_regions(X_std, y, classifier=ada)
&gt;&gt;&gt; plt.title('Adaline - Stochastic Gradient Descent')
&gt;&gt;&gt; plt.xlabel('sepal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal length [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()
&gt;&gt;&gt; plt.plot(range(1, len(ada.cost_) + 1), ada.cost_, marker='o')
&gt;&gt;&gt; plt.xlabel('Epochs')
&gt;&gt;&gt; plt.ylabel('Average Cost')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The two plots that we obtain from executing the preceding code example are shown in the following figure:</p><div class="mediaobject"><img src="images/00404.jpeg" alt="Large-scale machine learning and stochastic gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, the average cost goes down pretty quickly, and the final decision boundary after 15 epochs looks similar to the batch gradient descent Adaline. If we want to update our model, for example, in an online learning scenario with streaming data, we could simply call the <code class="email">partial_fit</code> method on individual samples&mdash;for instance <code class="email">ada.partial_fit(X_std[0, :], y[0])</code>.</p></div></div></div>

<div id="calibre_link-503" class="calibre"><div class="book" title="Summary" id="calibre_link-246"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-924"><a id="calibre_link-925" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, we gained a good understanding of the basic concepts of linear classifiers for supervised learning. After we implemented a perceptron, we saw how we can train adaptive linear neurons efficiently via a vectorized implementation of gradient descent and online learning via stochastic gradient descent.</p><p class="calibre8">Now that we have seen how to implement simple classifiers in Python, we are ready to move on to the next chapter, where we will use the Python scikit-learn machine learning library to get access to more advanced and powerful machine learning classifiers that are commonly used in academia as well as in industry. The object-oriented approach that we used to implement the perceptron and Adaline algorithms will help with understanding the scikit-learn API, which is implemented based on the same core concepts that we used in this chapter: the <code class="email">fit</code> and <code class="email">predict</code> methods. Based on these core concepts, we will learn about logistic regression for modeling class probabilities and support vector machines for working with nonlinear decision boundaries. In addition, we will introduce a different class of supervised learning algorithms, tree-based algorithms, which are commonly combined into robust ensemble classifiers.</p></div></div>

<div id="calibre_link-587" class="calibre">
<div id="calibre_link-926" class="calibre10"></div><div class="book" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" id="calibre_link-30"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-927"><a id="calibre_link-928" class="calibre1"></a>Chapter&nbsp;3.&nbsp;A Tour of Machine Learning Classifiers Using scikit-learn</h1></div></div></div><p class="calibre8">In this chapter, we will take a tour through a selection of popular and powerful machine learning algorithms that are commonly used in academia as well as in industry. While learning about the differences between several supervised learning algorithms for classification, we will also develop an intuitive appreciation of their individual strengths and weaknesses. In addition, we will take our first step with the scikit-learn library, which offers a user-friendly interface for using those algorithms efficiently and productively.</p><p class="calibre8">The topics that we will learn about throughout this chapter are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Introduction to robust and popular algorithms for classification, such as logistic regression, support vector machines, and decision trees</li><li class="listitem">Examples and explanations using the scikit-learn machine learning library, which provides a wide variety of machine learning algorithms via a user-friendly Python API</li><li class="listitem">Discussions about the strengths and weaknesses of classifiers with linear and non-linear decision boundaries</li></ul></div></div></div>

<div id="calibre_link-592" class="calibre">
<div class="book" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" id="calibre_link-929">
<div class="book" title="Choosing a classification algorithm"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-930"><a id="calibre_link-247" class="calibre1"></a>Choosing a classification algorithm</h1></div></div></div><p class="calibre8">Choosing <a id="calibre_link-931" class="calibre1"></a>an appropriate classification algorithm for a particular problem task requires practice; each algorithm has its own quirks and is based on certain assumptions. To restate the No Free Lunch theorem by David H. Wolpert, no single classifier works best across all possible scenarios (<span class="strong"><em class="calibre9">The Lack of A Priori Distinctions Between Learning Algorithms</em></span>, <span class="strong"><em class="calibre9">Wolpert</em></span> and <span class="strong"><em class="calibre9">David H</em></span>, <span class="strong"><em class="calibre9">Neural Computation 8.7</em></span> (1996): 1341-1390). In practice, it is always recommended that you compare the performance of at least a handful of different learning algorithms to select the best model for the particular problem; these may differ in the number of features or samples, the amount of noise in a dataset, and whether the classes are linearly separable or not.</p><p class="calibre8">Eventually, the<a id="calibre_link-932" class="calibre1"></a> performance of a classifier&mdash;computational performance as well as predictive power&mdash;depends heavily on the underlying data that is available for learning. The five main steps that are involved in training a machine learning algorithm can be summarized as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Selecting features and collecting training samples.</li><li class="listitem" value="2">Choosing a performance metric.</li><li class="listitem" value="3">Choosing a classifier and optimization algorithm.</li><li class="listitem" value="4">Evaluating the performance of the model.</li><li class="listitem" value="5">Tuning the algorithm.</li></ol><div class="calibre13"></div></div><p class="calibre8">Since the approach of this book is to build machine learning knowledge step by step, we will mainly focus on the main concepts of the different algorithms in this chapter and revisit topics such as feature selection and preprocessing, performance metrics, and hyperparameter tuning for more detailed discussions later in this book.</p></div></div></div>

<div id="calibre_link-597" class="calibre"><div class="book" title="First steps with scikit-learn â training a perceptron"><div class="book" id="calibre_link-7"><div class="book"><div class="book"><h1 class="title" id="calibre_link-933"><a id="calibre_link-934" class="calibre1"></a>First steps with scikit-learn &ndash; training a perceptron</h1></div></div></div><p class="calibre8">In <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, you learned about two related<a id="calibre_link-935" class="calibre1"></a> learning algorithms for classification, the <span class="strong"><strong class="calibre2">perceptron</strong></span> rule <a id="calibre_link-936" class="calibre1"></a>and <span class="strong"><strong class="calibre2">Adaline</strong></span>, which we implemented in Python by ourselves. Now we will take a look at the scikit-learn API, which combines a user-friendly interface with a highly optimized implementation of several classification algorithms. The scikit-learn library offers not only a large variety of learning algorithms, but also many convenient functions to preprocess data and to fine-tune and evaluate our models. We will discuss this in more detail, together with the underlying concepts, in <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>, and <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>.</p><p class="calibre8">To get started with the scikit-learn library, we will train a perceptron model similar to the one that we implemented in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. For simplicity, we will use the already familiar <span class="strong"><strong class="calibre2">Iris </strong></span>dataset<a id="calibre_link-937" class="calibre1"></a> throughout the following sections. Conveniently, the Iris dataset is already available via scikit-learn, since it is a simple yet popular dataset that is frequently used for testing and experimenting with algorithms. We will only use two features from the Iris dataset<a id="calibre_link-938" class="calibre1"></a> for visualization purposes.</p><p class="calibre8">We will assign the petal length and petal width of the 150 flower samples to the feature matrix <code class="email">X</code> and the corresponding class labels of the flower species to the vector <code class="email">y</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn import datasets
&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; X = iris.data[:, [2, 3]]
&gt;&gt;&gt; y = iris.target
&gt;&gt;&gt; print('Class labels:', np.unique(y))
Class labels: [0 1 2]</pre></div><p class="calibre8">The <code class="email">np.unique(y)</code> function<a id="calibre_link-939" class="calibre1"></a> returned the three unique class labels stored in <code class="email">iris.target</code>, and as we see, the Iris flower class names <code class="email">Iris-setosa</code>, <code class="email">Iris-versicolor</code>, and <code class="email">Iris-virginica</code> are already stored as integers (here: <code class="email">0</code>, <code class="email">1</code>, <code class="email">2</code>). Although many scikit-learn functions and class methods also work with class labels in string format, using integer labels is a recommended approach to avoid technical glitches and improve computational performance due to a smaller memory footprint; furthermore, encoding class labels as integers is a common convention among most machine learning libraries.</p><p class="calibre8">To evaluate how well a trained model performs on unseen data, we will further split the dataset into separate training and test datasets. Later in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we will discuss the best practices around model evaluation in more detail:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.3, random_state=1, stratify=y)</pre></div><p class="calibre8">Using the <code class="email">train_test_split</code> function from scikit-learn's <code class="email">model_selection</code> module, we randomly split the <code class="email">X</code> and <code class="email">y</code> arrays into 30 percent test data (45 samples) and 70 percent training data (105 samples).</p><p class="calibre8">Note that the <code class="email">train_test_split</code> function already shuffles the training sets internally before splitting; otherwise, all class <code class="email">0</code> and class <code class="email">1</code> samples would have ended up in the training set, and the test set would consist of 45 samples from class 2. Via the <code class="email">random_state</code> parameter, we provided a fixed random seed (<code class="email">random_state=1</code>) for the internal pseudo-random number generator that is used for shuffling the datasets prior to splitting. Using such a fixed <code class="email">random_state</code> ensures that our results are reproducible.</p><p class="calibre8">Lastly, we took advantage of the built-in support for stratification via <code class="email">stratify=y</code>. In this context, stratification means that the <code class="email">train_test_split</code> method returns training and test subsets that have the same proportions of class labels as the input dataset. We can use NumPy's <code class="email">bincount</code> function, which counts the number of occurrences of each value in an array, to verify that this is indeed the case:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Labels counts in y:', np.bincount(y))
Labels counts in y: [50 50 50]
&gt;&gt;&gt; print('Labels counts in y_train:', np.bincount(y_train))
Labels counts in y_train: [35 35 35]
&gt;&gt;&gt; print('Labels counts in y_test:', np.bincount(y_test))
Labels counts in y_test: [15 15 15]</pre></div><p class="calibre8">Many machine learning and<a id="calibre_link-940" class="calibre1"></a> optimization algorithms also require feature scaling for optimal performance, as we remember from the <span class="strong"><strong class="calibre2">gradient descent </strong></span>example in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. Here, we will standardize the features using the <code class="email">StandardScaler</code> class from scikit-learn's <code class="email">preprocessing</code> module: </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; sc = StandardScaler()
&gt;&gt;&gt; sc.fit(X_train)
&gt;&gt;&gt; X_train_std = sc.transform(X_train)
&gt;&gt;&gt; X_test_std = sc.transform(X_test)</pre></div><p class="calibre8">Using the preceding code, we loaded the <code class="email">StandardScaler</code> class from the <code class="email">preprocessing</code> module and initialized a new <code class="email">StandardScaler</code> object that we assigned to the <code class="email">sc</code> variable. Using the <code class="email">fit</code> method, <code class="email">StandardScaler</code> estimated the parameters <span class="strong"><em class="calibre9">Î¼</em></span> (sample mean) and <span class="strong"><em class="calibre9">Ï</em></span> (standard deviation) for each feature dimension from the training data. By calling the <code class="email">transform</code> method, we then standardized the training data using those estimated parameters <span class="strong"><img src="images/00410.jpeg" alt="First steps with scikit-learn â training a perceptron" class="calibre14" /></span> and <span class="strong"><img src="images/00137.jpeg" alt="First steps with scikit-learn â training a perceptron" class="calibre14" /></span>. Note that we used the same scaling parameters to standardize the test set so that both the values in the training and test dataset are comparable to each other.</p><p class="calibre8">Having standardized the training data, we can now train a perceptron model. Most algorithms in scikit-learn already support multiclass classification by default via the <span class="strong"><strong class="calibre2">One-versus-Rest</strong></span> (<span class="strong"><strong class="calibre2">OvR</strong></span>) method, which<a id="calibre_link-941" class="calibre1"></a> allows us to feed the three flower classes to the perceptron all at once. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import Perceptron

&gt;&gt;&gt; ppn = Perceptron(n_iter=40, eta0=0.1, random_state=1)
&gt;&gt;&gt; ppn.fit(X_train_std, y_train)</pre></div><p class="calibre8">The scikit-learn interface reminds us of our perceptron implementation in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>: after loading the <code class="email">Perceptron</code> class from the <code class="email">linear_model</code> module, we initialized a new <code class="email">Perceptron</code> object and trained the model via the <code class="email">fit</code> method. Here, the model parameter <code class="email">eta0</code> is equivalent to the learning rate <code class="email">eta</code> that we used in our own perceptron implementation, and the <code class="email">n_iter</code> parameter defines the number of epochs (passes over the training set).</p><p class="calibre8">As we remember from <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, finding an appropriate learning rate requires some experimentation. If the learning rate is too large, the algorithm will overshoot the global cost minimum. If the learning rate is too small, the algorithm requires more epochs until convergence, which can make the learning slow&mdash;especially for large datasets. Also, we used the <code class="email">random_state</code> parameter to ensure the reproducibility of the initial shuffling of the training dataset after each epoch.</p><p class="calibre8">Having trained a model in scikit-learn, we can make predictions via the <code class="email">predict</code> method, just like in our own perceptron implementation in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_pred = ppn.predict(X_test_std)
&gt;&gt;&gt; print('Misclassified samples: %d' % (y_test != y_pred).sum())
Misclassified samples: 3</pre></div><p class="calibre8">Executing the code, we see <a id="calibre_link-942" class="calibre1"></a>that the perceptron misclassifies three out of the 45 flower samples. Thus, the misclassification error on the test dataset is approximately 0.067 or 6.7 percent <span class="strong"><img src="images/00196.jpeg" alt="First steps with scikit-learn â training a perceptron" class="calibre14" /></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-943" class="calibre1"></a>Note</h3><p class="calibre8">Instead of the misclassification <span class="strong"><em class="calibre9">error</em></span>, many machine learning practitioners report the classification <span class="strong"><em class="calibre9">accuracy</em></span> of a model, which is simply calculated as follows:</p><p class="calibre8">
<span class="strong"><em class="calibre9">1-error = 0.933 or 93.3 percent</em></span>.</p></div><p class="calibre8">The scikit-learn library also implements a large variety of different performance metrics that are available via the <code class="email">metrics</code> module. For example, we can calculate the classification accuracy of the perceptron on the test set as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import accuracy_score
&gt;&gt;&gt; print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))
Accuracy: 0.93</pre></div><p class="calibre8">Here, <code class="email">y_test</code> are the true class labels and <code class="email">y_pred</code> are the class labels that we predicted previously. Alternatively, each classifier in scikit-learn has a <code class="email">score</code> method, which computes a classifier's prediction accuracy by combining the <code class="email">predict</code> call with <code class="email">accuracy_score</code> as shown here:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Accuracy: %.2f' % ppn.score(X_test_std, y_test))
    Accuracy: 0.93</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-944" class="calibre1"></a>Note</h3><p class="calibre8">Note that we evaluate the performance of our models based on the test set in this chapter. In <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>, you will learn about useful techniques, including graphical analysis such as learning curves, to detect and prevent <span class="strong"><strong class="calibre2">overfitting</strong></span>. Overfitting<a id="calibre_link-945" class="calibre1"></a> means that the model captures the patterns in the training data well, but fails to generalize well to unseen data.</p></div><p class="calibre8">Finally, we can use <a id="calibre_link-946" class="calibre1"></a>our <code class="email">plot_decision_regions</code> function from <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, to plot the <span class="strong"><strong class="calibre2">decision regions</strong></span> <a id="calibre_link-947" class="calibre1"></a>of our newly trained perceptron model and visualize how well it separates the different flower samples. However, let's add a small modification to highlight the samples from the test dataset via small circles:</p><div class="informalexample"><pre class="programlisting">from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt


def plot_decision_regions(X, y, classifier, test_idx=None,  
                          resolution=0.02):

    # setup marker generator and color map
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])

    # plot the decision surface
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))
    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    Z = Z.reshape(xx1.shape)
    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())

    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],
                    alpha=0.8, c=colors[idx],
                    marker=markers[idx], label=cl, 
                    edgecolor='black')

    # highlight test samples
    if test_idx:
        # plot all samples
        X_test, y_test = X[test_idx, :], y[test_idx]

        plt.scatter(X_test[:, 0], X_test[:, 1],
                    c='', edgecolor='black', alpha=1.0,
                    linewidth=1, marker='o',
                    s=100, label='test set')</pre></div><p class="calibre8">With the slight<a id="calibre_link-948" class="calibre1"></a> modification that we made to the <code class="email">plot_decision_regions</code> function, we can now specify the indices of the samples that we want to mark on the resulting plots. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_combined_std = np.vstack((X_train_std, X_test_std))
&gt;&gt;&gt; y_combined = np.hstack((y_train, y_test))
&gt;&gt;&gt; plot_decision_regions(X=X_combined_std,
...                       y=y_combined,
...                       classifier=ppn, 
...                       test_idx=range(105, 150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting plot, the three flower classes cannot be perfectly separated by a linear decision boundary:</p><div class="mediaobject"><img src="images/00252.jpeg" alt="First steps with scikit-learn â training a perceptron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Remember from our discussion in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, that the perceptron algorithm never converges on datasets that aren't perfectly linearly<a id="calibre_link-949" class="calibre1"></a> separable, which is why the use of the perceptron algorithm is typically not recommended in practice. In the following sections, we will look at more powerful linear classifiers that converge to a cost minimum even if the classes are not perfectly linearly separable.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-950" class="calibre1"></a>Note</h3><p class="calibre8">The <code class="email">Perceptron</code>, as well as other scikit-learn functions and classes, often have additional parameters that we omit for clarity. You can read more about those parameters using the <code class="email">help</code> function in Python (for instance, <code class="email">help(Perceptron)</code>) or by going through the excellent scikit-learn online documentation at <a class="calibre1" href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a>.</p></div></div></div>

<div id="calibre_link-581" class="calibre">
<div id="calibre_link-951" class="calibre10"></div><div class="book" title="Modeling class probabilities via logistic regression"><div class="book" id="calibre_link-8"><div class="book"><div class="book"><h1 class="title" id="calibre_link-952"><a id="calibre_link-953" class="calibre1"></a>Modeling class probabilities via logistic regression</h1></div></div></div><p class="calibre8">Although the <a id="calibre_link-954" class="calibre1"></a>perceptron rule offers a nice and <a id="calibre_link-955" class="calibre1"></a>easygoing introduction to machine learning algorithms for classification, its biggest disadvantage is that it never converges if the classes are not perfectly linearly separable. The classification task in the previous section would be an example of such a scenario. Intuitively, we can think of the reason as the weights are continuously being updated since there is always at least one misclassified sample present in each epoch. Of course, you can change the learning rate and increase the number of epochs, but be warned that the perceptron will never converge on this dataset. To make better use of our time, we will now take a look at another simple yet more powerful algorithm for linear and binary classification problems: <span class="strong"><strong class="calibre2">logistic regression</strong></span>. Note that, in spite of its name, logistic regression is a model for classification, not regression.</p></div></div>

<div id="calibre_link-601" class="calibre">
<div class="book" title="Modeling class probabilities via logistic regression">
<div class="book" title="Logistic regression intuition and conditional probabilities"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-956"><a id="calibre_link-248" class="calibre1"></a>Logistic regression intuition and conditional probabilities</h2></div></div></div><p class="calibre8">Logistic regression is <a id="calibre_link-957" class="calibre1"></a>a classification model that is very easy to implement but performs very well on linearly separable classes. It is one of the most widely used algorithms for classification in industry. Similar to the perceptron and Adaline, the logistic regression model in this chapter is also a linear model for binary classification that can be extended to multiclass classification, for example, via the OvR technique.</p><p class="calibre8">To explain the idea behind logistic regression as a probabilistic model, let's first introduce the <span class="strong"><strong class="calibre2">odds ratio</strong></span>: the odds<a id="calibre_link-958" class="calibre1"></a> in favor of a particular event. The odds ratio can be written as <span class="strong"><img src="images/00010.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> where <span class="strong"><img src="images/00021.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> stands for the probability of the positive event. The term <span class="strong"><em class="calibre9">positive</em></span> <span class="strong"><em class="calibre9">event</em></span> does not necessarily mean <span class="strong"><em class="calibre9">good</em></span>, but refers to the event that we want to predict, for example, the probability that a patient has a certain disease; we can think of the positive event as class label <span class="strong"><img src="images/00000.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span>. We can then further define the <span class="strong"><strong class="calibre2">logit</strong></span> function, which is simply the logarithm of the odds ratio (log-odds):</p><div class="mediaobject"><img src="images/00035.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that <span class="strong"><em class="calibre9">log</em></span> refers to the <a id="calibre_link-959" class="calibre1"></a>natural logarithm, as it is the common convention in computer science. The <span class="strong"><em class="calibre9">logit</em></span> function<a id="calibre_link-960" class="calibre1"></a> takes as input values in the range 0 to 1 and transforms them to values over the entire real-number range, which we can use to express a linear relationship between feature values and the log-odds:</p><div class="mediaobject"><img src="images/00046.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00055.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> is the conditional probability that a particular sample belongs to class 1 given its features <span class="strong"><strong class="calibre2">x</strong></span>.</p><p class="calibre8">Now, we are actually interested in predicting the probability that a certain sample belongs to a particular class, which is the inverse<a id="calibre_link-961" class="calibre1"></a> form of the <code class="email">logit</code> function. It is also called <span class="strong"><strong class="calibre2">logistic sigmoid function</strong></span>, sometimes simply abbreviated to <span class="strong"><strong class="calibre2">sigmoid function</strong></span>
<a id="calibre_link-962" class="calibre1"></a> due to its characteristic S-shape:</p><div class="mediaobject"><img src="images/00061.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here z is the net input, the linear combination of weights and sample features, <span class="strong"><img src="images/00076.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-963" class="calibre1"></a>Note</h3><p class="calibre8">Note that similar to the convention we used in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, <span class="strong"><img src="images/00090.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> refers to the bias unit, and is an additional input value that we provide <span class="strong"><img src="images/00459.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span>, which is set equal to 1.</p></div><p class="calibre8">Now let us simply plot the <a id="calibre_link-964" class="calibre1"></a>sigmoid function for some values in the range -7 to 7 to see how it looks:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; def sigmoid(z):
...     return 1.0 / (1.0 + np.exp(-z))
&gt;&gt;&gt; z = np.arange(-7, 7, 0.1)
&gt;&gt;&gt; phi_z = sigmoid(z)
&gt;&gt;&gt; plt.plot(z, phi_z)
&gt;&gt;&gt; plt.axvline(0.0, color='k')
&gt;&gt;&gt; plt.ylim(-0.1, 1.1)
&gt;&gt;&gt; plt.xlabel('z')
&gt;&gt;&gt; plt.ylabel('$\phi (z)$')
&gt;&gt;&gt; # y axis ticks and gridline
&gt;&gt;&gt; plt.yticks([0.0, 0.5, 1.0])
&gt;&gt;&gt; ax = plt.gca()
&gt;&gt;&gt; ax.yaxis.grid(True)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As a result of executing the previous code example, we should now see the S-shaped (sigmoidal) curve:</p><div class="mediaobject"><img src="images/00110.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can see that <span class="strong"><img src="images/00123.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> approaches 1 if z goes towards infinity (<span class="strong"><img src="images/00131.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span>) since <span class="strong"><img src="images/00148.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> becomes very small for <a id="calibre_link-965" class="calibre1"></a>large values of z. Similarly, <span class="strong"><img src="images/00123.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> goes towards 0 for <span class="strong"><img src="images/00159.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> as a result of an increasingly large denominator. Thus, we conclude that this sigmoid function takes real number values as input and transforms them into values in the range [0, 1] with an intercept at <span class="strong"><img src="images/00805.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span>.</p><p class="calibre8">To build some intuition for the logistic regression model, we can relate it to <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. In Adaline, we used the identity function <span class="strong"><img src="images/00180.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> as the activation function. In logistic regression, this activation function simply becomes the sigmoid function that we defined earlier. The difference between Adaline and logistic regression is illustrated in the following figure:</p><div class="mediaobject"><img src="images/00195.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The output of the<a id="calibre_link-966" class="calibre1"></a> sigmoid function is then interpreted as the probability of a particular sample belonging to class 1,<span class="strong"><img src="images/00028.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span>, given its features <span class="strong"><strong class="calibre2">x</strong></span> parameterized by the weights <span class="strong"><strong class="calibre2">w</strong></span>. For example, if we compute <span class="strong"><img src="images/00079.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> for a particular flower sample, it means that the chance that this sample is an <code class="email">Iris-versicolor</code> flower is 80 percent. Therefore, the probability that this flower is an <code class="email">Iris-setosa</code> flower can be calculated as <span class="strong"><img src="images/00231.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre14" /></span> or 20 percent. The predicted probability can then simply be converted into a binary outcome via a threshold function:</p><div class="mediaobject"><img src="images/00235.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">If we look at the preceding plot of the sigmoid function, this is equivalent to the following:</p><div class="mediaobject"><img src="images/00243.jpeg" alt="Logistic regression intuition and conditional probabilities" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In fact, there are many applications where we are not only interested in the predicted class labels, but where the estimation of the class-membership probability is particularly useful (the output of the sigmoid function prior to applying the threshold function). Logistic regression is used in weather forecasting, for example, not only to predict if it will rain on a particular day but also to report the chance of rain. Similarly, logistic regression can be used to predict the chance that a patient has a particular disease given certain symptoms, which is why logistic regression enjoys great popularity in the field of medicine.</p></div></div></div>

<div id="calibre_link-604" class="calibre">
<div class="book" title="Modeling class probabilities via logistic regression">
<div class="book" title="Learning the weights of the logistic cost function"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-967"><a id="calibre_link-249" class="calibre1"></a>Learning the weights of the logistic cost function</h2></div></div></div><p class="calibre8">You learned how we<a id="calibre_link-968" class="calibre1"></a> could use the logistic regression <a id="calibre_link-969" class="calibre1"></a>model to predict probabilities and class labels; now, let us briefly talk about how we fit the parameters of the model, for instance the weights <span class="strong"><strong class="calibre2">w</strong></span>. In the previous chapter, we defined the sum-squared-error cost function as follows:</p><div class="mediaobject"><img src="images/00256.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We minimized this function in order to learn the weights <span class="strong"><strong class="calibre2">w</strong></span> for our Adaline classification model. To explain how we can derive the cost function for logistic regression, let's first define the likelihood <span class="strong"><em class="calibre9">L</em></span> that we want to maximize when we build a logistic regression model, assuming that the individual samples in our dataset are independent of one another. The formula is as follows:</p><div class="mediaobject"><img src="images/00266.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In practice, it is easier to maximize the (natural) log of this equation, which is called the log-likelihood function:</p><div class="mediaobject"><img src="images/00279.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Firstly, applying the log<a id="calibre_link-970" class="calibre1"></a> function reduces the potential for <a id="calibre_link-971" class="calibre1"></a>numerical underflow, which can occur if the likelihoods are very small. Secondly, we can convert the product of factors into a summation of factors, which makes it easier to obtain the derivative of this function via the addition trick, as you may remember from calculus.</p><p class="calibre8">Now we could use an optimization algorithm such as gradient ascent to maximize this log-likelihood function. Alternatively, let's rewrite the log-likelihood as a cost function <span class="strong"><em class="calibre9">J</em></span> that can be minimized using gradient descent as in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>:</p><div class="mediaobject"><img src="images/00292.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To get a better grasp of this cost function, let us take a look at the cost that we calculate for one single-sample training instance:</p><div class="mediaobject"><img src="images/00301.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Looking at the equation, we can see that the first term becomes zero if <span class="strong"><img src="images/00312.jpeg" alt="Learning the weights of the logistic cost function" class="calibre14" /></span>, and the second term becomes zero if <span class="strong"><img src="images/00000.jpeg" alt="Learning the weights of the logistic cost function" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00321.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's write a short code snippet to create a plot that illustrates the cost of classifying a single-sample instance for different values of <span class="strong"><img src="images/00123.jpeg" alt="Learning the weights of the logistic cost function" class="calibre14" /></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def cost_1(z):
...     return - np.log(sigmoid(z))
&gt;&gt;&gt; def cost_0(z):
...     return - np.log(1 - sigmoid(z))
&gt;&gt;&gt; z = np.arange(-10, 10, 0.1)
&gt;&gt;&gt; phi_z = sigmoid(z)
&gt;&gt;&gt; c1 = [cost_1(x) for x in z]
&gt;&gt;&gt; plt.plot(phi_z, c1, label='J(w) if y=1')
&gt;&gt;&gt; c0 = [cost_0(x) for x in z]
&gt;&gt;&gt; plt.plot(phi_z, c0, linestyle='--', label='J(w) if y=0')
&gt;&gt;&gt; plt.ylim(0.0, 5.1)
&gt;&gt;&gt; plt.xlim([0, 1])
&gt;&gt;&gt; plt.xlabel('$\phi$(z)')
&gt;&gt;&gt; plt.ylabel('J(w)')
&gt;&gt;&gt; plt.legend(loc='best')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The resulting plot <a id="calibre_link-972" class="calibre1"></a>shows the sigmoid activation on the <span class="strong"><em class="calibre9">x</em></span> axis, in <a id="calibre_link-973" class="calibre1"></a>the range <code class="email">0</code> to <code class="email">1</code> (the inputs to the sigmoid function were z values in the range <code class="email">-10</code> to <code class="email">10</code>) and the associated logistic cost on the <span class="strong"><em class="calibre9">y</em></span>-axis:</p><div class="mediaobject"><img src="images/00333.jpeg" alt="Learning the weights of the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can see that the cost approaches 0 (continuous line) if we correctly predict that a sample belongs to class 1. Similarly, we can see on the <span class="strong"><em class="calibre9">y</em></span>-axis that the cost also approaches 0 if we <a id="calibre_link-974" class="calibre1"></a>correctly predict <span class="strong"><img src="images/00312.jpeg" alt="Learning the weights of the logistic cost function" class="calibre14" /></span> (dashed line). However, if the <a id="calibre_link-975" class="calibre1"></a>prediction is wrong, the cost goes towards infinity. The main point is that we penalize wrong predictions with an increasingly larger cost.</p></div></div></div>

<div id="calibre_link-609" class="calibre">
<div class="book" title="Modeling class probabilities via logistic regression">
<div class="book" title="Converting an Adaline implementation into an algorithm for logistic regression"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-976"><a id="calibre_link-250" class="calibre1"></a>Converting an Adaline implementation into an algorithm for logistic regression</h2></div></div></div><p class="calibre8">If we were to implement <a id="calibre_link-977" class="calibre1"></a>logistic regression ourselves, we could simply substitute the cost function <span class="strong"><em class="calibre9">J</em></span> in our Adaline implementation from <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span> with the new cost function:</p><div class="mediaobject"><img src="images/00346.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We use this to compute the cost of classifying all training samples per epoch. Also, we need to swap the linear activation function with the sigmoid activation and change the threshold function to return class labels 0 and 1 instead of -1 and 1. If we make those three changes to the Adaline code, we would end up with a working logistic regression implementation, as shown here:</p><div class="informalexample"><pre class="programlisting">class LogisticRegressionGD(object):
    """Logistic Regression Classifier using gradient descent.

    Parameters
    ------------
    eta : float
      Learning rate (between 0.0 and 1.0)
    n_iter : int
      Passes over the training dataset.
    random_state : int
      Random number generator seed for random weight
      initialization.


    Attributes
    -----------
    w_ : 1d-array
      Weights after fitting.
    cost_ : list
      Sum-of-squares cost function value in each epoch.

    """
    def __init__(self, eta=0.05, n_iter=100, random_state=1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state

    def fit(self, X, y):
        """ Fit training data.

        Parameters
        ----------
        X : {array-like}, shape = [n_samples, n_features]
          Training vectors, where n_samples is the number of 
          samples and
          n_features is the number of features.
        y : array-like, shape = [n_samples]
          Target values.

        Returns
        -------
        self : object

        """
        rgen = np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc=0.0, scale=0.01, 
                              size=1 + X.shape[1])
        self.cost_ = []

        for i in range(self.n_iter):
            net_input = self.net_input(X)
            output = self.activation(net_input)
            errors = (y - output)
            self.w_[1:] += self.eta * X.T.dot(errors)
            self.w_[0] += self.eta * errors.sum()
            
            # note that we compute the logistic `cost` now
            # instead of the sum of squared errors cost
            cost = (-y.dot(np.log(output)) - 
                    ((1 - y).dot(np.log(1 - output))))
            self.cost_.append(cost)
        return self
    
    def net_input(self, X):
        """Calculate net input"""
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def activation(self, z):
        """Compute logistic sigmoid activation"""
        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))

    def predict(self, X):
        """Return class label after unit step"""
        return np.where(self.net_input(X) &gt;= 0.0, 1, 0)
        # equivalent to:
        # return np.where(self.activation(self.net_input(X)) 
        #                 &gt;= 0.5, 1, 0)</pre></div><p class="calibre8">When we fit a<a id="calibre_link-978" class="calibre1"></a> logistic regression model, we have to keep in mind that it only works for binary classification tasks. So, let us consider only <code class="email">Iris-setosa</code> and <code class="email">Iris-versicolor</code> flowers (classes <code class="email">0</code> and <code class="email">1</code>) and check that our implementation of logistic regression works:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train_01_subset = X_train[(y_train == 0) | (y_train == 1)]
&gt;&gt;&gt; y_train_01_subset = y_train[(y_train == 0) | (y_train == 1)]
&gt;&gt;&gt; lrgd = LogisticRegressionGD(eta=0.05, 
...                             n_iter=1000,
...                             random_state=1)
&gt;&gt;&gt; lrgd.fit(X_train_01_subset,
...          y_train_01_subset)The 
&gt;&gt;&gt; plot_decision_regions(X=X_train_01_subset, 
...                              y=y_train_01_subset,
...                              classifier=lrgd)
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The resulting decision region plot looks as follows:</p><div class="mediaobject"><img src="images/00354.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-979" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">The gradient descent learning algorithm for logistic regression</strong></span>
</p><p class="calibre8">Using calculus, we<a id="calibre_link-980" class="calibre1"></a> can show that the weight update in logistic regression via gradient descent is equal to the equation that we used in Adaline in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. However, please note that the following derivation <a id="calibre_link-981" class="calibre1"></a>of the gradient descent learning rule is intended for readers who are interested in the mathematical concepts behind the gradient descent learning rule for logistic regression. It is not essential for following the rest of this chapter.</p><p class="calibre8">Let's start by calculating the partial derivative of the log-likelihood function with respect to the <span class="strong"><em class="calibre9">j</em></span>th weight:</p><div class="mediaobject1"><img src="images/00361.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Before we continue, let's also calculate the partial derivative of the sigmoid function:</p><div class="mediaobject1"><img src="images/00373.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-982" class="calibre1"></a>Note</h3><p class="calibre8">Now, we<a id="calibre_link-983" class="calibre1"></a> can re-substitute <span class="strong"><img src="images/00384.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre14" /></span> in our first equation to obtain the following:</p><div class="mediaobject1"><img src="images/00082.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Remember that the goal is to find the weights that maximize the log-likelihood so that we perform the update for each weight as follows:</p><div class="mediaobject1"><img src="images/00140.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since we update all weights simultaneously, we can write the general update rule as follows:
<span class="strong"><img src="images/00411.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre14" /></span>
</p><p class="calibre8">We define <span class="strong"><img src="images/00426.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre14" /></span> as follows:
<span class="strong"><img src="images/00439.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre14" /></span></p><p class="calibre8">Since<a id="calibre_link-984" class="calibre1"></a> maximizing the log-likelihood is equal to minimizing the cost function <span class="strong"><em class="calibre9">J</em></span> that we defined earlier, we can write the gradient descent update rule as follows:
<span class="strong"><img src="images/00451.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre14" /></span>
</p><div class="mediaobject1"><img src="images/00011.jpeg" alt="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
</p><p class="calibre8">This is equal to the gradient descent rule for Adaline in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>.</p></div></div></div></div>

<div id="calibre_link-611" class="calibre">
<div class="book" title="Modeling class probabilities via logistic regression">
<div class="book" title="Training a logistic regression model with scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-985"><a id="calibre_link-251" class="calibre1"></a>Training a logistic regression model with scikit-learn</h2></div></div></div><p class="calibre8">We just <a id="calibre_link-986" class="calibre1"></a>went through useful coding and <a id="calibre_link-987" class="calibre1"></a>math exercises in the previous subsection, which helped illustrate the conceptual differences between Adaline and logistic regression. Now, let's learn how to use scikit-learn's more optimized implementation of logistic regression that also supports multi-class settings off the shelf (OvR by default). In the following code example, we will use the <code class="email">sklearn.linear_model.LogisticRegression</code> class as well as the familiar <code class="email">fit</code> method to train the model on all three classes in the standardized flower training dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; lr = LogisticRegression(C=100.0, random_state=1)
&gt;&gt;&gt; lr.fit(X_train_std, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined_std,
...                       y_combined, 
...                       classifier=lr,
...&nbsp;                      test_idx=range(105, 150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After fitting the model on the training data, we plotted the decision regions, training samples, and test samples, as shown in the following figure:</p><div class="mediaobject"><img src="images/00022.jpeg" alt="Training a logistic regression model with scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Looking at<a id="calibre_link-988" class="calibre1"></a> the preceding code that we <a id="calibre_link-989" class="calibre1"></a>used to train the <code class="email">LogisticRegression</code> model, you might now be wondering, "What is this mysterious parameter <code class="email">C</code>?" We will discuss this parameter in the next subsection, where we first introduce the concepts of overfitting and regularization. However, before we are moving on to those topics, let's finish our discussion of class-membership probabilities.</p><p class="calibre8">The probability that training examples belong to a certain class can be computed using the <code class="email">predict_proba</code> method. For example, we can predict the probabilities of the first three samples in the test set as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.predict_proba(X_test_std[:3, :])</pre></div><p class="calibre8">This code snippet returns the following array:</p><div class="informalexample"><pre class="programlisting">array([[  3.20136878e-08,   1.46953648e-01,   8.53046320e-01],
       [  8.34428069e-01,   1.65571931e-01,   4.57896429e-12],
       [  8.49182775e-01,   1.50817225e-01,   4.65678779e-13]])</pre></div><p class="calibre8">The first row corresponds to the class-membership probabilities of the first flower, the second row corresponds to the class-membership probabilities of the third flower, and so forth. Notice that the columns sum all up to one, as expected (you can confirm this by executing <code class="email">lr.predict_proba(X_test_std[:3, :]).sum(axis=1)</code>). The highest value in the first row is approximately 0.853, which means that the first sample belongs to class three (<code class="email">Iris-virginica</code>) with a predicted probability of 85.7 percent. So, as you may have already noticed, we can get the predicted class labels by identifying the largest column in each row, for example, using NumPy's <code class="email">argmax</code> function:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.predict_proba(X_test_std[:3, :]).argmax(axis=1)</pre></div><p class="calibre8">The returned class indices are shown here (they correspond to <code class="email">Iris-virginica</code>, <code class="email">Iris-setosa</code>, and <code class="email">Iris-setosa</code>):</p><div class="informalexample"><pre class="programlisting">array([2, 0, 0])</pre></div><p class="calibre8">The class labels we obtained from the preceding conditional probabilities is, of course, just a manual approach to calling the <code class="email">predict</code> method directly, which we can quickly verify as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.predict(X_test_std[:3, :])
array([2, 0, 0])</pre></div><p class="calibre8">Lastly, a word <a id="calibre_link-990" class="calibre1"></a>of caution if you want to predict<a id="calibre_link-991" class="calibre1"></a> the class label of a single flower sample: sciki-learn expects a two-dimensional array as data input; thus, we have to convert a single row slice into such a format first. One way to convert a single row entry into a two-dimensional data array is to use NumPy's <code class="email">reshape</code> method to add a new dimension, as demonstrated here:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.predict(X_test_std[0, :].reshape(1, -1)) 
array([2])</pre></div></div></div></div>

<div id="calibre_link-613" class="calibre">
<div class="book" title="Modeling class probabilities via logistic regression">
<div class="book" title="Tackling overfitting via regularization"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-992"><a id="calibre_link-252" class="calibre1"></a>Tackling overfitting via regularization</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Overfitting</strong></span> is a<a id="calibre_link-993" class="calibre1"></a> common problem <a id="calibre_link-994" class="calibre1"></a>in machine learning, where a <a id="calibre_link-995" class="calibre1"></a>model performs well on training data but does not generalize well to unseen data (test data). If a model suffers from overfitting, we also say that the model has a high variance, which can be caused by having too many parameters that lead to a model that is too complex given the underlying data. Similarly, our model can also suffer from <span class="strong"><strong class="calibre2">underfitting</strong></span> (high bias), which<a id="calibre_link-996" class="calibre1"></a> means that our model is not complex enough to capture the pattern in the training data well and therefore also suffers from low performance on unseen data.</p><p class="calibre8">Although we have only encountered linear models for classification so far, the problem of overfitting and underfitting can be best illustrated by comparing a linear decision boundary to more complex, nonlinear decision boundaries as shown in the following figure:</p><div class="mediaobject"><img src="images/00003.jpeg" alt="Tackling overfitting via regularization" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-997" class="calibre1"></a>Note</h3><p class="calibre8">Variance measures the consistency (or variability) of the model prediction for a particular sample instance if we were to retrain the model multiple times, for example, on different subsets of the training dataset. We can say that the model is sensitive to the randomness in the training data. In contrast, bias measures how far off the predictions are from the correct values in general if we rebuild the model multiple times on different training datasets; bias is the measure of the systematic error that is not due to randomness.</p></div><p class="calibre8">One way of<a id="calibre_link-998" class="calibre1"></a> finding a good bias-variance tradeoff is to tune the <a id="calibre_link-999" class="calibre1"></a>complexity of the model via regularization. Regularization is a very useful method to handle collinearity (high correlation among features), filter out noise from data, and eventually prevent overfitting. The concept behind regularization is to introduce additional information (bias) to penalize extreme parameter (weight) values. The most common form of regularization is so-called L2 regularization (sometimes also called L2 shrinkage or weight decay), which can be written as follows:</p><div class="mediaobject"><img src="images/00031.jpeg" alt="Tackling overfitting via regularization" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00042.jpeg" alt="Tackling overfitting via regularization" class="calibre14" /></span> is the <a id="calibre_link-1000" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">regularization parameter</strong></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1001" class="calibre1"></a>Note</h3><p class="calibre8">Regularization is another reason why feature scaling such as standardization is important. For regularization to work properly, we need to ensure that all our features are on comparable scales.</p></div><p class="calibre8">The cost function for logistic regression can be regularized by adding a simple regularization term, which will shrink the weights during model training:</p><div class="mediaobject"><img src="images/00056.jpeg" alt="Tackling overfitting via regularization" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Via the<a id="calibre_link-1002" class="calibre1"></a> regularization parameter <span class="strong"><img src="images/00042.jpeg" alt="Tackling overfitting via regularization" class="calibre14" /></span>, we can then control how well <a id="calibre_link-1003" class="calibre1"></a>we fit the training data while keeping the weights small. By increasing the value of <span class="strong"><img src="images/00042.jpeg" alt="Tackling overfitting via regularization" class="calibre14" /></span>, we increase the regularization strength.</p><p class="calibre8">The parameter <code class="email">C</code> that is implemented for the <code class="email">LogisticRegression</code> class in scikit-learn comes from a convention in support vector machines, which will be the topic of the next section. The term <code class="email">C</code> is directly related to the regularization parameter <span class="strong"><img src="images/00042.jpeg" alt="Tackling overfitting via regularization" class="calibre14" /></span>, which is its inverse. Consequently, decreasing the value of the inverse regularization parameter <code class="email">C</code> means that we are increasing the regularization strength, which we can visualize by plotting the L2-regularization path for the two weight coefficients:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; weights, params = [], []
&gt;&gt;&gt; for c in np.arange(-5, 5):
...     lr = LogisticRegression(C=10.**c, random_state=1)
...     lr.fit(X_train_std, y_train)
...     weights.append(lr.coef_[1])
...     params.append(10.**c)
&gt;&gt;&gt; weights = np.array(weights)
&gt;&gt;&gt; plt.plot(params, weights[:, 0],
...          label='petal length')
&gt;&gt;&gt; plt.plot(params, weights[:, 1], linestyle='--',
...          label='petal width')
&gt;&gt;&gt; plt.ylabel('weight coefficient')
&gt;&gt;&gt; plt.xlabel('C')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.xscale('log')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">By <a id="calibre_link-1004" class="calibre1"></a>executing the preceding code, we fitted ten logistic<a id="calibre_link-1005" class="calibre1"></a> regression models with different values for the inverse-regularization parameter <code class="email">C</code>. For the purposes of illustration, we only collected the weight coefficients of class <code class="email">1</code> (here, the second class in the dataset, <code class="email">Iris-versicolor</code>) versus all classifiers&mdash;remember that we are using the OvR technique for multiclass classification.</p><p class="calibre8">As we can see in the resulting plot, the weight coefficients shrink if we decrease parameter <code class="email">C</code>, that is, if we increase the regularization strength:</p><div class="mediaobject"><img src="images/00062.jpeg" alt="Tackling overfitting via regularization" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1006" class="calibre1"></a>Note</h3><p class="calibre8">Since an in-depth coverage of the individual classification algorithms exceeds the scope of this book, I strongly recommend <span class="strong"><em class="calibre9">Logistic Regression: From Introductory to Advanced Concepts and Applications</em></span>, <span class="strong"><em class="calibre9">Dr. Scott Menard's</em></span>, <span class="strong"><em class="calibre9">Sage Publications</em></span>, <span class="strong"><em class="calibre9">2009</em></span>, to readers who want to learn more about logistic regression.</p></div></div></div></div>

<div id="calibre_link-614" class="calibre">
<div id="calibre_link-1007" class="calibre10"></div><div class="book" title="Maximum margin classification with support vector machines"><div class="book" id="calibre_link-253"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1008"><a id="calibre_link-1009" class="calibre1"></a>Maximum margin classification with support vector machines</h1></div></div></div><p class="calibre8">Another powerful <a id="calibre_link-1010" class="calibre1"></a>and widely used learning algorithm <a id="calibre_link-1011" class="calibre1"></a>is the <span class="strong"><strong class="calibre2">Support Vector Machine </strong></span>(<span class="strong"><strong class="calibre2">SVM</strong></span>), which can be considered an extension of the perceptron. Using the perceptron algorithm, we minimized misclassification errors. However, in SVMs our <a id="calibre_link-1012" class="calibre1"></a>optimization objective is to maximize the margin. The margin is defined as the distance between the separating hyperplane (decision boundary) and the training samples that are closest to this hyperplane, which are the <a id="calibre_link-1013" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">support vectors</strong></span>. This is illustrated in the following figure:</p><div class="mediaobject"><img src="images/00072.jpeg" alt="Maximum margin classification with support vector machines" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-617" class="calibre">
<div class="book" title="Maximum margin classification with support vector machines">
<div class="book" title="Maximum margin intuition"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1014"><a id="calibre_link-254" class="calibre1"></a>Maximum margin intuition</h2></div></div></div><p class="calibre8">The rationale behind having <a id="calibre_link-1015" class="calibre1"></a>decision boundaries with large margins is that they tend to have a lower generalization error whereas models with small margins are more prone to overfitting. To get an idea of the margin maximization, let's take a closer look at those <span class="strong"><em class="calibre9">positive</em></span> and <span class="strong"><em class="calibre9">negative</em></span> hyperplanes that are parallel to the decision boundary, which can be expressed as follows:</p><div class="mediaobject"><img src="images/00086.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00099.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">If we subtract those two linear equations (1) and (2) from each other, we get:</p><div class="mediaobject"><img src="images/00111.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can normalize this equation by the length of the vector <span class="strong"><strong class="calibre2">w</strong></span>, which is defined as follows:</p><div class="mediaobject"><img src="images/00124.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">So we arrive at the following equation:</p><div class="mediaobject"><img src="images/00132.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The left side of the preceding <a id="calibre_link-1016" class="calibre1"></a>equation can then be interpreted as the distance between the positive and negative hyperplane, which is the so-called <span class="strong"><strong class="calibre2">margin</strong></span>
<a id="calibre_link-1017" class="calibre1"></a> that we want to maximize.</p><p class="calibre8">Now, the objective function of the SVM becomes the maximization of this margin by maximizing <span class="strong"><img src="images/00149.jpeg" alt="Maximum margin intuition" class="calibre14" /></span> under the constraint that the samples are classified correctly, which can be written as:</p><div class="mediaobject"><img src="images/00160.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00613.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00182.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><em class="calibre9">N</em></span> is the number of samples in our dataset.</p><p class="calibre8">These two equations basically say that all negative samples should fall on one side of the negative hyperplane, whereas all the positive samples should fall behind the positive hyperplane, which can also be written more compactly as follows:</p><div class="mediaobject"><img src="images/00737.jpeg" alt="Maximum margin intuition" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In practice though, it is easier to minimize the reciprocal term <span class="strong"><img src="images/00794.jpeg" alt="Maximum margin intuition" class="calibre14" /></span>, which can be solved by quadratic programming. However, a detailed discussion about quadratic programming is beyond the scope of this book. You can learn more about support vector machines in <span class="strong"><em class="calibre9">The Nature of Statistical Learning Theory</em></span>, <span class="strong"><em class="calibre9"> Springer Science+Business Media</em></span>, <span class="strong"><em class="calibre9">Vladimir Vapnik</em></span>, 2000 or Chris J.C. Burges' excellent explanation in<span class="strong"><em class="calibre9"> A Tutorial on Support Vector Machines for Pattern Recognition</em></span> (<span class="strong"><em class="calibre9">Data Mining and Knowledge Discovery, 2(2)</em></span>: 121-167, <span class="strong"><em class="calibre9">1998</em></span>).</p></div></div></div>

<div id="calibre_link-624" class="calibre">
<div class="book" title="Maximum margin classification with support vector machines">
<div class="book" title="Dealing with a nonlinearly separable case using slack variables"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1018"><a id="calibre_link-255" class="calibre1"></a>Dealing with a nonlinearly separable case using slack variables</h2></div></div></div><p class="calibre8">Although we don't <a id="calibre_link-1019" class="calibre1"></a>want to dive<a id="calibre_link-1020" class="calibre1"></a> much deeper into the more involved mathematical concepts behind the maximum-margin classification, let us briefly mention the slack variable <span class="strong"><img src="images/00855.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre14" /></span>, which was introduced by Vladimir Vapnik in 1995 and led to the <a id="calibre_link-1021" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">soft-margin classification</strong></span>. The motivation for introducing the slack variable <span class="strong"><img src="images/00855.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre14" /></span> was that the linear constraints need to be relaxed for nonlinearly separable data to allow the convergence of the optimization in the presence of misclassifications, under appropriate cost penalization.</p><p class="calibre8">The positive-values slack variable is simply added to the linear constraints:</p><div class="mediaobject"><img src="images/00924.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00236.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00182.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><em class="calibre9">N</em></span> is the number of samples in our dataset. So the new objective to be minimized (subject to the constraints) becomes:</p><div class="mediaobject"><img src="images/00244.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Via the variable <code class="email">C</code>, we <a id="calibre_link-1022" class="calibre1"></a>can then control the <a id="calibre_link-1023" class="calibre1"></a>penalty for misclassification. Large values of <code class="email">C</code> correspond to large error penalties, whereas we are less strict about misclassification errors if we choose smaller values for <code class="email">C</code>. We can then use the <code class="email">C</code> parameter to control the width of the margin and therefore tune the bias-variance trade-off, as illustrated in the following figure:</p><div class="mediaobject"><img src="images/00257.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This concept is <a id="calibre_link-1024" class="calibre1"></a>related to<a id="calibre_link-1025" class="calibre1"></a> regularization, which we discussed in the previous section in the context of regularized regression where decreasing the value of <code class="email">C</code> increases the bias and lowers the variance of the model.</p><p class="calibre8">Now that we have learned the basic concepts behind a linear SVM, let us train an SVM model to classify the different flowers in our Iris dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.svm import SVC
&gt;&gt;&gt; svm = SVC(kernel='linear', C=1.0, random_state=1)
&gt;&gt;&gt; svm.fit(X_train_std, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined_std, 
...                       y_combined,
...                       classifier=svm, 
...                       test_idx=range(105, 150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The three decision regions of the SVM, visualized after training the classifier on the Iris dataset by executing the preceding code example, are shown in the following plot:</p><div class="mediaobject"><img src="images/00267.jpeg" alt="Dealing with a nonlinearly separable case using slack variables" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1026" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Logistic regression versus support vector machines</strong></span>
</p><p class="calibre8">In practical <a id="calibre_link-1027" class="calibre1"></a>classification tasks, linear<a id="calibre_link-1028" class="calibre1"></a> logistic regression and linear SVMs often yield very similar results. Logistic regression tries to maximize the conditional likelihoods of the training data, which makes it more prone to outliers than SVMs, which mostly care about the points that are closest to the decision boundary (support vectors). On the other hand, logistic regression has the advantage that it is a simpler model and can be implemented more easily. Furthermore, logistic regression models can be easily updated, which is attractive when working with streaming data.</p></div></div></div></div>

<div id="calibre_link-627" class="calibre">
<div class="book" title="Maximum margin classification with support vector machines">
<div class="book" title="Alternative implementations in scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1029"><a id="calibre_link-256" class="calibre1"></a>Alternative implementations in scikit-learn</h2></div></div></div><p class="calibre8">The scikit-learn library's <code class="email">Perceptron</code> and <code class="email">LogisticRegression</code> classes, which we used in the previous sections, make <a id="calibre_link-1030" class="calibre1"></a>use of the LIBLINEAR library, which is a highly optimized C/C++ library developed at the National Taiwan University (<a class="calibre1" href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">http://www.csie.ntu.edu.tw/~cjlin/liblinear/</a>). Similarly, the <code class="email">SVC</code> class that we used to train an SVM makes use of LIBSVM, which is an equivalent C/C++ library specialized for SVMs (<a class="calibre1" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</a>).</p><p class="calibre8">The advantage of using LIBLINEAR and LIBSVM over native Python implementations is that they allow the extremely quick training of large amounts of linear classifiers. However, sometimes our datasets are too large to fit into computer memory. Thus, scikit-learn also offers alternative implementations via the <code class="email">SGDClassifier</code> class, which also supports online learning via the <code class="email">partial_fit</code> method. The concept behind the <code class="email">SGDClassifier</code> class is similar to the stochastic gradient algorithm that we implemented in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, for Adaline. We could initialize the stochastic gradient descent version of the perceptron, logistic regression, and a support <a id="calibre_link-1031" class="calibre1"></a>vector machine with default parameters as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import SGDClassifier
&gt;&gt;&gt; ppn = SGDClassifier(loss='perceptron')
&gt;&gt;&gt; lr = SGDClassifier(loss='log')
&gt;&gt;&gt; svm = SGDClassifier(loss='hinge')</pre></div></div></div></div>

<div id="calibre_link-628" class="calibre">
<div id="calibre_link-1032" class="calibre10"></div><div class="book" title="Solving nonlinear problems using a kernel SVM"><div class="book" id="calibre_link-84"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1033"><a id="calibre_link-1034" class="calibre1"></a>Solving nonlinear problems using a kernel SVM</h1></div></div></div><p class="calibre8">Another reason why<a id="calibre_link-1035" class="calibre1"></a> SVMs enjoy high popularity among <a id="calibre_link-1036" class="calibre1"></a>machine learning practitioners is that it can be easily <span class="strong"><strong class="calibre2">kernelized</strong></span> to solve nonlinear classification problems. Before we discuss the main concept behind a <span class="strong"><strong class="calibre2">kernel SVM</strong></span>, let's first create a sample dataset to see what such a nonlinear classification problem may look like.</p></div></div>

<div id="calibre_link-632" class="calibre">
<div class="book" title="Solving nonlinear problems using a kernel SVM">
<div class="book" title="Kernel methods for linearly inseparable data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1037"><a id="calibre_link-257" class="calibre1"></a>Kernel methods for linearly inseparable data</h2></div></div></div><p class="calibre8">Using the following code, we<a id="calibre_link-1038" class="calibre1"></a> will create a simple dataset that has the form of an XOR gate using the <code class="email">logical_or</code> function from NumPy, where 100 samples will be assigned the class label <code class="email">1</code>, and 100 samples will be assigned the class label <code class="email">-1</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(1)
&gt;&gt;&gt; X_xor = np.random.randn(200, 2)
&gt;&gt;&gt; y_xor = np.logical_xor(X_xor[:, 0] &gt; 0,
...                        X_xor[:, 1] &gt; 0)
&gt;&gt;&gt; y_xor = np.where(y_xor, 1, -1)
&gt;&gt;&gt; plt.scatter(X_xor[y_xor == 1, 0],
...             X_xor[y_xor == 1, 1],
...             c='b', marker='x',
...             label='1')
&gt;&gt;&gt; plt.scatter(X_xor[y_xor == -1, 0],
...             X_xor[y_xor == -1, 1],
...             c='r',
...             marker='s',
...             label='-1')
&gt;&gt;&gt; plt.xlim([-3, 3])
&gt;&gt;&gt; plt.ylim([-3, 3])
&gt;&gt;&gt; plt.legend(loc='best')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the code, we will have an XOR dataset with random noise, as shown in the following figure:</p><div class="mediaobject"><img src="images/00280.jpeg" alt="Kernel methods for linearly inseparable data" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Obviously, we would <a id="calibre_link-1039" class="calibre1"></a>not be able to separate samples from the positive and negative class very well using a linear hyperplane as a decision boundary via the linear logistic regression or linear SVM model that we discussed in earlier sections.</p><p class="calibre8">The basic idea behind <span class="strong"><strong class="calibre2">kernel methods</strong></span> to deal with such linearly inseparable data is to create nonlinear combinations of the original features to project them onto a higher-dimensional space via a mapping function <span class="strong"><img src="images/00293.jpeg" alt="Kernel methods for linearly inseparable data" class="calibre14" /></span> where it becomes linearly separable. As shown in the following figure, we can transform a two-dimensional dataset onto a new three-dimensional feature space where the classes become separable via the following projection:</p><div class="mediaobject"><img src="images/00302.jpeg" alt="Kernel methods for linearly inseparable data" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This allows us to separate <a id="calibre_link-1040" class="calibre1"></a>the two classes shown in the plot via a linear hyperplane that becomes a nonlinear decision boundary if we project it back onto the original feature space:</p><div class="mediaobject"><img src="images/00309.jpeg" alt="Kernel methods for linearly inseparable data" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-507" class="calibre">
<div class="book" title="Solving nonlinear problems using a kernel SVM">
<div class="book" title="Using the kernel trick to find separating hyperplanes in high-dimensional space"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1041"><a id="calibre_link-258" class="calibre1"></a>Using the kernel trick to find separating hyperplanes in high-dimensional space</h2></div></div></div><p class="calibre8">To solve a<a id="calibre_link-1042" class="calibre1"></a> nonlinear problem using an SVM, we would transform the training data onto a higher-dimensional feature space via a mapping function <span class="strong"><img src="images/00293.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> and train a linear SVM model to classify the data in this new feature space. Then, we can use the same mapping function <span class="strong"><img src="images/00293.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> to transform new, unseen data to classify it using the linear SVM model.</p><p class="calibre8">However, one problem with this mapping approach is that the construction of the new features is computationally very expensive, especially if we are dealing with high-dimensional data. This is where the so-called kernel trick comes into play. Although we didn't go into much detail about how to solve the quadratic programming task to train an SVM, in practice all we need is to replace the dot product <span class="strong"><img src="images/00322.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> by <span class="strong"><img src="images/00334.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span>. In order to save the expensive step of calculating this dot product between two points explicitly, we define a <a id="calibre_link-1043" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">kernel function</strong></span>: <span class="strong"><img src="images/00558.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span>.</p><p class="calibre8">One of the most <a id="calibre_link-1044" class="calibre1"></a>widely used kernels is the <span class="strong"><strong class="calibre2">Radial Basis Function</strong></span> (<span class="strong"><strong class="calibre2">RBF</strong></span>)<a id="calibre_link-1045" class="calibre1"></a> kernel or simply called<a id="calibre_link-1046" class="calibre1"></a> the <span class="strong"><strong class="calibre2">Gaussian kernel</strong></span>:</p><div class="mediaobject"><img src="images/00615.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This is often simplified to:</p><div class="mediaobject"><img src="images/00362.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00374.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> is a free parameter that is to be optimized.</p><p class="calibre8">Roughly speaking, the term <span class="strong"><strong class="calibre2">kernel</strong></span> can be interpreted as a<a id="calibre_link-1047" class="calibre1"></a> <span class="strong"><strong class="calibre2">similarity function</strong></span> between a pair of samples. The minus sign inverts the distance measure into a similarity score, and, due to the exponential term, the resulting similarity score will fall into a range between 1 (for exactly similar samples) and 0 (for very dissimilar samples).</p><p class="calibre8">Now that we defined the big picture behind the kernel trick, let us see if we can train a kernel SVM that is able to draw a nonlinear decision boundary that separates the XOR data well. Here, we simply use the <code class="email">SVC</code> class from scikit-learn that we imported earlier and replace the <code class="email">kernel='linear'</code> parameter with <code class="email">kernel='rbf'</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; svm = SVC(kernel='rbf', random_state=1, gamma=0.10, C=10.0)
&gt;&gt;&gt; svm.fit(X_xor, y_xor)
&gt;&gt;&gt; plot_decision_regions(X_xor, y_xor, classifier=svm)
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the <a id="calibre_link-1048" class="calibre1"></a>resulting plot, the kernel SVM separates the XOR data relatively well:</p><div class="mediaobject"><img src="images/00385.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> parameter, which we set to <code class="email">gamma=0.1</code>, can be understood as a <span class="strong"><strong class="calibre2">cut-off</strong></span> parameter<a id="calibre_link-1049" class="calibre1"></a> for the Gaussian sphere. If we increase the value for <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span>, we increase the influence or reach of the training samples, which leads to a tighter and bumpier decision boundary. To get a better intuition for <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span>, let us apply an RBF kernel SVM to our Iris flower dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; svm = SVC(kernel='rbf', random_state=1, gamma=0.2, C=1.0)
&gt;&gt;&gt; svm.fit(X_train_std, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined_std, 
...                       y_combined, classifier=svm,
...                       test_idx=range(105,150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Since we chose<a id="calibre_link-1050" class="calibre1"></a> a relatively small value for <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span>, the resulting decision boundary of the RBF kernel SVM model will be relatively soft, as shown in the following figure:</p><div class="mediaobject"><img src="images/00927.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, let us increase the value of <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> and observe the effect on the decision boundary:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; svm = SVC(kernel='rbf', random_state=1, gamma=100.0, C=1.0)
&gt;&gt;&gt; svm.fit(X_train_std, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined_std,
...                       y_combined, classifier=svm,
...                       test_idx=range(105,150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">In the resulting plot, we <a id="calibre_link-1051" class="calibre1"></a>can now see that the decision boundary around the classes <code class="email">0</code> and <code class="email">1</code> is much tighter using a relatively large value of <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00412.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although the model fits the training dataset very well, such a classifier will likely have a high generalization error on unseen data. This illustrates that the <span class="strong"><img src="images/00856.jpeg" alt="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre14" /></span> parameter also plays an important role in controlling overfitting.</p></div></div></div>

<div id="calibre_link-639" class="calibre">
<div id="calibre_link-1052" class="calibre10"></div><div class="book" title="Decision tree learning"><div class="book" id="calibre_link-71"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1053"><a id="calibre_link-1054" class="calibre1"></a>Decision tree learning</h1></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Decision tree</strong></span> classifiers are <a id="calibre_link-1055" class="calibre1"></a>attractive models if we care about interpretability. As the name decision tree suggests, we can think of this model as breaking down our data by making decision based on asking a series of questions.</p><p class="calibre8">Let's consider the following example in which we use a decision tree to decide upon an activity on a particular day:</p><div class="mediaobject"><img src="images/00069.jpeg" alt="Decision tree learning" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Based on the <a id="calibre_link-1056" class="calibre1"></a>features in our training set, the decision tree model learns a series of questions to infer the class labels of the samples. Although the preceding figure illustrates the concept of a decision tree based on categorical variables, the same concept applies if our features are real numbers, like in the Iris dataset. For example, we could simply define a cut-off value along the <span class="strong"><strong class="calibre2">sepal width </strong></span>feature axis<a id="calibre_link-1057" class="calibre1"></a> and ask a binary question "Is sepal width â¥ 2.8 cm?."</p><p class="calibre8">Using the decision algorithm, we start at the tree root and split the data on the feature that results in the <a id="calibre_link-1058" class="calibre1"></a>largest <span class="strong"><strong class="calibre2">Information Gain</strong></span> (<span class="strong"><strong class="calibre2">IG</strong></span>), which will be explained in more detail in the following section. In an iterative process, we can then repeat this splitting procedure at each child node until the leaves are pure. This means that the samples at each node all belong to the same class. In practice, this can result in a very deep tree with many nodes, which can easily lead to overfitting. Thus, we typically want to <span class="strong"><strong class="calibre2">prune</strong></span>
<a id="calibre_link-1059" class="calibre1"></a> the tree by setting a limit for the maximal depth of the tree.</p></div></div>

<div id="calibre_link-643" class="calibre">
<div class="book" title="Decision tree learning">
<div class="book" title="Maximizing information gain â getting the most bang for your buck"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1060"><a id="calibre_link-259" class="calibre1"></a>Maximizing information gain &ndash; getting the most bang for your buck</h2></div></div></div><p class="calibre8">In order to split the nodes at the <a id="calibre_link-1061" class="calibre1"></a>most informative features, we need to define an objective function that we want to optimize via the tree learning algorithm. Here, our objective function is to maximize the information gain at each split, which we define as follows:</p><div class="mediaobject"><img src="images/00440.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><em class="calibre9">f</em></span> is the feature to perform the split, <span class="strong"><img src="images/00188.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> and <span class="strong"><img src="images/00012.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> are the dataset of the parent and <span class="strong"><em class="calibre9">j</em></span>th child node, <span class="strong"><em class="calibre9">I</em></span> is <a id="calibre_link-1062" class="calibre1"></a>our <span class="strong"><strong class="calibre2">impurity</strong></span> measure, <span class="strong"><img src="images/00023.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> is the total number of samples at the parent node, and <span class="strong"><img src="images/00004.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> is the number of samples in the <span class="strong"><em class="calibre9">j</em></span>th child node. As we can see, the information gain is simply the difference between the impurity of the parent node and the sum of the child node impurities &mdash; the lower the impurity of the child nodes, the larger the information gain. However, for simplicity and to reduce the combinatorial search space, most libraries (including scikit-learn) implement binary decision trees. This means that each parent node is split into two child nodes, <span class="strong"><img src="images/00036.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> and <span class="strong"><img src="images/00047.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00874.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, the three impurity measures or splitting criteria that are <a id="calibre_link-1063" class="calibre1"></a>commonly used in binary decision trees<a id="calibre_link-1064" class="calibre1"></a> are <span class="strong"><strong class="calibre2">Gini impurity</strong></span> (<span class="strong"><img src="images/00065.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>), <span class="strong"><strong class="calibre2">entropy</strong></span> (<span class="strong"><img src="images/00077.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>), and<a id="calibre_link-1065" class="calibre1"></a> the <span class="strong"><strong class="calibre2">classification error</strong></span> (<span class="strong"><img src="images/00091.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>). Let us start with the definition of entropy for <a id="calibre_link-1066" class="calibre1"></a>all <span class="strong"><strong class="calibre2">non-empty</strong></span> classes (<span class="strong"><img src="images/00100.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>):</p><div class="mediaobject"><img src="images/00112.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00265.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> is the <a id="calibre_link-1067" class="calibre1"></a>proportion of the samples that belong to class <span class="strong"><em class="calibre9">c</em></span> for a particular node <span class="strong"><em class="calibre9">t</em></span>. The entropy is therefore 0 if all samples at a node belong to the same class, and the entropy is maximal if we have a uniform class distribution. For example, in a binary class setting, the entropy is 0 if <span class="strong"><img src="images/00133.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> or <span class="strong"><img src="images/00146.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>. If the classes are distributed uniformly with <span class="strong"><img src="images/00157.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> and <span class="strong"><img src="images/00172.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>, the entropy is 1. Therefore, we can say that the entropy criterion attempts to maximize the mutual information in the tree.</p><p class="calibre8">Intuitively, the Gini impurity can be understood as a criterion to minimize the probability of misclassification:</p><div class="mediaobject"><img src="images/00181.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similar to entropy, the Gini impurity is maximal if the classes are perfectly mixed, for example, in a binary class setting (<span class="strong"><img src="images/00193.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>):</p><div class="mediaobject"><img src="images/00205.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, in practice<a id="calibre_link-1068" class="calibre1"></a> both Gini impurity and entropy typically yield very similar results, and it is often not worth spending much time on evaluating trees using different impurity criteria rather than experimenting with different pruning cut-offs.</p><p class="calibre8">Another impurity measure is the classification error:</p><div class="mediaobject"><img src="images/00218.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This is a useful criterion for pruning but not recommended for growing a decision tree, since it is less sensitive to changes in the class probabilities of the nodes. We can illustrate this by looking at the two possible splitting scenarios shown in the following figure:</p><div class="mediaobject"><img src="images/00752.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We start with a dataset <span class="strong"><img src="images/00188.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> at the parent node <span class="strong"><img src="images/00188.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>, which consists 40 samples from class 1 and 40 samples from class 2 that we split into two datasets, <span class="strong"><img src="images/00036.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span> and <span class="strong"><img src="images/00047.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>. The information gain using the classification error as a splitting criterion would be the same (<span class="strong"><img src="images/00237.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>) in both scenarios, A and B:</p><div class="mediaobject"><img src="images/00246.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00260.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00270.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00282.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00295.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00303.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00313.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, the Gini impurity<a id="calibre_link-1069" class="calibre1"></a> would favor the split in scenario B (<span class="strong"><img src="images/00319.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>) over scenario A (<span class="strong"><img src="images/00331.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>), which is indeed more pure:</p><div class="mediaobject"><img src="images/00343.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00355.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00359.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00371.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00383.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00393.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00403.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similarly, the entropy<a id="calibre_link-1070" class="calibre1"></a> criterion would also favor scenario B (<span class="strong"><img src="images/00414.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>) over scenario A (<span class="strong"><img src="images/00885.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre14" /></span>):</p><div class="mediaobject"><img src="images/00957.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00040.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00009.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00020.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00001.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00032.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00043.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">For a more visual comparison of the three different impurity criteria that we discussed previously, let us plot <a id="calibre_link-1071" class="calibre1"></a>the impurity indices for the probability range [0, 1] for class 1. Note that we will also add a scaled version of the entropy (entropy / 2) to observe that the Gini impurity is an intermediate measure between entropy and the classification error. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; def gini(p):
...     return (p)*(1 - (p)) + (1 - p)*(1 - (1-p))
&gt;&gt;&gt; def entropy(p):
...     return - p*np.log2(p) - (1 - p)*np.log2((1 - p))
&gt;&gt;&gt; def error(p):
...     return 1 - np.max([p, 1 - p])
&gt;&gt;&gt; x = np.arange(0.0, 1.0, 0.01)
&gt;&gt;&gt; ent = [entropy(p) if p != 0 else None for p in x]
&gt;&gt;&gt; sc_ent = [e*0.5 if e else None for e in ent]
&gt;&gt;&gt; err = [error(i) for i in x]
&gt;&gt;&gt; fig = plt.figure()
&gt;&gt;&gt; ax = plt.subplot(111)
&gt;&gt;&gt; for i, lab, ls, c, in zip([ent, sc_ent, gini(x), err], 
...                   ['Entropy', 'Entropy (scaled)', 
...                       'Gini Impurity', 
...                       'Misclassification Error'],
...                   ['-', '-', '--', '-.'],
...                   ['black', 'lightgray',
...                      'red', 'green', 'cyan']):
...     line = ax.plot(x, i, label=lab, 
...                    linestyle=ls, lw=2, color=c)
&gt;&gt;&gt; ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),
...           ncol=5, fancybox=True, shadow=False)
&gt;&gt;&gt; ax.axhline(y=0.5, linewidth=1, color='k', linestyle='--')
&gt;&gt;&gt; ax.axhline(y=1.0, linewidth=1, color='k', linestyle='--')
&gt;&gt;&gt; plt.ylim([0, 1.1])
&gt;&gt;&gt; plt.xlabel('p(i=1)')
&gt;&gt;&gt; plt.ylabel('Impurity Index')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The plot produced by the preceding code example is as follows:</p><div class="mediaobject"><img src="images/00057.jpeg" alt="Maximizing information gain â getting the most bang for your buck" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-646" class="calibre">
<div class="book" title="Decision tree learning">
<div class="book" title="Building a decision tree"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1072"><a id="calibre_link-260" class="calibre1"></a>Building a decision tree</h2></div></div></div><p class="calibre8">Decision trees can build complex<a id="calibre_link-1073" class="calibre1"></a> decision boundaries by dividing the feature space into rectangles. However, we have to be careful since the deeper the decision tree, the more complex the decision boundary becomes, which can easily result in overfitting. Using scikit-learn, we will now train a decision tree with a maximum depth of 3, using entropy as a criterion for impurity. Although feature scaling may be desired for visualization purposes, note that feature scaling is not a requirement for decision tree algorithms. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier
&gt;&gt;&gt; tree = DecisionTreeClassifier(criterion='gini',
...                               max_depth=4, 
...                               random_state=1)
&gt;&gt;&gt; tree.fit(X_train, y_train)
&gt;&gt;&gt; X_combined = np.vstack((X_train, X_test))
&gt;&gt;&gt; y_combined = np.hstack((y_train, y_test))
&gt;&gt;&gt; plot_decision_regions(X_combined, 
...                       y_combined, 
...                       classifier=tree, 
...                       test_idx=range(105, 150))
&gt;&gt;&gt; plt.xlabel('petal length [cm]')
&gt;&gt;&gt; plt.ylabel('petal width [cm]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the code example, we get the typical axis-parallel decision boundaries of the decision tree:</p><div class="mediaobject"><img src="images/00063.jpeg" alt="Building a decision tree" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">A nice feature <a id="calibre_link-1074" class="calibre1"></a>in scikit-learn is that it allows us to export the decision tree as a <code class="email">.dot</code> file after training, which we can visualize using the GraphViz program, for example. </p><p class="calibre8">This program is freely available from <a class="calibre1" href="http://www.graphviz.org">http://www.graphviz.org</a> and supported by Linux, Windows, and macOS. In addition to GraphViz, we will use a Python library called <code class="email">pydotplus</code>, which has capabilities similar to GraphViz and allows us to convert <code class="email">.dot</code> data files into a decision tree image file. After you installed GraphViz (by following the instructions on <a class="calibre1" href="http://www.graphviz.org/Download.php">http://www.graphviz.org/Download.php</a>), you can install <code class="email">pydotplus</code> directly via the pip installer, for example, by executing the following command in your Terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; pip3 install pydotplus</strong></span>
</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1075" class="calibre1"></a>Note</h3><p class="calibre8">Note that on some systems, you may have to install the <code class="email">pydotplus</code> prerequisites manually by executing the following commands:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip3 install graphviz</strong></span>
<span class="strong"><strong class="calibre2">pip3 install pyparsing</strong></span>
</pre></div></div><p class="calibre8">The following code will create an image of our decision tree in PNG format in our local directory:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from pydotplus import graph_from_dot_data
&gt;&gt;&gt; from sklearn.tree import export_graphviz
&gt;&gt;&gt; dot_data = export_graphviz(tree,
...                            filled=True, 
...                            rounded=True,
...                            class_names=['Setosa', 
...                                         'Versicolor',
...                                         'Virginica'],
...                            feature_names=['petal length', 
...                                           'petal width'],
...                            out_file=None) 
&gt;&gt;&gt; graph = graph_from_dot_data(dot_data) 
&gt;&gt;&gt; graph.write_png('tree.png')</pre></div><p class="calibre8">By using the <code class="email">out_file=None</code> setting, we directly assigned the dot data to a <code class="email">dot_data</code> variable, instead of writing an intermediate <code class="email">tree.dot</code> file to disk. The arguments for <code class="email">filled</code>, <code class="email">rounded</code>, <code class="email">class_names</code>, and <code class="email">feature_names</code> are optional but make the resulting image file<a id="calibre_link-1076" class="calibre1"></a> visually more appealing by adding color, rounding the box edges, showing the name of the majority class label at each node, and displaying the feature names in the splitting criterion. These settings resulted in the following decision tree image:</p><div class="mediaobject"><img src="images/00073.jpeg" alt="Building a decision tree" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Looking at the decision tree figure, we can now nicely trace back the splits that the decision tree determined from our training dataset. We started with 105 samples at the root and split them into two child nodes with 35 and 70 samples, using the <span class="strong"><strong class="calibre2">petal width</strong></span> cut-off â¤ 0.75 cm. After the first split, we can see that the left child node is already pure and only contains samples from the <code class="email">Iris-setosa</code> class (Gini Impurity = 0). The further splits on the right are then used to separate the samples from the <code class="email">Iris-versicolor</code> and <code class="email">Iris-virginica</code> class.</p><p class="calibre8">Looking at this tree, and the<a id="calibre_link-1077" class="calibre1"></a> decision region plot of the tree, we see that the decision tree does a very good job of separating the flower classes. Unfortunately, scikit-learn currently does not implement functionality to manually post-prune a decision tree. However, we could go back to our previous code example, change the <code class="email">max_depth</code> of our decision tree to <code class="email">3</code>, and compare it to our current model, but we leave this as an exercise for the interested reader.</p></div></div></div>

<div id="calibre_link-650" class="calibre">
<div class="book" title="Decision tree learning">
<div class="book" title="Combining multiple decision trees via random forests"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1078"><a id="calibre_link-261" class="calibre1"></a>Combining multiple decision trees via random forests</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Random forests</strong></span> have gained <a id="calibre_link-1079" class="calibre1"></a>huge popularity in<a id="calibre_link-1080" class="calibre1"></a> applications of machine learning during the last decade due to their good classification performance, scalability, and ease of use. Intuitively, a random forest can be considered as an <span class="strong"><strong class="calibre2">ensemble</strong></span> of decision trees. The idea behind a random forest is to average multiple (deep) decision trees that individually suffer from high variance, to build a more robust model that has a better generalization performance and is less susceptible to overfitting. The random forest algorithm can be summarized in four simple steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Draw a random <span class="strong"><strong class="calibre2">bootstrap</strong></span> sample of size <span class="strong"><em class="calibre9">n</em></span> (randomly choose <span class="strong"><em class="calibre9">n</em></span> samples from the training set with replacement).</li><li class="listitem" value="2">Grow a decision tree from the bootstrap sample. At each node:<p class="calibre16">a. Randomly select <span class="strong"><em class="calibre9">d</em></span> features without replacement.</p><p class="calibre16">b. Split the node using the feature that provides the best split according to the objective function, for instance, maximizing the information gain.</p></li><li class="listitem" value="3">Repeat the steps 1-2 <span class="strong"><em class="calibre9">k</em></span> times.</li><li class="listitem" value="4">Aggregate the prediction by each tree to assign the class label by <span class="strong"><strong class="calibre2">majority vote</strong></span>. Majority voting will be discussed in more detail in <a class="calibre1" title="ChapterÂ 7.Â Combining Different Models for Ensemble Learning" href="#calibre_link-38">Chapter 7</a>, <span class="strong"><em class="calibre9">Combining Different Models for Ensemble Learning</em></span>.</li></ol><div class="calibre13"></div></div><p class="calibre8">We should note one slight modification in step 2 when we are training the individual decision trees: instead of evaluating all features to determine the best split at each node, we only consider a random subset of those.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1081" class="calibre1"></a>Note</h3><p class="calibre8">In case you are not familiar with the terms sampling <span class="strong"><em class="calibre9">with</em></span> and <span class="strong"><em class="calibre9">without</em></span> replacement, let's walk through a simple thought experiment. Let's assume we are playing a lottery game where we randomly draw numbers from an urn. We start with an urn that holds five unique numbers, 0, 1, 2, 3, and 4, and we draw exactly one number each turn. In the first round, the chance of drawing a particular number from the urn would be 1/5. Now, in sampling without replacement, we do not put the number back into the urn after each turn. Consequently, the probability of drawing a particular number from the set of remaining numbers in the next round depends on the previous round. For example, if we have a remaining set of numbers 0, 1, 2, and 4, the chance of drawing number 0 would become 1/4 in the next turn.</p><p class="calibre8">However, in random sampling with replacement, we always return the drawn number to the urn so that the probabilities of drawing a particular number at each turn does not change; we can draw the same number more than once. In other words, in sampling <span class="strong"><em class="calibre9">with</em></span> replacement, the samples (numbers) are independent and have a covariance of zero. For example, the results from five rounds of drawing random numbers could look like this:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Random sampling without replacement: 2, 1, 3, 4, 0</li><li class="listitem">Random sampling with replacement: 1, 3, 3, 4, 1</li></ul></div></div><p class="calibre8">Although<a id="calibre_link-1082" class="calibre1"></a> random forests don't offer the<a id="calibre_link-1083" class="calibre1"></a> same level of interpretability as decision trees, a big advantage of random forests is that we don't have to worry so much about choosing good hyperparameter values. We typically don't need to prune the random forest since the ensemble model is quite robust to noise from the individual decision trees. The only parameter that we really need to care about in practice is the number of trees <span class="strong"><em class="calibre9">k</em></span> (step 3) that we choose for the random forest. Typically, the larger the number of trees, the better the performance of the random forest classifier at the expense of an increased computational cost.</p><p class="calibre8">Although it is less common in practice, other hyperparameters of the random forest classifier that can be optimized&mdash;using techniques we will discuss in <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>&mdash;are the size <span class="strong"><em class="calibre9">n</em></span> of the bootstrap sample (step 1) and the number of features <span class="strong"><em class="calibre9">d</em></span> that is randomly chosen for each split (step 2.1), respectively. Via the sample size <span class="strong"><em class="calibre9">n</em></span> of the bootstrap sample, we control the bias-variance tradeoff of the random forest.</p><p class="calibre8">Decreasing the size of the bootstrap sample increases the diversity among the individual trees, since the probability that a particular training sample is included in the bootstrap sample is lower. Thus, shrinking the size of the bootstrap samples may increase the <span class="strong"><em class="calibre9">randomness</em></span> of the random forest, and it can help to reduce the effect of overfitting. However, smaller bootstrap samples typically result in a lower overall performance of the random forest, a small gap between training and test performance, but a low test performance overall. Conversely, increasing the size of the bootstrap sample may increase the degree of overfitting. Because the bootstrap samples, and consequently the individual decision trees, become more similar to each other, they learn to fit the original training dataset more closely.</p><p class="calibre8">In most implementations, including the <code class="email">RandomForestClassifier</code> implementation in scikit-learn, the size of the bootstrap sample is chosen to be equal to the number of samples in the original training set, which usually provides a good bias-variance tradeoff. For the number of <a id="calibre_link-1084" class="calibre1"></a>features <span class="strong"><em class="calibre9">d</em></span> at each split, we <a id="calibre_link-1085" class="calibre1"></a>want to choose a value that is smaller than the total number of features in the training set. A reasonable default that is used in scikit-learn and other implementations is <span class="strong"><img src="images/00087.jpeg" alt="Combining multiple decision trees via random forests" class="calibre14" /></span>, where <span class="strong"><em class="calibre9">m</em></span> is the number of features in the training set.</p><p class="calibre8">Conveniently, we don't have to construct the random forest classifier from individual decision trees by ourselves because there is already an implementation in scikit-learn that we can use:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier
&gt;&gt;&gt; forest = RandomForestClassifier(criterion='gini',
...                                 n_estimators=25,
...                                 random_state=1,
...                                 n_jobs=2)
&gt;&gt;&gt; forest.fit(X_train, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined, y_combined, 
...                classifier=forest, test_idx=range(105,150))
&gt;&gt;&gt; plt.xlabel('petal length')
&gt;&gt;&gt; plt.ylabel('petal width')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the preceding code, we should see the decision regions formed by the ensemble of trees in the random forest, as shown in the following figure:</p><div class="mediaobject"><img src="images/00102.jpeg" alt="Combining multiple decision trees via random forests" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Using the <a id="calibre_link-1086" class="calibre1"></a>preceding code, we trained a random <a id="calibre_link-1087" class="calibre1"></a>forest from 25 decision trees via the <code class="email">n_estimators</code> parameter and used the entropy criterion as an impurity measure to split the nodes. Although we are growing a very small random forest from a very small training dataset, we used the <code class="email">n_jobs</code> parameter for demonstration purposes, which allows us to parallelize the model training using multiple cores of our computer (here two cores).</p></div></div></div>

<div id="calibre_link-653" class="calibre"><div class="book" title="K-nearest neighbors â a lazy learning algorithm"><div class="book" id="calibre_link-81"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1088"><a id="calibre_link-1089" class="calibre1"></a>K-nearest neighbors &ndash; a lazy learning algorithm</h1></div></div></div><p class="calibre8">The last supervised learning algorithm that we want to discuss in this chapter is the <span class="strong"><strong class="calibre2">k-nearest neighbor</strong></span> (<span class="strong"><strong class="calibre2">KNN</strong></span>) classifier, which <a id="calibre_link-1090" class="calibre1"></a>is particularly interesting because it is fundamentally different from the learning algorithms that we have discussed so far.</p><p class="calibre8">KNN is a typical example of <a id="calibre_link-1091" class="calibre1"></a>a <span class="strong"><strong class="calibre2">lazy learner</strong></span>. It is called <span class="strong"><em class="calibre9">lazy</em></span> not because of its apparent simplicity, but because it doesn't learn a discriminative function from the training data, but memorizes the training dataset instead.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1092" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Parametric versus nonparametric models</strong></span>
</p><p class="calibre8">Machine learning algorithms can be grouped into <span class="strong"><strong class="calibre2">parametric </strong></span>and <span class="strong"><strong class="calibre2">nonparametric</strong></span> models<a id="calibre_link-1093" class="calibre1"></a>. Using parametric models, we estimate parameters from the training dataset to learn a function that <a id="calibre_link-1094" class="calibre1"></a>can classify new data points without requiring the original training dataset anymore. Typical examples of parametric models are the perceptron, logistic regression, and the linear SVM. In contrast, nonparametric models can't be characterized by a fixed set of parameters, and the number of parameters grows with the training data. Two examples of non-parametric models that we have seen so far are the decision tree classifier/random forest and the kernel SVM.</p><p class="calibre8">KNN belongs to a subcategory of nonparametric models that is described as <span class="strong"><strong class="calibre2">instance-based learning</strong></span>. Models based on <a id="calibre_link-1095" class="calibre1"></a>instance-based learning are characterized by memorizing the training dataset, and lazy learning is a special case of instance-based learning that is associated with no (zero) cost during the learning process.</p></div><p class="calibre8">The KNN algorithm itself is fairly straightforward and can be summarized by the following steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Choose the number of <span class="strong"><em class="calibre9">k</em></span> and a distance metric.</li><li class="listitem" value="2">Find the <span class="strong"><em class="calibre9">k</em></span>-nearest neighbors of the sample that we want to classify.</li><li class="listitem" value="3">Assign the class label by majority vote.</li></ol><div class="calibre13"></div></div><p class="calibre8">The following <a id="calibre_link-1096" class="calibre1"></a>figure illustrates how a new data point (?) is assigned the triangle class label based on majority voting among its five nearest neighbors.</p><div class="mediaobject"><img src="images/00114.jpeg" alt="K-nearest neighbors â a lazy learning algorithm" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Based on the chosen distance metric, the KNN algorithm finds the <span class="strong"><em class="calibre9">k</em></span> samples in the training dataset that are closest (most similar) to the point that we want to classify. The class label of the new data point is then determined by a majority vote among its <span class="strong"><em class="calibre9">k</em></span> nearest neighbors.</p><p class="calibre8">The main advantage of such a memory-based approach is that the classifier immediately adapts as we collect new training data. However, the downside is that the computational complexity for classifying new samples grows linearly with the number of samples in the training dataset in the worst-case scenario&mdash;unless the dataset has very few dimensions (features) and the algorithm has been implemented using efficient data structures such as KD-trees. <span class="strong"><em class="calibre9">An Algorithm for Finding Best Matches in Logarithmic Expected Time</em></span>, <span class="strong"><em class="calibre9">J. H. Friedman</em></span>, <span class="strong"><em class="calibre9">J. L. Bentley</em></span>, and <span class="strong"><em class="calibre9">R.A. Finkel</em></span>, <span class="strong"><em class="calibre9">ACM transactions on mathematical software </em></span>(<span class="strong"><em class="calibre9">TOMS</em></span>), <span class="strong"><em class="calibre9">3(3): 209&ndash;226</em></span>, <span class="strong"><em class="calibre9">1977</em></span>. Furthermore, we can't discard training samples since no <span class="strong"><em class="calibre9">training</em></span> step is involved. Thus, storage space can become a challenge if we are working with large datasets.</p><p class="calibre8">By executing the <a id="calibre_link-1097" class="calibre1"></a>following code, we will now implement a KNN model in scikit-learn using a Euclidean distance metric:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; knn = KNeighborsClassifier(n_neighbors=5, p=2,
...                            metric='minkowski')
&gt;&gt;&gt; knn.fit(X_train_std, y_train)
&gt;&gt;&gt; plot_decision_regions(X_combined_std, y_combined, 
...                       classifier=knn, test_idx=range(105,150))
&gt;&gt;&gt; plt.xlabel('petal length [standardized]')
&gt;&gt;&gt; plt.ylabel('petal width [standardized]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">By specifying five neighbors in the KNN model for this dataset, we obtain a relatively smooth decision boundary, as shown in the following figure:</p><div class="mediaobject"><img src="images/00120.jpeg" alt="K-nearest neighbors â a lazy learning algorithm" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1098" class="calibre1"></a>Note</h3><p class="calibre8">In the case of a tie, the scikit-learn implementation of the KNN algorithm will prefer the neighbors with a closer distance to the sample. If the neighbors have similar distances, the algorithm will choose the class label that comes first in the training dataset.</p></div><p class="calibre8">The <span class="strong"><em class="calibre9">right</em></span> choice of <span class="strong"><em class="calibre9">k</em></span> is crucial to find a good balance between overfitting and underfitting. We also have to make sure that we choose a distance metric that is appropriate for the features in the dataset. Often, a simple Euclidean distance measure is used for real-value samples, for example, the flowers in our Iris dataset, which have features measured in centimeters. However, if we are using a Euclidean distance measure, it is also important to standardize the data so that each feature contributes equally to the distance. The <code class="email">minkowski</code> distance that we used in the previous code is just a generalization of the <a id="calibre_link-1099" class="calibre1"></a>Euclidean and Manhattan distance, which can be written as follows:</p><div class="mediaobject"><img src="images/00134.jpeg" alt="K-nearest neighbors â a lazy learning algorithm" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">It becomes the Euclidean distance if we set the parameter <code class="email">p=2</code> or the Manhattan distance at <code class="email">p=1</code>. Many other distance metrics are available in scikit-learn and can be provided to the metric parameter. They are listed at <a class="calibre1" href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1100" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">The curse of dimensionality</strong></span>
</p><p class="calibre8">It is important to mention that KNN is very susceptible to overfitting due to the <span class="strong"><strong class="calibre2">curse of dimensionality</strong></span>. The curse<a id="calibre_link-1101" class="calibre1"></a> of dimensionality describes the phenomenon where the feature space becomes increasingly sparse for an increasing number of dimensions of a fixed-size training dataset. Intuitively, we can think of even the closest neighbors being too far away in a high-dimensional space to give a good estimate.</p><p class="calibre8">We have discussed the concept of regularization in the section about logistic regression as one way to avoid overfitting. However, in models where regularization is not applicable, such as decision trees and KNN, we can use feature selection and dimensionality reduction techniques to help us avoid the curse of dimensionality. This will be discussed in more detail in the next chapter.</p></div></div></div>

<div id="calibre_link-509" class="calibre"><div class="book" title="Summary" id="calibre_link-262"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1102"><a id="calibre_link-1103" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, you learned about many different machine learning algorithms that are used to tackle linear and nonlinear problems. We have seen that decision trees are particularly attractive if we care about interpretability. Logistic regression is not only a useful model for online learning via stochastic gradient descent, but also allows us to predict the probability of a particular event. Although support vector machines are powerful linear models that can be extended to nonlinear problems via the kernel trick, they have many parameters that have to be tuned in order to make good predictions. In contrast, ensemble methods such as random forests don't require much parameter tuning and don't overfit as easily as decision trees, which makes them attractive models for many practical problem domains. The KNN classifier offers an alternative approach to classification via lazy learning that allows us to make predictions without any model training, but with a more computationally expensive prediction step.</p><p class="calibre8">However, even more important than the choice of an appropriate learning algorithm is the available data in our training dataset. No algorithm will be able to make good predictions without informative and discriminatory features.</p><p class="calibre8">In the next chapter, we will discuss important topics regarding the preprocessing of data, feature selection, and dimensionality reduction, which we will need to build powerful machine learning models. Later in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we will see how we can evaluate and compare the performance of our models and learn useful tricks to fine-tune the different algorithms.</p></div></div>

<div id="calibre_link-602" class="calibre">
<div id="calibre_link-1104" class="calibre10"></div><div class="book" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing"><div class="book" id="calibre_link-36"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1105"><a id="calibre_link-1106" class="calibre1"></a>Chapter&nbsp;4.&nbsp;Building Good Training Sets &ndash; Data Preprocessing</h1></div></div></div><p class="calibre8">The quality of the data and the amount of useful information that it contains are key factors that determine how well a machine learning algorithm can learn. Therefore, it is absolutely critical that we make sure to examine and preprocess a dataset before we feed it to a learning algorithm. In this chapter, we will discuss the essential data preprocessing techniques that will help us build good machine learning models.</p><p class="calibre8">The topics that we will cover in this chapter are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Removing and imputing missing values from the dataset</li><li class="listitem">Getting categorical data into shape for machine learning algorithms</li><li class="listitem">Selecting relevant features for the model construction</li></ul></div></div></div>

<div id="calibre_link-517" class="calibre">
<div class="book" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing">
<div class="book" title="Dealing with missing data"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1107"><a id="calibre_link-263" class="calibre1"></a>Dealing with missing data</h1></div></div></div><p class="calibre8">It is not<a id="calibre_link-1108" class="calibre1"></a> uncommon in real-world applications for our samples to be missing one or more values for various reasons. There could have been an error in the data collection process, certain measurements are not applicable, or particular fields could have been simply left blank in a survey, for example. We typically see missing values as the blank spaces in our data table or as placeholder strings such as <code class="email">NaN</code>, which stands for not a number, or <code class="email">NULL</code> (a commonly used indicator of unknown values in relational databases).</p><p class="calibre8">Unfortunately, most computational tools are unable to handle such missing values, or produce unpredictable results if we simply ignore them. Therefore, it is crucial that we take care of those missing values before we proceed with further analyses. In this section, we will work through several practical techniques for dealing with missing values by removing entries from our dataset or imputing missing values from other samples and features.</p></div></div></div>

<div id="calibre_link-544" class="calibre">
<div class="book" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing">
<div class="book" title="Dealing with missing data">
<div class="book" title="Identifying missing values in tabular data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1109"><a id="calibre_link-264" class="calibre1"></a>Identifying missing values in tabular data</h2></div></div></div><p class="calibre8">But before<a id="calibre_link-1110" class="calibre1"></a> we discuss several techniques for <a id="calibre_link-1111" class="calibre1"></a>dealing with missing values, let's create a <a id="calibre_link-1112" class="calibre1"></a>simple example data frame from a <span class="strong"><strong class="calibre2">Comma-separated Values</strong></span> (<span class="strong"><strong class="calibre2">CSV</strong></span>) file to get a better grasp of the problem:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from io import StringIO

&gt;&gt;&gt; csv_data = \
... '''A,B,C,D
... 1.0,2.0,3.0,4.0
... 5.0,6.0,,8.0
... 10.0,11.0,12.0,'''
&gt;&gt;&gt; # If you are using Python 2.7, you need
&gt;&gt;&gt; # to convert the string to unicode:
&gt;&gt;&gt; # csv_data = unicode(csv_data)
&gt;&gt;&gt; df = pd.read_csv(StringIO(csv_data))
&gt;&gt;&gt; df
    A    B    C    D
0 1.0  2.0  3.0  4.0
1 5.0  6.0  NaN  8.0
2 10.0 11.0 12.0 NaN</pre></div><p class="calibre8">Using the preceding code, we read CSV-formatted data into a pandas <code class="email">DataFrame</code> via the <code class="email">read_csv</code> function and noticed that the two missing cells were replaced by <code class="email">NaN</code>. The <code class="email">StringIO</code> function in the preceding code example was simply used for the purposes of illustration. It allows us to read the string assigned to <code class="email">csv_data</code> into a pandas <code class="email">DataFrame</code> as if it was a regular CSV file on our hard drive.</p><p class="calibre8">For a larger <code class="email">DataFrame</code>, it can be tedious to look for missing values manually; in this case, we can use the <code class="email">isnull</code> method to return a <code class="email">DataFrame</code> with Boolean values that indicate whether a cell contains a numeric value (<code class="email">False</code>) or if data is missing (<code class="email">True</code>). Using the <code class="email">sum</code> method, we can then return the number of missing values per column as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df.isnull().sum()
A    0
B    0
C    1
D    1
dtype: int64</pre></div><p class="calibre8">This way, we can count the number of missing values per column; in the following subsections, we will take a look at different strategies for how to deal with this<a id="calibre_link-1113" class="calibre1"></a> missing data.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1114" class="calibre1"></a>Note</h3><p class="calibre8">Although scikit-learn was<a id="calibre_link-1115" class="calibre1"></a> developed for working with NumPy arrays, it can sometimes be more convenient to preprocess data using pandas' <code class="email">DataFrame</code>. We can always access the underlying NumPy array of a <code class="email">DataFrame</code> via the <code class="email">values</code> attribute before we feed it into a scikit-learn estimator:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df.values
array([[  1.,   2.,   3.,   4.],
       [  5.,   6.,  nan,   8.],
       [ 10.,  11.,  12.,  nan]])</pre></div></div></div></div></div></div>

<div id="calibre_link-565" class="calibre">
<div class="book" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing">
<div class="book" title="Dealing with missing data">
<div class="book" title="Eliminating samples or features with missing values"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1116"><a id="calibre_link-265" class="calibre1"></a>Eliminating samples or features with missing values</h2></div></div></div><p class="calibre8">One of the easiest<a id="calibre_link-1117" class="calibre1"></a> ways to deal with missing data is to <a id="calibre_link-1118" class="calibre1"></a>simply remove the corresponding <a id="calibre_link-1119" class="calibre1"></a>features (columns) or samples (rows) from<a id="calibre_link-1120" class="calibre1"></a> the dataset entirely; rows with missing values can be easily dropped via the <code class="email">dropna</code> method:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df.dropna(axis=0)
     A    B    C    D
0  1.0  2.0  3.0  4.0</pre></div><p class="calibre8">Similarly, we can drop columns that have at least one <code class="email">NaN</code> in any row by setting the <code class="email">axis</code> argument to <code class="email">1</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df.dropna(axis=1)
     A    B
0  1.0  2.0
1  5.0  6.0
2  10.0 11.0</pre></div><p class="calibre8">The <code class="email">dropna</code> method supports several additional parameters that can come in handy:</p><div class="informalexample"><pre class="programlisting"># only drop rows where all columns are NaN
# (returns the whole array here since we don't
# have a row with where all values are NaN
&gt;&gt;&gt; df.dropna(how='all')
     A    B    C    D
0  1.0  2.0  3.0  4.0
1  5.0  6.0  NaN  8.0
2 10.0 11.0 12.0  NaN


# drop rows that have less than 4 real values
&gt;&gt;&gt; df.dropna(thresh=4)
     A    B    C    D
0  1.0  2.0  3.0  4.0


# only drop rows where NaN appear in specific columns (here: 'C')
&gt;&gt;&gt; df.dropna(subset=['C'])
     A    B    C   D
0  1.0  2.0  3.0 4.0
2 10.0 11.0 12.0 NaN</pre></div><p class="calibre8">Although the <a id="calibre_link-1121" class="calibre1"></a>removal of missing data seems to be a <a id="calibre_link-1122" class="calibre1"></a>convenient approach, it also comes with <a id="calibre_link-1123" class="calibre1"></a>certain disadvantages; for example, we may <a id="calibre_link-1124" class="calibre1"></a>end up removing too many samples, which will make a reliable analysis impossible. Or, if we remove too many feature columns, we will run the risk of losing valuable information that our classifier needs to discriminate between classes. In the next section, we will thus look at one of the most commonly used alternatives for dealing with missing values: interpolation techniques.</p></div></div></div></div>

<div id="calibre_link-522" class="calibre">
<div class="book" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing">
<div class="book" title="Dealing with missing data">
<div class="book" title="Imputing missing values"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1125"><a id="calibre_link-266" class="calibre1"></a>Imputing missing values</h2></div></div></div><p class="calibre8">Often, the removal of <a id="calibre_link-1126" class="calibre1"></a>samples or dropping of entire feature columns is simply not feasible, because we might lose too much valuable data. In this case, we can use different interpolation techniques to estimate the missing values from the other training samples in our dataset. One of the most common interpolation techniques<a id="calibre_link-1127" class="calibre1"></a> is <span class="strong"><strong class="calibre2">mean imputation</strong></span>, where we simply replace the missing value with the mean value of the entire feature column. A convenient way to achieve this is by using the <code class="email">Imputer</code> class from scikit-learn, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import Imputer
&gt;&gt;&gt; imr = Imputer(missing_values='NaN', strategy='mean', axis=0)
&gt;&gt;&gt; imr = imr.fit(df.values)
&gt;&gt;&gt; imputed_data = imr.transform(df.values)
&gt;&gt;&gt; imputed_data
array([[  1.,   2.,   3.,   4.],
       [  5.,   6.,  7.5,   8.],
       [ 10.,  11.,  12.,   6.]])</pre></div><p class="calibre8">Here, we replaced each <code class="email">NaN</code> value with the corresponding mean, which is separately calculated for each feature column. If we changed the <code class="email">axis=0</code> setting to <code class="email">axis=1</code>, we'd calculate the row means. Other options for the <code class="email">strategy</code> parameter are <code class="email">median</code> or <code class="email">most_frequent</code>, where the<a id="calibre_link-1128" class="calibre1"></a> latter replaces the missing values with the most frequent values. This is useful for imputing categorical feature values, for example, a feature column that stores an encoding of color names, such as red, green, and blue, and we will encounter examples of such data later in this chapter.</p></div></div></div></div>

<div id="calibre_link-526" class="calibre">
<div class="book" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing">
<div class="book" title="Dealing with missing data">
<div class="book" title="Understanding the scikit-learn estimator API"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1129"><a id="calibre_link-267" class="calibre1"></a>Understanding the scikit-learn estimator API</h2></div></div></div><p class="calibre8">In the previous section, we<a id="calibre_link-1130" class="calibre1"></a> used the <code class="email">Imputer</code> class from scikit-learn to impute missing values in our dataset. The <code class="email">Imputer</code> class belongs to the so-called <span class="strong"><strong class="calibre2">transformer</strong></span> classes<a id="calibre_link-1131" class="calibre1"></a> in scikit-learn, which are used for data transformation. The two essential methods of those estimators are <code class="email">fit</code> and <code class="email">transform</code>. The <code class="email">fit</code> method is used to learn the parameters from the training data, and the <code class="email">transform</code> method uses those parameters to transform the data. Any data array that is to be transformed needs to have the same number of features as the data array that was used to fit the model. The following figure illustrates how a transformer, fitted on the training data, is used to transform a training dataset as well as a new test dataset:</p><div class="mediaobject"><img src="images/00165.jpeg" alt="Understanding the scikit-learn estimator API" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The classifiers that we used in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, belong to the so-called <span class="strong"><strong class="calibre2">estimators</strong></span> in scikit-learn with an API that is conceptually very similar to the transformer class. Estimators have a <code class="email">predict</code> method but can also have a <code class="email">transform</code> method, as we will see later in this chapter. As you may recall, we also used the <code class="email">fit</code> method to learn the parameters of a model when we trained those estimators for classification. However, in supervised learning tasks, we additionally provide the class labels for <a id="calibre_link-1132" class="calibre1"></a>fitting the model, which can then be used to make predictions about new data samples via the <code class="email">predict</code> method, as illustrated in the following figure:</p><div class="mediaobject"><img src="images/00223.jpeg" alt="Understanding the scikit-learn estimator API" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-531" class="calibre">
<div id="calibre_link-1133" class="calibre10"></div><div class="book" title="Handling categorical data"><div class="book" id="calibre_link-68"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1134"><a id="calibre_link-1135" class="calibre1"></a>Handling categorical data</h1></div></div></div><p class="calibre8">So far, we have only been<a id="calibre_link-1136" class="calibre1"></a> working with numerical values. However, it is not uncommon that real-world datasets contain one or more categorical feature columns. In this section, we will make use of simple yet effective examples to see how we deal with this type of data in numerical computing libraries.</p></div></div>

<div id="calibre_link-635" class="calibre">
<div class="book" title="Handling categorical data">
<div class="book" title="Nominal and ordinal features"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1137"><a id="calibre_link-268" class="calibre1"></a>Nominal and ordinal features</h2></div></div></div><p class="calibre8">When we are talking <a id="calibre_link-1138" class="calibre1"></a>about categorical data, we have to further distinguish between <span class="strong"><strong class="calibre2">nominal</strong></span> and <span class="strong"><strong class="calibre2">ordinal</strong></span> features. Ordinal<a id="calibre_link-1139" class="calibre1"></a> features can be understood as categorical values that can be sorted or ordered. For example, t-shirt size would be an ordinal feature, because we can define an order <span class="strong"><em class="calibre9">XL &gt; L &gt; M</em></span>. In contrast, nominal features don't imply any order and, to continue with the previous example, we could think of t-shirt color as a nominal feature since it typically doesn't make sense to say that, for example, red is larger than blue.</p><div class="book" title="Creating an example dataset"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-269" class="calibre1"></a>Creating an example dataset</h3></div></div></div><p class="calibre8">Before we explore different techniques to<a id="calibre_link-1140" class="calibre1"></a> handle such categorical data, let's create a new <code class="email">DataFrame</code> to illustrate the problem:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.DataFrame([
...            ['green', 'M', 10.1, 'class1'],
...            ['red', 'L', 13.5, 'class2'], 
...            ['blue', 'XL', 15.3, 'class1']])
&gt;&gt;&gt; df.columns = ['color', 'size', 'price', 'classlabel']
&gt;&gt;&gt; df
   color size  price classlabel
0  green    M   10.1     class1
1    red    L   13.5     class2
2   blue   XL   15.3     class1</pre></div><p class="calibre8">As we can see in the preceding output, the newly created <code class="email">DataFrame</code> contains a nominal feature (<code class="email">color</code>), an ordinal feature (<code class="email">size</code>), and a numerical feature (<code class="email">price</code>) column. The class labels (assuming that we created a dataset for a supervised learning task) are stored in the last column. The learning algorithms for classification that we discuss in this book do not use ordinal information in class labels.</p></div></div></div></div>

<div id="calibre_link-655" class="calibre">
<div class="book" title="Handling categorical data">
<div class="book" title="Mapping ordinal features"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1141"><a id="calibre_link-270" class="calibre1"></a>Mapping ordinal features</h2></div></div></div><p class="calibre8">To make sure that the learning<a id="calibre_link-1142" class="calibre1"></a> algorithm interprets the ordinal features correctly, we need to convert the categorical string values into integers. Unfortunately, there is no convenient function that can automatically derive the correct order of the labels of our <code class="email">size</code> feature, so we have to define the mapping manually. In the following simple example, let's assume that we know the numerical difference between features, for example, <span class="strong"><img src="images/00277.jpeg" alt="Mapping ordinal features" class="calibre14" /></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; size_mapping = {
...                 'XL': 3,
...                 'L': 2,
...                 'M': 1}
&gt;&gt;&gt; df['size'] = df['size'].map(size_mapping)
&gt;&gt;&gt; df
   color  size  price classlabel
0  green     1   10.1     class1
1    red     2   13.5     class2
2   blue     3   15.3     class1</pre></div><p class="calibre8">If we want to transform the integer values back to the original string representation at a later stage, we can simply define a reverse-mapping dictionary <code class="email">inv_size_mapping = {v: k for k, v in size_mapping.items()}</code> that can then be used via the pandas <code class="email">map</code> method on the transformed <a id="calibre_link-1143" class="calibre1"></a>feature column, similar to the <code class="email">size_mapping</code> dictionary that we used previously. We can use it as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; inv_size_mapping = {v: k for k, v in size_mapping.items()}
&gt;&gt;&gt; df['size'].map(inv_size_mapping)
0     M
1     L
2    XL
Name: size, dtype: object</pre></div></div></div></div>

<div id="calibre_link-32" class="calibre">
<div class="book" title="Handling categorical data">
<div class="book" title="Encoding class labels"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1144"><a id="calibre_link-271" class="calibre1"></a>Encoding class labels</h2></div></div></div><p class="calibre8">Many machine learning libraries<a id="calibre_link-1145" class="calibre1"></a> require that class labels are encoded as integer values. Although most estimators for classification in scikit-learn convert class labels to integers internally, it is considered good practice to provide class labels as integer arrays to avoid technical glitches. To encode the class labels, we can use an approach similar to the mapping of ordinal features discussed previously. We need to remember that class labels are <span class="strong"><em class="calibre9">not</em></span> ordinal, and it doesn't matter which integer number we assign to a particular string label. Thus, we can simply enumerate the class labels, starting at <code class="email">0</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; class_mapping = {label:idx for idx,label in
...                  enumerate(np.unique(df['classlabel']))}
&gt;&gt;&gt; class_mapping
{'class1': 0, 'class2': 1}</pre></div><p class="calibre8">Next, we can use the mapping dictionary to transform the class labels into integers:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df['classlabel'] = df['classlabel'].map(class_mapping)
&gt;&gt;&gt; df
   color  size  price  classlabel
0  green     1   10.1           0
1    red     2   13.5           1
2   blue     3   15.3           0</pre></div><p class="calibre8">We can reverse the key-value pairs in the mapping dictionary as follows to map the converted class labels back to the original string representation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; inv_class_mapping = {v: k for k, v in class_mapping.items()}
&gt;&gt;&gt; df['classlabel'] = df['classlabel'].map(inv_class_mapping)
&gt;&gt;&gt; df
   color  size  price classlabel
0  green     1   10.1     class1
1    red     2   13.5     class2
2   blue     3   15.3     class1</pre></div><p class="calibre8">Alternatively, there is a <a id="calibre_link-1146" class="calibre1"></a>convenient <code class="email">LabelEncoder</code> class directly implemented in scikit-learn to achieve this:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder
&gt;&gt;&gt; class_le = LabelEncoder()
&gt;&gt;&gt; y = class_le.fit_transform(df['classlabel'].values)
&gt;&gt;&gt; y
array([0, 1, 0])</pre></div><p class="calibre8">Note that the <code class="email">fit_transform</code> method is just a shortcut for calling <code class="email">fit</code> and <code class="email">transform</code> separately, and we can use the <code class="email">inverse_transform</code> method to transform the integer class labels back into their original string representation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; class_le.inverse_transform(y)
array(['class1', 'class2', 'class1'], dtype=object)</pre></div></div></div></div>

<div id="calibre_link-543" class="calibre">
<div class="book" title="Handling categorical data">
<div class="book" title="Performing one-hot encoding on nominal features"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1147"><a id="calibre_link-272" class="calibre1"></a>Performing one-hot encoding on nominal features</h2></div></div></div><p class="calibre8">In the previous section, we<a id="calibre_link-1148" class="calibre1"></a> used a simple dictionary-mapping <a id="calibre_link-1149" class="calibre1"></a>approach to convert the ordinal <code class="email">size</code> feature into integers. Since scikit-learn's estimators for classification treat class labels as categorical data that does not imply any order (nominal), we used the convenient <code class="email">LabelEncoder</code> to encode the string labels into integers. It may appear that we could use a similar approach to transform the nominal <code class="email">color</code> column of our dataset, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X = df[['color', 'size', 'price']].values
&gt;&gt;&gt; color_le = LabelEncoder()
&gt;&gt;&gt; X[:, 0] = color_le.fit_transform(X[:, 0])
&gt;&gt;&gt; X
array([[1, 1, 10.1],
       [2, 2, 13.5],
       [0, 3, 15.3]], dtype=object)</pre></div><p class="calibre8">After executing the preceding code, the first column of the NumPy array <code class="email">X</code> now holds the new <code class="email">color</code> values, which are encoded as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">blue</code> = <code class="email">0</code></li><li class="listitem"><code class="email">green</code> = <code class="email">1</code></li><li class="listitem"><code class="email">red</code> = <code class="email">2</code></li></ul></div><p class="calibre8">If we stop at this point and feed the array to our classifier, we will make one of the most common mistakes in dealing with categorical data. Can you spot the problem? Although the color values don't come in any particular order, a learning algorithm will now assume that <code class="email">green</code> is larger than <code class="email">blue</code>, and <code class="email">red</code> is larger than <code class="email">green</code>. Although this assumption is incorrect, the algorithm could still produce useful results. However, those results would not be optimal.</p><p class="calibre8">A common workaround<a id="calibre_link-1150" class="calibre1"></a> for this problem is to use a <a id="calibre_link-1151" class="calibre1"></a>technique called <span class="strong"><strong class="calibre2">one-hot encoding</strong></span>. The idea behind this approach is to create a new dummy feature for each unique value in the nominal feature column. Here, we would convert the <code class="email">color</code> feature into three new features: <code class="email">blue</code>, <code class="email">green</code>, and <code class="email">red</code>. Binary values can then be used to indicate the particular <code class="email">color</code> of a sample; for example, a <code class="email">blue</code> sample can be encoded as <code class="email">blue=1</code>, <code class="email">green=0</code>, <code class="email">red=0</code>. To perform this transformation, we can use the <code class="email">OneHotEncoder</code> that is implemented in the <code class="email">scikit-learn.preprocessing</code> module:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import OneHotEncoder

&gt;&gt;&gt; ohe = OneHotEncoder(categorical_features=[0])
&gt;&gt;&gt; ohe.fit_transform(X).toarray()
array([[  0. ,   1. ,   0. ,   1. ,  10.1],
       [  0. ,   0. ,   1. ,   2. ,  13.5],
       [  1. ,   0. ,   0. ,   3. ,  15.3]])</pre></div><p class="calibre8">When we initialized the <code class="email">OneHotEncoder</code>, we defined the column position of the variable that we want to transform via the <code class="email">categorical_features</code> parameter (note that <code class="email">color</code> is the first column in the feature matrix <code class="email">X</code>). By default, the <code class="email">OneHotEncoder</code> returns a sparse matrix when we use the <code class="email">transform</code> method, and we converted the sparse matrix representation into a regular (<span class="strong"><em class="calibre9">dense</em></span>) NumPy array for the purpose of visualization via the <code class="email">toarray</code> method. Sparse matrices are a more efficient way of storing large datasets and one that is supported by many scikit-learn functions, which is especially useful if an array contains a lot of zeros. To omit the <code class="email">toarray</code> step, we could alternatively initialize the encoder as <code class="email">OneHotEncoder(..., sparse=False)</code> to return a regular NumPy array.</p><p class="calibre8">An even more convenient way to create those dummy features via one-hot encoding is to use the <code class="email">get_dummies</code> method implemented in pandas. Applied to a <code class="email">DataFrame</code>, the <code class="email">get_dummies</code> method will only convert string columns and leave all other columns unchanged:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; pd.get_dummies(df[['price', 'color', 'size']])
   price  size  color_blue  color_green  color_red
0   10.1     1           0            1          0
1   13.5     2           0            0          1
2   15.3     3           1            0          0</pre></div><p class="calibre8">When we are using one-hot encoding datasets, we have to keep in mind that it introduces multicollinearity, which can be an issue for certain methods (for instance, methods that require matrix inversion). If features are highly correlated, matrices are computationally difficult to invert, which can lead to numerically unstable estimates. To reduce the correlation among variables, we can simply remove one feature column from the one-hot encoded array. Note that we do not lose any important information by removing a feature column, though; for example, if we remove the column <code class="email">color_blue</code>, the feature information is still preserved since if we observe <code class="email">color_green=0</code> and <code class="email">color_red=0</code>, it implies that the <a id="calibre_link-1152" class="calibre1"></a>observation must be <code class="email">blue</code>.</p><p class="calibre8">If we use the <code class="email">get_dummies</code> function, we can<a id="calibre_link-1153" class="calibre1"></a> drop the first column by passing a <code class="email">True</code> argument to the <code class="email">drop_first</code> parameter, as shown in the following code example:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; pd.get_dummies(df[['price', 'color', 'size']],
...                drop_first=True)
   price  size  color_green  color_red
0   10.1     1            1          0
1   13.5     2            0          1
2   15.3     3            0          0</pre></div><p class="calibre8">The <code class="email">OneHotEncoder</code> does not have a parameter for column removal, but we can simply slice the one-hot encoded NumPy array as shown in the following code snippet:</p><div class="informalexample"><pre class="programlisting">ohe = OneHotEncoder(categorical_features=[0])
ohe.fit_transform(X).toarray()[:, 1:]
array([[  1. ,   0. ,   1. ,  10.1],
       [  0. ,   1. ,   2. ,  13.5],
       [  0. ,   0. ,   3. ,  15.3]])</pre></div></div></div></div>

<div id="calibre_link-97" class="calibre"><div class="book" title="Partitioning a dataset into separate training and test sets" id="calibre_link-107"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1154"><a id="calibre_link-1155" class="calibre1"></a>Partitioning a dataset into separate training and test sets</h1></div></div></div><p class="calibre8">We briefly<a id="calibre_link-1156" class="calibre1"></a> introduced the concept of partitioning a dataset into <a id="calibre_link-1157" class="calibre1"></a>separate datasets for training and <a id="calibre_link-1158" class="calibre1"></a>testing in <a class="calibre1" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" href="#calibre_link-17">Chapter 1</a>, <span class="strong"><em class="calibre9">Giving Computers the Ability to Learn from Data</em></span>, and <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>. Remember that comparing predictions to true labels in the test set can be understood as the unbiased performance evaluation of our model before we let it loose on the real world. In this section, we will prepare a new<a id="calibre_link-1159" class="calibre1"></a> dataset, the <span class="strong"><strong class="calibre2">Wine</strong></span> dataset. After we have preprocessed the dataset, we will explore different techniques for feature selection to reduce the dimensionality of a dataset.</p><p class="calibre8">The Wine dataset is another <a id="calibre_link-1160" class="calibre1"></a>open-source dataset that is available from the UCI machine learning repository<a id="calibre_link-1161" class="calibre1"></a> (<a class="calibre1" href="https://archive.ics.uci.edu/ml/datasets/Wine">https://archive.ics.uci.edu/ml/datasets/Wine</a>); it consists of 178 wine samples with 13 features describing their different chemical properties.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1162" class="calibre1"></a>Note</h3><p class="calibre8">You can find a copy of the Wine dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the dataset at <a class="calibre1" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data">https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data</a> is temporarily unavailable on the UCI server. For instance, to load the Wine dataset from a local directory, you can replace this line:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('https://archive.ics.uci.edu/ml/'
        'machine-learning-databases/wine/wine.data',
         header=None)</pre></div></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1163" class="calibre1"></a>Note</h3><p class="calibre8">Replace it with this:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('your/local/path/to/wine.data',
                 header=None)</pre></div></div><p class="calibre8">Using the <code class="email">pandas</code> library, we<a id="calibre_link-1164" class="calibre1"></a> will directly read in the open source Wine dataset <a id="calibre_link-1165" class="calibre1"></a>from the UCI machine<a id="calibre_link-1166" class="calibre1"></a> learning repository:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                          'ml/machine-learning-databases/'
                          'wine/wine.data', header=None)
&gt;&gt;&gt; df_wine.columns = ['Class label', 'Alcohol',
...                    'Malic acid', 'Ash',
...                    'Alcalinity of ash', 'Magnesium',
...                    'Total phenols', 'Flavanoids',
...                    'Nonflavanoid phenols',
...                    'Proanthocyanins',
...                    'Color intensity', 'Hue',
...                    'OD280/OD315 of diluted wines',
...                    'Proline']
&gt;&gt;&gt; print('Class labels', np.unique(df_wine['Class label']))
Class labels [1 2 3]
&gt;&gt;&gt; df_wine.head()</pre></div><p class="calibre8">The 13 different features in the<a id="calibre_link-1167" class="calibre1"></a> Wine dataset, describing the chemical properties of the 178 wine samples, are listed in the following table:</p><div class="mediaobject"><img src="images/00183.jpeg" alt="Partitioning a dataset into separate training and test sets" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The samples belong to one of three different classes, <code class="email">1</code>, <code class="email">2</code>, and <code class="email">3</code>, which refer to the three different types of grape grown in the same region in Italy but derived from different wine cultivars, as described in the dataset summary (<a class="calibre1" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names">https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names</a>).</p><p class="calibre8">A convenient way to randomly partition this dataset into separate test and training datasets is to use the <code class="email">train_test_split</code> function from scikit-learn's <code class="email">model_selection</code> submodule:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values
&gt;&gt;&gt; X_train, X_test, y_train, y_test =\
...     train_test_split(X, y,
...                      test_size=0.3,
...                      random_state=0,
...                      stratify=y)</pre></div><p class="calibre8">First, we assigned the<a id="calibre_link-1168" class="calibre1"></a> NumPy array representation of the feature<a id="calibre_link-1169" class="calibre1"></a> columns 1-13 to the variable <code class="email">X</code>; we assigned the <a id="calibre_link-1170" class="calibre1"></a>class labels from the first column to the<a id="calibre_link-1171" class="calibre1"></a> variable <code class="email">y</code>. Then, we used the <code class="email">train_test_split</code> function to randomly split <code class="email">X</code> and <code class="email">y</code> into separate training and test datasets. By setting <code class="email">test_size=0.3</code>, we assigned 30 percent of the wine samples to <code class="email">X_test</code> and <code class="email">y_test</code>, and the remaining 70 percent of the samples were assigned to <code class="email">X_train</code> and <code class="email">y_train</code>, respectively. Providing the class label array <code class="email">y</code> as an argument to <code class="email">stratify</code> ensures that both training and test datasets have the same class proportions as the original dataset.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1172" class="calibre1"></a>Note</h3><p class="calibre8">If we are dividing a dataset into training and test datasets, we have to keep in mind that we are withholding valuable information that the learning algorithm could benefit from. Thus, we don't want to allocate too much information to the test set. However, the smaller the test set, the more inaccurate the estimation of the generalization error. Dividing a dataset into training and test sets is all about balancing this trade-off. In practice, the most commonly used splits are 60:40, 70:30, or 80:20, depending on the size of the initial dataset. However, for large datasets, 90:10 or 99:1 splits into training and test subsets are also common and appropriate. Instead of discarding the allocated test data after model training and evaluation, it is a common practice to retrain a classifier on the entire dataset as it can improve the predictive performance of the model. While this approach is generally recommended, it could lead to worse generalization performance if the dataset is small and the test set contains outliers, for example. Also, after refitting the model on the whole dataset, we don't have any independent data left to evaluate its performance.</p></div></div></div>

<div id="calibre_link-130" class="calibre"><div class="book" title="Bringing features onto the same scale"><div class="book" id="calibre_link-161"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1173"><a id="calibre_link-1174" class="calibre1"></a>Bringing features onto the same scale</h1></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Feature scaling</strong></span> is a<a id="calibre_link-1175" class="calibre1"></a> crucial step in our preprocessing pipeline that can easily be forgotten. Decision trees and random forests are two of the very few machine learning algorithms where we don't need to worry about feature scaling. Those algorithms are scale invariant. However, the majority of machine learning and optimization algorithms behave much better if features are on the same scale, as we have seen in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, when we implemented <a id="calibre_link-1176" class="calibre1"></a>the <span class="strong"><strong class="calibre2">gradient descent</strong></span> optimization algorithm.</p><p class="calibre8">The importance of feature scaling can be illustrated by a simple example. Let's assume that we have two features where one feature is measured on a scale from 1 to 10 and the second feature is measured on a scale from 1 to 100,000, respectively. When we think of the squared error function in Adaline in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, it is intuitive to say that the algorithm will mostly be busy optimizing the weights according to the larger errors in the second feature. Another example is the <span class="strong"><strong class="calibre2">k-nearest neighbors</strong></span> (<span class="strong"><strong class="calibre2">KNN</strong></span>) algorithm <a id="calibre_link-1177" class="calibre1"></a>with a Euclidean distance measure; the computed distances between samples will be dominated by the second feature axis.</p><p class="calibre8">Now, there are two common approaches to bring different features onto the <a id="calibre_link-1178" class="calibre1"></a>same scale: <span class="strong"><strong class="calibre2">normalization</strong></span> and <span class="strong"><strong class="calibre2">standardization</strong></span>. Those<a id="calibre_link-1179" class="calibre1"></a> terms are often used quite loosely in different fields, and the meaning has to be derived from the context. Most often, normalization refers to the rescaling of the features to a range of [0, 1], which is a special <a id="calibre_link-1180" class="calibre1"></a>case of <span class="strong"><strong class="calibre2">min-max scaling</strong></span>. To normalize our data, we can simply apply the min-max scaling to each feature column, where the new value <span class="strong"><img src="images/00378.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> of a sample <span class="strong"><img src="images/00433.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> can be calculated as follows:</p><div class="mediaobject"><img src="images/00487.jpeg" alt="Bringing features onto the same scale" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00433.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> is a particular sample, <span class="strong"><img src="images/00536.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> is the smallest value in a feature column, and <span class="strong"><img src="images/00234.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> the largest value.</p><p class="calibre8">The min-max scaling procedure is implemented in scikit-learn and can be used as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler
&gt;&gt;&gt; mms = MinMaxScaler()
&gt;&gt;&gt; X_train_norm = mms.fit_transform(X_train)
&gt;&gt;&gt; X_test_norm = mms.transform(X_test)</pre></div><p class="calibre8">Although normalization via min-max scaling is a commonly used technique that is useful when we need values in a bounded interval, standardization can be more practical for many machine learning algorithms, especially for optimization algorithms such as gradient descent. The reason is that many linear models, such as the logistic regression and SVM that we remember from <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, initialize the weights to 0 or small random values close to 0. Using standardization, we center the feature columns at mean 0 with standard deviation 1 so that the feature columns takes the form of a normal distribution, which makes it easier to learn the weights. Furthermore, standardization maintains useful information about outliers and makes the<a id="calibre_link-1181" class="calibre1"></a> algorithm less sensitive to them in contrast to min-max scaling, which scales the data to a limited range of values.</p><p class="calibre8">The procedure for standardization can be expressed by the following equation:</p><div class="mediaobject"><img src="images/00245.jpeg" alt="Bringing features onto the same scale" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00258.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> is the sample mean of a particular feature column and <span class="strong"><img src="images/00268.jpeg" alt="Bringing features onto the same scale" class="calibre14" /></span> is the corresponding standard deviation.</p><p class="calibre8">The following table illustrates the difference between the two commonly used feature scaling techniques, standardization and normalization, on a simple sample dataset consisting of numbers 0 to 5:</p><div class="informalexample"><table border="1" class="calibre17"><colgroup class="calibre18"><col class="calibre19"></col><col class="calibre19"></col><col class="calibre19"></col></colgroup><thead class="calibre20"><tr class="calibre21"><th valign="bottom" class="calibre22">
<p class="calibre23">Input</p>
</th><th valign="bottom" class="calibre22">
<p class="calibre23">Standardized</p>
</th><th valign="bottom" class="calibre22">
<p class="calibre23">Min-max normalized</p>
</th></tr></thead><tbody class="calibre24"><tr class="calibre21"><td class="calibre25">
<p class="calibre23">0.0</p>
</td><td class="calibre25">
<p class="calibre23">-1.46385</p>
</td><td class="calibre25">
<p class="calibre23">0.0</p>
</td></tr><tr class="calibre21"><td class="calibre25">
<p class="calibre23">1.0</p>
</td><td class="calibre25">
<p class="calibre23">-0.87831</p>
</td><td class="calibre25">
<p class="calibre23">0.2</p>
</td></tr><tr class="calibre21"><td class="calibre25">
<p class="calibre23">2.0</p>
</td><td class="calibre25">
<p class="calibre23">-0.29277</p>
</td><td class="calibre25">
<p class="calibre23">0.4</p>
</td></tr><tr class="calibre21"><td class="calibre25">
<p class="calibre23">3.0</p>
</td><td class="calibre25">
<p class="calibre23">0.29277</p>
</td><td class="calibre25">
<p class="calibre23">0.6</p>
</td></tr><tr class="calibre21"><td class="calibre25">
<p class="calibre23">4.0</p>
</td><td class="calibre25">
<p class="calibre23">0.87831</p>
</td><td class="calibre25">
<p class="calibre23">0.8</p>
</td></tr><tr class="calibre21"><td class="calibre25">
<p class="calibre23">5.0</p>
</td><td class="calibre25">
<p class="calibre23">1.46385</p>
</td><td class="calibre25">
<p class="calibre23">1.0</p>
</td></tr></tbody></table></div><p class="calibre8">You can perform the standardization and normalization shown in the table manually by executing the following code examples:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ex = np.array([0, 1, 2, 3, 4, 5])
&gt;&gt;&gt; print('standardized:', (ex - ex.mean()) / ex.std())
standardized: [-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]
&gt;&gt;&gt; print('normalized:', (ex - ex.min()) / (ex.max() - ex.min()))
normalized: [ 0.   0.2  0.4  0.6  0.8  1. ]</pre></div><p class="calibre8">Similar to the <code class="email">MinMaxScaler</code> class, scikit-learn also implements a class for standardization:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; stdsc = StandardScaler()
&gt;&gt;&gt; X_train_std = stdsc.fit_transform(X_train)
&gt;&gt;&gt; X_test_std = stdsc.transform(X_test)</pre></div><p class="calibre8">Again, it is also important to highlight that we fit the <code class="email">StandardScaler</code> class only once&mdash;on the training data&mdash;and use those parameters to transform the test set or any new data point.</p></div></div>

<div id="calibre_link-553" class="calibre">
<div id="calibre_link-1182" class="calibre10"></div><div class="book" title="Selecting meaningful features"><div class="book" id="calibre_link-82"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1183"><a id="calibre_link-1184" class="calibre1"></a>Selecting meaningful features</h1></div></div></div><p class="calibre8">If we notice that a model performs <a id="calibre_link-1185" class="calibre1"></a>much better on a training dataset than on the test dataset, this observation is a strong indicator of <span class="strong"><strong class="calibre2">overfitting</strong></span>. As we <a id="calibre_link-1186" class="calibre1"></a>discussed in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, overfitting means the model fits the parameters too closely with regard to the particular observations in the training dataset, but does not generalize well to new data, and we say the model has a <span class="strong"><em class="calibre9">high variance</em></span>. The reason for the overfitting is that our model is too complex for the given training data. Common solutions to reduce the generalization error are listed as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Collect more training data</li><li class="listitem">Introduce a penalty for complexity via regularization</li><li class="listitem">Choose a simpler model with fewer parameters</li><li class="listitem">Reduce the dimensionality of the data</li></ul></div><p class="calibre8">Collecting more training <a id="calibre_link-1187" class="calibre1"></a>data is often not applicable. In <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we will learn about a useful technique to check whether more training data is helpful at all. In the following sections, we will look at common ways to reduce overfitting by regularization and dimensionality reduction via feature selection, which leads to simpler models by requiring fewer parameters to be fitted to the data.</p></div></div>

<div id="calibre_link-558" class="calibre">
<div class="book" title="Selecting meaningful features">
<div class="book" title="L1 and L2 regularization as penalties against model complexity"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1188"><a id="calibre_link-273" class="calibre1"></a>L1 and L2 regularization as penalties against model complexity</h2></div></div></div><p class="calibre8">We recall from <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, that <span class="strong"><strong class="calibre2">L2 regularization</strong></span>
<a id="calibre_link-1189" class="calibre1"></a> is one approach to reduce the complexity of a model by penalizing large individual weights, where we defined the L2 norm of our weight vector <span class="strong"><strong class="calibre2">w</strong></span> as follows:</p><div class="mediaobject"><img src="images/00281.jpeg" alt="L1 and L2 regularization as penalties against model complexity" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Another approach to reduce the model <a id="calibre_link-1190" class="calibre1"></a>complexity is the related <span class="strong"><strong class="calibre2">L1 regularization</strong></span>:</p><div class="mediaobject"><img src="images/00294.jpeg" alt="L1 and L2 regularization as penalties against model complexity" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, we simply replaced the square of the weights by the sum of the absolute values of the weights. In contrast to L2 regularization, L1 regularization usually yields sparse feature vectors; most feature weights will be zero. Sparsity can be useful in practice if we have a high-dimensional dataset with many features that are irrelevant, especially cases where we have more irrelevant dimensions than samples. In this sense, L1 regularization can be understood as a technique for feature selection.</p></div></div></div>

<div id="calibre_link-564" class="calibre">
<div class="book" title="Selecting meaningful features">
<div class="book" title="A geometric interpretation of L2 regularization"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1191"><a id="calibre_link-274" class="calibre1"></a>A geometric interpretation of L2 regularization</h2></div></div></div><p class="calibre8">As mentioned in the <a id="calibre_link-1192" class="calibre1"></a>previous section, L2 regularization adds a penalty<a id="calibre_link-1193" class="calibre1"></a> term to the cost function that effectively results in less extreme weight values compared to a model trained with an unregularized cost function. To better understand how L1 regularization encourages sparsity, let's take a step back and take a look at a geometric interpretation of regularization. Let us plot the contours of a convex cost function for two weight coefficients <span class="strong"><img src="images/00299.jpeg" alt="A geometric interpretation of L2 regularization" class="calibre14" /></span> and <span class="strong"><img src="images/00310.jpeg" alt="A geometric interpretation of L2 regularization" class="calibre14" /></span>. Here, we will consider the <span class="strong"><strong class="calibre2">Sum of Squared Errors</strong></span> (<span class="strong"><strong class="calibre2">SSE</strong></span>)<a id="calibre_link-1194" class="calibre1"></a> cost function that we used for Adaline in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, since it is spherical and easier to draw than the cost function of logistic regression; however, the same concepts apply to the latter. Remember that our goal is to find the combination of weight coefficients that minimize the cost function for the training data, as shown in the following figure (the point in the center of the ellipses):</p><div class="mediaobject"><img src="images/00318.jpeg" alt="A geometric interpretation of L2 regularization" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, we can think of regularization as adding a penalty term to the cost function to encourage smaller weights; or in other words, we penalize large weights.</p><p class="calibre8">Thus, by increasing the regularization strength via the regularization parameter <span class="strong"><img src="images/00335.jpeg" alt="A geometric interpretation of L2 regularization" class="calibre14" /></span>, we shrink the weights towards zero and decrease the dependence of our model on the training data. Let us illustrate this<a id="calibre_link-1195" class="calibre1"></a> concept in the following figure for the <a id="calibre_link-1196" class="calibre1"></a>L2 penalty term:</p><div class="mediaobject"><img src="images/00344.jpeg" alt="A geometric interpretation of L2 regularization" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The quadratic L2 regularization term is represented by the shaded ball. Here, our weight coefficients cannot exceed our regularization budget&mdash;the combination of the weight coefficients cannot fall outside the shaded area. On the other hand, we still want to minimize the cost function. Under the penalty constraint, our best effort is to choose the point where the L2 ball intersects with the contours of the unpenalized cost function. The larger the value of the regularization parameter <span class="strong"><img src="images/00335.jpeg" alt="A geometric interpretation of L2 regularization" class="calibre14" /></span> gets, the faster the penalized cost grows, which leads to a narrower L2 ball. For example, if we increase the regularization parameter towards infinity, the weight coefficients will become effectively zero, denoted by the center of the L2 ball. To summarize the main message of the example, our goal is to minimize the sum of the unpenalized cost plus the penalty term, which can be understood as adding bias and preferring a simpler model to reduce the variance in the absence of sufficient training data to fit the model.</p></div></div></div>

<div id="calibre_link-486" class="calibre">
<div class="book" title="Selecting meaningful features">
<div class="book" title="Sparse solutions with L1 regularization"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1197"><a id="calibre_link-275" class="calibre1"></a>Sparse solutions with L1 regularization</h2></div></div></div><p class="calibre8">Now, let us discuss <a id="calibre_link-1198" class="calibre1"></a>L1 regularization and sparsity. The main concept<a id="calibre_link-1199" class="calibre1"></a> behind L1 regularization is similar to what we have discussed in the previous section. However, since the L1 penalty is the sum of the absolute weight coefficients (remember that the L2 term is quadratic), we can represent it as a diamond-shape budget, as shown in the following figure:</p><div class="mediaobject"><img src="images/00287.jpeg" alt="Sparse solutions with L1 regularization" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the preceding figure, we can see that the contour of the cost function touches the L1 diamond at <span class="strong"><img src="images/00363.jpeg" alt="Sparse solutions with L1 regularization" class="calibre14" /></span>. Since the contours of an L1 regularized system are sharp, it is more likely that the optimum&mdash;that is, the intersection between the ellipses of the cost function and the boundary of the L1 diamond&mdash;is located on the axes, which encourages sparsity.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1200" class="calibre1"></a>Note</h3><p class="calibre8">The mathematical details of why L1 regularization can lead to sparse solutions are beyond the scope of this book. If you are interested, an excellent explanation of L2 versus L1 regularization can be found in <span class="strong"><em class="calibre9">Section 3.4</em></span>, <span class="strong"><em class="calibre9">The Elements of Statistical Learning</em></span>, <span class="strong"><em class="calibre9">Trevor Hastie</em></span>, <span class="strong"><em class="calibre9">Robert Tibshirani</em></span>, and <span class="strong"><em class="calibre9">Jerome Friedman</em></span>, <span class="strong"><em class="calibre9">Springer Science+Business Media</em></span>, <span class="strong"><em class="calibre9">2009</em></span>).</p></div><p class="calibre8">For regularized models in scikit-learn that support L1 regularization, we can simply set the <code class="email">penalty</code> parameter to <code class="email">'l1'</code> to obtain a sparse solution:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; LogisticRegression(penalty='l1')</pre></div><p class="calibre8">Applied to the standardized Wine data, the L1 regularized logistic regression would yield the following sparse solution:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr = LogisticRegression(penalty='l1', C=1.0)
&gt;&gt;&gt; lr.fit(X_train_std, y_train)
&gt;&gt;&gt; print('Training accuracy:', lr.score(X_train_std, y_train))
Training accuracy: 1.0
&gt;&gt;&gt; print('Test accuracy:', lr.score(X_test_std, y_test))
Test accuracy: 1.0</pre></div><p class="calibre8">Both training and test accuracies (both 100 percent) indicate that our model does a perfect job on both datasets. When we access the intercept terms via the <code class="email">lr.intercept_</code> attribute, we can see that the array returns three values:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.intercept_
array([-1.26338637, -1.21582071, -2.3701035 ])</pre></div><p class="calibre8">Since we fit the <code class="email">LogisticRegression</code> object on a multiclass dataset, it uses the <span class="strong"><strong class="calibre2">One-versus-Rest</strong></span> (<span class="strong"><strong class="calibre2">OvR</strong></span>) approach<a id="calibre_link-1201" class="calibre1"></a> by <a id="calibre_link-1202" class="calibre1"></a>default, where the first intercept belongs to<a id="calibre_link-1203" class="calibre1"></a> the model that fits class 1 versus class 2 and 3, the second value is the intercept of the model that fits class 2 versus class 1 and 3, and the third value is the intercept of the model that fits class 3 versus class 1 and 2:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.coef_
array([[ 1.24559337, 0.18041967, 0.74328894, -1.16046277, 0. ,
         0., 1.1678711, 0., 0., 0., 0., 0.54941931, 2.51017406],
       [-1.53720749, -0.38727002, -0.99539203, 0.3651479, 
         -0.0596352 , 0., 0.66833149, 0., 0., -1.9346134,
         1.23297955, 0., -2.23135027],
       [ 0.13579227, 0.16837686, 0.35723831, 0., 0., 0., 
         -2.43809275, 0., 0., 1.56391408, -0.81933286, 
         -0.49187817, 0.]])</pre></div><p class="calibre8">The weight array that we accessed via the <code class="email">lr.coef_</code> attribute contains three rows of weight coefficients, one weight vector for each class. Each row consists of 13 weights where each weight is multiplied by the respective feature in the 13-dimensional Wine dataset to calculate the net input:</p><div class="mediaobject"><img src="images/00386.jpeg" alt="Sparse solutions with L1 regularization" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1204" class="calibre1"></a>Note</h3><p class="calibre8">In scikit-learn, <span class="strong"><img src="images/00443.jpeg" alt="Sparse solutions with L1 regularization" class="calibre14" /></span> corresponds to the <code class="email">intercept_</code> and <span class="strong"><img src="images/00488.jpeg" alt="Sparse solutions with L1 regularization" class="calibre14" /></span> with <span class="strong"><img src="images/00538.jpeg" alt="Sparse solutions with L1 regularization" class="calibre14" /></span> correspond to the values in <code class="email">coef_</code>.</p></div><p class="calibre8">As a result of L1 <a id="calibre_link-1205" class="calibre1"></a>regularization, which serves as a method<a id="calibre_link-1206" class="calibre1"></a> for feature selection, we just trained a model that is robust to the potentially irrelevant features in this dataset.</p><p class="calibre8">Strictly speaking, the weight vectors from the previous example are not necessarily sparse, though, because they contain more non-zero than zero entries. However, we could enforce sparsity (more zero entries) by further increasing the regularization strength&mdash;that is, choosing lower values for the <code class="email">C</code> parameter.</p><p class="calibre8">In the last example on regularization in this chapter, we will vary the regularization strength and plot the regularization path&mdash;the weight coefficients of the different features for different regularization strengths:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt

&gt;&gt;&gt; fig = plt.figure()
&gt;&gt;&gt; ax = plt.subplot(111)

&gt;&gt;&gt; colors = ['blue', 'green', 'red', 'cyan',
...          'magenta', 'yellow', 'black',
...          'pink', 'lightgreen', 'lightblue',
...          'gray', 'indigo', 'orange']
&gt;&gt;&gt; weights, params = [], []
&gt;&gt;&gt; for c in np.arange(-4., 6.):
...     lr = LogisticRegression(penalty='l1', 
...                             C=10.**c,
...                             random_state=0)
...     lr.fit(X_train_std, y_train)
...     weights.append(lr.coef_[1])
...     params.append(10**c)

&gt;&gt;&gt; weights = np.array(weights)

&gt;&gt;&gt; for column, color in zip(range(weights.shape[1]), colors):
...     plt.plot(params, weights[:, column],
...              label=df_wine.columns[column + 1],
...              color=color)
&gt;&gt;&gt; plt.axhline(0, color='black', linestyle='--', linewidth=3)
&gt;&gt;&gt; plt.xlim([10**(-5), 10**5])
&gt;&gt;&gt; plt.ylabel('weight coefficient')
&gt;&gt;&gt; plt.xlabel('C')
&gt;&gt;&gt; plt.xscale('log')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; ax.legend(loc='upper center',
...           bbox_to_anchor=(1.38, 1.03),
...           ncol=1, fancybox=True)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The resulting plot provides us <a id="calibre_link-1207" class="calibre1"></a>with further insights into the behavior of <a id="calibre_link-1208" class="calibre1"></a>L1 regularization. As we can see, all feature weights will be zero if we penalize the model with a strong regularization parameter (<span class="strong"><img src="images/00413.jpeg" alt="Sparse solutions with L1 regularization" class="calibre14" /></span>); <span class="strong"><em class="calibre9">C</em></span> is the inverse of the regularization parameter <span class="strong"><img src="images/00335.jpeg" alt="Sparse solutions with L1 regularization" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00651.jpeg" alt="Sparse solutions with L1 regularization" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-577" class="calibre">
<div class="book" title="Selecting meaningful features">
<div class="book" title="Sequential feature selection algorithms"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1209"><a id="calibre_link-276" class="calibre1"></a>Sequential feature selection algorithms</h2></div></div></div><p class="calibre8">An alternative way to reduce the<a id="calibre_link-1210" class="calibre1"></a> complexity of the model and avoid overfitting is <span class="strong"><strong class="calibre2">dimensionality reduction</strong></span>
<a id="calibre_link-1211" class="calibre1"></a> via feature selection, which is especially useful for unregularized models. There are two main categories of dimensionality reduction techniques: <span class="strong"><strong class="calibre2">feature selection</strong></span> <a id="calibre_link-1212" class="calibre1"></a>and <span class="strong"><strong class="calibre2">feature extraction</strong></span>. Via feature selection, we select a subset of the original features, whereas<a id="calibre_link-1213" class="calibre1"></a> in feature extraction, we derive information from the feature set to construct a new feature subspace.</p><p class="calibre8">In this section, we will take a look at a classic family of feature selection algorithms. In the next chapter, <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>, we will learn about different feature extraction techniques to compress a dataset onto a lower-dimensional feature subspace.</p><p class="calibre8">Sequential feature selection algorithms are a family of greedy search algorithms that are used to reduce an initial <span class="strong"><em class="calibre9">d</em></span>-dimensional feature space to a <span class="strong"><em class="calibre9">k</em></span>-dimensional feature subspace where <span class="strong"><em class="calibre9">k&lt;d</em></span>. The motivation behind feature selection algorithms is to automatically select a subset of features that are most relevant to the problem, to improve computational efficiency or reduce the generalization error of the model by removing irrelevant features or noise, which can be useful for algorithms that don't support regularization.</p><p class="calibre8">A classic sequential feature selection <a id="calibre_link-1214" class="calibre1"></a>algorithm is <span class="strong"><strong class="calibre2">Sequential Backward Selection </strong></span>(<span class="strong"><strong class="calibre2">SBS</strong></span>), which aims to reduce the dimensionality of the initial feature subspace with a minimum decay in performance of the classifier to improve upon computational efficiency. In certain cases, SBS can even improve the predictive power of the model if a model suffers from overfitting.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1215" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Greedy algorithms</strong></span> make<a id="calibre_link-1216" class="calibre1"></a> locally optimal choices at each stage of a combinatorial search problem and generally yield a suboptimal solution to the problem, in contrast<a id="calibre_link-1217" class="calibre1"></a> to <span class="strong"><strong class="calibre2">exhaustive search algorithms</strong></span>, which evaluate all possible combinations and are guaranteed to find the optimal solution. However, in practice, an exhaustive search is often computationally not feasible, whereas greedy algorithms allow for a less complex, computationally more efficient solution.</p></div><p class="calibre8">The idea behind the SBS algorithm is quite simple: SBS sequentially removes features from the full feature subset until the new feature subspace contains the desired number of features. In order to determine which feature is to be removed at each stage, we need to define the criterion function <span class="strong"><em class="calibre9">J</em></span> that we want to minimize. The criterion calculated by the criterion function can simply be the difference in performance of the classifier before and after the removal of a particular feature. Then, the feature to be removed at each stage can simply be defined as the feature that maximizes this criterion; or in more intuitive terms, at each stage we eliminate the feature that causes the least performance loss after removal. Based on the preceding definition of SBS, we can outline the algorithm in four simple steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">
Initialize the <a id="calibre_link-1218" class="calibre1"></a>algorithm with <span class="strong"><em class="calibre9">k=d</em></span>, where <span class="strong"><em class="calibre9">d</em></span> is the dimensionality of the full feature space <span class="strong"><img src="images/00441.jpeg" alt="Sequential feature selection algorithms" class="calibre14" /></span>.
</li><li class="listitem" value="2">
Determine the feature <span class="strong"><img src="images/00774.jpeg" alt="Sequential feature selection algorithms" class="calibre14" /></span> that maximizes the criterion: <span class="strong"><img src="images/00013.jpeg" alt="Sequential feature selection algorithms" class="calibre14" /></span>), where <span class="strong"><img src="images/00024.jpeg" alt="Sequential feature selection algorithms" class="calibre14" /></span>.
</li><li class="listitem" value="3">
Remove the feature <span class="strong"><img src="images/00774.jpeg" alt="Sequential feature selection algorithms" class="calibre14" /></span> from the feature set: <span class="strong"><img src="images/00002.jpeg" alt="Sequential feature selection algorithms" class="calibre14" /></span>.
</li><li class="listitem" value="4">Terminate if <span class="strong"><em class="calibre9">k</em></span> equals the number of desired features; otherwise, go to step 2.</li></ol><div class="calibre13"></div></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1219" class="calibre1"></a>Note</h3><p class="calibre8">You can find a detailed evaluation of several sequential feature algorithms in <span class="strong"><em class="calibre9">Comparative Study of Techniques for Large-Scale Feature Selection</em></span>, <span class="strong"><em class="calibre9">F. Ferri</em></span>, <span class="strong"><em class="calibre9">P. Pudil</em></span>, <span class="strong"><em class="calibre9">M. Hatef</em></span>, and <span class="strong"><em class="calibre9">J. Kittler</em></span>, pages 403-413, <span class="strong"><em class="calibre9">1994</em></span>.</p></div><p class="calibre8">Unfortunately, the SBS algorithm has not been implemented in scikit-learn yet. But since it is so simple, let us go ahead and implement it in Python from scratch:</p><div class="informalexample"><pre class="programlisting">from sklearn.base import clone
from itertools import combinations
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split


class SBS():
    def __init__(self, estimator, k_features, 
                 scoring=accuracy_score,
                 test_size=0.25, random_state=1):
        self.scoring = scoring
        self.estimator = clone(estimator)
        self.k_features = k_features
        self.test_size = test_size
        self.random_state = random_state

    def fit(self, X, y):
        
        X_train, X_test, y_train, y_test = \
            train_test_split(X, y, test_size=self.test_size,
                             random_state=self.random_state)

        dim = X_train.shape[1]
        self.indices_ = tuple(range(dim))
        self.subsets_ = [self.indices_]
        score = self._calc_score(X_train, y_train,
                                 X_test, y_test, self.indices_)
        self.scores_ = [score]

        while dim &gt; self.k_features:
            scores = []
            subsets = []

            for p in combinations(self.indices_, r=dim - 1):
                score = self._calc_score(X_train, y_train,
                                         X_test, y_test, p)
                scores.append(score)
                subsets.append(p)

            best = np.argmax(scores)
            self.indices_ = subsets[best]
            self.subsets_.append(self.indices_)
            dim -= 1

            self.scores_.append(scores[best])
        self.k_score_ = self.scores_[-1]

        return self

    def transform(self, X):
        return X[:, self.indices_]

    def _calc_score(self, X_train, y_train, X_test, y_test,
                    indices):
        self.estimator.fit(X_train[:, indices], y_train)
        y_pred = self.estimator.predict(X_test[:, indices])
        score = self.scoring(y_test, y_pred)
        return score</pre></div><p class="calibre8">In the preceding implementation, we defined the <code class="email">k_features</code> parameter to specify the desired number of features we want to return. By default, we use the <code class="email">accuracy_score</code> from scikit-learn to evaluate the performance of a model (an estimator for classification) on the feature subsets. Inside the <code class="email">while</code> loop of the <code class="email">fit</code> method, the feature subsets created by the <code class="email">itertools.combination</code> function are evaluated and reduced until the feature subset has the desired dimensionality. In each iteration, the accuracy score of the best subset is collected in a list, <code class="email">self.scores_</code>, based on the internally created test dataset <code class="email">X_test</code>. We will use those scores later to evaluate the results. The column indices of the final feature subset<a id="calibre_link-1220" class="calibre1"></a> are assigned to <code class="email">self.indices_</code>, which we can use via the <code class="email">transform</code> method to return a new data array with the selected feature columns. Note that, instead of calculating the criterion explicitly inside the <code class="email">fit</code> method, we simply removed the feature that is not contained in the best performing feature subset.</p><p class="calibre8">Now, let us see our SBS implementation in action using the KNN classifier from scikit-learn:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier

&gt;&gt;&gt; knn = KNeighborsClassifier(n_neighbors=5)

&gt;&gt;&gt; sbs = SBS(knn, k_features=1)
&gt;&gt;&gt; sbs.fit(X_train_std, y_train)</pre></div><p class="calibre8">Although our SBS implementation already splits the dataset into a test and training dataset inside the <code class="email">fit</code> function, we still fed the training dataset <code class="email">X_train</code> to the algorithm. The SBS <code class="email">fit</code> method will then create new training subsets for testing (validation) and training, which is why this test set is also called<a id="calibre_link-1221" class="calibre1"></a> the <span class="strong"><strong class="calibre2">validation dataset</strong></span>. This approach is necessary to prevent our <span class="strong"><em class="calibre9">original</em></span> test set from becoming part of the training data.</p><p class="calibre8">Remember that our SBS algorithm collects the scores of the best feature subset at each stage, so let us move on to the more exciting part of our implementation and plot the classification accuracy of the KNN classifier that was calculated on the validation dataset. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; k_feat = [len(k) for k in sbs.subsets_]

&gt;&gt;&gt; plt.plot(k_feat, sbs.scores_, marker='o')
&gt;&gt;&gt; plt.ylim([0.7, 1.02])
&gt;&gt;&gt; plt.ylabel('Accuracy')
&gt;&gt;&gt; plt.xlabel('Number of features')
&gt;&gt;&gt; plt.grid()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the following figure, the accuracy of the KNN classifier improved on the validation dataset as we reduced the number of features, which is likely due to a decrease in the <span class="strong"><strong class="calibre2">curse of dimensionality</strong></span> that <a id="calibre_link-1222" class="calibre1"></a>we discussed in the context of the KNN algorithm in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>. Also, we can see in the following plot that the classifier achieved 100 percent accuracy for <span class="strong"><em class="calibre9">k={3, 7, 8, 9, 10, 11, 12}</em></span>:</p><div class="mediaobject"><img src="images/00033.jpeg" alt="Sequential feature selection algorithms" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To satisfy our own <a id="calibre_link-1223" class="calibre1"></a>curiosity, let's see what the smallest feature subset (<span class="strong"><em class="calibre9">k=3</em></span>) that yielded such a good performance on the validation dataset looks like:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; k3 = list(sbs.subsets_[10])
&gt;&gt;&gt; print(df_wine.columns[1:][k3])
Index(['Alcohol', 'Malic acid', 'OD280/OD315 of diluted wines'], dtype='object')</pre></div><p class="calibre8">Using the preceding code, we obtained the column indices of the three-feature subset from the 10th position in the <code class="email">sbs.subsets_</code> attribute and returned the corresponding feature names from the column-index of the pandas Wine <code class="email">DataFrame</code>.</p><p class="calibre8">Next let's evaluate the performance of the KNN classifier on the original test set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; knn.fit(X_train_std, y_train)
&gt;&gt;&gt; print('Training accuracy:', knn.score(X_train_std, y_train))
Training accuracy: 0.967741935484
&gt;&gt;&gt; print('Test accuracy:', knn.score(X_test_std, y_test))
Test accuracy: 0.962962962963</pre></div><p class="calibre8">In the preceding code section, we used the complete feature set and obtained approximately 97 percent accuracy on the training dataset and approximately 96 percent accuracy on the test, which indicates that our model already generalizes well to new data. Now, let us use the selected three-feature subset and see how well KNN performs:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; knn.fit(X_train_std[:, k3], y_train)
&gt;&gt;&gt; print('Training accuracy:', 
...        knn.score(X_train_std[:, k3], y_train))
Training accuracy: 0.951612903226
&gt;&gt;&gt; print('Test accuracy:',
...        knn.score(X_test_std[:, k3], y_test))
Test accuracy: 0.925925925926</pre></div><p class="calibre8">Using less than a<a id="calibre_link-1224" class="calibre1"></a> quarter of the original features in the Wine dataset, the prediction accuracy on the test set declined slightly. This may indicate that those three features do not provide less discriminatory information than the original dataset. However, we also have to keep in mind that the Wine dataset is a small dataset, which is very susceptible to randomness&mdash;that is, the way we split the dataset into training and test subsets, and how we split the training dataset further into a training and validation subset.</p><p class="calibre8">While we did not increase the performance of the KNN model by reducing the number of features, we shrank the size of the dataset, which can be useful in real-world applications that may involve expensive data collection steps. Also, by substantially reducing the number of features, we obtain simpler models, which are easier to interpret.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1225" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Feature selection algorithms in scikit-learn</strong></span>
</p><p class="calibre8">There are many more feature selection algorithms available via scikit-learn. Those include <span class="strong"><strong class="calibre2">recursive backward elimination</strong></span>
<a id="calibre_link-1226" class="calibre1"></a> based on feature weights, tree-based methods to select features by importance, and univariate statistical tests. A comprehensive discussion of the different feature selection methods is beyond the scope of this book, but a good summary with illustrative examples can be found at <a class="calibre1" href="http://scikit-learn.org/stable/modules/feature_selection.html">http://scikit-learn.org/stable/modules/feature_selection.html</a>. Furthermore, I implemented several different flavors of sequential feature selection, related to the simple SBS that we implemented previously. You can find these implementations in the<a id="calibre_link-1227" class="calibre1"></a> Python package <code class="email">mlxtend</code> at <a class="calibre1" href="http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/">http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/</a>.</p></div></div></div></div>

<div id="calibre_link-582" class="calibre"><div class="book" title="Assessing feature importance with random forests" id="calibre_link-160"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1228"><a id="calibre_link-1229" class="calibre1"></a>Assessing feature importance with random forests</h1></div></div></div><p class="calibre8">In previous sections, you <a id="calibre_link-1230" class="calibre1"></a>learned how to use L1 regularization<a id="calibre_link-1231" class="calibre1"></a> to zero out irrelevant features via logistic regression, and use the SBS algorithm for feature selection and apply it to a KNN algorithm. Another useful approach to select relevant features from a dataset is to use a <span class="strong"><strong class="calibre2">random forest</strong></span>, an ensemble technique that we introduced in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>. Using a random forest, we can measure the feature importance as the averaged impurity decrease computed from all decision trees in the forest, without making any assumptions about whether our data is linearly separable or not. Conveniently, the random forest implementation in scikit-learn already collects the feature importance values for us so that we can access them via the <code class="email">feature_importances_</code> attribute after fitting a <code class="email">RandomForestClassifier</code>. By executing the following code, we will now train a forest of 10,000 trees on the Wine dataset and rank the 13 features by their respective importance measures&mdash;remember from our discussion in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span> that we don't need to use standardized or normalized features in tree-based models:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier

&gt;&gt;&gt; feat_labels = df_wine.columns[1:]

&gt;&gt;&gt; forest = RandomForestClassifier(n_estimators=500,
...                                random_state=1)
&gt;&gt;&gt; forest.fit(X_train, y_train)
&gt;&gt;&gt; importances = forest.feature_importances_

&gt;&gt;&gt; indices = np.argsort(importances)[::-1]

&gt;&gt;&gt; for f in range(X_train.shape[1]):
...     print("%2d) %-*s %f" % (f + 1, 30,
...                             feat_labels[indices[f]],
...                             importances[indices[f]]))
&gt;&gt;&gt; plt.title('Feature Importance')
&gt;&gt;&gt; plt.bar(range(X_train.shape[1]),
...         importances[indices],
...         align='center')

&gt;&gt;&gt; plt.xticks(range(X_train.shape[1]),
...            feat_labels, rotation=90)
&gt;&gt;&gt; plt.xlim([-1, X_train.shape[1]])
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()

 1) Proline                        0.185453
 2) Flavanoids                     0.174751
 3) Color intensity                0.143920
 4) OD280/OD315 of diluted wines   0.136162
 5) Alcohol                        0.118529
 6) Hue                            0.058739
 7) Total phenols                  0.050872
 8) Magnesium                      0.031357
 9) Malic acid                     0.025648
10) Proanthocyanins                0.025570
11) Alcalinity of ash              0.022366
12) Nonflavanoid phenols           0.013354
13) Ash                            0.013279</pre></div><p class="calibre8">After executing the code, we created a plot that ranks the different features in the Wine dataset, by their relative importance; note that the feature importance values <a id="calibre_link-1232" class="calibre1"></a>are normalized so that they <a id="calibre_link-1233" class="calibre1"></a>sum up to 1.0:</p><div class="mediaobject"><img src="images/00044.jpeg" alt="Assessing feature importance with random forests" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can conclude that the proline and flavonoid levels, the color intensity, the OD280/OD315 diffraction, and the alcohol concentration of wine are the most discriminative features in the dataset based on the average impurity decrease in the 500 decision trees. Interestingly, two of the top-ranked features in the plot are also in the three-feature subset selection from the SBS algorithm that we implemented in the previous section (alcohol concentration and OD280/OD315 of diluted wines). However, as far as interpretability is concerned, the random forest technique comes with an important <span class="strong"><em class="calibre9">gotcha</em></span> that is worth mentioning. If two or more features are highly correlated, one feature may be ranked very highly while the information of the other feature(s) may not be fully captured. On the other hand, we don't need to be concerned about this problem if we are merely interested in the predictive performance of a model rather than the interpretation of feature importance values.</p><p class="calibre8">To conclude this section about feature importance values and random forests, it is worth mentioning that scikit-learn also implements a <code class="email">SelectFromModel</code> object that selects features based on a user-specified threshold after model fitting, which is useful if we want to use the <code class="email">RandomForestClassifier</code> as a feature selector and intermediate step in a scikit-learn <code class="email">Pipeline</code> object, which allows us to connect different preprocessing steps with an estimator, as we will see in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>. For example, we could set the <code class="email">threshold</code> to <code class="email">0.1</code> to reduce the <a id="calibre_link-1234" class="calibre1"></a>dataset to the five most important <a id="calibre_link-1235" class="calibre1"></a>features using the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.feature_selection import SelectFromModel

&gt;&gt;&gt; sfm = SelectFromModel(forest, threshold=0.1, prefit=True)
&gt;&gt;&gt; X_selected = sfm.transform(X_train)
&gt;&gt;&gt; print('Number of samples that meet this criterion:',
...       X_selected.shape[0])
Number of samples that meet this criterion: 124

&gt;&gt;&gt; for f in range(X_selected.shape[1]):
...     print("%2d) %-*s %f" % (f + 1, 30, 
...                             feat_labels[indices[f]], 
...                             importances[indices[f]]))
1) Proline                        0.185453
2) Flavanoids                     0.174751
3) Color intensity                0.143920
4) OD280/OD315 of diluted wines   0.136162
5) Alcohol                        0.118529</pre></div></div></div>

<div id="calibre_link-588" class="calibre"><div class="book" title="Summary" id="calibre_link-277"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1236"><a id="calibre_link-1237" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">We started this chapter by looking at useful techniques to make sure that we handle missing data correctly. Before we feed data to a machine learning algorithm, we also have to make sure that we encode categorical variables correctly, and we have seen how we can map ordinal and nominal feature values to integer representations.</p><p class="calibre8">Moreover, we briefly discussed L1 regularization, which can help us to avoid overfitting by reducing the complexity of a model. As an alternative approach to removing irrelevant features, we used a sequential feature selection algorithm to select meaningful features from a dataset.</p><p class="calibre8">In the next chapter, you will learn about yet another useful approach to dimensionality reduction: feature extraction. It allows us to compress features onto a lower-dimensional subspace, rather than removing features entirely as in feature selection.</p></div></div>

<div id="calibre_link-566" class="calibre">
<div id="calibre_link-1238" class="calibre10"></div><div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction"><div class="book" id="calibre_link-26"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1239"><a id="calibre_link-1240" class="calibre1"></a>Chapter&nbsp;5.&nbsp;Compressing Data via Dimensionality Reduction</h1></div></div></div><p class="calibre8">In <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>, you learned about the different approaches for reducing the dimensionality of a dataset using different feature selection techniques. An alternative approach to feature selection for dimensionality reduction is <span class="strong"><strong class="calibre2">feature extraction</strong></span>. In this chapter, you will learn about three fundamental techniques that will help us to summarize the information content of a dataset by transforming it onto a new feature subspace of lower dimensionality than the original one. Data compression is an important topic in machine learning, and it helps us to store and analyze the increasing amounts of data that are produced and collected in the modern age of technology.</p><p class="calibre8">In this chapter, we will cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Principal Component Analysis</strong></span> (<span class="strong"><strong class="calibre2">PCA</strong></span>) for unsupervised data compression</li><li class="listitem"><span class="strong"><strong class="calibre2">Linear Discriminant Analysis</strong></span> (<span class="strong"><strong class="calibre2">LDA</strong></span>) as a supervised dimensionality reduction technique for maximizing class separability</li><li class="listitem">Nonlinear dimensionality reduction via <span class="strong"><strong class="calibre2">Kernel Principal Component Analysis </strong></span>(<span class="strong"><strong class="calibre2">KPCA</strong></span>)</li></ul></div></div></div>

<div id="calibre_link-596" class="calibre">
<div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction">
<div class="book" title="Unsupervised dimensionality reduction via principal component analysis"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1241"><a id="calibre_link-278" class="calibre1"></a>Unsupervised dimensionality reduction via principal component analysis</h1></div></div></div><p class="calibre8">Similar to feature selection, we can use <a id="calibre_link-1242" class="calibre1"></a>different feature extraction techniques to reduce the number of features in a dataset. The difference between feature selection and feature extraction is that while we maintain the original features when we used feature selection algorithms, such as <span class="strong"><em class="calibre9">sequential backward selection</em></span>, we use feature extraction to transform or project the data onto a new feature space. In the context of dimensionality reduction, feature extraction can be understood as an approach to data compression with the goal of maintaining most of the relevant information. In practice, feature extraction is not only used to improve storage space or the computational efficiency of the learning algorithm, but can also improve the predictive performance by reducing the <span class="strong"><em class="calibre9">curse of dimensionality</em></span>&mdash;especially if<a id="calibre_link-1243" class="calibre1"></a> we are working with non-regularized models.</p></div></div></div>

<div id="calibre_link-600" class="calibre">
<div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction">
<div class="book" title="Unsupervised dimensionality reduction via principal component analysis">
<div class="book" title="The main steps behind principal component analysis"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1244"><a id="calibre_link-279" class="calibre1"></a>The main steps behind principal component analysis</h2></div></div></div><p class="calibre8">In this section, we will <a id="calibre_link-1245" class="calibre1"></a>discuss PCA, an unsupervised linear transformation technique that is widely used across different fields, most prominently for feature extraction and dimensionality reduction. Other popular applications of PCA include exploratory data analyses and de-noising of signals in stock market trading, and the analysis of genome data and gene expression levels in the field of bioinformatics.</p><p class="calibre8">PCA helps us to identify patterns in data based on the correlation between features. In a nutshell, PCA aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions than the original one. The orthogonal axes (principal components) of the new subspace can be interpreted as the directions of maximum variance given the constraint that the new feature axes are orthogonal to each other, as illustrated in the following figure:</p><div class="mediaobject"><img src="images/00058.jpeg" alt="The main steps behind principal component analysis" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the preceding figure, <span class="strong"><img src="images/00064.jpeg" alt="The main steps behind principal component analysis" class="calibre14" /></span> and <span class="strong"><img src="images/00074.jpeg" alt="The main steps behind principal component analysis" class="calibre14" /></span> are the original feature axes, and <span class="strong"><strong class="calibre2">PC1 </strong></span>and <span class="strong"><strong class="calibre2">PC2 </strong></span>are the principal components.</p><p class="calibre8">If we use PCA for <a id="calibre_link-1246" class="calibre1"></a>dimensionality reduction, we construct a <span class="strong"><img src="images/00088.jpeg" alt="The main steps behind principal component analysis" class="calibre14" /></span>&ndash;dimensional transformation matrix <span class="strong"><strong class="calibre2">W</strong></span> that allows us to map a sample vector <span class="strong"><strong class="calibre2">x</strong></span> onto a new <span class="strong"><em class="calibre9">k</em></span>&ndash;dimensional feature subspace that has fewer dimensions than the original <span class="strong"><em class="calibre9">d</em></span>&ndash;dimensional feature space:</p><div class="mediaobject"><img src="images/00101.jpeg" alt="The main steps behind principal component analysis" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00113.jpeg" alt="The main steps behind principal component analysis" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00121.jpeg" alt="The main steps behind principal component analysis" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As a result of transforming the original <span class="strong"><em class="calibre9">d</em></span>-dimensional data onto this new <span class="strong"><em class="calibre9">k</em></span>-dimensional subspace (typically <span class="strong"><em class="calibre9">k</em></span> &lt;&lt; <span class="strong"><em class="calibre9">d</em></span>), the first principal component will have the largest possible variance, and all consequent principal components will have the largest variance given the constraint that these components are uncorrelated (orthogonal) to the other principal components&mdash;even if the input features are correlated, the resulting principal components will be mutually orthogonal (uncorrelated). Note that the PCA directions are highly sensitive to data scaling, and we need to standardize the features <span class="strong"><strong class="calibre2">prior</strong></span> to PCA if the features were measured on different scales and we want to assign equal importance to all features.</p><p class="calibre8">Before looking at the PCA algorithm for dimensionality reduction in more detail, let's summarize the approach in a few simple steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Standardize the <span class="strong"><em class="calibre9">d</em></span>-dimensional dataset.</li><li class="listitem" value="2">Construct the covariance matrix.</li><li class="listitem" value="3">Decompose the covariance matrix into its eigenvectors and eigenvalues.</li><li class="listitem" value="4">Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors.</li><li class="listitem" value="5">
Select <span class="strong"><em class="calibre9">k</em></span> eigenvectors which correspond to the <span class="strong"><em class="calibre9">k</em></span> largest eigenvalues, where <span class="strong"><em class="calibre9">k</em></span> is the dimensionality of the new feature subspace (<span class="strong"><img src="images/00135.jpeg" alt="The main steps behind principal component analysis" class="calibre14" /></span>).
</li><li class="listitem" value="6">Construct a <a id="calibre_link-1247" class="calibre1"></a>projection matrix <span class="strong"><strong class="calibre2">W</strong></span> from the "top" <span class="strong"><em class="calibre9">k</em></span> eigenvectors.</li><li class="listitem" value="7">Transform the <span class="strong"><em class="calibre9">d</em></span>-dimensional input dataset <span class="strong"><strong class="calibre2">X</strong></span> using the projection matrix <span class="strong"><strong class="calibre2">W</strong></span> to obtain the new <span class="strong"><em class="calibre9">k</em></span>-dimensional feature subspace.</li></ol><div class="calibre13"></div></div><p class="calibre8">In the following sections, we will perform a PCA step by step, using Python as a learning exercise. Then, we will see how to perform a PCA more conveniently using scikit-learn.</p></div></div></div></div>

<div id="calibre_link-621" class="calibre">
<div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction">
<div class="book" title="Unsupervised dimensionality reduction via principal component analysis">
<div class="book" title="Extracting the principal components step by step"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1248"><a id="calibre_link-280" class="calibre1"></a>Extracting the principal components step by step</h2></div></div></div><p class="calibre8">In this subsection, we <a id="calibre_link-1249" class="calibre1"></a>will tackle the first four steps of a PCA:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Standardizing the data.</li><li class="listitem" value="2">Constructing the covariance matrix.</li><li class="listitem" value="3">Obtaining the eigenvalues and eigenvectors of the covariance matrix.</li><li class="listitem" value="4">Sorting the eigenvalues by decreasing order to rank the eigenvectors.</li></ol><div class="calibre13"></div></div><p class="calibre8">First, we will start by loading the Wine dataset that we have been working with in<a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36"> Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'
                      'machine-learning-databases/wine/wine.data',
                      header=None)</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1250" class="calibre1"></a>Note</h3><p class="calibre8">You can find a copy of the Wine dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the UCI server at <a class="calibre1" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data">https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data</a> is temporarily unavailable. For instance, to load the Wine dataset from a local directory, you can replace the following line:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('https://archive.ics.uci.edu/ml/'
        'machine-learning-databases/wine/wine.data', header=None)</pre></div><p class="calibre8">Replace it with this:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('your/local/path/to/wine.data', header=None)</pre></div></div><p class="calibre8">Next, we will process the Wine data into separate training and test sets&mdash;using 70 percent and 30 percent of the data, respectively&mdash;and standardize it to unit variance:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values
&gt;&gt;&gt; X_train, X_test, y_train, y_test = \
&gt;&gt;&gt;     train_test_split(X, y, test_size=0.3, 
...                      stratify=y,
...                      random_state=0)
&gt;&gt;&gt; # standardize the features
&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; sc = StandardScaler()
&gt;&gt;&gt; X_train_std = sc.fit_transform(X_train)
&gt;&gt;&gt; X_test_std = sc.transform(X_test)</pre></div><p class="calibre8">After completing the<a id="calibre_link-1251" class="calibre1"></a> mandatory preprocessing by executing the preceding code, let's advance to the second step: constructing the covariance matrix. The symmetric <span class="strong"><img src="images/00049.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span>-dimensional covariance matrix, where <span class="strong"><em class="calibre9">d</em></span> is the number of dimensions in the dataset, stores the pairwise covariances between the different features. For example, the covariance between two features <span class="strong"><img src="images/00104.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span> and <span class="strong"><img src="images/00162.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span> on the population level can be calculated via the following equation:</p><div class="mediaobject"><img src="images/00220.jpeg" alt="Extracting the principal components step by step" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00275.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span> and <span class="strong"><img src="images/00326.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span> are the sample means of features <span class="strong"><em class="calibre9">j</em></span> and <span class="strong"><em class="calibre9">k</em></span>, respectively. Note that the sample means are zero if we standardized the dataset. A positive covariance between two features indicates that the features increase or decrease together, whereas a negative covariance indicates that the features vary in opposite directions. For example, the covariance matrix of three features can then be written as follows (note that <span class="strong"><img src="images/00376.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span> stands for the Greek uppercase letter <span class="strong"><strong class="calibre2">sigma</strong></span>, which is not to be confused with the <span class="strong"><strong class="calibre2">sum</strong></span> symbol):</p><div class="mediaobject"><img src="images/00429.jpeg" alt="Extracting the principal components step by step" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The eigenvectors of the <a id="calibre_link-1252" class="calibre1"></a>covariance matrix represent the principal components (the directions of maximum variance), whereas the corresponding eigenvalues will define their magnitude. In the case of the Wine dataset, we would obtain 13 eigenvectors and eigenvalues from the 13 x 13-dimensional covariance matrix.</p><p class="calibre8">Now, for our third step, let's obtain the eigenpairs of the covariance matrix. As we remember from our introductory linear algebra classes, an eigenvector <span class="strong"><strong class="calibre2">v</strong></span> satisfies the following condition:</p><div class="mediaobject"><img src="images/00238.jpeg" alt="Extracting the principal components step by step" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00247.jpeg" alt="Extracting the principal components step by step" class="calibre14" /></span> is a scalar: the eigenvalue. Since the manual computation of eigenvectors and eigenvalues is a somewhat tedious and elaborate task, we will use the <code class="email">linalg.eig</code> function from NumPy to obtain the eigenpairs of the Wine covariance matrix:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; cov_mat = np.cov(X_train_std.T)
&gt;&gt;&gt; eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)
&gt;&gt;&gt; print('\nEigenvalues \n%s' % eigen_vals)
Eigenvalues 
[ 4.84274532  2.41602459  1.54845825  0.96120438  0.84166161  0.6620634     0.51828472  0.34650377  0.3131368   0.10754642  0.21357215  0.15362835    0.1808613 ]</pre></div><p class="calibre8">Using the <code class="email">numpy.cov</code> function, we computed the covariance matrix of the standardized training dataset. Using the <code class="email">linalg.eig</code> function, we performed the eigendecomposition, which yielded a vector (<code class="email">eigen_vals</code>) consisting of 13 eigenvalues and the corresponding eigenvectors stored as columns in a 13 x 13-dimensional matrix (<code class="email">eigen_vecs</code>).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1253" class="calibre1"></a>Note</h3><p class="calibre8">The <code class="email">numpy.linalg.eig</code> function was designed to operate on both symmetric and non-symmetric square matrices. However, you may find that it returns complex eigenvalues in certain cases.</p><p class="calibre8">A related function, <code class="email">numpy.linalg.eigh</code>, has been implemented to decompose Hermetian matrices, which is a numerically more stable approach to work with symmetric matrices such as the covariance matrix; <code class="email">numpy.linalg.eigh</code> always returns real eigenvalues.</p></div></div></div></div></div>

<div id="calibre_link-637" class="calibre">
<div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction">
<div class="book" title="Unsupervised dimensionality reduction via principal component analysis">
<div class="book" title="Total and explained variance"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1254"><a id="calibre_link-281" class="calibre1"></a>Total and explained variance</h2></div></div></div><p class="calibre8">Since we want to<a id="calibre_link-1255" class="calibre1"></a> reduce the dimensionality of our dataset by compressing it onto a new feature<a id="calibre_link-1256" class="calibre1"></a> subspace, we only select the subset of the eigenvectors (principal components) that contains most of the information (variance). The eigenvalues define the magnitude of the eigenvectors, so we have to sort the eigenvalues by decreasing magnitude; we are interested in the top <span class="strong"><em class="calibre9">k</em></span> eigenvectors based on the values of their corresponding eigenvalues. But before we collect those <span class="strong"><em class="calibre9">k</em></span> most informative eigenvectors, let us plot the <span class="strong"><em class="calibre9">variance explained ratios</em></span> of the eigenvalues. The variance explained ratio of an eigenvalue <span class="strong"><img src="images/00261.jpeg" alt="Total and explained variance" class="calibre14" /></span> is simply the fraction of an eigenvalue <span class="strong"><img src="images/00261.jpeg" alt="Total and explained variance" class="calibre14" /></span> and the total sum of the eigenvalues:</p><div class="mediaobject"><img src="images/00271.jpeg" alt="Total and explained variance" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Using the NumPy <code class="email">cumsum</code> function, we can then calculate the cumulative sum of explained variances, which we will then plot via Matplotlib's <code class="email">step</code> function:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; tot = sum(eigen_vals)
&gt;&gt;&gt; var_exp = [(i / tot) for i in
...            sorted(eigen_vals, reverse=True)]
&gt;&gt;&gt; cum_var_exp = np.cumsum(var_exp)
&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; plt.bar(range(1,14), var_exp, alpha=0.5, align='center',
...         label='individual explained variance')
&gt;&gt;&gt; plt.step(range(1,14), cum_var_exp, where='mid',
...         label='cumulative explained variance')
&gt;&gt;&gt; plt.ylabel('Explained variance ratio')
&gt;&gt;&gt; plt.xlabel('Principal component index')
&gt;&gt;&gt; plt.legend(loc='best')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The resulting plot indicates<a id="calibre_link-1257" class="calibre1"></a> that the first principal component alone accounts for <a id="calibre_link-1258" class="calibre1"></a>approximately 40 percent of the variance. Also, we can see that the first two principal components combined explain almost 60 percent of the variance in the dataset:</p><div class="mediaobject"><img src="images/00284.jpeg" alt="Total and explained variance" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although the explained variance plot reminds us of the feature importance values that we computed in <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>, via random forests, we should remind ourselves that PCA is an unsupervised method, which means that information about the class labels is ignored. Whereas a random forest uses the class membership information to compute the node impurities, variance measures the spread of values along a feature axis.</p></div></div></div></div>

<div id="calibre_link-656" class="calibre">
<div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction">
<div class="book" title="Unsupervised dimensionality reduction via principal component analysis">
<div class="book" title="Feature transformation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1259"><a id="calibre_link-282" class="calibre1"></a>Feature transformation</h2></div></div></div><p class="calibre8">After we have successfully<a id="calibre_link-1260" class="calibre1"></a> decomposed the covariance matrix into eigenpairs, let's now proceed with the last three steps to transform the Wine dataset onto the new principal component axes. The remaining steps we are going to tackle in this section are the following ones:</p><div class="book"><ul class="itemizedlist"><li class="listitem">
Select <span class="strong"><em class="calibre9">k</em></span> eigenvectors, which correspond to the <span class="strong"><em class="calibre9">k</em></span> largest eigenvalues, where <span class="strong"><em class="calibre9">k</em></span> is the dimensionality of the new feature subspace (<span class="strong"><img src="images/00135.jpeg" alt="Feature transformation" class="calibre14" /></span>).
</li><li class="listitem">Construct a projection matrix <span class="strong"><strong class="calibre2">W</strong></span> from the "top" <span class="strong"><em class="calibre9">k</em></span> eigenvectors.</li><li class="listitem">Transform the <span class="strong"><em class="calibre9">d</em></span>-dimensional input dataset <span class="strong"><strong class="calibre2">X</strong></span> using the projection matrix <span class="strong"><strong class="calibre2">W</strong></span> to obtain the new <span class="strong"><em class="calibre9">k</em></span>-dimensional feature subspace.</li></ul></div><p class="calibre8">Or, in less technical terms, we will sort the eigenpairs by descending order of the eigenvalues, construct a projection matrix from the selected eigenvectors, and use the projection matrix to transform the data onto the lower-dimensional subspace.</p><p class="calibre8">We start by sorting the eigenpairs by decreasing order of the eigenvalues:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; # Make a list of (eigenvalue, eigenvector) tuples
&gt;&gt;&gt; eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])
...                for i in range(len(eigen_vals))]
&gt;&gt;&gt; # Sort the (eigenvalue, eigenvector) tuples from high to low
&gt;&gt;&gt; eigen_pairs.sort(key=lambda k: k[0], reverse=True)</pre></div><p class="calibre8">Next, we collect the two eigenvectors that correspond to the two largest eigenvalues, to capture about 60 percent of the variance in this dataset. Note that we only chose two eigenvectors for the purpose of illustration, since we are going to plot the data via a two-dimensional scatter plot later in this subsection. In practice, the number of principal components has to be <a id="calibre_link-1261" class="calibre1"></a>determined by a trade-off between computational efficiency and the performance of the classifier:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; w = np.hstack((eigen_pairs[0][1][:, np.newaxis],
...                eigen_pairs[1][1][:, np.newaxis]))
&gt;&gt;&gt; print('Matrix W:\n', w)
Matrix W:
 [[-0.13724218  0.50303478]
 [ 0.24724326  0.16487119]
 [-0.02545159  0.24456476]
 [ 0.20694508 -0.11352904]
 [-0.15436582  0.28974518]
 [-0.39376952  0.05080104]
 [-0.41735106 -0.02287338]
 [ 0.30572896  0.09048885]
 [-0.30668347  0.00835233]
 [ 0.07554066  0.54977581]
 [-0.32613263 -0.20716433]
 [-0.36861022 -0.24902536]
 [-0.29669651  0.38022942]]</pre></div><p class="calibre8">By executing the preceding code, we have created a 13 x 2-dimensional projection matrix <span class="strong"><strong class="calibre2">W</strong></span> from the top two eigenvectors.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1262" class="calibre1"></a>Note</h3><p class="calibre8">Depending on which version of NumPy and LAPACK you are using, you may obtain the matrix W with its signs flipped. Please note that this is not an issue; if <span class="strong"><strong class="calibre2">v</strong></span> is an eigenvector of a matrix <span class="strong"><img src="images/00376.jpeg" alt="Feature transformation" class="calibre14" /></span>, we have:</p><div class="mediaobject1"><img src="images/00238.jpeg" alt="Feature transformation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here <span class="strong"><img src="images/00247.jpeg" alt="Feature transformation" class="calibre14" /></span> is our eigenvalue, and -<span class="strong"><img src="images/00247.jpeg" alt="Feature transformation" class="calibre14" /></span> is also an eigenvector that has the same eigenvalue, since:</p><div class="mediaobject1"><img src="images/00763.jpeg" alt="Feature transformation" class="calibre11" /></div><p class="calibre12"> </p></div><p class="calibre8">Using the <a id="calibre_link-1263" class="calibre1"></a>projection matrix, we can now transform a sample <span class="strong"><strong class="calibre2">x</strong></span> (represented as a 1 x 13-dimensional row vector) onto the PCA subspace (the principal components one and two) obtaining <span class="strong"><img src="images/00304.jpeg" alt="Feature transformation" class="calibre14" /></span>, now a two-dimensional sample vector consisting of two new features:</p><div class="mediaobject"><img src="images/00314.jpeg" alt="Feature transformation" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train_std[0].dot(w)
array([ 2.38299011,  0.45458499])</pre></div><p class="calibre8">Similarly, we can transform the entire 124 x 13-dimensional training dataset onto the two principal components by calculating the matrix dot product:</p><div class="mediaobject"><img src="images/00323.jpeg" alt="Feature transformation" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train_pca = X_train_std.dot(w)</pre></div><p class="calibre8">Lastly, let us visualize the transformed Wine training set, now stored as an 124 x 2-dimensional matrix, in a two-dimensional scatterplot:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; colors = ['r', 'b', 'g']
&gt;&gt;&gt; markers = ['s', 'x', 'o']
&gt;&gt;&gt; for l, c, m in zip(np.unique(y_train), colors, markers):
...     plt.scatter(X_train_pca[y_train==l, 0], 
...                 X_train_pca[y_train==l, 1], 
...                 c=c, label=l, marker=m) 
&gt;&gt;&gt; plt.xlabel('PC 1')
&gt;&gt;&gt; plt.ylabel('PC 2')
&gt;&gt;&gt; plt.legend(loc='lower left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the <a id="calibre_link-1264" class="calibre1"></a>resulting plot, the data is more spread along the <span class="strong"><em class="calibre9">x</em></span>-axis&mdash;the first principal component&mdash;than the second principal component (<span class="strong"><em class="calibre9">y</em></span>-axis), which is consistent with the explained variance ratio plot that we created in the previous subsection. However, we can intuitively see that a linear classifier will likely be able to separate the classes well:</p><div class="mediaobject"><img src="images/00336.jpeg" alt="Feature transformation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although we encoded the class label information for the purpose of illustration in the preceding scatter plot, we have to keep in mind that PCA is an unsupervised technique that doesn't use any class label information.</p></div></div></div></div>

<div id="calibre_link-608" class="calibre">
<div class="book" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction">
<div class="book" title="Unsupervised dimensionality reduction via principal component analysis">
<div class="book" title="Principal component analysis in scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1265"><a id="calibre_link-283" class="calibre1"></a>Principal component analysis in scikit-learn</h2></div></div></div><p class="calibre8">Although the verbose approach in the<a id="calibre_link-1266" class="calibre1"></a> previous subsection <a id="calibre_link-1267" class="calibre1"></a>helped us to follow the inner workings of PCA, we will now discuss how to use the <code class="email">PCA</code> class implemented in scikit-learn. The <code class="email">PCA</code> class is another one of scikit-learn's transformer classes, where we first fit the model using the training data before we transform both the training data and the test dataset using the same model parameters. Now, let's use the <code class="email">PCA</code> class from scikit-learn on the Wine training dataset, classify the transformed samples via logistic regression, and visualize the decision regions via the <code class="email">plot_decision_region</code> function that we defined in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>:</p><div class="informalexample"><pre class="programlisting">from matplotlib.colors import ListedColormap

def plot_decision_regions(X, y, classifier, resolution=0.02):

    # setup marker generator and color map
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])

    # plot the decision surface
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))
    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    Z = Z.reshape(xx1.shape)
    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())

    # plot class samples
    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(x=X[y == cl, 0], 
                    y=X[y == cl, 1],
                    alpha=0.6, 
                    c=cmap(idx),
                    edgecolor='black',
                    marker=markers[idx], 
                    label=cl)

&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.decomposition import PCA
&gt;&gt;&gt; pca = PCA(n_components=2)
&gt;&gt;&gt; lr = LogisticRegression()
&gt;&gt;&gt; X_train_pca = pca.fit_transform(X_train_std)
&gt;&gt;&gt; X_test_pca = pca.transform(X_test_std)
&gt;&gt;&gt; lr.fit(X_train_pca, y_train)
&gt;&gt;&gt; plot_decision_regions(X_train_pca, y_train, classifier=lr)
&gt;&gt;&gt; plt.xlabel('PC 1')
&gt;&gt;&gt; plt.ylabel('PC 2')
&gt;&gt;&gt; plt.legend(loc='lower left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">By executing the preceding <a id="calibre_link-1268" class="calibre1"></a>code, we should now see the<a id="calibre_link-1269" class="calibre1"></a> decision regions for the training data reduced to two principal component axes:</p><div class="mediaobject"><img src="images/00105.jpeg" alt="Principal component analysis in scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">When we compare PCA projections via scikit-learn with our own PCA implementation, it can happen that the resulting plots are mirror images of each other. Note that this is not due to an error in either of those two implementations, but the reason for this difference is that, depending on the eigensolver, eigenvectors can have either negative or positive signs. Not that it matters, but we could simply revert the mirror image by multiplying the data by <code class="email">-1</code> if we wanted to; note that eigenvectors are typically scaled to unit length 1. For the sake of completeness, let's plot the decision regions of the logistic regression on the transformed test dataset to see if it can separate the classes well:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plot_decision_regions(X_test_pca, y_test, classifier=lr)
&gt;&gt;&gt; plt.xlabel('PC1')
&gt;&gt;&gt; plt.ylabel('PC2')
&gt;&gt;&gt; plt.legend(loc='lower left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After we plotted the decision regions<a id="calibre_link-1270" class="calibre1"></a> for the test set by executing <a id="calibre_link-1271" class="calibre1"></a>the preceding code, we can see that logistic regression performs quite well on this small two-dimensional feature subspace and only misclassifies very few samples in the test dataset:</p><div class="mediaobject"><img src="images/00163.jpeg" alt="Principal component analysis in scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">If we are interested in the explained variance ratios of the different principal components, we can simply initialize the <code class="email">PCA</code> class with the <code class="email">n_components</code> parameter set to <code class="email">None</code>, so all principal components are kept and the explained variance ratio can then be accessed via the <code class="email">explained_variance_ratio_</code> attribute:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; pca = PCA(n_components=None)
&gt;&gt;&gt; X_train_pca = pca.fit_transform(X_train_std)
&gt;&gt;&gt; pca.explained_variance_ratio_
array([ 0.36951469,  0.18434927,  0.11815159,  0.07334252,  0.06422108, 0.05051724,  0.03954654,  0.02643918,  0.02389319,  0.01629614, 0.01380021,  0.01172226,  0.00820609])</pre></div><p class="calibre8">Note that we set <code class="email">n_components=None</code> when we initialized the <code class="email">PCA</code> class so that it will return all principal components in a sorted order instead of performing a dimensionality reduction.</p></div></div></div></div>

<div id="calibre_link-612" class="calibre">
<div id="calibre_link-1272" class="calibre10"></div><div class="book" title="Supervised data compression via linear discriminant analysis"><div class="book" id="calibre_link-162"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1273"><a id="calibre_link-1274" class="calibre1"></a>Supervised data compression via linear discriminant analysis</h1></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Linear Discriminant Analysis</strong></span> (<span class="strong"><strong class="calibre2">LDA</strong></span>) can be<a id="calibre_link-1275" class="calibre1"></a> used as a technique for feature extraction to increase the computational efficiency and reduce the degree of overfitting due to the curse of dimensionality in non-regularized models.</p><p class="calibre8">The general concept behind LDA is very similar to PCA. Whereas PCA attempts to find the orthogonal component axes of maximum variance in a dataset, the goal in LDA is to find the feature subspace that optimizes class separability. In the following sections, we will discuss the similarities between LDA and PCA in more detail and walk through the LDA approach step by step.</p></div></div>

<div id="calibre_link-99" class="calibre">
<div class="book" title="Supervised data compression via linear discriminant analysis">
<div class="book" title="Principal component analysis versus linear discriminant analysis"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1276"><a id="calibre_link-284" class="calibre1"></a>Principal component analysis versus linear discriminant analysis</h2></div></div></div><p class="calibre8">Both LDA and PCA are<a id="calibre_link-1277" class="calibre1"></a> linear transformation<a id="calibre_link-1278" class="calibre1"></a> techniques that can be used to reduce the number of dimensions in a dataset; the former is an unsupervised algorithm, whereas the latter is supervised. Thus, we might intuitively think that LDA is a superior feature extraction technique for classification tasks compared to PCA. However, A.M. Martinez reported that preprocessing via PCA tends to result in better classification results in an image recognition task in certain cases, for instance if each class consists of only a small number of samples (<span class="strong"><em class="calibre9">PCA Versus LDA</em></span>, <span class="strong"><em class="calibre9">A. M. Martinez</em></span> and <span class="strong"><em class="calibre9">A. C. Kak</em></span>, <span class="strong"><em class="calibre9">IEEE Transactions on Pattern Analysis and Machine Intelligence</em></span>, 23(2): 228-233, <span class="strong"><em class="calibre9">2001</em></span>).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1279" class="calibre1"></a>Note</h3><p class="calibre8">LDA is sometimes also called Fisher's LDA. Ronald A. Fisher initially formulated <span class="strong"><em class="calibre9">Fisher's Linear Discriminant</em></span> for two-class classification problems in 1936 (<span class="strong"><em class="calibre9">The Use of Multiple Measurements in Taxonomic Problems</em></span>, <span class="strong"><em class="calibre9">R. A. Fisher</em></span>, <span class="strong"><em class="calibre9">Annals of Eugenics</em></span>, 7(2): 179-188, <span class="strong"><em class="calibre9">1936</em></span>). Fisher's linear discriminant was later generalized for multi-class problems by C. Radhakrishna Rao under the assumption of equal class covariances and normally distributed classes in 1948, which we now call LDA (<span class="strong"><em class="calibre9">The Utilization of Multiple Measurements in Problems of Biological Classification</em></span>, <span class="strong"><em class="calibre9">C. R. Rao</em></span>, <span class="strong"><em class="calibre9">Journal of the Royal Statistical Society</em></span>. Series B (Methodological), 10(2): 159-203, <span class="strong"><em class="calibre9">1948</em></span>).</p></div><p class="calibre8">The following figure summarizes the concept of LDA for a two-class problem. Samples from class <code class="email">1</code> are shown as circles, and samples from class <code class="email">2</code> are shown as crosses:</p><div class="mediaobject"><img src="images/00364.jpeg" alt="Principal component analysis versus linear discriminant analysis" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">A linear discriminant, as<a id="calibre_link-1280" class="calibre1"></a> shown on the<span class="strong"><em class="calibre9"> x</em></span>-axis (LD 1), would separate the two normal distributed classes well. Although<a id="calibre_link-1281" class="calibre1"></a> the exemplary linear discriminant shown on the <span class="strong"><em class="calibre9">y</em></span>-axis (LD 2) captures a lot of the variance in the dataset, it would fail as a good linear discriminant since it does not capture any of the class-discriminatory information.</p><p class="calibre8">One assumption in LDA is that the data is normally distributed. Also, we assume that the classes have identical covariance matrices and that the features are statistically independent of each other. However, even if one or more of those assumptions are (slightly) violated, LDA for dimensionality reduction can still work reasonably well (<span class="strong"><em class="calibre9">Pattern Classification 2nd Edition</em></span>, <span class="strong"><em class="calibre9">R. O. Duda</em></span>, <span class="strong"><em class="calibre9">P. E. Hart</em></span>, and <span class="strong"><em class="calibre9">D. G. Stork</em></span>, <span class="strong"><em class="calibre9">New York</em></span>, <span class="strong"><em class="calibre9">2001</em></span>).</p></div></div></div>

<div id="calibre_link-132" class="calibre">
<div class="book" title="Supervised data compression via linear discriminant analysis">
<div class="book" title="The inner workings of linear discriminant analysis"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1282"><a id="calibre_link-285" class="calibre1"></a>The inner workings of linear discriminant analysis</h2></div></div></div><p class="calibre8">Before we dive into the<a id="calibre_link-1283" class="calibre1"></a> code implementation, let's briefly summarize the main steps that are required to perform LDA:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Standardize the <span class="strong"><em class="calibre9">d</em></span>-dimensional dataset (<span class="strong"><em class="calibre9">d</em></span> is the number of features).</li><li class="listitem" value="2">For each class, compute the <span class="strong"><em class="calibre9">d</em></span>-dimensional mean vector.</li><li class="listitem" value="3">
Construct the between-class scatter matrix <span class="strong"><img src="images/00276.jpeg" alt="The inner workings of linear discriminant analysis" class="calibre14" /></span> and the within-class scatter matrix <span class="strong"><img src="images/00327.jpeg" alt="The inner workings of linear discriminant analysis" class="calibre14" /></span>.
</li><li class="listitem" value="4">
Compute the eigenvectors and corresponding eigenvalues of the matrix <span class="strong"><img src="images/00377.jpeg" alt="The inner workings of linear discriminant analysis" class="calibre14" /></span>.
</li><li class="listitem" value="5">Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors.</li><li class="listitem" value="6">
Choose the <span class="strong"><em class="calibre9">k</em></span> eigenvectors that correspond to the <span class="strong"><em class="calibre9">k</em></span> largest eigenvalues to construct a <span class="strong"><img src="images/00088.jpeg" alt="The inner workings of linear discriminant analysis" class="calibre14" /></span>-dimensional transformation matrix <span class="strong"><strong class="calibre2">W</strong></span>; the eigenvectors are the columns of this matrix.
</li><li class="listitem" value="7">Project the <a id="calibre_link-1284" class="calibre1"></a>samples onto the new feature subspace using the transformation matrix <span class="strong"><strong class="calibre2">W</strong></span>.</li></ol><div class="calibre13"></div></div><p class="calibre8">As we can see, LDA is quite similar to PCA in the sense that we are decomposing matrices into eigenvalues and eigenvectors, which will form the new lower-dimensional feature space. However, as mentioned before, LDA takes class label information into account, which is represented in the form of the mean vectors computed in step 2. In the following sections, we will discuss these seven steps in more detail, accompanied by illustrative code implementations.</p></div></div></div>

<div id="calibre_link-618" class="calibre">
<div class="book" title="Supervised data compression via linear discriminant analysis">
<div class="book" title="Computing the scatter matrices"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1285"><a id="calibre_link-286" class="calibre1"></a>Computing the scatter matrices</h2></div></div></div><p class="calibre8">Since we already standardized <a id="calibre_link-1286" class="calibre1"></a>the features of the Wine dataset in the PCA section at the beginning of this chapter, we can skip the first step and proceed with the calculation of the mean vectors, which we will use to construct the within-class scatter matrix and between-class scatter matrix, respectively. Each mean vector <span class="strong"><img src="images/00430.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span> stores the mean feature value <span class="strong"><img src="images/00415.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span> with respect to the samples of class <span class="strong"><em class="calibre9">i</em></span>:</p><div class="mediaobject"><img src="images/00527.jpeg" alt="Computing the scatter matrices" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This results in three mean vectors:</p><div class="mediaobject"><img src="images/00583.jpeg" alt="Computing the scatter matrices" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; np.set_printoptions(precision=4)
&gt;&gt;&gt; mean_vecs = []
&gt;&gt;&gt; for label in range(1,4):
...     mean_vecs.append(np.mean(
...                X_train_std[y_train==label], axis=0))
...     print('MV %s: %s\n' %(label, mean_vecs[label-1]))
MV 1: [ 0.9066 -0.3497  0.3201 -0.7189  0.5056  0.8807  0.9589 -0.5516  0.5416  0.2338  0.5897  0.6563  1.2075]

MV 2: [-0.8749 -0.2848 -0.3735  0.3157 -0.3848 -0.0433  0.0635 -0.0946  0.0703 -0.8286  0.3144  0.3608 -0.7253]

MV 3: [ 0.1992  0.866   0.1682  0.4148 -0.0451 -1.0286 -1.2876  0.8287 -0.7795  0.9649 -1.209  -1.3622 -0.4013]</pre></div><p class="calibre8">Using the mean vectors, we <a id="calibre_link-1287" class="calibre1"></a>can now compute the within-class scatter matrix <span class="strong"><img src="images/00641.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00014.jpeg" alt="Computing the scatter matrices" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This is calculated by summing up the individual scatter matrices <span class="strong"><img src="images/00025.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span> of each individual class <span class="strong"><em class="calibre9">i</em></span>:</p><div class="mediaobject"><img src="images/00005.jpeg" alt="Computing the scatter matrices" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; d = 13 # number of features
&gt;&gt;&gt; S_W = np.zeros((d, d))
&gt;&gt;&gt; for label, mv in zip(range(1, 4), mean_vecs):
...     class_scatter = np.zeros((d, d))
&gt;&gt;&gt;     for row in X_train_std[y_train == label]:
...         row, mv = row.reshape(d, 1), mv.reshape(d, 1)  
...         class_scatter += (row - mv).dot((row - mv).T)
...     S_W += class_scatter
&gt;&gt;&gt; print('Within-class scatter matrix: %sx%s' % (
...       S_W.shape[0], S_W.shape[1]))
Within-class scatter matrix: 13x13</pre></div><p class="calibre8">The assumption that we are making when we are computing the scatter matrices is that the class labels in the training set are uniformly distributed. However, if we print the number of class labels, we see that this assumption is violated:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Class label distribution: %s' 
...       % np.bincount(y_train)[1:])
Class label distribution: [41 50 33]</pre></div><p class="calibre8">Thus, we want to scale the<a id="calibre_link-1288" class="calibre1"></a> individual scatter matrices <span class="strong"><img src="images/00025.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span> before we sum them up as scatter matrix <span class="strong"><img src="images/00641.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span>. When we divide the scatter matrices by the number of class-samples <span class="strong"><img src="images/00481.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span>, we can see that computing the scatter matrix is in fact the same as computing the covariance matrix <span class="strong"><img src="images/00493.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span>&mdash;the covariance matrix is a normalized version of the scatter matrix:</p><div class="mediaobject"><img src="images/00500.jpeg" alt="Computing the scatter matrices" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; d = 13 # number of features
&gt;&gt;&gt; S_W = np.zeros((d, d))
&gt;&gt;&gt; for label,mv in zip(range(1, 4), mean_vecs):
...     class_scatter = np.cov(X_train_std[y_train==label].T)
...     S_W += class_scatter
&gt;&gt;&gt; print('Scaled within-class scatter matrix: %sx%s' 
...       % (S_W.shape[0], S_W.shape[1]))
Scaled within-class scatter matrix: 13x13</pre></div><p class="calibre8">After we computed the scaled within-class scatter matrix (or covariance matrix), we can move on to the next step and <a id="calibre_link-1289" class="calibre1"></a>compute the between-class scatter matrix <span class="strong"><img src="images/00276.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00510.jpeg" alt="Computing the scatter matrices" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00515.jpeg" alt="Computing the scatter matrices" class="calibre14" /></span> is the overall mean that is computed, including samples from all classes:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; mean_overall = np.mean(X_train_std, axis=0)
&gt;&gt;&gt; d = 13  # number of features
&gt;&gt;&gt; S_B = np.zeros((d, d))
&gt;&gt;&gt; for i, mean_vec in enumerate(mean_vecs):
...     n = X_train[y_train == i + 1, :].shape[0]
...     mean_vec = mean_vec.reshape(d, 1)  # make column vector
...     mean_overall = mean_overall.reshape(d, 1) 
...     S_B += n * (mean_vec - mean_overall).dot(
...                (mean_vec - mean_overall).T)
&gt;&gt;&gt; print('Between-class scatter matrix: %sx%s' % (
...                S_B.shape[0], S_B.shape[1]))</pre></div></div></div></div>

<div id="calibre_link-625" class="calibre">
<div class="book" title="Supervised data compression via linear discriminant analysis">
<div class="book" title="Selecting linear discriminants for the new feature subspace"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1290"><a id="calibre_link-287" class="calibre1"></a>Selecting linear discriminants for the new feature subspace</h2></div></div></div><p class="calibre8">The remaining steps of the<a id="calibre_link-1291" class="calibre1"></a> LDA are similar to the <a id="calibre_link-1292" class="calibre1"></a>steps of the PCA. However, instead of performing the eigendecomposition on the covariance matrix, we solve the generalized eigenvalue problem of the matrix <span class="strong"><img src="images/00377.jpeg" alt="Selecting linear discriminants for the new feature subspace" class="calibre14" /></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; eigen_vals, eigen_vecs =\
...            np.linalg.eig(np.linalg.inv(S_W).dot(S_B))</pre></div><p class="calibre8">After we computed the eigenpairs, we can now sort the eigenvalues in descending order:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:,i]) 
...              for i in range(len(eigen_vals))]
&gt;&gt;&gt; eigen_pairs = sorted(eigen_pairs, 
...               key=lambda k: k[0], reverse=True)
&gt;&gt;&gt; print('Eigenvalues in descending order:\n')
&gt;&gt;&gt; for eigen_val in eigen_pairs:
...     print(eigen_val[0])


Eigenvalues in descending order:

349.617808906
172.76152219
3.78531345125e-14
2.11739844822e-14
1.51646188942e-14
1.51646188942e-14
1.35795671405e-14
1.35795671405e-14
7.58776037165e-15
5.90603998447e-15
5.90603998447e-15
2.25644197857e-15
0.0</pre></div><p class="calibre8">In LDA, the number of <a id="calibre_link-1293" class="calibre1"></a>linear discriminants is at most <span class="strong"><em class="calibre9">câ1</em></span>, where <span class="strong"><em class="calibre9">c</em></span> is the number of class labels, since the in-between scatter matrix <span class="strong"><img src="images/00276.jpeg" alt="Selecting linear discriminants for the new feature subspace" class="calibre14" /></span> is the<a id="calibre_link-1294" class="calibre1"></a> sum of <span class="strong"><em class="calibre9">c</em></span> matrices with rank 1 or less. We can indeed see that we only have two nonzero eigenvalues (the eigenvalues 3-13 are not exactly zero, but this is due to the floating point arithmetic in NumPy).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1295" class="calibre1"></a>Note</h3><p class="calibre8">Note that in the rare case of perfect collinearity (all aligned sample points fall on a straight line), the covariance matrix would have rank one, which would result in only one eigenvector with a nonzero eigenvalue.</p></div><p class="calibre8">To measure how much of the class-discriminatory information is captured by the linear discriminants (eigenvectors), let's plot the linear discriminants by decreasing eigenvalues similar to the explained variance plot that we created in the PCA section. For simplicity, we will call the content of <a id="calibre_link-1296" class="calibre1"></a>class-discriminatory <a id="calibre_link-1297" class="calibre1"></a>information <span class="strong"><strong class="calibre2">discriminability</strong></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; tot = sum(eigen_vals.real)
&gt;&gt;&gt; discr = [(i / tot) for i in sorted(eigen_vals.real, reverse=True)]
&gt;&gt;&gt; cum_discr = np.cumsum(discr)
&gt;&gt;&gt; plt.bar(range(1, 14), discr, alpha=0.5, align='center',
...         label='individual "discriminability"')
&gt;&gt;&gt; plt.step(range(1, 14), cum_discr, where='mid',
...          label='cumulative "discriminability"')
&gt;&gt;&gt; plt.ylabel('"discriminability" ratio')
&gt;&gt;&gt; plt.xlabel('Linear Discriminants')
&gt;&gt;&gt; plt.ylim([-0.1, 1.1])
&gt;&gt;&gt; plt.legend(loc='best')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting figure, the first two linear discriminants alone capture 100 percent of the useful information in the Wine training dataset:</p><div class="mediaobject"><img src="images/00521.jpeg" alt="Selecting linear discriminants for the new feature subspace" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's now stack the two most discriminative eigenvector columns to create the transformation matrix <span class="strong"><strong class="calibre2">W</strong></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; w = np.hstack((eigen_pairs[0][1][:, np.newaxis].real,
...                eigen_pairs[1][1][:, np.newaxis].real))
&gt;&gt;&gt; print('Matrix W:\n', w)
Matrix W:
 [[-0.1481 -0.4092]
 [ 0.0908 -0.1577]
 [-0.0168 -0.3537]
 [ 0.1484  0.3223]
 [-0.0163 -0.0817]
 [ 0.1913  0.0842]
 [-0.7338  0.2823]
 [-0.075  -0.0102]
 [ 0.0018  0.0907]
 [ 0.294  -0.2152]
 [-0.0328  0.2747]
 [-0.3547 -0.0124]
 [-0.3915 -0.5958]]</pre></div></div></div></div>

<div id="calibre_link-460" class="calibre">
<div class="book" title="Supervised data compression via linear discriminant analysis">
<div class="book" title="Projecting samples onto the new feature space"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1298"><a id="calibre_link-288" class="calibre1"></a>Projecting samples onto the new feature space</h2></div></div></div><p class="calibre8">Using the transformation <a id="calibre_link-1299" class="calibre1"></a>matrix <span class="strong"><strong class="calibre2">W</strong></span> that we created in the<a id="calibre_link-1300" class="calibre1"></a> previous subsection, we can now transform the training dataset by multiplying the matrices:</p><div class="mediaobject"><img src="images/00323.jpeg" alt="Projecting samples onto the new feature space" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train_lda = X_train_std.dot(w)
&gt;&gt;&gt; colors = ['r', 'b', 'g']
&gt;&gt;&gt; markers = ['s', 'x', 'o']
&gt;&gt;&gt; for l, c, m in zip(np.unique(y_train), colors, markers):
...     plt.scatter(X_train_lda[y_train==l, 0], 
...                 X_train_lda[y_train==l, 1] * (-1), 
...                 c=c, label=l, marker=m)
&gt;&gt;&gt; plt.xlabel('LD 1')
&gt;&gt;&gt; plt.ylabel('LD 2')
&gt;&gt;&gt; plt.legend(loc='lower right')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting plot, the three wine classes are now perfectly linearly separable in the new feature subspace:</p><div class="mediaobject"><img src="images/00524.jpeg" alt="Projecting samples onto the new feature space" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-491" class="calibre">
<div class="book" title="Supervised data compression via linear discriminant analysis">
<div class="book" title="LDA via scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1301"><a id="calibre_link-289" class="calibre1"></a>LDA via scikit-learn</h2></div></div></div><p class="calibre8">The step-by-step implementation <a id="calibre_link-1302" class="calibre1"></a>was a good exercise to understand the inner workings of an LDA and understand the differences between LDA and PCA. Now, let's look at the <code class="email">LDA</code> class implemented in scikit-learn:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.discriminant_analysis import 
...    LinearDiscriminantAnalysis as LDA
&gt;&gt;&gt; lda = LDA(n_components=2)
&gt;&gt;&gt; X_train_lda = lda.fit_transform(X_train_std, y_train)</pre></div><p class="calibre8">Next, let's see how the logistic regression classifier handles the lower-dimensional training dataset after the LDA transformation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr = LogisticRegression()
&gt;&gt;&gt; lr = lr.fit(X_train_lda, y_train)
&gt;&gt;&gt; plot_decision_regions(X_train_lda, y_train, classifier=lr)
&gt;&gt;&gt; plt.xlabel('LD 1')
&gt;&gt;&gt; plt.ylabel('LD 2')
&gt;&gt;&gt; plt.legend(loc='lower left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Looking at the resulting plot, we see that the logistic regression model misclassifies one of the samples from class <code class="email">2</code>:</p><div class="mediaobject"><img src="images/00533.jpeg" alt="LDA via scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">By lowering the regularization<a id="calibre_link-1303" class="calibre1"></a> strength, we could probably shift the decision boundaries so that the logistic regression model classifies all samples in the training dataset correctly. However, and more importantly, let us take a look at the results on the test set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_test_lda = lda.transform(X_test_std)
&gt;&gt;&gt; plot_decision_regions(X_test_lda, y_test, classifier=lr)
&gt;&gt;&gt; plt.xlabel('LD 1')
&gt;&gt;&gt; plt.ylabel('LD 2')
&gt;&gt;&gt; plt.legend(loc='lower left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the following plot, the logistic regression classifier is able to get a perfect accuracy score for classifying the samples in the test dataset by only using a two-dimensional feature subspace instead of the original 13 Wine features:</p><div class="mediaobject"><img src="images/00537.jpeg" alt="LDA via scikit-learn" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-631" class="calibre">
<div id="calibre_link-1304" class="calibre10"></div><div class="book" title="Using kernel principal component analysis for nonlinear mappings"><div class="book" id="calibre_link-11"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1305"><a id="calibre_link-1306" class="calibre1"></a>Using kernel principal component analysis for nonlinear mappings</h1></div></div></div><p class="calibre8">Many machine<a id="calibre_link-1307" class="calibre1"></a> learning algorithms <a id="calibre_link-1308" class="calibre1"></a>make assumptions about the linear separability of the input data. You learned that the perceptron even requires perfectly linearly separable training data to converge. Other algorithms that we have covered so far assume that the lack of perfect linear separability is due to noise: Adaline, logistic regression, and the (standard) SVM<a id="calibre_link-1309" class="calibre1"></a> to just name a few.</p><p class="calibre8">However, if we are dealing with nonlinear problems, which we may encounter rather frequently in real-world applications, linear transformation techniques for dimensionality reduction, such as PCA and LDA, may not be the best choice. In this section, we will take a look at a kernelized version of PCA, or KPCA, which relates to the concepts of kernel SVM that we remember from <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>. Using kernel PCA, we will learn how to transform data that is not linearly separable onto a new, lower-dimensional subspace that is suitable for linear classifiers.</p><div class="mediaobject"><img src="images/00544.jpeg" alt="Using kernel principal component analysis for nonlinear mappings" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-634" class="calibre">
<div class="book" title="Using kernel principal component analysis for nonlinear mappings">
<div class="book" title="Kernel functions and the kernel trick"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1310"><a id="calibre_link-290" class="calibre1"></a>Kernel functions and the kernel trick</h2></div></div></div><p class="calibre8">As we remember from<a id="calibre_link-1311" class="calibre1"></a> our discussion about <a id="calibre_link-1312" class="calibre1"></a>kernel SVMs in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, we can tackle nonlinear problems by projecting them onto a new feature space of higher dimensionality where the classes become linearly separable. To transform the samples <span class="strong"><img src="images/00548.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> onto this higher <span class="strong"><em class="calibre9">k</em></span>-dimensional subspace, we defined a nonlinear mapping function <span class="strong"><img src="images/00551.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00559.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can think of <span class="strong"><img src="images/00551.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> as a function that creates nonlinear combinations of the original features to map the original <span class="strong"><em class="calibre9">d</em></span>-dimensional dataset onto a larger, <span class="strong"><em class="calibre9">k</em></span>-dimensional feature space. For example, if we had a feature vector <span class="strong"><img src="images/00548.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> (<span class="strong"><strong class="calibre2">x</strong></span> is a column vector consisting of <span class="strong"><em class="calibre9">d</em></span> features) with two dimensions <span class="strong"><img src="images/00564.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>, a potential mapping onto a 3D-space could be:</p><div class="mediaobject"><img src="images/00569.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00577.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00580.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In other words, we perform a nonlinear mapping via kernel PCA that transforms the data onto a higher-dimensional space. We then use standard PCA in this higher-dimensional space to project the data back onto a lower-dimensional space where the samples can be separated by a linear classifier (under the condition that the samples can be separated by density in the input space). However, one downside of this approach is that it is computationally very expensive, and this is where we <a id="calibre_link-1313" class="calibre1"></a>use the <span class="strong"><strong class="calibre2">kernel trick</strong></span>. Using the kernel trick, we can compute the similarity between two high-dimension feature vectors in the original feature space.</p><p class="calibre8">Before we proceed with more<a id="calibre_link-1314" class="calibre1"></a> details about the kernel trick to tackle this computationally expensive problem, let us think back to the standard PCA approach that we implemented at the beginning of this chapter. We computed the covariance between two features <span class="strong"><em class="calibre9">k</em></span> and <span class="strong"><em class="calibre9">j</em></span> as follows:</p><div class="mediaobject"><img src="images/00591.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since the standardizing of features centers them at mean zero, for instance, <span class="strong"><img src="images/00593.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> and <span class="strong"><img src="images/00599.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>, we can simplify this equation as follows:</p><div class="mediaobject"><img src="images/00603.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that the preceding equation refers to the covariance between two features; now, let us write the general equation to calculate the covariance matrix <span class="strong"><img src="images/00376.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00611.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Bernhard Scholkopf generalized this approach (<span class="strong"><em class="calibre9">Kernel principal component analysis,</em></span> <span class="strong"><em class="calibre9">B. Scholkopf</em></span>, <span class="strong"><em class="calibre9">A. Smola</em></span>, and <span class="strong"><em class="calibre9">K.R. Muller</em></span>, pages 583-588, <span class="strong"><em class="calibre9">1997</em></span>) so that we can replace the dot products between samples in the original feature space with the nonlinear feature combinations via <span class="strong"><img src="images/00551.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00616.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To<a id="calibre_link-1315" class="calibre1"></a> obtain the eigenvectors&mdash;the principal components&mdash;from this covariance matrix, we have to solve the following equation:</p><div class="mediaobject"><img src="images/00238.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00623.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00625.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00247.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> and <span class="strong"><strong class="calibre2">v</strong></span> are the eigenvalues<a id="calibre_link-1316" class="calibre1"></a> and eigenvectors of the covariance matrix <span class="strong"><img src="images/00376.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>, and <span class="strong"><strong class="calibre2">a</strong></span> can be obtained by extracting the eigenvectors of the kernel (similarity) matrix <span class="strong"><strong class="calibre2">K</strong></span>, as we will see in the next paragraphs.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1317" class="calibre1"></a>Note</h3><p class="calibre8">The derivation of the kernel matrix can be shown as follows. First, let's write the covariance matrix as in matrix notation, where <span class="strong"><img src="images/00458.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> is an <span class="strong"><em class="calibre9">n x k</em></span>-dimensional matrix:</p><div class="mediaobject1"><img src="images/00638.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, we can write the eigenvector equation as follows:</p><p class="calibre8"> </p><div class="mediaobject1"><img src="images/00649.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
</p><p class="calibre8">Since <span class="strong"><img src="images/00238.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>, we get:</p><div class="mediaobject1"><img src="images/00650.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Multiplying it by <span class="strong"><img src="images/00458.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> on both sides yields the following result:</p><div class="mediaobject1"><img src="images/00557.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00661.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00674.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><strong class="calibre2">K</strong></span> is the similarity (kernel) matrix:</p><p class="calibre8"> </p><div class="mediaobject1"><img src="images/00679.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
</p></div><p class="calibre8">As we recall from the <span class="strong"><em class="calibre9">Solving nonlinear problems using a kernel SVM</em></span> section in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, we use the kernel trick to avoid calculating the pairwise dot products of the samples <span class="strong"><strong class="calibre2">x</strong></span> under <span class="strong"><img src="images/00551.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> explicitly by using a kernel function <span class="strong"><img src="images/00676.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> so that we don't need to calculate the eigenvectors explicitly:</p><div class="mediaobject"><img src="images/00696.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In other words, what we obtain after kernel PCA are the samples already projected onto the respective components, rather than constructing a transformation matrix as in the standard PCA approach. Basically, the kernel function (or simply <span class="strong"><strong class="calibre2">kernel</strong></span>) can be understood as a function that calculates a dot product between two vectors&mdash;a measure of similarity.</p><p class="calibre8">The most commonly used<a id="calibre_link-1318" class="calibre1"></a> kernels are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">The polynomial kernel:<div class="mediaobject"><img src="images/00701.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p>
Here, <span class="strong"><img src="images/00708.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> is the threshold and <span class="strong"><img src="images/00712.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> is the power that has to be specified by the user.
</li><li class="listitem">The<a id="calibre_link-1319" class="calibre1"></a> hyperbolic tangent (sigmoid) kernel:<div class="mediaobject"><img src="images/00717.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p></li><li class="listitem">The <span class="strong"><strong class="calibre2">Radial Basis Function</strong></span> (<span class="strong"><strong class="calibre2">RBF</strong></span>) or Gaussian <a id="calibre_link-1320" class="calibre1"></a>kernel, which we will use in the following examples in the next subsection:<div class="mediaobject"><img src="images/00721.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p>
It is often written in the following form, introducing the variable <span class="strong"><img src="images/00727.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>:
<div class="mediaobject"><img src="images/00733.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p></li></ul></div><p class="calibre8">To summarize what we have learned so far, we can define the following three steps to implement an RBF kernel PCA:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">We compute the<a id="calibre_link-1321" class="calibre1"></a> kernel (similarity) matrix <span class="strong"><strong class="calibre2">K</strong></span>, where we need to calculate the following:<div class="mediaobject"><img src="images/00733.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p><p class="calibre16">We do this for each pair of samples:</p><div class="mediaobject"><img src="images/00738.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p><p class="calibre16">For example, if our dataset contains 100 training samples, the symmetric kernel matrix of the pairwise similarities would be 100 x 100-dimensional.</p></li><li class="listitem" value="2">We center the kernel matrix <span class="strong"><strong class="calibre2">K</strong></span> using the following equation:<div class="mediaobject"><img src="images/00742.jpeg" alt="Kernel functions and the kernel trick" class="calibre11" /></div><p class="calibre26"> </p>
Here, <span class="strong"><img src="images/00751.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span> is an <span class="strong"><img src="images/00755.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>-dimensional matrix (the same dimensions as the kernel matrix) where all values are equal to <span class="strong"><img src="images/00762.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>.
</li><li class="listitem" value="3">We collect the top <span class="strong"><strong class="calibre2">k</strong></span> eigenvectors of the centered kernel matrix based on their corresponding eigenvalues, which are ranked by decreasing magnitude. In contrast to standard PCA, the eigenvectors are not the principal component axes, but the samples already projected onto these axes.</li></ol><div class="calibre13"></div></div><p class="calibre8">At this point, you may be <a id="calibre_link-1322" class="calibre1"></a>wondering why we need to center the kernel matrix in the second step. We previously assumed that we are working with standardized data, where all features have mean zero when we formulated the covariance matrix and replaced the dot-products with the nonlinear feature combinations via <span class="strong"><img src="images/00551.jpeg" alt="Kernel functions and the kernel trick" class="calibre14" /></span>. Thus, the centering of the kernel matrix in the second step becomes necessary, since we do not compute the new feature space explicitly so that we cannot guarantee that the new feature space is also centered at zero.</p><p class="calibre8">In the next section, we will put those three steps into action by implementing a kernel PCA in Python.</p></div></div></div>

<div id="calibre_link-640" class="calibre">
<div class="book" title="Using kernel principal component analysis for nonlinear mappings">
<div class="book" title="Implementing a kernel principal component analysis in Python"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1323"><a id="calibre_link-291" class="calibre1"></a>Implementing a kernel principal component analysis in Python</h2></div></div></div><p class="calibre8">In the previous subsection, we <a id="calibre_link-1324" class="calibre1"></a>discussed the core <a id="calibre_link-1325" class="calibre1"></a>concepts behind kernel PCA. Now, we are going to implement an RBF kernel PCA in Python following the three steps that summarized the kernel PCA approach. Using some SciPy and NumPy helper functions, we will see that implementing a kernel PCA is actually really simple:</p><div class="informalexample"><pre class="programlisting">from scipy.spatial.distance import pdist, squareform
from scipy import exp
from scipy.linalg import eigh
import numpy as np

def rbf_kernel_pca(X, gamma, n_components):
    """
    RBF kernel PCA implementation.

    Parameters
    ------------
    X: {NumPy ndarray}, shape = [n_samples, n_features]
        
    gamma: float
      Tuning parameter of the RBF kernel
        
    n_components: int
      Number of principal components to return

    Returns
    ------------
     X_pc: {NumPy ndarray}, shape = [n_samples, k_features]
       Projected dataset

    """
    # Calculate pairwise squared Euclidean distances
    # in the MxN dimensional dataset.
    sq_dists = pdist(X, 'sqeuclidean')

    # Convert pairwise distances into a square matrix.
    mat_sq_dists = squareform(sq_dists)

    # Compute the symmetric kernel matrix.
    K = exp(-gamma * mat_sq_dists)

    # Center the kernel matrix.
    N = K.shape[0]
    one_n = np.ones((N,N)) / N
    K = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)

    # Obtaining eigenpairs from the centered kernel matrix
    # scipy.linalg.eigh returns them in ascending order
    eigvals, eigvecs = eigh(K)
    eigvals, eigvecs = eigvals[::-1], eigvecs[:, ::-1]

    # Collect the top k eigenvectors (projected samples)
    X_pc = np.column_stack((eigvecs[:, i]
                            for i in range(n_components)))

    return X_pc</pre></div><p class="calibre8">One downside of using an<a id="calibre_link-1326" class="calibre1"></a> RBF kernel PCA<a id="calibre_link-1327" class="calibre1"></a> for dimensionality reduction is that we have to specify the <span class="strong"><img src="images/00769.jpeg" alt="Implementing a kernel principal component analysis in Python" class="calibre14" /></span> parameter a priori. Finding an appropriate value for <span class="strong"><img src="images/00769.jpeg" alt="Implementing a kernel principal component analysis in Python" class="calibre14" /></span> requires experimentation and is best done using algorithms for parameter tuning, for example, performing a grid search, which we will discuss in more detail in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>.</p><div class="book" title="Example 1 â separating half-moon shapes"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-292" class="calibre1"></a>Example 1 &ndash; separating half-moon shapes</h3></div></div></div><p class="calibre8">Now, let us apply <a id="calibre_link-1328" class="calibre1"></a>our <code class="email">rbf_kernel_pca</code> on some nonlinear example datasets. We will start by creating a two-dimensional dataset of 100 sample points representing two half-moon shapes:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.datasets import make_moons
&gt;&gt;&gt; X, y = make_moons(n_samples=100, random_state=123)
&gt;&gt;&gt; plt.scatter(X[y==0, 0], X[y==0, 1], 
...             color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; plt.scatter(X[y==1, 0], X[y==1, 1],
...             color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">For the purposes of illustration, the half-moon of triangle symbols shall represent one class, and the half-moon depicted by the circle symbols represent the samples from another class:</p><div class="mediaobject"><img src="images/00773.jpeg" alt="Example 1 â separating half-moon shapes" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Clearly, these two half-moon shapes are not linearly separable, and our goal is to <span class="strong"><em class="calibre9">unfold</em></span> the half-moons via kernel PCA so that the dataset can serve as a suitable input for a linear classifier. But first, let's see how the dataset looks if we project it onto the principal components via standard PCA:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.decomposition import PCA
&gt;&gt;&gt; scikit_pca = PCA(n_components=2)
&gt;&gt;&gt; X_spca = scikit_pca.fit_transform(X)
&gt;&gt;&gt; fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(7,3))
&gt;&gt;&gt; ax[0].scatter(X_spca[y==0, 0], X_spca[y==0, 1], 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[0].scatter(X_spca[y==1, 0], X_spca[y==1, 1],
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_spca[y==0, 0], np.zeros((50,1))+0.02, 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_spca[y==1, 0], np.zeros((50,1))-0.02,
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[0].set_xlabel('PC1')
&gt;&gt;&gt; ax[0].set_ylabel('PC2')
&gt;&gt;&gt; ax[1].set_ylim([-1, 1])
&gt;&gt;&gt; ax[1].set_yticks([])
&gt;&gt;&gt; ax[1].set_xlabel('PC1')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Clearly, we can see in the <a id="calibre_link-1329" class="calibre1"></a>resulting figure that a linear classifier would be unable to perform well on the dataset transformed via standard PCA:</p><div class="mediaobject"><img src="images/00780.jpeg" alt="Example 1 â separating half-moon shapes" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that when we plotted the first principal component only (right subplot), we shifted the triangular samples slightly upwards and the circular samples slightly downwards to better visualize the class overlap. As the left subplot shows, the original half-moon shapes are only slightly sheared and flipped across the vertical center&mdash;this transformation would not help a linear classifier in discriminating between circles and triangles. Similarly, the circles and triangles corresponding to the two half-moon shapes are not linearly separable if we project the dataset onto a one-dimensional feature axis, as shown in the right subplot.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1330" class="calibre1"></a>Note</h3><p class="calibre8">Please remember that PCA is an unsupervised method and does not use class label information in order to maximize the variance in contrast to LDA. Here, the triangle and circle symbols were just added for visualization purposes to indicate the degree of separation.</p></div><p class="calibre8">Now, let us try out our <a id="calibre_link-1331" class="calibre1"></a>kernel PCA function <code class="email">rbf_kernel_pca</code>, which we implemented in the previous subsection:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_kpca = rbf_kernel_pca(X, gamma=15, n_components=2)
&gt;&gt;&gt; fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(7,3))
&gt;&gt;&gt; ax[0].scatter(X_kpca[y==0, 0], X_kpca[y==0, 1], 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[0].scatter(X_kpca[y==1, 0], X_kpca[y==1, 1],
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_kpca[y==0, 0], np.zeros((50,1))+0.02, 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_kpca[y==1, 0], np.zeros((50,1))-0.02,
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[0].set_xlabel('PC1')
&gt;&gt;&gt; ax[0].set_ylabel('PC2')
&gt;&gt;&gt; ax[1].set_ylim([-1, 1])
&gt;&gt;&gt; ax[1].set_yticks([])
&gt;&gt;&gt; ax[1].set_xlabel('PC1')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">We can now see that the two classes (<code class="email">circles</code> and <code class="email">triangles</code>) are linearly well separated so that it becomes a suitable training dataset for linear classifiers:</p><div class="mediaobject"><img src="images/00783.jpeg" alt="Example 1 â separating half-moon shapes" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Unfortunately, there is no<a id="calibre_link-1332" class="calibre1"></a> universal value for the tuning parameter <span class="strong"><img src="images/00769.jpeg" alt="Example 1 â separating half-moon shapes" class="calibre14" /></span> that works well for different datasets. Finding a <span class="strong"><img src="images/00769.jpeg" alt="Example 1 â separating half-moon shapes" class="calibre14" /></span> value that is appropriate for a given problem requires experimentation. In <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we will discuss techniques that can help us to automate the task of optimizing such tuning parameters. Here, I will use values for <span class="strong"><img src="images/00769.jpeg" alt="Example 1 â separating half-moon shapes" class="calibre14" /></span> that I found produce good results.</p></div><div class="book" title="Example 2 â separating concentric circles"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-293" class="calibre1"></a>Example 2 &ndash; separating concentric circles</h3></div></div></div><p class="calibre8">In the previous <a id="calibre_link-1333" class="calibre1"></a>subsection, we showed how to separate half-moon shapes via kernel PCA. Since we put so much effort into understanding the concepts of kernel PCA, let us take a look at another interesting example of a nonlinear problem, concentric circles:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.datasets import make_circles
&gt;&gt;&gt; X, y = make_circles(n_samples=1000, 
...            random_state=123, noise=0.1, factor=0.2)
&gt;&gt;&gt; plt.scatter(X[y==0, 0], X[y==0, 1],
...            color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; plt.scatter(X[y==1, 0], X[y==1, 1],
...            color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Again, we assume a two-class problem where the triangle shapes represent one class, and the circle shapes represent another class:</p><div class="mediaobject"><img src="images/00790.jpeg" alt="Example 2 â separating concentric circles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's start with the <a id="calibre_link-1334" class="calibre1"></a>standard PCA approach to compare it to the results of the RBF kernel PCA:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; scikit_pca = PCA(n_components=2)
&gt;&gt;&gt; X_spca = scikit_pca.fit_transform(X)
&gt;&gt;&gt; fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(7,3))
&gt;&gt;&gt; ax[0].scatter(X_spca[y==0, 0], X_spca[y==0, 1], 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[0].scatter(X_spca[y==1, 0], X_spca[y==1, 1],
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_spca[y==0, 0], np.zeros((500,1))+0.02, 
...              color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_spca[y==1, 0], np.zeros((500,1))-0.02,
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[0].set_xlabel('PC1')
&gt;&gt;&gt; ax[0].set_ylabel('PC2')
&gt;&gt;&gt; ax[1].set_ylim([-1, 1])
&gt;&gt;&gt; ax[1].set_yticks([])
&gt;&gt;&gt; ax[1].set_xlabel('PC1')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Again, we can see that standard PCA is not able to produce results suitable for training a linear classifier:</p><div class="mediaobject"><img src="images/00795.jpeg" alt="Example 2 â separating concentric circles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Given an appropriate<a id="calibre_link-1335" class="calibre1"></a> value for <span class="strong"><img src="images/00769.jpeg" alt="Example 2 â separating concentric circles" class="calibre14" /></span>, let us see if we are luckier using the RBF kernel PCA implementation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_kpca = rbf_kernel_pca(X, gamma=15, n_components=2)
&gt;&gt;&gt; fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(7,3))
&gt;&gt;&gt; ax[0].scatter(X_kpca[y==0, 0], X_kpca[y==0, 1], 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[0].scatter(X_kpca[y==1, 0], X_kpca[y==1, 1],
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_kpca[y==0, 0], np.zeros((500,1))+0.02, 
...               color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; ax[1].scatter(X_kpca[y==1, 0], np.zeros((500,1))-0.02,
...               color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; ax[0].set_xlabel('PC1')
&gt;&gt;&gt; ax[0].set_ylabel('PC2')
&gt;&gt;&gt; ax[1].set_ylim([-1, 1])
&gt;&gt;&gt; ax[1].set_yticks([])
&gt;&gt;&gt; ax[1].set_xlabel('PC1')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Again, the RBF kernel PCA projected the data onto a new subspace where the two classes become linearly separable:</p><div class="mediaobject"><img src="images/00800.jpeg" alt="Example 2 â separating concentric circles" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-644" class="calibre">
<div class="book" title="Using kernel principal component analysis for nonlinear mappings">
<div class="book" title="Projecting new data points"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1336"><a id="calibre_link-294" class="calibre1"></a>Projecting new data points</h2></div></div></div><p class="calibre8">In the two previous <a id="calibre_link-1337" class="calibre1"></a>example applications of kernel PCA, the half-moon shapes and the concentric circles, we projected a single dataset onto a new feature. In real applications, however, we may have more than one dataset that we want to transform, for example, training and test data, and typically also new samples we will collect after the model building and evaluation. In this section, you will learn how to project data points that were not part of the training dataset.</p><p class="calibre8">As we remember from the standard PCA approach at the beginning of this chapter, we project data by calculating the dot product between a transformation matrix and the input samples; the columns of the projection matrix are the top <span class="strong"><strong class="calibre2">k</strong></span> eigenvectors (<span class="strong"><strong class="calibre2">v</strong></span>) that we obtained from the covariance matrix.</p><p class="calibre8">Now, the question is how we can transfer this concept to kernel PCA. If we think back to the idea behind kernel PCA, we remember that we obtained an eigenvector (<span class="strong"><strong class="calibre2">a</strong></span>) of the centered kernel matrix (not the covariance matrix), which means that those are the samples that are already projected onto the principal component axis <span class="strong"><strong class="calibre2">v</strong></span>. Thus, if we want to project a new sample <span class="strong"><img src="images/00810.jpeg" alt="Projecting new data points" class="calibre14" /></span> onto this principal component axis, we'd need to compute the following:</p><div class="mediaobject"><img src="images/00817.jpeg" alt="Projecting new data points" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Fortunately, we can use the kernel trick so that we don't have to calculate the projection <span class="strong"><img src="images/00817.jpeg" alt="Projecting new data points" class="calibre14" /></span> explicitly. However, it is worth noting that kernel PCA, in contrast to standard PCA, is a memory-based method, which means that we have to re-use the original training set each time to project new samples. We have to calculate the pairwise RBF kernel (similarity) between <a id="calibre_link-1338" class="calibre1"></a>each <span class="strong"><em class="calibre9">i</em></span>th sample in the training dataset and the new sample <span class="strong"><img src="images/00810.jpeg" alt="Projecting new data points" class="calibre14" /></span>:</p><div class="mediaobject"><img src="images/00820.jpeg" alt="Projecting new data points" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00829.jpeg" alt="Projecting new data points" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, the eigenvectors <span class="strong"><strong class="calibre2">a</strong></span> and eigenvalues <span class="strong"><img src="images/00247.jpeg" alt="Projecting new data points" class="calibre14" /></span> of the kernel matrix <span class="strong"><strong class="calibre2">K</strong></span> satisfy the following condition in the equation:</p><div class="mediaobject"><img src="images/00832.jpeg" alt="Projecting new data points" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">After calculating the similarity between the new samples and the samples in the training set, we have to normalize the eigenvector <span class="strong"><strong class="calibre2">a</strong></span> by its eigenvalue. Thus, let us modify the <code class="email">rbf_kernel_pca</code> function that we implemented earlier so that it also returns the eigenvalues of the kernel matrix:</p><div class="informalexample"><pre class="programlisting">from scipy.spatial.distance import pdist, squareform
from scipy import exp
from scipy.linalg import eigh
import numpy as np

def rbf_kernel_pca(X, gamma, n_components):
    """
    RBF kernel PCA implementation.

    Parameters
    ------------
    X: {NumPy ndarray}, shape = [n_samples, n_features]
        
    gamma: float
      Tuning parameter of the RBF kernel
        
    n_components: int
      Number of principal components to return

    Returns
    ------------
     X_pc: {NumPy ndarray}, shape = [n_samples, k_features]
       Projected dataset   
     
     lambdas: list
       Eigenvalues

    """
    # Calculate pairwise squared Euclidean distances
    # in the MxN dimensional dataset.
    sq_dists = pdist(X, 'sqeuclidean')

    # Convert pairwise distances into a square matrix.
    mat_sq_dists = squareform(sq_dists)

    # Compute the symmetric kernel matrix.
    K = exp(-gamma * mat_sq_dists)

    # Center the kernel matrix.
    N = K.shape[0]
    one_n = np.ones((N,N)) / N
    K = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)

    # Obtaining eigenpairs from the centered kernel matrix
    # scipy.linalg.eigh returns them in ascending order
    eigvals, eigvecs = eigh(K)
    eigvals, eigvecs = eigvals[::-1], eigvecs[:, ::-1]

    # Collect the top k eigenvectors (projected samples)
    alphas = np.column_stack((eigvecs[:, i]
                              for i in range(n_components)))

    # Collect the corresponding eigenvalues
    lambdas = [eigvals[i] for i in range(n_components)]

    return alphas, lambdas</pre></div><p class="calibre8">Now, let's create a new half-moon dataset and project it onto a one-dimensional subspace using the updated RBF kernel PCA implementation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X, y = make_moons(n_samples=100, random_state=123)
&gt;&gt;&gt; alphas, lambdas = rbf_kernel_pca(X, gamma=15, n_components=1)</pre></div><p class="calibre8">To make sure that we <a id="calibre_link-1339" class="calibre1"></a>implemented the code for projecting new samples, let us assume that the 26th point from the half-moon dataset is a new data point <span class="strong"><img src="images/00810.jpeg" alt="Projecting new data points" class="calibre14" /></span>, and our task is to project it onto this new subspace:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; x_new = X[25]
&gt;&gt;&gt; x_new
array([ 1.8713187 ,  0.00928245])
&gt;&gt;&gt; x_proj = alphas[25] # original projection
&gt;&gt;&gt; x_proj
array([ 0.07877284])
&gt;&gt;&gt; def project_x(x_new, X, gamma, alphas, lambdas):
...     pair_dist = np.array([np.sum(
...                  (x_new-row)**2) for row in X])
...     k = np.exp(-gamma * pair_dist)
...     return k.dot(alphas / lambdas)</pre></div><p class="calibre8">By executing the following code, we are able to reproduce the original projection. Using the <code class="email">project_x</code> function, we will be able to project any new data sample as well. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; x_reproj = project_x(x_new, X, 
...       gamma=15, alphas=alphas, lambdas=lambdas)
&gt;&gt;&gt; x_reproj
array([ 0.07877284])</pre></div><p class="calibre8">Lastly, let's visualize the projection on the first principal component:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(alphas[y==0, 0], np.zeros((50)), 
...             color='red', marker='^',alpha=0.5)
&gt;&gt;&gt; plt.scatter(alphas[y==1, 0], np.zeros((50)), 
...             color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; plt.scatter(x_proj, 0, color='black', 
...             label='original projection of point X[25]',
...             marker='^', s=100)
&gt;&gt;&gt; plt.scatter(x_reproj, 0, color='green', 
...             label='remapped point X[25]',
...             marker='x', s=500)
&gt;&gt;&gt; plt.legend(scatterpoints=1)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can now also see in the<a id="calibre_link-1340" class="calibre1"></a> following scatterplot, we mapped the sample <span class="strong"><img src="images/00810.jpeg" alt="Projecting new data points" class="calibre14" /></span> onto the first principal component correctly:</p><div class="mediaobject"><img src="images/00840.jpeg" alt="Projecting new data points" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-645" class="calibre">
<div class="book" title="Using kernel principal component analysis for nonlinear mappings">
<div class="book" title="Kernel principal component analysis in scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1341"><a id="calibre_link-295" class="calibre1"></a>Kernel principal component analysis in scikit-learn</h2></div></div></div><p class="calibre8">For our convenience, scikit-learn<a id="calibre_link-1342" class="calibre1"></a> implements a kernel PCA class in the <code class="email">sklearn.decomposition</code> submodule. The usage is similar to the standard PCA class, and we can specify the kernel via the <code class="email">kernel</code> parameter:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.decomposition import KernelPCA
&gt;&gt;&gt; X, y = make_moons(n_samples=100, random_state=123)
&gt;&gt;&gt; scikit_kpca = KernelPCA(n_components=2, 
...               kernel='rbf', gamma=15)
&gt;&gt;&gt; X_skernpca = scikit_kpca.fit_transform(X)</pre></div><p class="calibre8">To check that we get results that are consistent with our own kernel PCA implementation, let's plot the transformed half-moon shape data onto the first two principal components:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(X_skernpca[y==0, 0], X_skernpca[y==0, 1], 
...             color='red', marker='^', alpha=0.5)
&gt;&gt;&gt; plt.scatter(X_skernpca[y==1, 0], X_skernpca[y==1, 1], 
...             color='blue', marker='o', alpha=0.5)
&gt;&gt;&gt; plt.xlabel('PC1')
&gt;&gt;&gt; plt.ylabel('PC2')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see, the results of <a id="calibre_link-1343" class="calibre1"></a>scikit-learn's <code class="email">KernelPCA</code> are consistent with our own implementation:</p><div class="mediaobject"><img src="images/00843.jpeg" alt="Kernel principal component analysis in scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1344" class="calibre1"></a>Note</h3><p class="calibre8">The scikit-learn library also implements advanced techniques for nonlinear dimensionality<a id="calibre_link-1345" class="calibre1"></a> reduction that are beyond the scope of this book. The interested reader can find a nice overview of the current implementations in scikit-learn, complemented by illustrative examples, at <a class="calibre1" href="http://scikit-learn.org/stable/modules/manifold.html">http://scikit-learn.org/stable/modules/manifold.html</a>.</p></div></div></div></div>

<div id="calibre_link-649" class="calibre"><div class="book" title="Summary" id="calibre_link-296"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1346"><a id="calibre_link-1347" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, you learned about three different, fundamental dimensionality reduction techniques for feature extraction: standard PCA, LDA, and kernel PCA. Using PCA, we projected data onto a lower-dimensional subspace to maximize the variance along the orthogonal feature axes, while ignoring the class labels. LDA, in contrast to PCA, is a technique for supervised dimensionality reduction, which means that it considers class information in the training dataset to attempt to maximize the class-separability in a linear feature space.</p><p class="calibre8">Lastly, you learned about a nonlinear feature extractor, kernel PCA. Using the kernel trick and a temporary projection into a higher-dimensional feature space, you were ultimately able to compress datasets consisting of nonlinear features onto a lower-dimensional subspace where the classes became linearly separable.</p><p class="calibre8">Equipped with these essential preprocessing techniques, you are now well prepared to learn about the best practices for efficiently incorporating different preprocessing techniques and evaluating the performance of different models in the next chapter.</p></div></div>

<div id="calibre_link-654" class="calibre">
<div id="calibre_link-1348" class="calibre10"></div><div class="book" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" id="calibre_link-37"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1349"><a id="calibre_link-1350" class="calibre1"></a>Chapter&nbsp;6.&nbsp;Learning Best Practices for Model Evaluation and Hyperparameter Tuning</h1></div></div></div><p class="calibre8">In the previous chapters, you learned about the essential machine learning algorithms for classification and how to get our data into shape before we feed it into those algorithms. Now, it's time to learn about the best practices of building good machine learning models by fine-tuning the algorithms and evaluating the model's performance! In this chapter, we will learn how to do the following:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Obtain unbiased estimates of a model's performance</li><li class="listitem">Diagnose the common problems of machine learning algorithms</li><li class="listitem">Fine-tune machine learning models</li><li class="listitem">Evaluate predictive models using different performance metrics</li></ul></div></div></div>

<div id="calibre_link-513" class="calibre">
<div class="book" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" id="calibre_link-1351">
<div class="book" title="Streamlining workflows with pipelines"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1352"><a id="calibre_link-297" class="calibre1"></a>Streamlining workflows with pipelines</h1></div></div></div><p class="calibre8">When <a id="calibre_link-1353" class="calibre1"></a>we applied different preprocessing techniques <a id="calibre_link-1354" class="calibre1"></a>in the previous chapters, such as standardization for feature scaling in <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>, or principal component analysis for data compression in <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>, you learned that we have to reuse the parameters that were obtained during the fitting of the training data to scale and compress any new data, such as the samples in the separate test dataset. In this section, you will learn about an extremely handy tool, the <code class="email">Pipeline</code> class in scikit-learn. It allows us to fit a model including an arbitrary number of transformation steps and apply it to make predictions about new data.</p></div></div></div>

<div id="calibre_link-516" class="calibre">
<div class="book" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" id="calibre_link-1355">
<div class="book" title="Streamlining workflows with pipelines">
<div class="book" title="Loading the Breast Cancer Wisconsin dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1356"><a id="calibre_link-298" class="calibre1"></a>Loading the Breast Cancer Wisconsin dataset</h2></div></div></div><p class="calibre8">In this chapter, we <a id="calibre_link-1357" class="calibre1"></a>will be working with the Breast Cancer Wisconsin dataset, which contains 569 samples of malignant and benign tumor cells. The first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnoses (<code class="email">M</code> = malignant, <code class="email">B</code> = benign), respectively. Columns 3-32 contain 30 real-valued features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant. The Breast Cancer Wisconsin dataset<a id="calibre_link-1358" class="calibre1"></a> has been deposited in the UCI Machine Learning Repository, and more detailed information about this dataset can be found at <a class="calibre1" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1359" class="calibre1"></a>Note</h3><p class="calibre8">You can find a copy of the breast cancer dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the UCI server at <a class="calibre1" href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data">https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data</a> is temporarily unavailable. For instance, to load the Wine dataset from a local directory, you can take the following lines:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('https://archive.ics.uci.edu/ml/'
                 'machine-learning-databases'
                 '/breast-cancer-wisconsin/wdbc.data',
                 header=None)</pre></div><p class="calibre8">Replace the preceding lines with this:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('your/local/path/to/wdbc.data',
                 header=None)</pre></div></div><p class="calibre8">In this section, we will read in the dataset and split it into training and test datasets in three simple steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">We will start by reading in the dataset directly from the UCI website using <code class="email">pandas</code>:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv('https://archive.ics.uci.edu/ml/'
...                  'machine-learning-databases'
...                  '/breast-cancer-wisconsin/wdbc.data',
                     header=None)</pre></div></li><li class="listitem" value="2">Next, we assign the 30 features to a NumPy array <code class="email">X</code>. Using a <code class="email">LabelEncoder</code> object, we transform the class labels from their original string representation (<code class="email">'M'</code> and <code class="email">'B'</code>) into integers:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder

&gt;&gt;&gt; X = df.loc[:, 2:].values
&gt;&gt;&gt; y = df.loc[:, 1].values
&gt;&gt;&gt; le = LabelEncoder()
&gt;&gt;&gt; y = le.fit_transform(y)
&gt;&gt;&gt; le.classes_
array(['B', 'M'], dtype=object)</pre></div><p class="calibre16">After<a id="calibre_link-1360" class="calibre1"></a> encoding the class labels (diagnosis) in an array <code class="email">y</code>, the malignant tumors are now represented as class <code class="email">1</code>, and the benign tumors are represented as class <code class="email">0</code>, respectively. We can double-check this mapping by calling the <code class="email">transform</code> method of the fitted <code class="email">LabelEncoder</code> on two dummy class labels:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; le.transform(['M', 'B'])
array([1, 0])</pre></div></li><li class="listitem" value="3">Before we construct our first model pipeline in the following subsection, let us divide the dataset into a separate training dataset (80 percent of the data) and a separate test dataset (20 percent of the data):<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import train_test_split

&gt;&gt;&gt; X_train, X_test, y_train, y_test = \
&gt;&gt;&gt;     train_test_split(X, y,
...                  test_size=0.20,
...                  stratify=y,
...                  random_state=1)</pre></div></li></ol><div class="calibre13"></div></div></div></div></div></div>

<div id="calibre_link-510" class="calibre">
<div class="book" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" id="calibre_link-1361">
<div class="book" title="Streamlining workflows with pipelines">
<div class="book" title="Combining transformers and estimators in a pipeline"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1362"><a id="calibre_link-299" class="calibre1"></a>Combining transformers and estimators in a pipeline</h2></div></div></div><p class="calibre8">In the previous chapter, you <a id="calibre_link-1363" class="calibre1"></a>learned that many learning <a id="calibre_link-1364" class="calibre1"></a>algorithms require input<a id="calibre_link-1365" class="calibre1"></a> features on the same scale for optimal performance. Thus, we need to standardize the columns in the Breast Cancer Wisconsin dataset before we can feed them to a linear classifier, such as logistic regression. Furthermore, let's assume that we want to compress our data from the initial 30 dimensions onto a lower two-dimensional subspace via <span class="strong"><strong class="calibre2">Principal Component Analysis</strong></span> (<span class="strong"><strong class="calibre2">PCA</strong></span>), a feature<a id="calibre_link-1366" class="calibre1"></a> extraction technique for dimensionality reduction that we introduced in <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>.</p><p class="calibre8">Instead of going through the fitting and transformation steps for the training and test datasets separately, we can chain the <code class="email">StandardScaler</code>, <code class="email">PCA</code>, and <code class="email">LogisticRegression</code> objects in a pipeline:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; from sklearn.decomposition import PCA
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.pipeline import make_pipeline
&gt;&gt;&gt; pipe_lr = make_pipeline(StandardScaler(),
...                         PCA(n_components=2),
...                         LogisticRegression(random_state=1))
&gt;&gt;&gt; pipe_lr.fit(X_train, y_train)
&gt;&gt;&gt; y_pred = pipe_lr.predict(X_test)
&gt;&gt; print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))
Test Accuracy: 0.956</pre></div><p class="calibre8">The <code class="email">make_pipeline</code> function<a id="calibre_link-1367" class="calibre1"></a> takes an arbitrary number of <a id="calibre_link-1368" class="calibre1"></a>scikit-learn transformers (objects that support the <code class="email">fit</code> and <code class="email">transform</code> methods as input), followed by a scikit-learn estimator that implements the <code class="email">fit</code> and <code class="email">predict</code> methods. In our preceding code<a id="calibre_link-1369" class="calibre1"></a> example, we provided two transformers, <code class="email">StandardScaler</code> and <code class="email">PCA</code>, and a <code class="email">LogisticRegression</code> estimator as inputs to the <code class="email">make_pipeline</code> function, which constructs a scikit-learn <code class="email">Pipeline</code> object from these objects.</p><p class="calibre8">We can think of a scikit-learn <code class="email">Pipeline</code> as a meta-estimator or wrapper around those individual transformers and estimators. If we call the <code class="email">fit</code> method of <code class="email">Pipeline</code>, the data will be passed down a series of transformers via <code class="email">fit</code> and <code class="email">transform</code> calls on these intermediate steps until it arrives at the estimator object (the final element in a pipeline). The estimator will then be fitted to the transformed training data.</p><p class="calibre8">When we executed the <code class="email">fit</code> method on the <code class="email">pipe_lr</code> pipeline in the preceding code example, <code class="email">StandardScaler</code> first performed <code class="email">fit</code> and <code class="email">transform</code> calls on the training data. Second, the transformed training data was passed on to the next object in the pipeline, <code class="email">PCA</code>. Similar to the previous step, <code class="email">PCA</code> also executed <code class="email">fit</code> and <code class="email">transform</code> on the scaled input data and passed it to the final element of the pipeline, the estimator.</p><p class="calibre8">Finally, the <code class="email">LogisticRegression</code> estimator was fit to the training data after it underwent transformations via <code class="email">StandardScaler</code> and <code class="email">PCA</code>. Again, we should note that there is no limit to the number of intermediate steps in a pipeline; however, the last pipeline element has to be an estimator.</p><p class="calibre8">Similar to calling <code class="email">fit</code> on a pipeline, pipelines also implement a <code class="email">predict</code> method. If we feed a dataset to the <code class="email">predict</code> call of a <code class="email">Pipeline</code> object instance, the data will pass through the intermediate steps via <code class="email">transform</code> calls. In the final step, the estimator object will then return a prediction on the transformed data.</p><p class="calibre8">The pipelines of scikit-learn library are immensely useful wrapper tools, which we will use frequently throughout the rest of this book. To make sure that you've got a good grasp of how <code class="email">Pipeline</code> object works, please take a close look at the following illustration, which summarizes our discussion from the previous paragraphs:</p><div class="mediaobject"><img src="images/00852.jpeg" alt="Combining transformers and estimators in a pipeline" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-29" class="calibre">
<div id="calibre_link-1370" class="calibre10"></div><div class="book" title="Using k-fold cross-validation to assess model performance"><div class="book" id="calibre_link-300"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1371"><a id="calibre_link-1372" class="calibre1"></a>Using k-fold cross-validation to assess model performance</h1></div></div></div><p class="calibre8">One of the key steps in <a id="calibre_link-1373" class="calibre1"></a>building a machine <a id="calibre_link-1374" class="calibre1"></a>learning model is to estimate its performance on data that the model hasn't seen before. Let's assume that we fit our model on a training dataset and use the same data to estimate how well it performs on new data. We remember from the <span class="strong"><em class="calibre9">Tackling overfitting via regularization</em></span> section in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, that a model can either suffer from underfitting (high bias) if the model is too simple, or it can overfit the training data (high variance) if the model is too complex for the underlying training data.</p><p class="calibre8">To find an acceptable bias-variance trade-off, we need to evaluate our model carefully. In this section, you will learn about the common cross-validation<a id="calibre_link-1375" class="calibre1"></a> techniques <span class="strong"><strong class="calibre2">holdout cross-validation</strong></span> and <span class="strong"><strong class="calibre2">k-fold cross-validation</strong></span>, which can help us obtain reliable <a id="calibre_link-1376" class="calibre1"></a>estimates of the model's generalization performance, that is, how well the model performs on unseen data.</p></div></div>

<div id="calibre_link-537" class="calibre">
<div class="book" title="Using k-fold cross-validation to assess model performance">
<div class="book" title="The holdout method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1377"><a id="calibre_link-301" class="calibre1"></a>The holdout method</h2></div></div></div><p class="calibre8">A classic and popular approach for estimating<a id="calibre_link-1378" class="calibre1"></a> the generalization performance of machine learning models is holdout cross-validation. Using the holdout method, we split our initial dataset into a separate training and test dataset&mdash;the former is used for model training, and the latter is used to estimate its generalization performance. However, in typical machine learning applications, we are also interested in tuning and comparing different parameter settings to further improve the performance for making predictions on unseen data. This process is <a id="calibre_link-1379" class="calibre1"></a>called <span class="strong"><strong class="calibre2">model selection</strong></span>, where the term model selection refers to a given classification problem for which we want to select the <span class="strong"><em class="calibre9">optimal</em></span> values of tuning parameters (also called hyperparameters). However, if we reuse the same test dataset over and over again during model selection, it will become part of our training data and thus the model will be more likely to overfit. Despite this issue, many people still use the test set for model selection, which is not a good machine learning practice.</p><p class="calibre8">A better way of using the holdout method for model selection is to separate the data into three parts: a training set, a validation set, and a test set. The training set is used to fit the different models, and the performance on the validation set is then used for the model selection. The advantage of having a test set that the model hasn't seen before during the training and model selection steps is that we can obtain a less biased estimate of its ability to generalize to new data. The following figure illustrates the concept of holdout cross-validation, where we use a validation set to repeatedly evaluate the performance of the model after training using different parameter values. Once we are satisfied with the tuning of hyperparameter values, we estimate the models' generalization performance on the test dataset:</p><div class="mediaobject"><img src="images/00857.jpeg" alt="The holdout method" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">A disadvantage of the holdout method is that the performance estimate may be very sensitive to how we partition the training set into the training and validation subsets; the estimate will vary for different samples of the data. In the next subsection, we will take a look at a more robust technique for performance estimation, k-fold cross-validation, where we repeat the holdout method <span class="strong"><em class="calibre9">k</em></span> times on <span class="strong"><em class="calibre9">k</em></span> subsets of the training data.</p></div></div></div>

<div id="calibre_link-555" class="calibre">
<div class="book" title="Using k-fold cross-validation to assess model performance">
<div class="book" title="K-fold cross-validation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1380"><a id="calibre_link-302" class="calibre1"></a>K-fold cross-validation</h2></div></div></div><p class="calibre8">In k-fold cross-validation, we randomly<a id="calibre_link-1381" class="calibre1"></a> split the training dataset into <span class="strong"><em class="calibre9">k</em></span> folds without replacement, where <span class="strong"><em class="calibre9">k</em></span> &mdash; 1 folds are used for the model training, and one fold is used for performance evaluation. This procedure is repeated <span class="strong"><em class="calibre9">k</em></span> times so that we obtain <span class="strong"><em class="calibre9">k</em></span> models and performance estimates.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1382" class="calibre1"></a>Note</h3><p class="calibre8">We looked at an example to illustrate sampling <span class="strong"><em class="calibre9">with</em></span> and <span class="strong"><em class="calibre9">without</em></span> replacement in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>. If you haven't read that chapter, or want a refresher, refer to the information box in the <span class="strong"><em class="calibre9">Combining multiple decision trees via random forests</em></span> section in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>.</p></div><p class="calibre8">We then calculate the average performance of the models based on the different, independent folds to obtain a performance estimate that is less sensitive to the sub-partitioning of the training data compared to the holdout method. Typically, we use k-fold cross-validation for model tuning, that is, finding the optimal hyperparameter values that yields a satisfying generalization performance.</p><p class="calibre8">Once we have found satisfactory hyperparameter values, we can retrain the model on the complete training set and obtain a final performance estimate using the independent test set. The rationale behind fitting a model to the whole training dataset after k-fold cross-validation is that providing more training samples to a learning algorithm usually results in a more accurate and robust model.</p><p class="calibre8">Since k-fold cross-validation is a resampling technique without replacement, the advantage of this approach is that each sample point will be used for training and validation (as part of a test fold) exactly once, which yields a lower-variance estimate of the model performance than the holdout method. The following figure summarizes the concept behind k-fold cross-validation with <span class="strong"><em class="calibre9">k = 10</em></span>. The training dataset is divided into 10 folds, and during the 10 iterations, nine folds are used for training, and one fold will be used as the test set for the model evaluation. Also, the estimated performances <span class="strong"><img src="images/00867.jpeg" alt="K-fold cross-validation" class="calibre14" /></span> (for example, classification accuracy or error) for each fold are then used to calculate the estimated average performance <span class="strong"><em class="calibre9">E</em></span> of the model:</p><div class="mediaobject"><img src="images/00873.jpeg" alt="K-fold cross-validation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">A good standard value for <span class="strong"><em class="calibre9">k</em></span> in k-fold cross-validation is 10, as empirical evidence shows. For instance, experiments by Ron Kohavi on various real-world datasets suggest that 10-fold cross-validation offers the best trade-off between bias and variance (<span class="strong"><em class="calibre9">A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection</em></span>, <span class="strong"><em class="calibre9">Kohavi, Ron</em></span>, <span class="strong"><em class="calibre9">International Joint Conference on Artificial Intelligence (IJCAI)</em></span>, 14 (12): 1137-43, <span class="strong"><em class="calibre9">1995</em></span>).</p><p class="calibre8">However, if we are working with <a id="calibre_link-1383" class="calibre1"></a>relatively small training sets, it can be useful to increase the number of folds. If we increase the value of <span class="strong"><em class="calibre9">k</em></span>, more training data will be used in each iteration, which results in a lower bias towards estimating the generalization performance by averaging the individual model estimates. However, large values of <span class="strong"><em class="calibre9">k</em></span> will also increase the runtime of the cross-validation algorithm and yield estimates with higher variance, since the training folds will be more similar to each other. On the other hand, if we are working with large datasets, we can choose a smaller value for <span class="strong"><em class="calibre9">k</em></span>, for example, <span class="strong"><em class="calibre9">k = 5</em></span>, and still obtain an accurate estimate of the average performance of the model while reducing the computational cost of refitting and evaluating the model on the <a id="calibre_link-1384" class="calibre1"></a>different folds.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1385" class="calibre1"></a>Note</h3><p class="calibre8">A special case of k-fold cross-validation is the <span class="strong"><strong class="calibre2">Leave-one-out cross-validation</strong></span> (<span class="strong"><strong class="calibre2">LOOCV</strong></span>) method. In LOOCV, we set the number of folds equal to the number of training samples (<span class="strong"><em class="calibre9">k = n</em></span>) so that only one training sample is used for testing during each iteration, which is a recommended approach for working with very small datasets.</p></div><p class="calibre8">A slight improvement over the <a id="calibre_link-1386" class="calibre1"></a>standard k-fold cross-validation approach is stratified k-fold cross-validation, which can yield better bias and variance estimates, especially in cases of unequal class proportions, as has been shown in a study by Ron Kohavi (<span class="strong"><em class="calibre9">A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection</em></span>, <span class="strong"><em class="calibre9">International Joint Conference on Artificial Intelligence (IJCAI)</em></span>, 14 (12): 1137-43, <span class="strong"><em class="calibre9">1995</em></span>). In stratified cross-validation, the class proportions are preserved in each fold to ensure that each fold is representative of the class proportions in the training dataset, which we will illustrate by using the <code class="email">StratifiedKFold</code> iterator in scikit-learn:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import StratifiedKFold

&gt;&gt;&gt; kfold = StratifiedKFold(n_splits=10,
...                         random_state=1).split(X_train,
...                                               y_train)
&gt;&gt;&gt; scores = []
&gt;&gt;&gt; for k, (train, test) in enumerate(kfold):
...     pipe_lr.fit(X_train[train], y_train[train])
...     score = pipe_lr.score(X_train[test], y_train[test])
...     scores.append(score)
...     print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,
...           np.bincount(y_train[train]), score))
Fold:  1, Class dist.: [256 153], Acc: 0.935
Fold:  2, Class dist.: [256 153], Acc: 0.935
Fold:  3, Class dist.: [256 153], Acc: 0.957
Fold:  4, Class dist.: [256 153], Acc: 0.957
Fold:  5, Class dist.: [256 153], Acc: 0.935
Fold:  6, Class dist.: [257 153], Acc: 0.956
Fold:  7, Class dist.: [257 153], Acc: 0.978
Fold:  8, Class dist.: [257 153], Acc: 0.933
Fold:  9, Class dist.: [257 153], Acc: 0.956
Fold: 10, Class dist.: [257 153], Acc: 0.956</pre></div><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('\nCV accuracy: %.3f +/- %.3f' %
...       (np.mean(scores), np.std(scores)))
CV accuracy: 0.950 +/- 0.014</pre></div><p class="calibre8">First, we initialized the <code class="email">StratifiedKfold</code> iterator from the <code class="email">sklearn.model_selection</code> module with the <code class="email">y_train</code> class labels in the training set, and we specified the number of folds via the <code class="email">n_splits</code> parameter. When we used the <code class="email">kfold</code> iterator to loop through the <code class="email">k</code> folds, we used the returned indices in <code class="email">train</code> to fit the logistic regression pipeline that we set up at the beginning of this chapter. Using the <code class="email">pipe_lr</code> pipeline, we ensured that the samples were scaled properly (for instance, standardized) in each iteration. We then used the <code class="email">test</code> indices to calculate the accuracy score of the model, which we collected in the <code class="email">scores</code> list to calculate the average accuracy and the standard deviation of the estimate.</p><p class="calibre8">Although the previous code example was useful to illustrate how k-fold cross-validation works, scikit-learn also implements a k-fold cross-validation scorer, which allows us to evaluate our model using stratified k-fold cross-validation less verbosely:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import cross_val_score

&gt;&gt;&gt; scores = cross_val_score(estimator=pipe_lr,
...                          X=X_train,
...                          y=y_train,
...                          cv=10,
...                          n_jobs=1)
&gt;&gt;&gt; print('CV accuracy scores: %s' % scores)
CV accuracy scores: [ 0.93478261  0.93478261  0.95652174
                      0.95652174  0.93478261  0.95555556
                      0.97777778  0.93333333  0.95555556
                      0.95555556]
&gt;&gt;&gt; print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),
...       np.std(scores)))
CV accuracy: 0.950 +/- 0.014</pre></div><p class="calibre8">An extremely useful feature of<a id="calibre_link-1387" class="calibre1"></a> the <code class="email">cross_val_score</code> approach is that we can distribute the evaluation of the different folds across multiple CPUs on our machine. If we set the <code class="email">n_jobs</code> parameter to <code class="email">1</code>, only one CPU will be used to evaluate the performances, just like in our <code class="email">StratifiedKFold</code> example previously. However, by setting <code class="email">n_jobs=2</code>, we could distribute the 10 rounds of cross-validation to two CPUs (if available on our machine), and by setting <code class="email">n_jobs=-1</code>, we can use all available CPUs on our machine to do the computation in parallel.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1388" class="calibre1"></a>Note</h3><p class="calibre8">Please note that a detailed discussion of how the variance of the generalization performance is estimated in cross-validation is beyond the scope of this book, but I have written a series of articles about model evaluation and cross-validation that discuss these topics in more depth. These articles are available here:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><a class="calibre1" href="https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html">https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html</a></li><li class="listitem"><a class="calibre1" href="https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html">https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html</a></li><li class="listitem"><a class="calibre1" href="https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html">https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html</a></li></ul></div><p class="calibre8">In addition, you can find a detailed discussion in this excellent article by M. Markatou and others (<span class="strong"><em class="calibre9">Analysis of Variance of Cross-validation Estimators of the Generalization Error</em></span>, <span class="strong"><em class="calibre9">M. Markatou</em></span>, <span class="strong"><em class="calibre9">H. Tian</em></span>, <span class="strong"><em class="calibre9">S. Biswas</em></span>, and <span class="strong"><em class="calibre9">G. M. Hripcsak</em></span>, <span class="strong"><em class="calibre9">Journal of Machine Learning Research</em></span>, 6: 1127-1168, <span class="strong"><em class="calibre9">2005</em></span>).</p><p class="calibre8">You can also read about alternative cross-validation techniques, such as the .632 Bootstrap cross-validation method (<span class="strong"><em class="calibre9">Improvements on Cross-validation: The .632+ Bootstrap Method</em></span>, <span class="strong"><em class="calibre9">B. Efron</em></span> and <span class="strong"><em class="calibre9">R. Tibshirani</em></span>, <span class="strong"><em class="calibre9">Journal of the American Statistical Association</em></span>, 92(438): 548-560, <span class="strong"><em class="calibre9">1997</em></span>).</p></div></div></div></div>

<div id="calibre_link-584" class="calibre">
<div id="calibre_link-1389" class="calibre10"></div><div class="book" title="Debugging algorithms with learning and validation curves"><div class="book" id="calibre_link-14"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1390"><a id="calibre_link-1391" class="calibre1"></a>Debugging algorithms with learning and validation curves</h1></div></div></div><p class="calibre8">In this section, we will take<a id="calibre_link-1392" class="calibre1"></a> a look at two very simple yet powerful<a id="calibre_link-1393" class="calibre1"></a> diagnostic tools that can help us<a id="calibre_link-1394" class="calibre1"></a> improve the performance of a learning <a id="calibre_link-1395" class="calibre1"></a>algorithm: <span class="strong"><strong class="calibre2">learning curves</strong></span> and <span class="strong"><strong class="calibre2">validation curves</strong></span>. In the next subsections, we will discuss how we can use learning curves to diagnose whether a learning algorithm has a problem with overfitting (high variance) or underfitting (high bias). Furthermore, we will take a look at validation curves that can help us address the common issues of a learning algorithm.</p></div></div>

<div id="calibre_link-57" class="calibre">
<div class="book" title="Debugging algorithms with learning and validation curves">
<div class="book" title="Diagnosing bias and variance problems with learning curves"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1396"><a id="calibre_link-303" class="calibre1"></a>Diagnosing bias and variance problems with learning curves</h2></div></div></div><p class="calibre8">If a model is too<a id="calibre_link-1397" class="calibre1"></a> complex for a given training dataset&mdash;there<a id="calibre_link-1398" class="calibre1"></a> are too many degrees <a id="calibre_link-1399" class="calibre1"></a>of freedom or parameters in this <a id="calibre_link-1400" class="calibre1"></a>model&mdash;the model tends to overfit the training data and does not generalize well to unseen data. Often, it can help to collect more training samples to reduce the degree of overfitting. However, in practice, it can often be very expensive or simply not feasible to collect more data. By plotting the model training and validation accuracies as functions of the training set size, we can easily detect whether the model suffers from high variance or high bias, and whether the collection of more data could help address this problem. But before we discuss how to plot learning curves in scikit-learn, let's discuss those two common model issues by walking through the following illustration:</p><div class="mediaobject"><img src="images/00881.jpeg" alt="Diagnosing bias and variance problems with learning curves" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The graph in the upper-left<a id="calibre_link-1401" class="calibre1"></a> shows a model with high bias. This <a id="calibre_link-1402" class="calibre1"></a>model has both low training and cross-validation accuracy, which indicates that it underfits the training data. Common ways to address this issue are to increase the number of parameters of the <a id="calibre_link-1403" class="calibre1"></a>model, for example, by <a id="calibre_link-1404" class="calibre1"></a>collecting or constructing additional features, or by decreasing the degree of regularization, for example, in SVM or logistic regression classifiers.</p><p class="calibre8">The graph in the upper-right shows a model that suffers from high variance, which is indicated by the large gap between the training and cross-validation accuracy. To address this problem of overfitting, we can collect more training data, reduce the complexity of the model, or increase the regularization parameter, for example. For unregularized models, it can also help decrease the number of features via feature selection (<a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>) or feature extraction (<a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>) to decrease the degree of overfitting. While collecting more training data usually tends to decrease the chance of overfitting, it may not always help, for example, if the training data is extremely noisy or the model is already very close to optimal.</p><p class="calibre8">In the next subsection, we will see how to address those model issues using validation curves, but let's first see how <a id="calibre_link-1405" class="calibre1"></a>we can use the learning curve function<a id="calibre_link-1406" class="calibre1"></a> from scikit-learn<a id="calibre_link-1407" class="calibre1"></a> to evaluate <a id="calibre_link-1408" class="calibre1"></a>the model:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; from sklearn.model_selection import learning_curve

&gt;&gt;&gt; pipe_lr = make_pipeline(StandardScaler(),
...                         LogisticRegression(penalty='l2',
...                                            random_state=1))
&gt;&gt;&gt; train_sizes, train_scores, test_scores =\
...                 learning_curve(estimator=pipe_lr,
...                                X=X_train,
...                                y=y_train,
...                                train_sizes=np.linspace(
...                                  0.1, 1.0, 10),
...                                cv=10,
...                                n_jobs=1)
&gt;&gt;&gt; train_mean = np.mean(train_scores, axis=1)
&gt;&gt;&gt; train_std = np.std(train_scores, axis=1)
&gt;&gt;&gt; test_mean = np.mean(test_scores, axis=1)
&gt;&gt;&gt; test_std = np.std(test_scores, axis=1)

&gt;&gt;&gt; plt.plot(train_sizes, train_mean,
...          color='blue', marker='o',
...          markersize=5, label='training accuracy')

&gt;&gt;&gt; plt.fill_between(train_sizes,
...                  train_mean + train_std,
...                  train_mean - train_std,
...                  alpha=0.15, color='blue')

&gt;&gt;&gt; plt.plot(train_sizes, test_mean,
...          color='green', linestyle='--',
...          marker='s', markersize=5,
...          label='validation accuracy')

&gt;&gt;&gt; plt.fill_between(train_sizes,
...                  test_mean + test_std,
...                  test_mean - test_std,
...                  alpha=0.15, color='green')
&gt;&gt;&gt; plt.grid()
&gt;&gt;&gt; plt.xlabel('Number of training samples')
&gt;&gt;&gt; plt.ylabel('Accuracy')
&gt;&gt;&gt; plt.legend(loc='lower right')
&gt;&gt;&gt; plt.ylim([0.8, 1.0])
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After we have successfully<a id="calibre_link-1409" class="calibre1"></a> executed the preceding code, we<a id="calibre_link-1410" class="calibre1"></a> obtain the following learning curve plot:</p><div class="mediaobject"><img src="images/00888.jpeg" alt="Diagnosing bias and variance problems with learning curves" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Via the <code class="email">train_sizes</code> parameter in the <code class="email">learning_curve</code> function, we can control the absolute or relative number of training samples that are used to generate the learning curves. Here, we set <code class="email">train_sizes=np.linspace(0.1, 1.0, 10)</code> to use 10 evenly spaced, relative intervals for the training set sizes. By default, the <code class="email">learning_curve</code> function uses stratified k-fold cross-validation to calculate the cross-validation accuracy of a classifier, and we set <span class="strong"><em class="calibre9">k=10</em></span> via the <code class="email">cv</code> parameter for 10-fold stratified cross-validation. Then, we <a id="calibre_link-1411" class="calibre1"></a>simply calculated the average accuracies<a id="calibre_link-1412" class="calibre1"></a> from the returned cross-validated training and test scores for the different sizes of the training set, which we plotted using Matplotlib's <code class="email">plot</code> function. Furthermore, we added the standard deviation of the average accuracy to the plot using the <code class="email">fill_between</code> function to indicate the variance of the estimate.</p><p class="calibre8">As we can see in the preceding learning curve plot, our model performs quite well on both the training and validation dataset if it had seen more than 250 samples during training. We can also see that the training accuracy increases for training sets with fewer than 250 samples, and the gap between validation and training accuracy widens&mdash;an indicator of an increasing degree of overfitting.</p></div></div></div>

<div id="calibre_link-59" class="calibre">
<div class="book" title="Debugging algorithms with learning and validation curves">
<div class="book" title="Addressing over- and underfitting with validation curves"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1413"><a id="calibre_link-304" class="calibre1"></a>Addressing over- and underfitting with validation curves</h2></div></div></div><p class="calibre8">Validation curves are a<a id="calibre_link-1414" class="calibre1"></a> useful tool for improving the <a id="calibre_link-1415" class="calibre1"></a>performance of a model <a id="calibre_link-1416" class="calibre1"></a>by addressing issues such as <a id="calibre_link-1417" class="calibre1"></a>overfitting or underfitting. Validation curves are related to learning curves, but instead of plotting the training and test accuracies as functions of the sample size, we vary the values of the model parameters, for example, the inverse regularization parameter <code class="email">C</code> in logistic regression. Let's go ahead and see how we create validation curves via scikit-learn:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import validation_curve
&gt;&gt;&gt; param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
&gt;&gt;&gt; train_scores, test_scores = validation_curve(
...                 estimator=pipe_lr,
...                 X=X_train,
...                 y=y_train,
...                 param_name='logisticregression__C',
...                 param_range=param_range,
...                 cv=10)
&gt;&gt;&gt; train_mean = np.mean(train_scores, axis=1)
&gt;&gt;&gt; train_std = np.std(train_scores, axis=1)
&gt;&gt;&gt; test_mean = np.mean(test_scores, axis=1)
&gt;&gt;&gt; test_std = np.std(test_scores, axis=1)
&gt;&gt;&gt; plt.plot(param_range, train_mean,
...          color='blue', marker='o',
...          markersize=5, label='training accuracy')
&gt;&gt;&gt; plt.fill_between(param_range, train_mean + train_std,
...                  train_mean - train_std, alpha=0.15,
...                  color='blue')
&gt;&gt;&gt; plt.plot(param_range, test_mean,
...          color='green', linestyle='--',
...          marker='s', markersize=5,
...          label='validation accuracy')
&gt;&gt;&gt; plt.fill_between(param_range,
...                  test_mean + test_std,
...                  test_mean - test_std,
...                  alpha=0.15, color='green')
&gt;&gt;&gt; plt.grid()
&gt;&gt;&gt; plt.xscale('log')
&gt;&gt;&gt; plt.legend(loc='lower right')
&gt;&gt;&gt; plt.xlabel('Parameter C')
&gt;&gt;&gt; plt.ylabel('Accuracy')
&gt;&gt;&gt; plt.ylim([0.8, 1.03])
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Using<a id="calibre_link-1418" class="calibre1"></a> the preceding code, we obtained<a id="calibre_link-1419" class="calibre1"></a> the validation curve plot for the parameter <code class="email">C</code>:</p><div class="mediaobject"><img src="images/00680.jpeg" alt="Addressing over- and underfitting with validation curves" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similar to<a id="calibre_link-1420" class="calibre1"></a> the <code class="email">learning_curve</code> function, the <code class="email">validation_curve</code> function uses stratified k-fold cross-validation by default to estimate the<a id="calibre_link-1421" class="calibre1"></a> performance of the classifier. Inside the <code class="email">validation_curve</code> function, we specified the parameter that we wanted to evaluate. In this case, it is <code class="email">C</code>, the inverse regularization parameter of the <code class="email">LogisticRegression</code> classifier, which we wrote as <code class="email">'logisticregression__C'</code> to access the <code class="email">LogisticRegression</code> object inside the scikit-learn pipeline for a specified value range that we set via the <code class="email">param_range</code> parameter. Similar to the learning curve example in the previous section, we plotted the average training and cross-validation accuracies and the corresponding standard deviations.</p><p class="calibre8">Although the differences in the accuracy for varying values of <code class="email">C</code> are subtle, we can see that the model slightly underfits the data when we increase the regularization strength (small values of <code class="email">C</code>). However, for large values of <code class="email">C</code>, it means lowering the strength of regularization, so the model tends to slightly overfit the data. In this case, the sweet spot appears to be between <code class="email">0.01</code> and <code class="email">0.1</code> of the <code class="email">C</code> value.</p></div></div></div>

<div id="calibre_link-629" class="calibre">
<div id="calibre_link-1422" class="calibre10"></div><div class="book" title="Fine-tuning machine learning models via grid search" id="calibre_link-13"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1423"><a id="calibre_link-1424" class="calibre1"></a>Fine-tuning machine learning models via grid search</h1></div></div></div><p class="calibre8">In machine learning, we have two<a id="calibre_link-1425" class="calibre1"></a> types of parameters: those that<a id="calibre_link-1426" class="calibre1"></a> are learned from the training data, for example, the weights in logistic regression, and the parameters of a learning algorithm that are optimized separately. The latter are the tuning parameters, also <a id="calibre_link-1427" class="calibre1"></a>called <span class="strong"><strong class="calibre2">hyperparameters</strong></span>, of a model, for example, the regularization parameter in logistic regression or the depth parameter of a decision tree.</p><p class="calibre8">In the previous section, we used validation curves to improve the performance of a model by tuning one of its hyperparameters. In this section, we will take a look at a popular hyperparameter optimization technique called <span class="strong"><strong class="calibre2">grid search</strong></span>
<a id="calibre_link-1428" class="calibre1"></a> that can further help improve the performance of a model by finding the <span class="strong"><em class="calibre9">optimal</em></span> combination of hyperparameter values.</p></div></div>

<div id="calibre_link-647" class="calibre">
<div class="book" title="Fine-tuning machine learning models via grid search" id="calibre_link-1429">
<div class="book" title="Tuning hyperparameters via grid search"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1430"><a id="calibre_link-305" class="calibre1"></a>Tuning hyperparameters via grid search</h2></div></div></div><p class="calibre8">The approach of grid <a id="calibre_link-1431" class="calibre1"></a>search is quite simple; it's a brute-force <a id="calibre_link-1432" class="calibre1"></a>exhaustive search paradigm where we specify a list of values for different hyperparameters, and the computer evaluates the model performance for each combination of those to obtain the optimal combination of values from this set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import GridSearchCV
&gt;&gt;&gt; from sklearn.svm import SVC

&gt;&gt;&gt; pipe_svc = make_pipeline(StandardScaler(),
...                          SVC(random_state=1))
&gt;&gt;&gt; param_range = [0.0001, 0.001, 0.01, 0.1,
...                1.0, 10.0, 100.0, 1000.0]
&gt;&gt;&gt; param_grid = [{'svc__C': param_range,
...                'svc__kernel': ['linear']},
...               {'svc__C': param_range,
                   'svc__gamma': param_range,
...                'svc__kernel': ['rbf']}]

&gt;&gt;&gt; gs = GridSearchCV(estimator=pipe_svc,
...                   param_grid=param_grid,
...                   scoring='accuracy',
...                   cv=10,
...                   n_jobs=-1)
&gt;&gt;&gt; gs = gs.fit(X_train, y_train)
&gt;&gt;&gt; print(gs.best_score_)
0.984615384615
&gt;&gt;&gt; print(gs.best_params_)
{'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}</pre></div><p class="calibre8">Using the preceding<a id="calibre_link-1433" class="calibre1"></a> code, we initialized a <code class="email">GridSearchCV</code> object from the <code class="email">sklearn.model_selection</code> module to train and tune a <span class="strong"><strong class="calibre2">Support Vector Machine</strong></span> (<span class="strong"><strong class="calibre2">SVM</strong></span>)<a id="calibre_link-1434" class="calibre1"></a> pipeline. We set the <code class="email">param_grid</code> parameter of <code class="email">GridSearchCV</code> to a<a id="calibre_link-1435" class="calibre1"></a> list of dictionaries to specify the parameters that we'd want to tune. For the linear SVM, we only evaluated the inverse regularization parameter <code class="email">C</code>; for the RBF kernel SVM, we tuned both the <code class="email">svc__C</code> and <code class="email">svc__gamma</code> parameter. Note that the <code class="email">svc__gamma</code> parameter is specific to kernel SVMs.</p><p class="calibre8">After we used the training data to perform the grid search, we obtained the score of the best-performing model via the <code class="email">best_score_</code> attribute and looked at its parameters that can be accessed via the <code class="email">best_params_</code> attribute. In this particular case, the RBF-kernel SVM model with <code class="email">svc__C = 100.0</code> yielded the best k-fold cross-validation accuracy: 98.5 percent.</p><p class="calibre8">Finally, we will use the independent test dataset to estimate the performance of the best-selected model, which is available via the <code class="email">best_estimator_</code> attribute of the <code class="email">GridSearchCV</code> object:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; clf = gs.best_estimator_
&gt;&gt;&gt; clf.fit(X_train, y_train)
&gt;&gt;&gt; print('Test accuracy: %.3f' % clf.score(X_test, y_test))
Test accuracy: 0.974</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1436" class="calibre1"></a>Note</h3><p class="calibre8">Although grid search is a powerful approach for finding the optimal set of parameters, the evaluation of all possible parameter combinations is also computationally very expensive. An alternative approach to sampling different parameter combinations using scikit-learn is randomized search. Using the <code class="email">RandomizedSearchCV</code> class in scikit-learn, we can draw random parameter combinations<a id="calibre_link-1437" class="calibre1"></a> from sampling distributions with a specified budget. More details and examples of its usage can be found at <a class="calibre1" href="http://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization">http://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization</a>.</p></div></div></div></div>

<div id="calibre_link-87" class="calibre">
<div class="book" title="Fine-tuning machine learning models via grid search" id="calibre_link-1438">
<div class="book" title="Algorithm selection with nested cross-validation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1439"><a id="calibre_link-306" class="calibre1"></a>Algorithm selection with nested cross-validation</h2></div></div></div><p class="calibre8">Using k-fold cross-validation in<a id="calibre_link-1440" class="calibre1"></a> combination with <a id="calibre_link-1441" class="calibre1"></a>grid search is a useful approach for fine-tuning the performance of a machine learning model by varying its hyperparameter values, as we saw in the previous subsection. If we want to select among different machine learning algorithms, though, another recommended approach is nested cross-validation. In a nice study on the bias in error estimation, Varma and Simon concluded that the true error of the estimate is almost unbiased relative to the test set when nested cross-validation is used (<span class="strong"><em class="calibre9">Bias in Error Estimation When Using Cross-validation for Model Selection</em></span>, <span class="strong"><em class="calibre9">BMC Bioinformatics</em></span>, <span class="strong"><em class="calibre9">S. Varma</em></span> and <span class="strong"><em class="calibre9">R. Simon</em></span>, 7(1): 91, <span class="strong"><em class="calibre9">2006</em></span>).</p><p class="calibre8">In nested cross-validation, we have an outer k-fold cross-validation loop to split the data into training and test folds, and an inner loop is used to select the model using k-fold cross-validation on the training fold. After model selection, the test fold is then used to evaluate the model performance. The following figure explains the concept of nested cross-validation with only five outer and two inner folds, which can be useful for large datasets where computational performance is important; this particular type of nested cross-validation is also<a id="calibre_link-1442" class="calibre1"></a> known as <span class="strong"><strong class="calibre2">5x2 cross-validation</strong></span>:</p><div class="mediaobject"><img src="images/00900.jpeg" alt="Algorithm selection with nested cross-validation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In scikit-learn, we can perform nested cross-validation as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; gs = GridSearchCV(estimator=pipe_svc,
...                   param_grid=param_grid,
...                   scoring='accuracy',
...                   cv=2)

&gt;&gt;&gt; scores = cross_val_score(gs, X_train, y_train,
...                          scoring='accuracy', cv=5)
&gt;&gt;&gt; print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),
...                                       np.std(scores)))
CV accuracy: 0.974 +/- 0.015</pre></div><p class="calibre8">The returned average cross-validation accuracy gives us a good estimate of what to expect if we tune the hyperparameters of a model and use it on unseen data. For example, we can use the nested cross-validation approach to compare an SVM model to a simple decision tree classifier; for simplicity, we will only tune its depth parameter:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier

&gt;&gt;&gt; gs = GridSearchCV(estimator=DecisionTreeClassifier(
                                random_state=0),
...                   param_grid=[{'max_depth': [1, 2, 3,
...                                     4, 5, 6, 7, None]}],
...                   scoring='accuracy',
...                   cv=2)

&gt;&gt;&gt; scores = cross_val_score(gs, X_train, y_train,
...                          scoring='accuracy', cv=5)
&gt;&gt;&gt; print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),
...                                       np.std(scores)))
CV accuracy: 0.934 +/- 0.016</pre></div><p class="calibre8">As we can see, the<a id="calibre_link-1443" class="calibre1"></a> nested cross-validation<a id="calibre_link-1444" class="calibre1"></a> performance of the SVM model (97.4 percent) is notably better than the performance of the decision tree (93.4 percent), and thus, we'd expect that it might be the better choice to classify new data that comes from the same population as this particular dataset.</p></div></div></div>

<div id="calibre_link-89" class="calibre">
<div id="calibre_link-1445" class="calibre10"></div><div class="book" title="Looking at different performance evaluation metrics"><div class="book" id="calibre_link-2"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1446"><a id="calibre_link-1447" class="calibre1"></a>Looking at different performance evaluation metrics</h1></div></div></div><p class="calibre8">In the previous sections and<a id="calibre_link-1448" class="calibre1"></a> chapters, we evaluated our models using model accuracy, which is a useful metric with which to quantify the performance of a model in general. However, there are several other performance metrics that can be used to measure a model's relevance, such as precision, recall, and the F1-score.</p></div></div>

<div id="calibre_link-94" class="calibre">
<div class="book" title="Looking at different performance evaluation metrics">
<div class="book" title="Reading a confusion matrix"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1449"><a id="calibre_link-307" class="calibre1"></a>Reading a confusion matrix</h2></div></div></div><p class="calibre8">Before we get into the details of<a id="calibre_link-1450" class="calibre1"></a> different scoring metrics, let's take a look at a <span class="strong"><strong class="calibre2">confusion matrix</strong></span>, a matrix that lays out the performance of a learning algorithm. The confusion matrix is simply a square <a id="calibre_link-1451" class="calibre1"></a>matrix that reports the <a id="calibre_link-1452" class="calibre1"></a>counts of the<a id="calibre_link-1453" class="calibre1"></a> <span class="strong"><strong class="calibre2">True positive</strong></span> (<span class="strong"><strong class="calibre2">TP</strong></span>), <span class="strong"><strong class="calibre2">True negative</strong></span> (<span class="strong"><strong class="calibre2">TN</strong></span>), <span class="strong"><strong class="calibre2">False positive</strong></span> (<span class="strong"><strong class="calibre2">FP</strong></span>), and <span class="strong"><strong class="calibre2">False negative</strong></span> (<span class="strong"><strong class="calibre2">FN</strong></span>) predictions <a id="calibre_link-1454" class="calibre1"></a>of a classifier, as shown in the following figure:</p><div class="mediaobject"><img src="images/00739.jpeg" alt="Reading a confusion matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although these metrics can be easily computed manually by comparing the true and predicted class labels, scikit-learn provides a convenient <code class="email">confusion_matrix</code> function that we can use, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import confusion_matrix

&gt;&gt;&gt; pipe_svc.fit(X_train, y_train)
&gt;&gt;&gt; y_pred = pipe_svc.predict(X_test)
&gt;&gt;&gt; confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)
&gt;&gt;&gt; print(confmat)
[[71  1]
 [ 2 40]]</pre></div><p class="calibre8">The array that was returned after executing the code provides us with information about the different types of error the classifier made on the test dataset. We can map this information onto the confusion matrix illustration in the previous figure using Matplotlib's <code class="email">matshow</code> function:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; fig, ax = plt.subplots(figsize=(2.5, 2.5))
&gt;&gt;&gt; ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)
&gt;&gt;&gt; for i in range(confmat.shape[0]):
...     for j in range(confmat.shape[1]):
...         ax.text(x=j, y=i,
...                 s=confmat[i, j],
...                 va='center', ha='center')
&gt;&gt;&gt; plt.xlabel('predicted label')
&gt;&gt;&gt; plt.ylabel('true label')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Now, the following <a id="calibre_link-1455" class="calibre1"></a>confusion matrix plot, with the added labels, should make the results a little bit easier to interpret:</p><div class="mediaobject"><img src="images/00909.jpeg" alt="Reading a confusion matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Assuming that class <code class="email">1</code> (malignant) is the positive class in this example, our model correctly classified 71 of the samples that belong to class <code class="email">0</code> (TNs) and 40 samples that belong to class <code class="email">1</code> (TPs), respectively. However, our model also incorrectly misclassified two samples from class <code class="email">1</code> as class <code class="email">0</code> (FN), and it predicted that one sample is malignant although it is a benign tumor (FP). In the next section, we will learn how we can use this information to calculate various error metrics.</p></div></div></div>

<div id="calibre_link-121" class="calibre">
<div class="book" title="Looking at different performance evaluation metrics">
<div class="book" title="Optimizing the precision and recall of a classification model"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1456"><a id="calibre_link-308" class="calibre1"></a>Optimizing the precision and recall of a classification model</h2></div></div></div><p class="calibre8">Both the <a id="calibre_link-1457" class="calibre1"></a>prediction <span class="strong"><strong class="calibre2">error </strong></span>(<span class="strong"><strong class="calibre2">ERR</strong></span>) and <span class="strong"><strong class="calibre2">accuracy</strong></span> (<span class="strong"><strong class="calibre2">ACC</strong></span>) provide<a id="calibre_link-1458" class="calibre1"></a> general information about <a id="calibre_link-1459" class="calibre1"></a>how many<a id="calibre_link-1460" class="calibre1"></a> samples are<a id="calibre_link-1461" class="calibre1"></a> misclassified. The <a id="calibre_link-1462" class="calibre1"></a>error can be understood as the sum of all false predictions divided by the number of total predications, and the accuracy is calculated as the sum of correct predictions divided by the total number of predictions, respectively:</p><div class="mediaobject"><img src="images/00921.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The<a id="calibre_link-1463" class="calibre1"></a> prediction <a id="calibre_link-1464" class="calibre1"></a>accuracy<a id="calibre_link-1465" class="calibre1"></a> can then be <a id="calibre_link-1466" class="calibre1"></a>calculated directly from the error:</p><div class="mediaobject"><img src="images/00925.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The <span class="strong"><strong class="calibre2">True positive rate </strong></span>(<span class="strong"><strong class="calibre2">TPR</strong></span>) and <span class="strong"><strong class="calibre2">False positive rate </strong></span>(<span class="strong"><strong class="calibre2">FPR</strong></span>) are<a id="calibre_link-1467" class="calibre1"></a> performance metrics that are<a id="calibre_link-1468" class="calibre1"></a> especially useful for imbalanced class problems:</p><div class="mediaobject"><img src="images/00859.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00945.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In tumor diagnosis, for example, we are more concerned about the detection of malignant tumors in order to help a patient with the appropriate treatment. However, it is also important to decrease the number of benign tumors that were incorrectly classified as malignant (FPs) to not unnecessarily concern a patient. In contrast to the FPR, the TPR provides useful information about the fraction of positive (or relevant) samples that were correctly identified out of the total pool of positives(P).</p><p class="calibre8">The performance metrics <span class="strong"><strong class="calibre2">precision</strong></span> (<span class="strong"><strong class="calibre2">PRE</strong></span>) and <span class="strong"><strong class="calibre2">recall</strong></span> (<span class="strong"><strong class="calibre2">REC</strong></span>) are related to those true positive and negative rates, and in fact, REC is synonymous with TPR:</p><div class="mediaobject"><img src="images/00930.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00961.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In practice, often a combination of PRE and REC is used, the so-called <span class="strong"><strong class="calibre2">F1-score</strong></span>:</p><div class="mediaobject"><img src="images/00472.jpeg" alt="Optimizing the precision and recall of a classification model" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Those<a id="calibre_link-1469" class="calibre1"></a> scoring metrics are all implemented in <a id="calibre_link-1470" class="calibre1"></a>scikit-learn and can be imported from the <code class="email">sklearn.metrics</code> module as shown<a id="calibre_link-1471" class="calibre1"></a> in the <a id="calibre_link-1472" class="calibre1"></a>following snippet:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import precision_score
&gt;&gt;&gt; from sklearn.metrics import recall_score, f1_score

&gt;&gt;&gt; print('Precision: %.3f' % precision_score(
...              y_true=y_test, y_pred=y_pred))
Precision: 0.976
&gt;&gt;&gt; print('Recall: %.3f' % recall_score(
...              y_true=y_test, y_pred=y_pred))
Recall: 0.952
&gt;&gt;&gt; print('F1: %.3f' % f1_score(
...              y_true=y_test, y_pred=y_pred))
F1: 0.964</pre></div><p class="calibre8">Furthermore, we can use a different scoring metric than accuracy in the <code class="email">GridSearchCV</code> via the scoring parameter. A complete list of the different values that are accepted by the scoring parameter can be found at <a class="calibre1" href="http://scikit-learn.org/stable/modules/model_evaluation.html">http://scikit-learn.org/stable/modules/model_evaluation.html</a>.</p><p class="calibre8">Remember that the positive class in scikit-learn is the class that is labeled as class <code class="email">1</code>. If we want to specify a different <span class="strong"><em class="calibre9">positive label</em></span>, we can construct our own scorer via the <code class="email">make_scorer</code> function, which we can then directly provide as an argument to the scoring parameter in <code class="email">GridSearchCV</code> (in this example, using the <code class="email">f1_score</code> as a metric):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import make_scorer, f1_score
&gt;&gt;&gt; scorer = make_scorer(f1_score, pos_label=0)
&gt;&gt;&gt; gs = GridSearchCV(estimator=pipe_svc,
...                   param_grid=param_grid,
...                   scoring=scorer,
...                   cv=10)
&gt;&gt;&gt; gs = gs.fit(X_train, y_train)
&gt;&gt;&gt; print(gs.best_score_)
0.986202145696
&gt;&gt;&gt; print(gs.best_params_)
{'svc__C': 10.0, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}</pre></div></div></div></div>

<div id="calibre_link-111" class="calibre">
<div class="book" title="Looking at different performance evaluation metrics">
<div class="book" title="Plotting a receiver operating characteristic"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1473"><a id="calibre_link-309" class="calibre1"></a>Plotting a receiver operating characteristic</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Receiver Operating Characteristic </strong></span>(<span class="strong"><strong class="calibre2">ROC</strong></span>) graphs are useful tools to select models for classification based on their <a id="calibre_link-1474" class="calibre1"></a>performance with respect to the FPR and TPR, which are computed by shifting the decision threshold of the classifier. The diagonal of an ROC graph can be interpreted as <span class="strong"><em class="calibre9">random guessing</em></span>, and classification models that fall below the diagonal are considered as worse than random guessing. A perfect classifier would fall into the top left corner of the graph with a TPR of 1 and an FPR of 0. Based on the ROC curve, we can then compute the so-called <span class="strong"><strong class="calibre2">ROC Area Under the Curve </strong></span>(<span class="strong"><strong class="calibre2">ROC AUC</strong></span>)<a id="calibre_link-1475" class="calibre1"></a> to characterize the performance of a classification model.</p><p class="calibre8">Similar to ROC curves, we can compute <span class="strong"><strong class="calibre2">precision-recall curves</strong></span> for different probability thresholds of a classifier. A function for plotting those precision-recall curves<a id="calibre_link-1476" class="calibre1"></a> is also implemented in scikit-learn and is documented at <a class="calibre1" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html</a>.</p><p class="calibre8">Executing the following code example, we will plot an ROC curve of a classifier that only uses two features from the Breast Cancer Wisconsin dataset to predict whether a tumor is benign or malignant. Although we are going to use the same logistic regression pipeline that we defined previously, we are making the classification task more challenging for the classifier so that the resulting ROC curve becomes visually more interesting. For similar reasons, we are also reducing the number of folds in the <code class="email">StratifiedKFold</code> validator to three. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import roc_curve, auc
&gt;&gt;&gt; from scipy import interp

&gt;&gt;&gt; pipe_lr = make_pipeline(StandardScaler(),
...                         PCA(n_components=2),
...                         LogisticRegression(penalty='l2',
...                                            random_state=1,
...                                            C=100.0))

&gt;&gt;&gt; X_train2 = X_train[:, [4, 14]]

&gt;&gt;&gt; cv = list(StratifiedKFold(n_splits=3,
...                           random_state=1).split(X_train,
...                                                 y_train))
&gt;&gt;&gt; fig = plt.figure(figsize=(7, 5))

&gt;&gt;&gt; mean_tpr = 0.0
&gt;&gt;&gt; mean_fpr = np.linspace(0, 1, 100)
&gt;&gt;&gt; all_tpr = []

&gt;&gt;&gt; for i, (train, test) in enumerate(cv):
...     probas = pipe_lr.fit(X_train2[train],
...                  y_train[train]).predict_proba(X_train2[test])
...     fpr, tpr, thresholds = roc_curve(y_train[test],
...                                      probas[:, 1],
...                                      pos_label=1)
&gt;&gt;&gt;     mean_tpr += interp(mean_fpr, fpr, tpr)
&gt;&gt;&gt;     mean_tpr[0] = 0.0
&gt;&gt;&gt;     roc_auc = auc(fpr, tpr)
&gt;&gt;&gt;     plt.plot(fpr,
...              tpr,
...              label='ROC fold %d (area = %0.2f)'
...                    % (i+1, roc_auc))
&gt;&gt;&gt; plt.plot([0, 1],
...          [0, 1],
...          linestyle='--',
...          color=(0.6, 0.6, 0.6),
...          label='random guessing')

&gt;&gt;&gt; mean_tpr /= len(cv)
&gt;&gt;&gt; mean_tpr[-1] = 1.0
&gt;&gt;&gt; mean_auc = auc(mean_fpr, mean_tpr)
&gt;&gt;&gt; plt.plot(mean_fpr, mean_tpr, 'k--',
...          label='mean ROC (area = %0.2f)' % mean_auc, lw=2)
&gt;&gt;&gt; plt.plot([0, 0, 1],
...          [0, 1, 1],
...          linestyle=':',
...          color='black',
...          label='perfect performance')
&gt;&gt;&gt; plt.xlim([-0.05, 1.05])
&gt;&gt;&gt; plt.ylim([-0.05, 1.05])
&gt;&gt;&gt; plt.xlabel('false positive rate')
&gt;&gt;&gt; plt.ylabel('true positive rate')
&gt;&gt;&gt; plt.legend(loc="lower right")
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">In the preceding code <a id="calibre_link-1477" class="calibre1"></a>example, we used the already familiar <code class="email">StratifiedKFold</code> class from scikit-learn and calculated the ROC performance of the <code class="email">LogisticRegression</code> classifier in our <code class="email">pipe_lr</code> pipeline using the <code class="email">roc_curve</code> function from the <code class="email">sklearn.metrics</code> module separately for each iteration. Furthermore, we interpolated the average ROC curve from the three folds via the <code class="email">interp</code> function that we imported from SciPy and calculated the area under the curve via the <code class="email">auc</code> function. The resulting ROC curve indicates that there is a certain degree of variance between the different folds, and the average ROC AUC (0.76) falls between a perfect score (1.0) and random guessing (0.5):</p><div class="mediaobject"><img src="images/00506.jpeg" alt="Plotting a receiver operating characteristic" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note if we are just interested in the ROC AUC score, we could also directly import the <code class="email">roc_auc_score</code> function from the <code class="email">sklearn.metrics</code> submodule.</p><p class="calibre8">Reporting the performance of a classifier as the ROC AUC can yield further insights in a classifier's performance with respect to imbalanced samples. However, while the accuracy score can be interpreted as a single cut-off point on an ROC curve, A. P. Bradley <a id="calibre_link-1478" class="calibre1"></a>showed that the ROC AUC and accuracy metrics mostly agree with each other: <span class="strong"><em class="calibre9">The use of the area under the roc curve in the evaluation of machine learning algorithms</em></span>, <span class="strong"><em class="calibre9">A. P. Bradley</em></span>, <span class="strong"><em class="calibre9">Pattern Recognition</em></span>, 30(7): 1145-1159, <span class="strong"><em class="calibre9">1997</em></span>.</p></div></div></div>

<div id="calibre_link-116" class="calibre">
<div class="book" title="Looking at different performance evaluation metrics">
<div class="book" title="Scoring metrics for multiclass classification"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1479"><a id="calibre_link-310" class="calibre1"></a>Scoring metrics for multiclass classification</h2></div></div></div><p class="calibre8">The scoring <a id="calibre_link-1480" class="calibre1"></a>metrics that we discussed in this section are specific to binary classification systems. However, scikit-learn also implements macro and micro averaging methods to extend those scoring metrics to multiclass <a id="calibre_link-1481" class="calibre1"></a>problems via <span class="strong"><strong class="calibre2">One-versus-All</strong></span> (<span class="strong"><strong class="calibre2">OvA</strong></span>) classification. The micro-average is calculated from the individual TPs, TNs, FPs, and FNs of the system. For example, the micro-average of the precision score in a <span class="strong"><em class="calibre9">k</em></span>-class system can be calculated as follows:</p><div class="mediaobject"><img src="images/00462.jpeg" alt="Scoring metrics for multiclass classification" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The macro-average is simply calculated as the average scores of the different systems:</p><div class="mediaobject"><img src="images/00037.jpeg" alt="Scoring metrics for multiclass classification" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Micro-averaging is useful if we want to weight each instance or prediction equally, whereas macro-averaging weights all classes equally to evaluate the overall performance of a classifier with regard to the most frequent class labels.</p><p class="calibre8">If we are using binary <a id="calibre_link-1482" class="calibre1"></a>performance metrics to evaluate multiclass classification models in scikit-learn, a normalized or weighted variant of the macro-average is used by default. The weighted macro-average is calculated by weighting the score of each class label by the number of true instances when calculating the average. The weighted macro-average is useful if we are dealing with class imbalances, that is, different numbers of instances for each label.</p><p class="calibre8">While the weighted macro-average is the default for multiclass problems in scikit-learn, we can specify the averaging method via the <code class="email">average</code> parameter inside the different scoring functions that we import from the <code class="email">sklearn.metrics</code> module, for example, the <code class="email">precision_score</code> or <code class="email">make_scorer</code> functions:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; pre_scorer = make_scorer(score_func=precision_score,
...                          pos_label=1,
...                          greater_is_better=True,
...                          average='micro')</pre></div></div></div></div>

<div id="calibre_link-120" class="calibre"><div class="book" title="Dealing with class imbalance" id="calibre_link-72"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1483"><a id="calibre_link-1484" class="calibre1"></a>Dealing with class imbalance</h1></div></div></div><p class="calibre8">We've mentioned class imbalances<a id="calibre_link-1485" class="calibre1"></a> several times throughout this chapter, and yet we haven't actually discussed how to deal with such scenarios appropriately if they occur. Class imbalance is a quite common problem when working with real-world data&mdash;samples from one class or multiple classes are over-represented in a dataset. Intuitively, we can think of several domains where this may occur, such as spam filtering, fraud detection, or screening for diseases.</p><p class="calibre8">Imagine the breast cancer dataset that we've been working with in this chapter consisted of 90 percent healthy patients. In this case, we could achieve 90 percent accuracy on the test dataset by just predicting the majority class (benign tumor) for all samples, without the help of a supervised machine learning algorithm. Thus, training a model on such a dataset that achieves approximately 90 percent test accuracy would mean our model hasn't learned anything useful from the features provided in this dataset.</p><p class="calibre8">In this section, we will briefly go over some of the techniques that could help with imbalanced datasets. But before we discuss different methods to approach this problem, let's create an imbalanced dataset from our breast cancer dataset, which originally consisted of 357 benign tumors (class <code class="email">0</code>) and 212 malignant tumors (class <code class="email">1</code>):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_imb = np.vstack((X[y == 0], X[y == 1][:40]))
&gt;&gt;&gt; y_imb = np.hstack((y[y == 0], y[y == 1][:40]))</pre></div><p class="calibre8">In the previous code snippet, we took all 357 benign tumor samples and stacked them with the first 40 malignant samples to create a stark class imbalance. If we were to compute the accuracy of a model that always predicts the majority class (benign, class <code class="email">0</code>), we would achieve a prediction accuracy of approximately 90 percent:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_pred = np.zeros(y_imb.shape[0])
&gt;&gt;&gt; np.mean(y_pred == y_imb) * 100
89.924433249370267</pre></div><p class="calibre8">Thus, when we fit classifiers <a id="calibre_link-1486" class="calibre1"></a>on such datasets, it would make sense to focus on other metrics than accuracy when comparing different models, such as precision, recall, the ROC curve&mdash;whatever we care most about in our application. For instance, our priority might be to identify the majority of patients with malignant cancer patients to recommend an additional screening, then recall should be our metric of choice. In spam filtering, where we don't want to label emails as spam if the system is not very certain, precision might be a more appropriate metric.</p><p class="calibre8">Aside from evaluating machine learning models, class imbalance influences a learning algorithm during model fitting itself. Since machine learning algorithms typically optimize a reward or cost function that is computed as a sum over the training examples that it sees during fitting, the decision rule is likely going to be biased towards the majority class. In other words, the algorithm implicitly learns a model that optimizes the predictions based on the most abundant class in the dataset, in order to minimize the cost or maximize the reward during training.</p><p class="calibre8">One way to deal with imbalanced class proportions during model fitting is to assign a larger penalty to wrong predictions on the minority class. Via scikit-learn, adjusting such a penalty is as convenient as setting the <code class="email">class_weight</code> parameter to <code class="email">class_weight='balanced'</code>, which is implemented for most classifiers.</p><p class="calibre8">Other popular strategies for dealing with class imbalance include upsampling the minority class, downsampling the majority class, and the generation of synthetic training samples. Unfortunately, there's no universally best solution, no technique that works best across different problem domains. Thus, in practice, it is recommended to try out different strategies on a given<a id="calibre_link-1487" class="calibre1"></a> problem, evaluate the results, and choose the technique that seems most appropriate.</p><p class="calibre8">The scikit-learn library implements a simple <code class="email">resample</code> function that can help with the upsampling of the minority class by drawing new samples from the dataset with replacement. The following code will take the minority class from our imbalanced breast cancer dataset (here, class <code class="email">1</code>) and repeatedly draw new samples from it until it contains the same number of samples as class label <code class="email">0</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.utils import resample

&gt;&gt;&gt; print('Number of class 1 samples before:',
...       X_imb[y_imb == 1].shape[0])
Number of class 1 samples before: 40</pre></div><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_upsampled, y_upsampled = resample(X_imb[y_imb == 1],
...                         y_imb[y_imb == 1],
...                         replace=True,
...                         n_samples=X_imb[y_imb == 0].shape[0],
...                         random_state=123)
&gt;&gt;&gt; print('Number of class 1 samples after:',
...        X_upsampled.shape[0])
Number of class 1 samples after: 357</pre></div><p class="calibre8">After resampling, we can then stack the original class <code class="email">0</code> samples with the upsampled class <code class="email">1</code> subset to obtain a balanced dataset as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_bal = np.vstack((X[y == 0], X_upsampled))
&gt;&gt;&gt; y_bal = np.hstack((y[y == 0], y_upsampled))</pre></div><p class="calibre8">Consequently, a majority vote prediction rule would only achieve 50 percent accuracy:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_pred = np.zeros(y_bal.shape[0])
&gt;&gt;&gt; np.mean(y_pred == y_bal) * 100</pre></div><p class="calibre8">Similarly, we could downsample the majority class by removing training examples from the dataset. To perform downsampling using the <code class="email">resample</code> function, we could simply swap the class <code class="email">1</code> label with<a id="calibre_link-1488" class="calibre1"></a> class <code class="email">0</code> in the previous code example and vice versa.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1489" class="calibre1"></a>Note</h3><p class="calibre8">Another technique for dealing with class imbalance is the generation of synthetic training samples, which is beyond the scope of this book. The probably most widely used algorithm for <a id="calibre_link-1490" class="calibre1"></a>synthetic training sample generation is <span class="strong"><strong class="calibre2">Synthetic Minority Over-sampling Technique</strong></span> (<span class="strong"><strong class="calibre2">SMOTE</strong></span>), and you can learn more about this technique in the original research article by Nitesh Chawla and others: <span class="strong"><em class="calibre9">SMOTE: Synthetic Minority Over-sampling Technique</em></span>, <span class="strong"><em class="calibre9">Journal of Artificial Intelligence Research</em></span>, 16: 321-357, <span class="strong"><em class="calibre9">2002</em></span>. It is also highly recommended to check out <code class="email">imbalanced-learn</code>, a Python library that is entirely focused on imbalanced datasets, including an implementation of SMOTE. You<a id="calibre_link-1491" class="calibre1"></a> can learn more about <code class="email">imbalanced-learn</code> at <a class="calibre1" href="https://github.com/scikit-learn-contrib/imbalanced-learn">https://github.com/scikit-learn-contrib/imbalanced-learn</a>.</p></div></div></div>

<div id="calibre_link-127" class="calibre"><div class="book" title="Summary" id="calibre_link-311"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1492"><a id="calibre_link-1493" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">At the beginning of this chapter, we discussed how to chain different transformation techniques and classifiers in convenient model pipelines that helped us train and evaluate machine learning models more efficiently. We then used those pipelines to perform k-fold cross-validation, one of the essential techniques for model selection and evaluation. Using k-fold cross-validation, we plotted learning and validation curves to diagnose the common problems of learning algorithms, such as overfitting and underfitting. Using grid search, we further fine-tuned our model. We concluded this chapter by looking at a confusion matrix and various performance metrics that can be useful to further optimize a model's performance for a specific problem task. Now, we should be well-equipped with the essential techniques to build supervised machine learning models for classification successfully.</p><p class="calibre8">In the next chapter, we will look at ensemble methods: methods that allow us to combine multiple models and classification algorithms to boost the predictive performance of a machine learning system even further.</p></div></div>

<div id="calibre_link-133" class="calibre">
<div id="calibre_link-1494" class="calibre10"></div><div class="book" title="ChapterÂ 7.Â Combining Different Models for Ensemble Learning"><div class="book" id="calibre_link-38"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1495"><a id="calibre_link-1496" class="calibre1"></a>Chapter&nbsp;7.&nbsp;Combining Different Models for Ensemble Learning</h1></div></div></div><p class="calibre8">In the previous chapter, we focused on the best practices for tuning and evaluating different models for classification. In this chapter, we will build upon these techniques and explore different methods for constructing a set of classifiers that can often have a better predictive performance than any of its individual members. We will learn how to do the following:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Make predictions based on majority voting</li><li class="listitem">Use bagging to reduce overfitting by drawing random combinations of the training set with repetition</li><li class="listitem">Apply boosting to build powerful models from <span class="strong"><em class="calibre9">weak learners</em></span> that learn from their mistakes</li></ul></div></div></div>

<div id="calibre_link-147" class="calibre">
<div class="book" title="ChapterÂ 7.Â Combining Different Models for Ensemble Learning">
<div class="book" title="Learning with ensembles"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1497"><a id="calibre_link-312" class="calibre1"></a>Learning with ensembles</h1></div></div></div><p class="calibre8">The goal of <span class="strong"><strong class="calibre2">ensemble methods</strong></span>
<a id="calibre_link-1498" class="calibre1"></a> is to combine different classifiers into a meta-classifier that has better generalization performance than each individual classifier alone. For <a id="calibre_link-1499" class="calibre1"></a>example, assuming that we collected predictions from 10 experts, ensemble methods would allow us to strategically combine these predictions by the 10 experts to come up with a prediction that is more accurate and robust than the predictions by each individual expert. As we will see later in this chapter, there are several different approaches for creating an ensemble of classifiers. In this section, we will introduce a basic perception of how ensembles work and why they are typically recognized for yielding a good generalization performance.</p><p class="calibre8">In this chapter, we will focus on the most popular ensemble methods that use the <span class="strong"><strong class="calibre2">majority voting</strong></span> principle. Majority <a id="calibre_link-1500" class="calibre1"></a>voting simply means that we select the class label that has been predicted by the majority of classifiers, that is, received more than 50 percent of the votes. Strictly speaking, the term <span class="strong"><strong class="calibre2">majority vote</strong></span> refers to binary class settings only. However, it is easy to generalize the majority voting principle to multi-class settings, which is <a id="calibre_link-1501" class="calibre1"></a>called <span class="strong"><strong class="calibre2">plurality voting</strong></span>. Here, we<a id="calibre_link-1502" class="calibre1"></a> select the class label that received the most votes (mode). The following diagram illustrates the concept of majority and plurality voting for an ensemble of 10 classifiers where each unique symbol (triangle, square, and circle) represents a unique class label:</p><div class="mediaobject"><img src="images/00048.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Using the training set, we start by training <span class="strong"><em class="calibre9">m</em></span> different classifiers (<span class="strong"><img src="images/00253.jpeg" alt="Learning with ensembles" class="calibre14" /></span>). Depending on the technique, the ensemble can be built from different classification algorithms, for example, decision trees, support vector machines, logistic regression classifiers, and so on. Alternatively, we can also use the same base classification algorithm, fitting different subsets of the training set. One prominent example of this approach is the random forest algorithm, which combines different decision tree classifiers. The following figure illustrates the concept of a general ensemble approach using majority voting:</p><div class="mediaobject"><img src="images/00066.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To predict a class label via simple <a id="calibre_link-1503" class="calibre1"></a>majority or plurality voting, we combine the predicted class labels of each individual classifier, <span class="strong"><img src="images/00078.jpeg" alt="Learning with ensembles" class="calibre14" /></span>, and select the class label, <span class="strong"><img src="images/00092.jpeg" alt="Learning with ensembles" class="calibre14" /></span>, that received the most votes:</p><div class="mediaobject"><img src="images/00460.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">For example, in a binary classification task where <span class="strong"><img src="images/00512.jpeg" alt="Learning with ensembles" class="calibre14" /></span> and <span class="strong"><img src="images/00565.jpeg" alt="Learning with ensembles" class="calibre14" /></span>, we can write the majority vote prediction as follows:</p><div class="mediaobject"><img src="images/00136.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To illustrate why ensemble methods can work better than individual classifiers alone, let's apply the simple concepts of combinatorics. For the following example, we make the assumption that all <span class="strong"><em class="calibre9">n</em></span>-base classifiers for a binary classification task have an equal error rate, <span class="strong"><img src="images/00692.jpeg" alt="Learning with ensembles" class="calibre14" /></span>. Furthermore, we assume that the classifiers are independent and the error rates are not correlated. Under those assumptions, we can simply express the error probability of an ensemble of base classifiers as a <a id="calibre_link-1504" class="calibre1"></a>probability mass function of a binomial distribution:</p><div class="mediaobject"><img src="images/00749.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00806.jpeg" alt="Learning with ensembles" class="calibre14" /></span> is the binomial coefficient <span class="strong"><strong class="calibre2">n choose k</strong></span>. In other words, we compute the probability that the prediction of the ensemble is wrong. Now let's take a look at a more concrete example of 11 base classifiers (<span class="strong"><img src="images/00870.jpeg" alt="Learning with ensembles" class="calibre14" /></span>), where each classifier has an error rate of 0.25 (<span class="strong"><img src="images/00941.jpeg" alt="Learning with ensembles" class="calibre14" /></span>):</p><div class="mediaobject"><img src="images/00029.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1505" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">The binomial coefficient</strong></span>
</p><p class="calibre8">The binomial coefficient<a id="calibre_link-1506" class="calibre1"></a> refers to the number of ways we can choose subsets of <span class="strong"><em class="calibre9">k</em></span> unordered elements from a set of size <span class="strong"><em class="calibre9">n</em></span>; thus, it is often called "n choose k." Since the order does not matter here, the binomial coefficient is also sometimes referred to as <span class="strong"><em class="calibre9">combination</em></span> or <span class="strong"><em class="calibre9">combinatorial number</em></span>, and in its unabbreviated form, it is written as follows:</p><div class="mediaobject1"><img src="images/00080.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, the symbol (!) stands for factorial&mdash;for example, <span class="strong"><img src="images/00138.jpeg" alt="Learning with ensembles" class="calibre14" /></span>.</p></div><p class="calibre8">As we can see, the error rate of the<a id="calibre_link-1507" class="calibre1"></a> ensemble (0.034) is much lower than the error rate of each individual classifier (0.25) if all the assumptions are met. Note that, in this simplified illustration, a 50-50 split by an even number of classifiers <span class="strong"><em class="calibre9">n</em></span> is treated as an error, whereas this is only true half of the time. To compare such an idealistic ensemble classifier to a base classifier over a range of different base error rates, let's implement the probability mass function in Python:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from scipy.misc import comb
&gt;&gt;&gt; import math
&gt;&gt;&gt; def ensemble_error(n_classifier, error):
...     k_start = int(math.ceil(n_classifier / 2.))
...     probs = [comb(n_classifier, k) * 
...              error**k * 
...              (1-error)**(n_classifier - k) 
...              for k in range(k_start, n_classifier + 1)]
...     return sum(probs)
&gt;&gt;&gt; ensemble_error(n_classifier=11, error=0.25)
0.034327507019042969</pre></div><p class="calibre8">After we have implemented the <code class="email">ensemble_error</code> function, we can compute the ensemble error rates for a range of different base errors from 0.0 to 1.0 to visualize the relationship between ensemble and base errors in a line graph:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; error_range = np.arange(0.0, 1.01, 0.01)
&gt;&gt;&gt; ens_errors = [ensemble_error(n_classifier=11, error=error)
...               for error in error_range]
&gt;&gt;&gt; plt.plot(error_range, ens_errors, 
...          label='Ensemble error', 
...          linewidth=2)
&gt;&gt;&gt; plt.plot(error_range, error_range, 
...          linestyle='--', label='Base error',
...          linewidth=2)
&gt;&gt;&gt; plt.xlabel('Base error')
&gt;&gt;&gt; plt.ylabel('Base/Ensemble error')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.grid(alpha=0.5)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting plot, the<a id="calibre_link-1508" class="calibre1"></a> error probability of an ensemble is always better than the error of an individual base classifier, as long as the base classifiers perform better than random guessing (<span class="strong"><img src="images/00239.jpeg" alt="Learning with ensembles" class="calibre14" /></span>). Note that the <span class="strong"><em class="calibre9">y</em></span>-axis depicts the base error (dotted line) as well as the ensemble error (continuous line):</p><div class="mediaobject"><img src="images/00248.jpeg" alt="Learning with ensembles" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-149" class="calibre">
<div id="calibre_link-1509" class="calibre10"></div><div class="book" title="Combining classifiers via majority vote"><div class="book" id="calibre_link-50"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1510"><a id="calibre_link-1511" class="calibre1"></a>Combining classifiers via majority vote</h1></div></div></div><p class="calibre8">After the short introduction to<a id="calibre_link-1512" class="calibre1"></a> ensemble learning in the previous section, let's<a id="calibre_link-1513" class="calibre1"></a> start with a warm-up exercise and implement a simple ensemble classifier for majority voting in Python.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1514" class="calibre1"></a>Note</h3><p class="calibre8">Although the majority voting algorithm that we will discuss in this section also generalizes to multi-class settings via plurality voting, we will use the term majority voting for simplicity, as it is also often done in the literature.</p></div></div></div>

<div id="calibre_link-556" class="calibre">
<div class="book" title="Combining classifiers via majority vote">
<div class="book" title="Implementing a simple majority vote classifier"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1515"><a id="calibre_link-313" class="calibre1"></a>Implementing a simple majority vote classifier</h2></div></div></div><p class="calibre8">The algorithm that we are <a id="calibre_link-1516" class="calibre1"></a>going to implement in this section will allow us to combine different classification algorithms associated with individual weights for confidence. Our goal is to build a stronger meta-classifier that balances out the individual classifiers' weaknesses on a particular dataset. In more precise mathematical terms, we can write the weighted majority vote as follows:</p><div class="mediaobject"><img src="images/00262.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00272.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> is a weight associated with a base classifier, <span class="strong"><img src="images/00078.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>, <span class="strong"><img src="images/00285.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> is the predicted class label of the ensemble, <span class="strong"><img src="images/00469.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> (Greek chi) is the characteristic function <span class="strong"><img src="images/00305.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>, and <span class="strong"><em class="calibre9">A</em></span> is the set of unique class labels. For equal weights, we can simplify this equation and write it as follows:</p><div class="mediaobject"><img src="images/00315.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1517" class="calibre1"></a>Note</h3><p class="calibre8">In statistics, the <span class="strong"><em class="calibre9">mode</em></span> is the most frequent event or result in a set. For example, <span class="strong"><em class="calibre9">mode{1,2,1 1,2,4,5,4} = 1</em></span>.</p></div><p class="calibre8">To better understand the concept of <span class="strong"><em class="calibre9">weighting</em></span>, we will now take a look at a more concrete example. Let us<a id="calibre_link-1518" class="calibre1"></a> assume that we have an ensemble of three base classifiers, <span class="strong"><img src="images/00078.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> (<span class="strong"><img src="images/00324.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>), and want to predict the class label of a given sample instance, <span class="strong"><strong class="calibre2">x</strong></span>. Two out of three base classifiers predict the class label 0, and one, <span class="strong"><img src="images/00694.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>, predicts that the sample belongs to class 1. If we weight the predictions of each base classifier equally, the majority vote would predict that the sample belongs to class 0:</p><div class="mediaobject"><img src="images/00750.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00808.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, let us assign a weight of 0.6 to <span class="strong"><img src="images/00694.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> and weight <span class="strong"><img src="images/00365.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> and <span class="strong"><img src="images/00943.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> by a coefficient of 0.2:</p><div class="mediaobject"><img src="images/00030.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00083.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">More<a id="calibre_link-1519" class="calibre1"></a> intuitively, since 3 x 0.2 = 0.6, we can say that the prediction made by <span class="strong"><img src="images/00694.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> has three times more weight than the predictions by <span class="strong"><img src="images/00365.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> or <span class="strong"><img src="images/00943.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>, which we can write as follows:</p><div class="mediaobject"><img src="images/00141.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To translate the concept of the weighted majority vote into Python code, we can use NumPy's convenient <code class="email">argmax</code> and <code class="email">bincount</code> functions:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.argmax(np.bincount([0, 0, 1], 
...           weights=[0.2, 0.2, 0.6]))
1</pre></div><p class="calibre8">As we remember from the discussion on logistic regression in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, certain classifiers in scikit-learn can also return the probability of a predicted class label via the <code class="email">predict_proba</code> method. Using the predicted class probabilities instead of the class labels for majority voting can be useful if the classifiers in our ensemble are well calibrated. The modified version of the majority vote for predicting class labels from probabilities can be written as follows:</p><div class="mediaobject"><img src="images/00198.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00254.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> is the predicted probability of the <span class="strong"><em class="calibre9">j</em></span>th classifier for class label <span class="strong"><em class="calibre9">i</em></span>.</p><p class="calibre8">To continue with our previous example, let's assume that we have a binary classification problem with class labels <span class="strong"><img src="images/00306.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> and an ensemble of three classifiers <span class="strong"><img src="images/00078.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>(<span class="strong"><img src="images/00356.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span>). Let's assume that the classifiers <span class="strong"><img src="images/00078.jpeg" alt="Implementing a simple majority vote classifier" class="calibre14" /></span> return the following class membership probabilities for a particular sample <span class="strong"><strong class="calibre2">x</strong></span>:</p><div class="mediaobject"><img src="images/00015.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can then calculate the<a id="calibre_link-1520" class="calibre1"></a> individual class probabilities as follows:</p><div class="mediaobject"><img src="images/00026.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00006.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00489.jpeg" alt="Implementing a simple majority vote classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To implement the weighted majority vote based on class probabilities, we can again make use of NumPy using <code class="email">numpy.average</code> and <code class="email">np.argmax</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ex = np.array([[0.9, 0.1],
...                [0.8, 0.2],
...                [0.4, 0.6]])
&gt;&gt;&gt; p = np.average(ex, axis=0, weights=[0.2, 0.2, 0.6])
&gt;&gt;&gt; p
array([ 0.58,  0.42])
&gt;&gt;&gt; np.argmax(p)
0</pre></div><p class="calibre8">Putting everything<a id="calibre_link-1521" class="calibre1"></a> together, let's now implement <code class="email">MajorityVoteClassifier</code> in Python:</p><div class="informalexample"><pre class="programlisting">from sklearn.base import BaseEstimator
from sklearn.base import ClassifierMixin
from sklearn.preprocessing import LabelEncoder
from sklearn.externals import six
from sklearn.base import clone
from sklearn.pipeline import _name_estimators
import numpy as np
import operator

class MajorityVoteClassifier(BaseEstimator,
                             ClassifierMixin):
    """ A majority vote ensemble classifier

    Parameters
    ----------
    classifiers : array-like, shape = [n_classifiers]
      Different classifiers for the ensemble

    vote : str, {'classlabel', 'probability'}
      Default: 'classlabel'
      If 'classlabel' the prediction is based on
      the argmax of class labels. Else if
      'probability', the argmax of the sum of
      probabilities is used to predict the class label
      (recommended for calibrated classifiers).

    weights : array-like, shape = [n_classifiers]
      Optional, default: None
      If a list of `int` or `float` values are
      provided, the classifiers are weighted by
      importance; Uses uniform weights if `weights=None`.

    """
    def __init__(self, classifiers,
                 vote='classlabel', weights=None):

        self.classifiers = classifiers
        self.named_classifiers = {key: value for
                                  key, value in
                                  _name_estimators(classifiers)}
        self.vote = vote
        self.weights = weights

    def fit(self, X, y):
        """ Fit classifiers.

        Parameters
        ----------
        X : {array-like, sparse matrix},
            shape = [n_samples, n_features]
            Matrix of training samples.

        y : array-like, shape = [n_samples]
            Vector of target class labels.

        Returns
        -------
        self : object

        """
        # Use LabelEncoder to ensure class labels start
        # with 0, which is important for np.argmax
        # call in self.predict
        self.lablenc_ = LabelEncoder()
        self.lablenc_.fit(y)
        self.classes_ = self.lablenc_.classes_
        self.classifiers_ = []
        for clf in self.classifiers:
            fitted_clf = clone(clf).fit(X,
                              self.lablenc_.transform(y))
            self.classifiers_.append(fitted_clf)
        return self</pre></div><p class="calibre8">I've added a lot of <a id="calibre_link-1522" class="calibre1"></a>comments to the code to explain the individual parts. However, before we implement the remaining methods, let's take a quick break and discuss some of the code that may look confusing at first. We used the <code class="email">BaseEstimator</code> and <code class="email">ClassifierMixin</code> parent classes to get some base functionality <span class="strong"><em class="calibre9">for free</em></span>, including the <code class="email">get_params</code> and <code class="email">set_params</code> methods to set and return the classifier's parameters, as well as the <code class="email">score</code> method to calculate the prediction accuracy. Also note that we imported <code class="email">six</code> to make <code class="email">MajorityVoteClassifier</code> compatible with Python 2.6.</p><p class="calibre8">Next, we will add the <code class="email">predict</code> method to predict the class label via a majority vote based on the class labels if we initialize a new <code class="email">MajorityVoteClassifier</code> object with <code class="email">vote='classlabel'</code>. Alternatively, we will be able to initialize the ensemble classifier with <code class="email">vote='probability'</code> to predict the class label based on the class membership probabilities. Furthermore, we will also add a <code class="email">predict_proba</code> method to return the averaged probabilities, which is <a id="calibre_link-1523" class="calibre1"></a>useful when <a id="calibre_link-1524" class="calibre1"></a>computing the ROC AUC:</p><div class="informalexample"><pre class="programlisting">    def predict(self, X):
        """ Predict class labels for X.

        Parameters
        ----------
        X : {array-like, sparse matrix},
            Shape = [n_samples, n_features]
            Matrix of training samples.

        Returns
        ----------
        maj_vote : array-like, shape = [n_samples]
            Predicted class labels.

        """
        if self.vote == 'probability':
            maj_vote = np.argmax(self.predict_proba(X),
                                 axis=1)
        else:  # 'classlabel' vote

            #  Collect results from clf.predict calls
            predictions = np.asarray([clf.predict(X)
                                      for clf in
                                      self.classifiers_]).T

            maj_vote = np.apply_along_axis(
                           lambda x:
                           np.argmax(np.bincount(x,                                             
                                     weights=self.weights)),
                           axis=1,
                           arr=predictions)
        maj_vote = self.lablenc_.inverse_transform(maj_vote)
        return maj_vote

    def predict_proba(self, X):
        """ Predict class probabilities for X.

        Parameters
        ----------
        X : {array-like, sparse matrix},
            shape = [n_samples, n_features]
            Training vectors, where n_samples is
            the number of samples and
            n_features is the number of features.

        Returns
        ----------
        avg_proba : array-like,
            shape = [n_samples, n_classes]
            Weighted average probability for
            each class per sample.

        """
        probas = np.asarray([clf.predict_proba(X)
                             for clf in self.classifiers_])
        avg_proba = np.average(probas, 
                               axis=0, weights=self.weights)
        return avg_proba

    def get_params(self, deep=True):
        """ Get classifier parameter names for GridSearch"""
        if not deep:
            return super(MajorityVoteClassifier,
                         self).get_params(deep=False)
        else:
            out = self.named_classifiers.copy()
            for name, step in\ 
                    six.iteritems(self.named_classifiers):
                for key, value in six.iteritems(
                        step.get_params(deep=True)):
                    out['%s__%s' % (name, key)] = value
            return out</pre></div><p class="calibre8">Also, note that we defined our own modified version of the <code class="email">get_params</code> method to use the <code class="email">_name_estimators</code> function to access the parameters of individual classifiers in the ensemble; this may look a little bit complicated at first, but it will make perfect sense when we use grid search for<a id="calibre_link-1525" class="calibre1"></a> hyperparameter tuning in later sections.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1526" class="calibre1"></a>Note</h3><p class="calibre8">Although the <code class="email">MajorityVoteClassifier</code> implementation is very useful for demonstration purposes, we implemented a more sophisticated version of this majority vote classifier in scikit-learn based on the implementation in the first edition of this book. The ensemble classifier is available as <code class="email">sklearn.ensemble.VotingClassifier</code> in scikit-learn version 0.17 and newer.</p></div></div></div></div>

<div id="calibre_link-585" class="calibre">
<div class="book" title="Combining classifiers via majority vote">
<div class="book" title="Using the majority voting principle to make predictions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1527"><a id="calibre_link-314" class="calibre1"></a>Using the majority voting principle to make predictions</h2></div></div></div><p class="calibre8">Now it is about <a id="calibre_link-1528" class="calibre1"></a>time to put the <code class="email">MajorityVoteClassifier</code> that we <a id="calibre_link-1529" class="calibre1"></a>implemented in the previous section into action. But first, let's prepare a dataset that we can test it on. Since we are already familiar with techniques to load datasets from CSV files, we will take a shortcut and load the Iris dataset from scikit-learn's dataset module. Furthermore, we will only select two features, <span class="strong"><strong class="calibre2">sepal width</strong></span> <a id="calibre_link-1530" class="calibre1"></a>and <span class="strong"><strong class="calibre2">petal length</strong></span>, to <a id="calibre_link-1531" class="calibre1"></a>make the classification task more challenging for illustration purposes. Although our <code class="email">MajorityVoteClassifier</code> generalizes to multiclass problems, we will only classify flower samples from the <code class="email">Iris-versicolor</code> and <code class="email">Iris-virginica</code> classes, with which we will compute the ROC AUC later. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn import datasets
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder
&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; X, y = iris.data[50:, [1, 2]], iris.target[50:]
&gt;&gt;&gt; le = LabelEncoder()
&gt;&gt;&gt; y = le.fit_transform(y)</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1532" class="calibre1"></a>Note</h3><p class="calibre8">Note that scikit-learn uses the <code class="email">predict_proba</code> method (if applicable) to compute the ROC AUC score. In <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, we saw how the class probabilities are computed in logistic regression models. In decision trees, the probabilities are calculated from a frequency vector that is created for each node at training time. The vector collects the frequency values of each class label computed from the class label distribution at that node. Then, the frequencies are normalized so that they sum up to 1. Similarly, the class labels of the k-nearest neighbors are aggregated to return the normalized class label frequencies in the k-nearest neighbors algorithm. Although the normalized probabilities returned by both the decision tree and k-nearest neighbors classifier may look similar to the probabilities obtained from a logistic regression model, we have to be aware that these are actually not derived from probability mass functions.</p></div><p class="calibre8">Next, we split the Iris samples into 50 percent training and 50 percent test data:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train, X_test, y_train, y_test =\
...        train_test_split(X, y, 
...                         test_size=0.5, 
...                         random_state=1,
...                         stratify=y)</pre></div><p class="calibre8">Using the training dataset, we now will train three different classifiers:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Logistic regression classifier</li><li class="listitem">Decision tree classifier</li><li class="listitem">k-nearest neighbors classifier</li></ul></div><p class="calibre8">We then evaluate the <a id="calibre_link-1533" class="calibre1"></a>model performance of<a id="calibre_link-1534" class="calibre1"></a> each classifier via 10-fold cross-validation on the training dataset before we combine them into an ensemble classifier:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import cross_val_score
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier 
&gt;&gt;&gt; from sklearn.pipeline import Pipeline
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; clf1 = LogisticRegression(penalty='l2', 
...                           C=0.001, 
...                           random_state=1)
&gt;&gt;&gt; clf2 = DecisionTreeClassifier(max_depth=1, 
...                               criterion='entropy', 
...                               random_state=0)
&gt;&gt;&gt; clf3 = KNeighborsClassifier(n_neighbors=1, 
...                             p=2, 
...                             metric='minkowski')
&gt;&gt;&gt; pipe1 = Pipeline([['sc', StandardScaler()],
...                   ['clf', clf1]])
&gt;&gt;&gt; pipe3 = Pipeline([['sc', StandardScaler()],
...                   ['clf', clf3]])
&gt;&gt;&gt; clf_labels = ['Logistic regression', 'Decision tree', 'KNN']
&gt;&gt;&gt; print('10-fold cross validation:\n')
&gt;&gt;&gt; for clf, label in zip([pipe1, clf2, pipe3], clf_labels):
...     scores = cross_val_score(estimator=clf, 
...                              X=X_train, 
...                              y=y_train, 
...                              cv=10, 
...                              scoring='roc_auc')
...     print("ROC AUC: %0.2f (+/- %0.2f) [%s]" 
...                % (scores.mean(), scores.std(), label))</pre></div><p class="calibre8">The output that we receive, as shown in the following snippet, shows that the predictive performances of the individual classifiers are almost equal:</p><div class="informalexample"><pre class="programlisting">10-fold cross validation:

ROC AUC: 0.87 (+/- 0.17) [Logistic regression]
ROC AUC: 0.89 (+/- 0.16) [Decision tree]
ROC AUC: 0.88 (+/- 0.15) [KNN]</pre></div><p class="calibre8">You may be wondering why we trained the logistic regression and k-nearest neighbors classifier as part of a pipeline. The reason behind it is that, as discussed in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, both the logistic regression and k-nearest neighbors<a id="calibre_link-1535" class="calibre1"></a> algorithms (using the Euclidean distance metric) are not scale-invariant, in contrast to decision trees. Although <a id="calibre_link-1536" class="calibre1"></a>the Iris features are all measured on the same scale (cm), it is a good habit to work with standardized features.</p><p class="calibre8">Now let's move on to the more exciting part and combine the individual classifiers for majority rule voting in our <code class="email">MajorityVoteClassifier</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; mv_clf = MajorityVoteClassifier(
...                 classifiers=[pipe1, clf2, pipe3])
&gt;&gt;&gt; clf_labels += ['Majority voting']
&gt;&gt;&gt; all_clf = [pipe1, clf2, pipe3, mv_clf]
&gt;&gt;&gt; for clf, label in zip(all_clf, clf_labels):
...     scores = cross_val_score(estimator=clf, 
...                              X=X_train, 
...                              y=y_train, 
...                              cv=10, 
...                              scoring='roc_auc')
...     print("Accuracy: %0.2f (+/- %0.2f) [%s]" 
...                % (scores.mean(), scores.std(), label))
ROC AUC: 0.87 (+/- 0.17) [Logistic regression]
ROC AUC: 0.89 (+/- 0.16) [Decision tree]
ROC AUC: 0.88 (+/- 0.15) [KNN]
ROC AUC: 0.94 (+/- 0.13) [Majority voting]</pre></div><p class="calibre8">As we can see, the performance of <code class="email">MajorityVotingClassifier</code> has improved over the individual classifiers in the 10-fold cross-validation evaluation.</p></div></div></div>

<div id="calibre_link-156" class="calibre">
<div class="book" title="Combining classifiers via majority vote">
<div class="book" title="Evaluating and tuning the ensemble classifier"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1537"><a id="calibre_link-315" class="calibre1"></a>Evaluating and tuning the ensemble classifier</h2></div></div></div><p class="calibre8">In this section, we are going to<a id="calibre_link-1538" class="calibre1"></a> compute the ROC curves from the test set to check that <code class="email">MajorityVoteClassifier</code> generalizes well with unseen data. We shall remember that <a id="calibre_link-1539" class="calibre1"></a>the test set is not to be used for model selection; its purpose is merely to report an unbiased estimate of the generalization performance of a classifier system:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import roc_curve
&gt;&gt;&gt; from sklearn.metrics import auc
&gt;&gt;&gt; colors = ['black', 'orange', 'blue', 'green']
&gt;&gt;&gt; linestyles = [':', '--', '-.', '-']
&gt;&gt;&gt; for clf, label, clr, ls \
...         in zip(all_clf, clf_labels, colors, linestyles):
...     # assuming the label of the positive class is 1
...     y_pred = clf.fit(X_train, 
...                      y_train).predict_proba(X_test)[:, 1]
...     fpr, tpr, thresholds = roc_curve(y_true=y_test, 
...                                      y_score=y_pred)
...     roc_auc = auc(x=fpr, y=tpr)
...     plt.plot(fpr, tpr, 
...              color=clr, 
...              linestyle=ls, 
...              label='%s (auc = %0.2f)' % (label, roc_auc))
&gt;&gt;&gt; plt.legend(loc='lower right')
&gt;&gt;&gt; plt.plot([0, 1], [0, 1], 
...          linestyle='--', 
...          color='gray', 
...          linewidth=2)
&gt;&gt;&gt; plt.xlim([-0.1, 1.1])
&gt;&gt;&gt; plt.ylim([-0.1, 1.1])
&gt;&gt;&gt; plt.grid(alpha=0.5)
&gt;&gt;&gt; plt.xlabel('False positive rate (FPR)')
&gt;&gt;&gt; plt.ylabel('True positive rate (TPR)')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the <a id="calibre_link-1540" class="calibre1"></a>resulting ROC, the ensemble classifier also performs well on the <a id="calibre_link-1541" class="calibre1"></a>test set (ROC AUC = 0.95). However, we can see that the logistic regression classifier performs similarly well on the same dataset, which is probably due to the high variance (in this case, sensitivity of how we split the dataset) given the small size of the dataset:</p><div class="mediaobject"><img src="images/00501.jpeg" alt="Evaluating and tuning the ensemble classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since we only selected two features for the classification examples, it would be interesting to see what <a id="calibre_link-1542" class="calibre1"></a>the decision region of the ensemble classifier actually<a id="calibre_link-1543" class="calibre1"></a> looks like. Although it is not necessary to standardize the training features prior to model fitting, because our logistic regression and k-nearest neighbors pipelines will automatically take care of it, we will standardize the training set so that the decision regions of the decision tree will be on the same scale for visual purposes. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; sc = StandardScaler()
&gt;&gt;&gt; X_train_std = sc.fit_transform(X_train)
&gt;&gt;&gt; from itertools import product
&gt;&gt;&gt; x_min = X_train_std[:, 0].min() - 1
&gt;&gt;&gt; x_max = X_train_std[:, 0].max() + 1
&gt;&gt;&gt; y_min = X_train_std[:, 1].min() - 1
&gt;&gt;&gt; y_max = X_train_std[:, 1].max() + 1
&gt;&gt;&gt; xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
...                      np.arange(y_min, y_max, 0.1))
&gt;&gt;&gt; f, axarr = plt.subplots(nrows=2, ncols=2, 
...                         sharex='col', 
...                         sharey='row', 
...                         figsize=(7, 5))
&gt;&gt;&gt; for idx, clf, tt in zip(product([0, 1], [0, 1]),
...                         all_clf, clf_labels):
...     clf.fit(X_train_std, y_train)
...     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
...     Z = Z.reshape(xx.shape)
...     axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.3)    
...     axarr[idx[0], idx[1]].scatter(X_train_std[y_train==0, 0], 
...                                   X_train_std[y_train==0, 1], 
...                                   c='blue', 
...                                   marker='^',
...                                   s=50)    
...     axarr[idx[0], idx[1]].scatter(X_train_std[y_train==1, 0], 
...                                   X_train_std[y_train==1, 1], 
...                                   c='green', 
...                                   marker='o',
...                                   s=50)   
...     axarr[idx[0], idx[1]].set_title(tt)
&gt;&gt;&gt; plt.text(-3.5, -4.5, 
...          s='Sepal width [standardized]', 
...          ha='center', va='center', fontsize=12)
&gt;&gt;&gt; plt.text(-10.5, 4.5, 
...          s='Petal length [standardized]', 
...          ha='center', va='center', 
...          fontsize=12, rotation=90)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Interestingly, but also as<a id="calibre_link-1544" class="calibre1"></a> expected, the decision regions of the ensemble <a id="calibre_link-1545" class="calibre1"></a>classifier seem to be a hybrid of the decision regions from the individual classifiers. At first glance, the majority vote decision boundary looks a lot like the decision of the decision tree stump, which is orthogonal to the <span class="strong"><em class="calibre9">y</em></span> axis for <span class="strong"><img src="images/00513.jpeg" alt="Evaluating and tuning the ensemble classifier" class="calibre14" /></span>. However, we also notice the non-linearity from the k-nearest neighbor classifier mixed in:</p><div class="mediaobject"><img src="images/00522.jpeg" alt="Evaluating and tuning the ensemble classifier" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Before we tune the individual <a id="calibre_link-1546" class="calibre1"></a>classifier's parameters for ensemble classification, let's<a id="calibre_link-1547" class="calibre1"></a> call the <code class="email">get_params </code>method to get a basic idea of how we can access the individual parameters inside a <code class="email">GridSearch</code> object:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; mv_clf.get_params()
{'decisiontreeclassifier': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,
             max_features=None,
             max_leaf_nodes=None,
             min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             random_state=0, splitter='best'),
 'decisiontreeclassifier__class_weight': None,
 'decisiontreeclassifier__criterion': 'entropy',
 [...]
 'decisiontreeclassifier__random_state': 0,
 'decisiontreeclassifier__splitter': 'best',
 'pipeline-1': Pipeline(steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,
 intercept_scaling=1, max_iter=100, multi_class='ovr',
 penalty='l2', random_state=0, solver='liblinear', tol=0.0001,
 verbose=0))]),
 'pipeline-1__clf': LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,
           intercept_scaling=1, max_iter=100, multi_class='ovr',
           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,
           verbose=0),
 'pipeline-1__clf__C': 0.001,
 'pipeline-1__clf__class_weight': None,
 'pipeline-1__clf__dual': False,
 [...]
 'pipeline-1__sc__with_std': True,
 'pipeline-2': Pipeline(steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
            metric_params=None, n_neighbors=1, p=2, weights='uniform'))]),
 'pipeline-2__clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
            metric_params=None, n_neighbors=1, p=2, weights='uniform'),
 'pipeline-2__clf__algorithm': 'auto',
 [...]
 'pipeline-2__sc__with_std': True}</pre></div><p class="calibre8">Based on the values<a id="calibre_link-1548" class="calibre1"></a> returned by the <code class="email">get_params</code> method, we now know<a id="calibre_link-1549" class="calibre1"></a> how to access the individual classifier's attributes. Let's now tune the inverse regularization parameter C of the logistic regression classifier and the decision tree depth via a grid search for demonstration purposes:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import GridSearchCV
&gt;&gt;&gt; params = {'decisiontreeclassifier__max_depth': [1, 2],
...           'pipeline-1__clf__C': [0.001, 0.1, 100.0]}
&gt;&gt;&gt; grid = GridSearchCV(estimator=mv_clf, 
...                     param_grid=params, 
...                     cv=10, 
...                     scoring='roc_auc')
&gt;&gt;&gt; grid.fit(X_train, y_train)</pre></div><p class="calibre8">After the grid search has completed, we can print the different hyperparameter value combinations and the average ROC AUC scores computed via 10-fold cross-validation as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; for params, mean_score, scores in grid.grid_scores_:
...     print("%0.3f+/-%0.2f %r"
...            % (mean_score, scores.std() / 2, params))
0.933 +/- 0.07 {'pipeline-1__clf__C': 0.001, 'decisiontreeclassifier__max_depth': 1}
0.947 +/- 0.07 {'pipeline-1__clf__C': 0.1, 'decisiontreeclassifier__max_depth': 1}
0.973 +/- 0.04 {'pipeline-1__clf__C': 100.0, 'decisiontreeclassifier__max_depth': 1}
0.947 +/- 0.07 {'pipeline-1__clf__C': 0.001, 'decisiontreeclassifier__max_depth': 2}
0.947 +/- 0.07 {'pipeline-1__clf__C': 0.1, 'decisiontreeclassifier__max_depth': 2}
0.973 +/- 0.04 {'pipeline-1__clf__C': 100.0, 'decisiontreeclassifier__max_depth': 2}

&gt;&gt;&gt; print('Best parameters: %s' % grid.best_params_)
Best parameters: {'pipeline-1__clf__C': 100.0, 'decisiontreeclassifier__max_depth': 1}

&gt;&gt;&gt; print('Accuracy: %.2f' % grid.best_score_)
Accuracy: 0.97</pre></div><p class="calibre8">As we can see, we <a id="calibre_link-1550" class="calibre1"></a>get the best cross-validation results when we choose a <a id="calibre_link-1551" class="calibre1"></a>lower regularization strength (<code class="email">C=100.0</code>), whereas the tree depth does not seem to affect the performance at all, suggesting that a decision stump is sufficient to separate the data. To remind ourselves that it is a bad practice to use the test dataset more than once for model evaluation, we are not going to estimate the generalization performance of the tuned hyperparameters in this section. We will move on swiftly to an<a id="calibre_link-1552" class="calibre1"></a> alternative approach for ensemble learning: <span class="strong"><strong class="calibre2">bagging</strong></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1553" class="calibre1"></a>Note</h3><p class="calibre8">The majority vote approach we implemented in this section is not to be confused with <span class="strong"><strong class="calibre2">stacking</strong></span>. The stacking<a id="calibre_link-1554" class="calibre1"></a> algorithm can be understood as a two-layer ensemble, where the first layer consists of individual classifiers that feed their predictions to the second level, where another classifier (typically logistic regression) is fit to the level-1 classifier predictions to make the final predictions. The stacking algorithm has been described in more detail by David H. Wolpert in <span class="strong"><em class="calibre9">Stacked generalization</em></span>, <span class="strong"><em class="calibre9">Neural Networks</em></span>, 5(2):241&ndash;259, <span class="strong"><em class="calibre9">1992</em></span>.</p><p class="calibre8">Unfortunately, an implementation of this algorithm has not been implemented in scikit-learn at the time of writing; however, this feature is under way. In the meantime, you can find scikit-learn-compatible implementations<a id="calibre_link-1555" class="calibre1"></a> of stacking at <a class="calibre1" href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/">http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/</a> and <a class="calibre1" href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/.">http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/.</a>
</p></div></div></div></div>

<div id="calibre_link-163" class="calibre">
<div id="calibre_link-1556" class="calibre10"></div><div class="book" title="Bagging â building an ensemble of classifiers from bootstrap samples"><div class="book" id="calibre_link-51"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1557"><a id="calibre_link-1558" class="calibre1"></a>Bagging &ndash; building an ensemble of classifiers from bootstrap samples</h1></div></div></div><p class="calibre8">Bagging is an ensemble <a id="calibre_link-1559" class="calibre1"></a>learning technique that is closely related to the <code class="email">MajorityVoteClassifier</code> that we implemented in the previous section. However, instead of using the same training set to fit the individual classifiers in the ensemble, we draw bootstrap samples (random samples with replacement) from the initial training set, which is why bagging is also known as bootstrap aggregating.</p><p class="calibre8">The concept of bagging is summarized in the following diagram:</p><div class="mediaobject"><img src="images/00698.jpeg" alt="Bagging â building an ensemble of classifiers from bootstrap samples" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the following subsections, we will work through a simple example of bagging by hand and use scikit-learn for classifying wine samples.</p></div></div>

<div id="calibre_link-630" class="calibre">
<div class="book" title="Bagging â building an ensemble of classifiers from bootstrap samples">
<div class="book" title="Bagging in a nutshell"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1560"><a id="calibre_link-316" class="calibre1"></a>Bagging in a nutshell</h2></div></div></div><p class="calibre8">To provide a more concrete example of how the bootstrapping aggregating of a bagging classifier works, let's consider the <a id="calibre_link-1561" class="calibre1"></a>example shown in the following figure. Here, we have seven different training instances (denoted as indices 1-7) that are sampled randomly with replacement in each round of bagging. Each bootstrap sample is then used to fit a classifier <span class="strong"><img src="images/00078.jpeg" alt="Bagging in a nutshell" class="calibre14" /></span>, which is most typically an unpruned decision tree:</p><div class="mediaobject"><img src="images/00539.jpeg" alt="Bagging in a nutshell" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see from the previous illustration, each classifier receives a random subset of samples from the training set. Each subset contains a certain portion of duplicates and some of the original samples don't appear in a resampled dataset at all due to sampling with replacement. Once the individual classifiers are fit to the bootstrap samples, the predictions are combined using majority voting.</p><p class="calibre8">Note that bagging is also related <a id="calibre_link-1562" class="calibre1"></a>to the random forest classifier that we introduced in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>. In fact, random forests are a special case of bagging where we also use random feature subsets when fitting the individual decision trees.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1563" class="calibre1"></a>Note</h3><p class="calibre8">Bagging was first proposed by Leo Breiman in a technical report in 1994; he also showed that bagging can improve the accuracy of unstable models and decrease the degree of overfitting. I highly recommend you read about his research in <span class="strong"><em class="calibre9">Bagging predictors</em></span>, <span class="strong"><em class="calibre9">L. Breiman</em></span>, <span class="strong"><em class="calibre9">Machine Learning</em></span>, 24(2):123&ndash;140, <span class="strong"><em class="calibre9">1996</em></span>, which is freely available online, to learn more details about bagging.</p></div></div></div></div>

<div id="calibre_link-648" class="calibre">
<div class="book" title="Bagging â building an ensemble of classifiers from bootstrap samples">
<div class="book" title="Applying bagging to classify samples in the Wine dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1564"><a id="calibre_link-317" class="calibre1"></a>Applying bagging to classify samples in the Wine dataset</h2></div></div></div><p class="calibre8">To see bagging in action, let's create a <a id="calibre_link-1565" class="calibre1"></a>more complex classification problem using the Wine dataset that we introduced in <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets -- Data Preprocessing</em></span>. Here, we will only consider the Wine classes 2 and 3, and we select two features: <code class="email">Alcohol</code> and <code class="email">OD280/OD315 of diluted wines</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'
                      'machine-learning-databases/wine/wine.data',
                      header=None)
&gt;&gt;&gt; df_wine.columns = ['Class label', 'Alcohol', 
...                    'Malic acid', 'Ash', 
...                    'Alcalinity of ash', 
...                    'Magnesium', 'Total phenols', 
...                    'Flavanoids', 'Nonflavanoid phenols',
...                    'Proanthocyanins', 
...                    'Color intensity', 'Hue', 
...                    'OD280/OD315 of diluted wines', 
...                    'Proline']
&gt;&gt;&gt; # drop 1 class
&gt;&gt;&gt; df_wine = df_wine[df_wine['Class label'] != 1]
&gt;&gt;&gt; y = df_wine['Class label'].values
&gt;&gt;&gt; X = df_wine[['Alcohol', 
...              'OD280/OD315 of diluted wines']].values</pre></div><p class="calibre8">Next, we encode the class labels into binary format and split the dataset into 80 percent training and 20 percent test sets, respectively:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; le = LabelEncoder()
&gt;&gt;&gt; y = le.fit_transform(y)
&gt;&gt;&gt; X_train, X_test, y_train, y_test =\
...            train_test_split(X, y, 
...                             test_size=0.2, 
...                             random_state=1,
...                             stratify=y)</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1566" class="calibre1"></a>Note</h3><p class="calibre8">You can find a copy of the Wine dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the UCI server at <a class="calibre1" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data">https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data</a> is temporarily unavailable. For instance, to load the Wine dataset from a local directory, take these lines:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('https://archive.ics.uci.edu/ml/'
                 'machine-learning-databases'
                 '/wine/wine.data',
                 header=None)</pre></div></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1567" class="calibre1"></a>Note</h3><p class="calibre8">Replace them with this:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('your/local/path/to/wine.data',
                 header=None)</pre></div></div><p class="calibre8">A <code class="email">BaggingClassifier</code> algorithm<a id="calibre_link-1568" class="calibre1"></a> is already implemented in scikit-learn, which we can import from the <code class="email">ensemble</code> submodule. Here, we will use an unpruned decision tree as the base classifier and create an ensemble of 500 decision trees fit on different bootstrap samples of the training dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.ensemble import BaggingClassifier
&gt;&gt;&gt; tree = DecisionTreeClassifier(criterion='entropy',
...                               random_state=1,
...                               max_depth=None)
&gt;&gt;&gt; bag = BaggingClassifier(base_estimator=tree,
...                         n_estimators=500, 
...                         max_samples=1.0, 
...                         max_features=1.0, 
...                         bootstrap=True, 
...                         bootstrap_features=False, 
...                         n_jobs=1, 
...                         random_state=1)</pre></div><p class="calibre8">Next, we will calculate the accuracy score of the prediction on the training and test dataset to compare the performance of the bagging classifier to the performance of a single unpruned decision tree:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import accuracy_score
&gt;&gt;&gt; tree = tree.fit(X_train, y_train)
&gt;&gt;&gt; y_train_pred = tree.predict(X_train)
&gt;&gt;&gt; y_test_pred = tree.predict(X_test)
&gt;&gt;&gt; tree_train = accuracy_score(y_train, y_train_pred)
&gt;&gt;&gt; tree_test = accuracy_score(y_test, y_test_pred)
&gt;&gt;&gt; print('Decision tree train/test accuracies %.3f/%.3f'
...        % (tree_train, tree_test))
Decision tree train/test accuracies 1.000/0.833</pre></div><p class="calibre8">Based on the <a id="calibre_link-1569" class="calibre1"></a>accuracy values that we printed here, the unpruned decision tree predicts all the class labels of the training samples correctly; however, the substantially lower test accuracy indicates high variance (overfitting) of the model:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; bag = bag.fit(X_train, y_train)
&gt;&gt;&gt; y_train_pred = bag.predict(X_train)
&gt;&gt;&gt; y_test_pred = bag.predict(X_test)
&gt;&gt;&gt; bag_train = accuracy_score(y_train, y_train_pred) 
&gt;&gt;&gt; bag_test = accuracy_score(y_test, y_test_pred) 
&gt;&gt;&gt; print('Bagging train/test accuracies %.3f/%.3f'
...        % (bag_train, bag_test))
Bagging train/test accuracies 1.000/0.917</pre></div><p class="calibre8">Although the training accuracies of the decision tree and bagging classifier are similar on the training set (both 100 percent), we can see that the bagging classifier has a slightly better generalization performance, as estimated on the test set. Next, let's compare the decision regions between the decision tree and the bagging classifier:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; x_min = X_train[:, 0].min() - 1
&gt;&gt;&gt; x_max = X_train[:, 0].max() + 1
&gt;&gt;&gt; y_min = X_train[:, 1].min() - 1
&gt;&gt;&gt; y_max = X_train[:, 1].max() + 1
&gt;&gt;&gt; xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
...                      np.arange(y_min, y_max, 0.1))
&gt;&gt;&gt; f, axarr = plt.subplots(nrows=1, ncols=2, 
...                         sharex='col', 
...                         sharey='row', 
...                         figsize=(8, 3))
&gt;&gt;&gt; for idx, clf, tt in zip([0, 1],
...                         [tree, bag],
...                         ['Decision tree', 'Bagging']):
...     clf.fit(X_train, y_train)
...     
...     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
...     Z = Z.reshape(xx.shape)
...     axarr[idx].contourf(xx, yy, Z, alpha=0.3)
...     axarr[idx].scatter(X_train[y_train==0, 0], 
...                        X_train[y_train==0, 1], 
...                        c='blue', marker='^')    
...     axarr[idx].scatter(X_train[y_train==1, 0], 
...                        X_train[y_train==1, 1], 
...                        c='green', marker='o')    
...     axarr[idx].set_title(tt)
&gt;&gt;&gt; axarr[0].set_ylabel('Alcohol', fontsize=12)
&gt;&gt;&gt; plt.text(10.2, -1.2, 
...          s='OD280/OD315 of diluted wines', 
...          ha='center', va='center', fontsize=12)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting plot, the piece-wise linear decision boundary of the three-node deep decision tree looks smoother in the bagging ensemble:</p><div class="mediaobject"><img src="images/00552.jpeg" alt="Applying bagging to classify samples in the Wine dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We only looked at a <a id="calibre_link-1570" class="calibre1"></a>very simple bagging example in this section. In practice, more complex classification tasks and a dataset's high dimensionality can easily lead to overfitting in single decision trees, and this is where the bagging algorithm can really play to its strengths. Finally, we shall note that the bagging algorithm can be an effective approach to reduce the variance of a model. However, bagging is ineffective in reducing model bias, that is, models that are too simple to capture the trend in the data well. This is why we want to perform bagging on an ensemble of classifiers with low bias, for example, unpruned decision trees.</p></div></div></div>

<div id="calibre_link-170" class="calibre">
<div id="calibre_link-1571" class="calibre10"></div><div class="book" title="Leveraging weak learners via adaptive boosting"><div class="book" id="calibre_link-5"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1572"><a id="calibre_link-1573" class="calibre1"></a>Leveraging weak learners via adaptive boosting</h1></div></div></div><p class="calibre8">In this last section about ensemble<a id="calibre_link-1574" class="calibre1"></a> methods, we will discuss <span class="strong"><strong class="calibre2">boosting</strong></span> with a special focus on its most common <a id="calibre_link-1575" class="calibre1"></a>implementation, <span class="strong"><strong class="calibre2">AdaBoost</strong></span> (<span class="strong"><strong class="calibre2">Adaptive Boosting</strong></span>).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1576" class="calibre1"></a>Note</h3><p class="calibre8">The original idea behind AdaBoost was formulated by Robert E. Schapire in 1990. <span class="strong"><em class="calibre9">The Strength of Weak Learnability</em></span>, <span class="strong"><em class="calibre9">R. E. Schapire</em></span>, <span class="strong"><em class="calibre9">Machine Learning</em></span>, 5(2): 197-227, <span class="strong"><em class="calibre9">1990</em></span>. After Robert Schapire and Yoav Freund presented the AdaBoost algorithm in the <span class="strong"><em class="calibre9">Proceedings of the</em></span> <span class="strong"><em class="calibre9">Thirteenth International Conference</em></span> (ICML 1996), AdaBoost became one of the most widely used ensemble methods in the years that followed (<span class="strong"><em class="calibre9">Experiments with a New Boosting Algorithm</em></span> by <span class="strong"><em class="calibre9">Y. Freund</em></span>, <span class="strong"><em class="calibre9">R. E. Schapire</em></span>, and others, <span class="strong"><em class="calibre9">ICML</em></span>, volume 96, 148-156, <span class="strong"><em class="calibre9">1996</em></span>). In 2003, Freund and Schapire received the Goedel Prize for their groundbreaking work, which is a prestigious prize for the most outstanding publications in the field of computer science.</p></div><p class="calibre8">In boosting, the ensemble consists of very simple base classifiers, also often referred to as <span class="strong"><strong class="calibre2">weak learners</strong></span>, which often only have a slight performance advantage over random guessing&mdash;a typical example of a weak learner is a decision tree stump. The key concept behind boosting is to focus on training samples that are hard to classify, that is, to let the weak learners subsequently learn from misclassified training samples to improve the performance of the ensemble.</p><p class="calibre8">The following subsections will introduce the algorithmic procedure behind the general concept boosting and a popular variant called <span class="strong"><strong class="calibre2">AdaBoost</strong></span>. Lastly, we will use scikit-learn for a practical classification example.</p></div></div>

<div id="calibre_link-173" class="calibre">
<div class="book" title="Leveraging weak learners via adaptive boosting">
<div class="book" title="How boosting works"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1577"><a id="calibre_link-318" class="calibre1"></a>How boosting works</h2></div></div></div><p class="calibre8">In contrast to<a id="calibre_link-1578" class="calibre1"></a> bagging, the initial formulation of boosting, the algorithm uses random subsets of training samples drawn from the training dataset without replacement; the original boosting procedure is summarized in the following four key steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">
Draw a random subset of training samples <span class="strong"><img src="images/00567.jpeg" alt="How boosting works" class="calibre14" /></span> without replacement from training set <span class="strong"><img src="images/00946.jpeg" alt="How boosting works" class="calibre14" /></span> to train a weak learner <span class="strong"><img src="images/00365.jpeg" alt="How boosting works" class="calibre14" /></span>.
</li><li class="listitem" value="2">
Draw a second random training subset <span class="strong"><img src="images/00584.jpeg" alt="How boosting works" class="calibre14" /></span> without replacement from the training set and add 50 percent of the samples that were previously misclassified to train a weak learner <span class="strong"><img src="images/00943.jpeg" alt="How boosting works" class="calibre14" /></span>.
</li><li class="listitem" value="3">
Find the training samples <span class="strong"><img src="images/00594.jpeg" alt="How boosting works" class="calibre14" /></span> in training set <span class="strong"><img src="images/00946.jpeg" alt="How boosting works" class="calibre14" /></span>, which <span class="strong"><img src="images/00365.jpeg" alt="How boosting works" class="calibre14" /></span> and <span class="strong"><img src="images/00943.jpeg" alt="How boosting works" class="calibre14" /></span> disagree upon, to train a third weak learner <span class="strong"><img src="images/00694.jpeg" alt="How boosting works" class="calibre14" /></span>.
</li><li class="listitem" value="4">
Combine the weak learners <span class="strong"><img src="images/00365.jpeg" alt="How boosting works" class="calibre14" /></span>, <span class="strong"><img src="images/00943.jpeg" alt="How boosting works" class="calibre14" /></span>, and <span class="strong"><img src="images/00694.jpeg" alt="How boosting works" class="calibre14" /></span> via majority voting.
</li></ol><div class="calibre13"></div></div><p class="calibre8">As discussed by Leo <a id="calibre_link-1579" class="calibre1"></a>Breiman (<span class="strong"><em class="calibre9">Bias, variance, and arcing classifiers</em></span>, <span class="strong"><em class="calibre9">L. Breiman</em></span>, <span class="strong"><em class="calibre9">1996</em></span>), boosting can lead to a decrease in bias as well as variance compared to bagging models. In practice, however, boosting algorithms such as AdaBoost are also known for their high variance, that is, the tendency to overfit the training data (<span class="strong"><em class="calibre9">An improvement of AdaBoost to avoid overfitting</em></span>, <span class="strong"><em class="calibre9">G. Raetsch</em></span>, <span class="strong"><em class="calibre9">T. Onoda</em></span>, and <span class="strong"><em class="calibre9">K. R. Mueller</em></span>. Proceedings of the International Conference on Neural Information Processing, CiteSeer, 1998).</p><p class="calibre8">In contrast to the original boosting procedure as described here, AdaBoost uses the complete training set to train the weak learners where the training samples are reweighted in each iteration to build a strong classifier that learns from the mistakes of the previous weak learners in the ensemble. Before we dive deeper into the specific details of the AdaBoost algorithm, let's take a look at the following figure to get a better grasp of the basic concept behind AdaBoost:</p><div class="mediaobject"><img src="images/00607.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To walk through the<a id="calibre_link-1580" class="calibre1"></a> AdaBoost illustration step by step, we start with subfigure <span class="strong"><strong class="calibre2">1</strong></span>, which represents a training set for binary classification where all training samples are assigned equal weights. Based on this training set, we train a decision stump (shown as a dashed line) that tries to classify the samples of the two classes (triangles and circles), as well as possibly by minimizing the cost function (or the impurity score in the special case of decision tree ensembles).</p><p class="calibre8">For the next round (subfigure <span class="strong"><strong class="calibre2">2</strong></span>), we assign a larger weight to the two previously misclassified samples (circles). Furthermore, we lower the weight of the correctly classified samples. The next decision stump will now be more focused on the training samples that have the largest weights&mdash;the training samples that are supposedly hard to classify. The weak learner shown in subfigure <span class="strong"><strong class="calibre2">2</strong></span> misclassifies three different samples from the circle class, which are then assigned a larger weight, as shown in subfigure <span class="strong"><strong class="calibre2">3</strong></span>.</p><p class="calibre8">Assuming that our AdaBoost ensemble only consists of three rounds of boosting, we would then combine the three weak learners trained on different reweighted training subsets by a weighted majority vote, as shown in subfigure <span class="strong"><strong class="calibre2">4</strong></span>.</p><p class="calibre8">Now that have a better understanding behind the basic concept of AdaBoost, let's take a more detailed look at the algorithm using pseudo code. For clarity, we will denote element-wise multiplication by the cross symbol <span class="strong"><img src="images/00207.jpeg" alt="How boosting works" class="calibre14" /></span> and the dot-product between two vectors by a dot symbol <span class="strong"><img src="images/00627.jpeg" alt="How boosting works" class="calibre14" /></span>:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">
Set the weight vector <span class="strong"><strong class="calibre2">w</strong></span> to uniform weights, where <span class="strong"><img src="images/00642.jpeg" alt="How boosting works" class="calibre14" /></span>.
</li><li class="listitem" value="2">For <span class="strong"><em class="calibre9">j</em></span> in <span class="strong"><em class="calibre9">m</em></span> boosting rounds, do the following:
a. Train a weighted weak learner: <span class="strong"><img src="images/00653.jpeg" alt="How boosting works" class="calibre14" /></span>.
b. Predict class labels: <span class="strong"><img src="images/00670.jpeg" alt="How boosting works" class="calibre14" /></span>.
c. Compute weighted error rate: <span class="strong"><img src="images/00685.jpeg" alt="How boosting works" class="calibre14" /></span>.
d. Compute coefficient: <span class="strong"><img src="images/00702.jpeg" alt="How boosting works" class="calibre14" /></span>.
e. Update <a id="calibre_link-1581" class="calibre1"></a>weights: <span class="strong"><img src="images/00713.jpeg" alt="How boosting works" class="calibre14" /></span>.
f. Normalize weights to sum to 1: <span class="strong"><img src="images/00724.jpeg" alt="How boosting works" class="calibre14" /></span>.
</li><li class="listitem" value="3">
Compute the final prediction: <span class="strong"><img src="images/00728.jpeg" alt="How boosting works" class="calibre14" /></span>.
</li></ol><div class="calibre13"></div></div><p class="calibre8">Note that the expression <span class="strong"><img src="images/00743.jpeg" alt="How boosting works" class="calibre14" /></span> in step 2c refers to a binary vector consisting of 1s and 0s, where a 1 is assigned if the prediction is incorrect and 0 is assigned otherwise.</p><p class="calibre8">Although the <a id="calibre_link-1582" class="calibre1"></a>AdaBoost algorithm seems to be pretty straightforward, let's walk through a more concrete example using a training set consisting of 10 training samples, as illustrated in the following table:</p><div class="mediaobject"><img src="images/00756.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The first column of the table depicts the sample indices of training samples 1 to 10. In the second column, we see the feature values of the individual samples, assuming this is a one-dimensional dataset. The third column shows the true class label, <span class="strong"><img src="images/00770.jpeg" alt="How boosting works" class="calibre14" /></span>, for each training sample <span class="strong"><img src="images/00782.jpeg" alt="How boosting works" class="calibre14" /></span>, where <span class="strong"><img src="images/00785.jpeg" alt="How boosting works" class="calibre14" /></span>. The initial weights are shown in the fourth column; we initialize the weights uniformly (assigning the same constant value) and normalize them to sum to one. In the case of the 10-sample training set, we therefore assign 0.1 to each weight <span class="strong"><img src="images/00796.jpeg" alt="How boosting works" class="calibre14" /></span> in the weight vector <span class="strong"><strong class="calibre2">w</strong></span>. The predicted class labels <span class="strong"><img src="images/00819.jpeg" alt="How boosting works" class="calibre14" /></span> are shown in the fifth column, assuming that our splitting criterion is <span class="strong"><img src="images/00831.jpeg" alt="How boosting works" class="calibre14" /></span>. The last column of the table then shows the updated weights based on the update rules that we defined in the pseudo code.</p><p class="calibre8">Since the computation of the weight updates may look a little bit complicated at first, we will now follow the calculation step by step. We start by computing the weighted error rate <span class="strong"><img src="images/00692.jpeg" alt="How boosting works" class="calibre14" /></span> as described in step 2c:</p><div class="mediaobject"><img src="images/00833.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Next, we compute the <a id="calibre_link-1583" class="calibre1"></a>coefficient <span class="strong"><img src="images/00846.jpeg" alt="How boosting works" class="calibre14" /></span>&mdash;shown in step 2d&mdash;which is later used in step 2e to update the weights, as well as for the weights in the majority vote prediction (step 4):</p><div class="mediaobject"><img src="images/00863.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">After we have computed the coefficient <span class="strong"><img src="images/00846.jpeg" alt="How boosting works" class="calibre14" /></span>, we can now update the weight vector using the following equation:</p><div class="mediaobject"><img src="images/00713.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00883.jpeg" alt="How boosting works" class="calibre14" /></span> is an element-wise multiplication between the vectors of the predicted and true class labels, respectively. Thus, if a prediction <span class="strong"><img src="images/00892.jpeg" alt="How boosting works" class="calibre14" /></span> is correct, <span class="strong"><img src="images/00901.jpeg" alt="How boosting works" class="calibre14" /></span> will have a positive sign so that we decrease the <span class="strong"><em class="calibre9">i</em></span>th weight, since <span class="strong"><img src="images/00846.jpeg" alt="How boosting works" class="calibre14" /></span> is a positive number as well:</p><div class="mediaobject"><img src="images/00915.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similarly, we will increase the <span class="strong"><em class="calibre9">i</em></span>th weight if <span class="strong"><img src="images/00892.jpeg" alt="How boosting works" class="calibre14" /></span> predicted the label incorrectly, like this:</p><div class="mediaobject"><img src="images/00936.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Alternatively, it's like this:</p><div class="mediaobject"><img src="images/00948.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">After we have updated<a id="calibre_link-1584" class="calibre1"></a> each weight in the weight vector, we normalize the weights so that they sum up to one (step 2f):</p><div class="mediaobject"><img src="images/00474.jpeg" alt="How boosting works" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00484.jpeg" alt="How boosting works" class="calibre14" /></span>.</p><p class="calibre8">Thus, each weight that corresponds to a correctly classified sample will be reduced from the initial value of 0.1 to <span class="strong"><img src="images/00463.jpeg" alt="How boosting works" class="calibre14" /></span> for the next round of boosting. Similarly, the weights of the incorrectly classified samples will increase from 0.1 to <span class="strong"><img src="images/00039.jpeg" alt="How boosting works" class="calibre14" /></span>.</p></div></div></div>

<div id="calibre_link-90" class="calibre">
<div class="book" title="Leveraging weak learners via adaptive boosting">
<div class="book" title="Applying AdaBoost using scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1585"><a id="calibre_link-319" class="calibre1"></a>Applying AdaBoost using scikit-learn</h2></div></div></div><p class="calibre8">The previous subsection<a id="calibre_link-1586" class="calibre1"></a> introduced AdaBoost in a nutshell. Skipping<a id="calibre_link-1587" class="calibre1"></a> to the more practical part, let's now train an AdaBoost ensemble classifier via scikit-learn. We will use the same Wine subset that we used in the previous section to train the bagging meta-classifier. Via the <code class="email">base_estimator</code> attribute, we will train the <code class="email">AdaBoostClassifier</code> on 500 decision tree stumps:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.ensemble import AdaBoostClassifier
&gt;&gt;&gt; tree = DecisionTreeClassifier(criterion='entropy',
                                  random_state=1,
...                               max_depth=1)
&gt;&gt;&gt; ada = AdaBoostClassifier(base_estimator=tree,
...                          n_estimators=500, 
...                          learning_rate=0.1,
...                          random_state=1)
&gt;&gt;&gt; tree = tree.fit(X_train, y_train)
&gt;&gt;&gt; y_train_pred = tree.predict(X_train)
&gt;&gt;&gt; y_test_pred = tree.predict(X_test)
&gt;&gt;&gt; tree_train = accuracy_score(y_train, y_train_pred)
&gt;&gt;&gt; tree_test = accuracy_score(y_test, y_test_pred)
&gt;&gt;&gt; print('Decision tree train/test accuracies %.3f/%.3f'
...       % (tree_train, tree_test))
Decision tree train/test accuracies 0.916/0.875</pre></div><p class="calibre8">As we can see, the decision tree stump seems to underfit the training data in contrast to the unpruned decision tree that we saw in the previous section:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ada = ada.fit(X_train, y_train)
&gt;&gt;&gt; y_train_pred = ada.predict(X_train)
&gt;&gt;&gt; y_test_pred = ada.predict(X_test)
&gt;&gt;&gt; ada_train = accuracy_score(y_train, y_train_pred) 
&gt;&gt;&gt; ada_test = accuracy_score(y_test, y_test_pred) 
&gt;&gt;&gt; print('AdaBoost train/test accuracies %.3f/%.3f'
...       % (ada_train, ada_test))
AdaBoost train/test accuracies 1.000/0.917</pre></div><p class="calibre8">As we can see, the <a id="calibre_link-1588" class="calibre1"></a>AdaBoost model predicts all class labels <a id="calibre_link-1589" class="calibre1"></a>of the training set correctly and also shows a slightly improved test set performance compared to the decision tree stump. However, we also see that we introduced additional variance by our attempt to reduce the model bias&mdash;a higher gap between training and test performance.</p><p class="calibre8">Although we used another simple example for demonstration purposes, we can see that the performance of the AdaBoost classifier is slightly improved compared to the decision stump and achieved the very similar accuracy scores as the bagging classifier that we trained in the previous section. However, we shall note that it is considered bad practice to select a model based on the repeated usage of the test set. The estimate of the generalization performance may be over-optimistic, which we discussed in more detail in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>.</p><p class="calibre8">Lastly, let us check what the decision regions look like:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; x_min = X_train[:, 0].min() - 1
&gt;&gt;&gt; x_max = X_train[:, 0].max() + 1
&gt;&gt;&gt; y_min = X_train[:, 1].min() - 1
&gt;&gt;&gt; y_max = X_train[:, 1].max() + 1
&gt;&gt;&gt; xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
...                      np.arange(y_min, y_max, 0.1))
&gt;&gt;&gt; f, axarr = plt.subplots(1, 2, 
...                         sharex='col', 
...                         sharey='row', 
...                         figsize=(8, 3))
&gt;&gt;&gt; for idx, clf, tt in zip([0, 1],
...                         [tree, ada],
...                         ['Decision Tree', 'AdaBoost']):
...     clf.fit(X_train, y_train)   
...     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
...     Z = Z.reshape(xx.shape)
...     axarr[idx].contourf(xx, yy, Z, alpha=0.3)
...     axarr[idx].scatter(X_train[y_train==0, 0], 
...                        X_train[y_train==0, 1], 
...                        c='blue', 
...                        marker='^')
...     axarr[idx].scatter(X_train[y_train==1, 0], 
...                        X_train[y_train==1, 1], 
...                        c='red',
...                        marker='o')
...     axarr[idx].set_title(tt)
...     axarr[0].set_ylabel('Alcohol', fontsize=12)
&gt;&gt;&gt; plt.text(10.2, -0.5, 
...          s='OD280/OD315 of diluted wines', 
...          ha='center', 
...          va='center', 
...          fontsize=12)    
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">By looking at the <a id="calibre_link-1590" class="calibre1"></a>decision regions, we can see that the decision<a id="calibre_link-1591" class="calibre1"></a> boundary of the AdaBoost model is substantially more complex than the decision boundary of the decision stump. In addition, we note that the AdaBoost model separates the feature space very similarly to the bagging classifier that we trained in the previous section:</p><div class="mediaobject"><img src="images/00842.jpeg" alt="Applying AdaBoost using scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As concluding remarks <a id="calibre_link-1592" class="calibre1"></a>about ensemble techniques, it is worth noting<a id="calibre_link-1593" class="calibre1"></a> that ensemble learning increases the computational complexity compared to individual classifiers. In practice, we need to think carefully about whether we want to pay the price of increased computational costs for an often relatively modest improvement in predictive performance.</p><p class="calibre8">An often-cited example of this trade-off is the famous $1 million <span class="strong"><em class="calibre9">Netflix Prize</em></span>, which was won using ensemble techniques. The details about the algorithm were published in <span class="strong"><em class="calibre9">The BigChaos Solution to the Netflix Grand Prize</em></span> by <span class="strong"><em class="calibre9">A. Toescher</em></span>, <span class="strong"><em class="calibre9">M. Jahrer</em></span>, and <span class="strong"><em class="calibre9">R. M. Bell</em></span>, Netflix prize documentation, <span class="strong"><em class="calibre9">2009</em></span>, which is available at <a class="calibre1" href="http://www.stat.osu.edu/~dmsl/GrandPrize2009_BPC_BigChaos.pdf">http://www.stat.osu.edu/~dmsl/GrandPrize2009_BPC_BigChaos.pdf</a>. The winning team received the $1 million grand prize money; however, Netflix never implemented their model due to its complexity, which made it infeasible for a real-world application:</p><p class="calibre8">
<span class="strong"><em class="calibre9">"We evaluated some of the new methods offline but the additional accuracy gains that we measured did not seem to justify the engineering effort needed to bring them into a production environment."</em></span> (<a class="calibre1" href="http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html">http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html</a>).</p></div></div></div>

<div id="calibre_link-122" class="calibre"><div class="book" title="Summary" id="calibre_link-320"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1594"><a id="calibre_link-1595" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, we looked at some of the most popular and widely used techniques for ensemble learning. Ensemble methods combine different classification models to cancel out their individual weaknesses, which often results in stable and well-performing models that are very attractive for industrial applications as well as machine learning competitions.</p><p class="calibre8">At the beginning of this chapter, we implemented <code class="email">MajorityVoteClassifier</code> in Python, which allows us to combine different algorithms for classification. We then looked at bagging, a useful technique to reduce the variance of a model by drawing random bootstrap samples from the training set and combining the individually trained classifiers via majority vote. Lastly, we learned about AdaBoost, which is an algorithm that is based on weak learners that subsequently learn from mistakes.</p><p class="calibre8">Throughout the previous chapters, we learned a lot about different learning algorithms, tuning, and evaluation techniques. In the next chapter, we will look at a particular application of machine learning, sentiment analysis, which has become an interesting topic in the internet and social media era.</p></div></div>

<div id="calibre_link-188" class="calibre">
<div id="calibre_link-1596" class="calibre10"></div><div class="book" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" id="calibre_link-39"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1597"><a id="calibre_link-1598" class="calibre1"></a>Chapter&nbsp;8.&nbsp;Applying Machine Learning to Sentiment Analysis</h1></div></div></div><p class="calibre8">In this internet and social media age, people's opinions, reviews, and recommendations have become a valuable resource for political science and businesses. Thanks to modern technologies, we are now able to collect and analyze such data most efficiently. In this chapter, we will delve into a subfield of <span class="strong"><strong class="calibre2">Natural Language Processing</strong></span> (<span class="strong"><strong class="calibre2">NLP</strong></span>) called <span class="strong"><strong class="calibre2">sentiment analysis</strong></span> and learn how to use machine learning algorithms to classify documents based on their polarity: the attitude of the writer. In particular, we are going to work with a dataset of 50,000 movie reviews from the <span class="strong"><strong class="calibre2">Internet Movie Database</strong></span> (<span class="strong"><strong class="calibre2">IMDb</strong></span>) and build a predictor that can distinguish between positive and negative reviews.</p><p class="calibre8">The topics that we will cover in the following sections include the following:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Cleaning and preparing text data</li><li class="listitem">Building feature vectors from text documents</li><li class="listitem">Training a machine learning model to classify positive and negative movie reviews</li><li class="listitem">Working with large text datasets using out-of-core learning</li><li class="listitem">Inferring topics from document collections for categorization</li></ul></div></div></div>

<div id="calibre_link-193" class="calibre">
<div class="book" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" id="calibre_link-1599">
<div class="book" title="Preparing the IMDb movie review data for text processing"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1600"><a id="calibre_link-321" class="calibre1"></a>Preparing the IMDb movie review data for text processing</h1></div></div></div><p class="calibre8">Sentiment analysis, sometimes<a id="calibre_link-1601" class="calibre1"></a> also called <span class="strong"><strong class="calibre2">opinion mining</strong></span>, is a <a id="calibre_link-1602" class="calibre1"></a>popular <a id="calibre_link-1603" class="calibre1"></a>subdiscipline <a id="calibre_link-1604" class="calibre1"></a>of the broader field of NLP; it is concerned with analyzing the polarity of documents. A popular task in sentiment analysis is the classification of documents based on the expressed opinions or emotions of the authors with regard to a particular topic.</p><p class="calibre8">In this chapter, we <a id="calibre_link-1605" class="calibre1"></a>will be working with a large <a id="calibre_link-1606" class="calibre1"></a>dataset of movie reviews from the IMDb that has been collected by Maas and others (<span class="strong"><em class="calibre9">Learning Word Vectors for Sentiment Analysis</em></span>, <span class="strong"><em class="calibre9">A. L. Maas</em></span>, <span class="strong"><em class="calibre9">R. E. Daly</em></span>, <span class="strong"><em class="calibre9">P. T. Pham</em></span>, <span class="strong"><em class="calibre9">D. Huang</em></span>, <span class="strong"><em class="calibre9">A. Y. Ng</em></span>, and <span class="strong"><em class="calibre9">C. Potts</em></span>, <span class="strong"><em class="calibre9">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</em></span>, pages 142&ndash;150, Portland, Oregon, USA, Association for Computational Linguistics, <span class="strong"><em class="calibre9">June 2011</em></span>). The movie review dataset consists of 50,000 polar movie reviews that are labeled as either positive or negative; here, positive means that a movie was rated with more than six stars on IMDb, and negative means that a movie was rated with fewer than five stars on IMDb. In the following sections, we will download the dataset, preprocess it into a useable format for machine learning tools, and extract meaningful information from a subset of these movie reviews to build a machine learning model that can predict whether a certain reviewer liked or disliked a movie.</p></div></div></div>

<div id="calibre_link-198" class="calibre">
<div class="book" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" id="calibre_link-1607">
<div class="book" title="Preparing the IMDb movie review data for text processing">
<div class="book" title="Obtaining the movie review dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1608"><a id="calibre_link-322" class="calibre1"></a>Obtaining the movie review dataset</h2></div></div></div><p class="calibre8">A compressed<a id="calibre_link-1609" class="calibre1"></a> archive of the movie review dataset (84.1 MB) can be<a id="calibre_link-1610" class="calibre1"></a> downloaded from <a class="calibre1" href="http://ai.stanford.edu/~amaas/data/sentiment/">http://ai.stanford.edu/~amaas/data/sentiment/</a> as a Gzip-compressed tarball archive:</p><div class="book"><ul class="itemizedlist"><li class="listitem">If you are working with Linux or macOS, you can open a new Terminal window, <code class="email">cd</code> into the download directory, and execute <code class="email">tar -zxf aclImdb_v1.tar.gz</code> to decompress the dataset.</li><li class="listitem">If you are working with Windows, you can download a free archiver such as 7Zip (<a class="calibre1" href="http://www.7-zip.org">http://www.7-zip.org</a>) to extract<a id="calibre_link-1611" class="calibre1"></a> the files from the download archive.</li><li class="listitem">Alternatively, you can directly unpack the Gzip-compressed tarball archive directly in Python as follows:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tarfile
&gt;&gt;&gt; with tarfile.open('aclImdb_v1.tar.gz', 'r:gz') as tar:
...     tar.extractall()</pre></div></li></ul></div></div></div></div></div>

<div id="calibre_link-480" class="calibre">
<div class="book" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" id="calibre_link-1612">
<div class="book" title="Preparing the IMDb movie review data for text processing">
<div class="book" title="Preprocessing the movie dataset into more convenient format"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1613"><a id="calibre_link-323" class="calibre1"></a>Preprocessing the movie dataset into more convenient format</h2></div></div></div><p class="calibre8">Having <a id="calibre_link-1614" class="calibre1"></a>successfully extracted the dataset, we will now assemble the individual text documents from the decompressed download archive into a single CSV file.In the following code section, we will be reading the movie reviews into a pandas <code class="email">DataFrame</code> object, which can take up to 10 minutes on a standard desktop computer. To visualize the progress and estimated time until completion, we will use <a id="calibre_link-1615" class="calibre1"></a>the <span class="strong"><strong class="calibre2">Python Progress Indicator</strong></span> (<span class="strong"><strong class="calibre2">PyPrind</strong></span>, <a class="calibre1" href="https://pypi.python.org/pypi/PyPrind/">https://pypi.python.org/pypi/PyPrind/</a>) package that I developed several years ago for such purposes. PyPrind can be<a id="calibre_link-1616" class="calibre1"></a> installed by executing the <code class="email">pip install pyprind</code> command.</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pyprind
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import os

&gt;&gt;&gt; # change the `basepath` to the directory of the
&gt;&gt;&gt; # unzipped movie dataset

&gt;&gt;&gt; basepath = 'aclImdb'
&gt;&gt;&gt;
&gt;&gt;&gt; labels = {'pos': 1, 'neg': 0}
&gt;&gt;&gt; pbar = pyprind.ProgBar(50000)
&gt;&gt;&gt; df = pd.DataFrame()
&gt;&gt;&gt; for s in ('test', 'train'):
...     for l in ('pos', 'neg'):
...         path = os.path.join(basepath, s, l)
...         for file in os.listdir(path):
...             with open(os.path.join(path, file),
...                       'r', encoding='utf-8') as infile:
...                 txt = infile.read()
...             df = df.append([[txt, labels[l]]],
...                            ignore_index=True)
...             pbar.update()
&gt;&gt;&gt; df.columns = ['review', 'sentiment']
0%                          100%
[##############################] | ETA: 00:00:00
Total time elapsed: 00:03:37</pre></div><p class="calibre8">In the preceding code, we first initialized a new progress bar object <code class="email">pbar</code> with 50,000 iterations, which is the number of documents we were going to read in. Using the nested <code class="email">for</code> loops, we iterated over the <code class="email">train</code> and <code class="email">test</code> subdirectories in the main <code class="email">aclImdb</code> directory and read the individual text files from the <code class="email">pos</code> and <code class="email">neg</code> subdirectories that we eventually appended to the <code class="email">df</code> pandas <code class="email">DataFrame</code>, together with an integer class label (<code class="email">1</code> = positive and <code class="email">0</code> = negative).</p><p class="calibre8">Since the class labels in the assembled dataset are sorted, we will now shuffle <code class="email">DataFrame</code> using the <code class="email">permutation</code> function from the <code class="email">np.random</code> submodule&mdash;this will be useful to split the dataset into training and test sets in later sections when we will stream the data from our local drive directly. For our own convenience, we will also store the assembled and shuffled movie review dataset as a CSV file:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; df = df.reindex(np.random.permutation(df.index))
&gt;&gt;&gt; df.to_csv('movie_data.csv', index=False, encoding='utf-8')</pre></div><p class="calibre8">Since we are going to use this dataset later in this chapter, let's quickly confirm that we have successfully saved the data in the right format by reading in the CSV and printing an excerpt of the first three samples:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df = pd.read_csv('movie_data.csv', encoding='utf-8')
&gt;&gt;&gt; df.head(3)</pre></div><p class="calibre8">If you are running the code <a id="calibre_link-1617" class="calibre1"></a>examples in a Jupyter Notebook, you should now see the first three samples of the dataset, as shown in the following table:</p><div class="mediaobject"><img src="images/00910.jpeg" alt="Preprocessing the movie dataset into more convenient format" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-471" class="calibre">
<div id="calibre_link-1618" class="calibre10"></div><div class="book" title="Introducing the bag-of-words model"><div class="book" id="calibre_link-49"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1619"><a id="calibre_link-1620" class="calibre1"></a>Introducing the bag-of-words model</h1></div></div></div><p class="calibre8">You may remember from <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>, that we have to convert categorical data, such as text or words, into a numerical form before we can pass it on to a machine learning algorithm. In this section, we will introduce the <span class="strong"><strong class="calibre2">bag-of-words</strong></span>, which<a id="calibre_link-1621" class="calibre1"></a> allows us to represent text as numerical feature vectors. The idea behind the bag-of-words model is quite simple and can be summarized as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">We create a vocabulary of unique tokens&mdash;for example, words&mdash;from the entire set of documents.</li><li class="listitem" value="2">We construct a feature vector from each document that contains the counts of how often each word occurs in the particular document.</li></ol><div class="calibre13"></div></div><p class="calibre8">Since the unique words in each document represent only a small subset of all the words in the bag-of-words vocabulary, the feature vectors will mostly consist of zeros, which is why we call them <span class="strong"><strong class="calibre2">sparse</strong></span>. Do not worry if this sounds too abstract; in the following subsections, we will walk through the process of creating a simple bag-of-words model step-by-step.</p></div></div>

<div id="calibre_link-476" class="calibre">
<div class="book" title="Introducing the bag-of-words model">
<div class="book" title="Transforming words into feature vectors"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1622"><a id="calibre_link-324" class="calibre1"></a>Transforming words into feature vectors</h2></div></div></div><p class="calibre8">To construct a <a id="calibre_link-1623" class="calibre1"></a>bag-of-words model based on the word<a id="calibre_link-1624" class="calibre1"></a> counts in the respective documents, we can use the <code class="email">CountVectorizer</code> class implemented in scikit-learn. As we will see in the following code section, <code class="email">CountVectorizer</code> takes an array of text data, which can be documents or sentences, and constructs the bag-of-words model for us:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.feature_extraction.text import CountVectorizer
&gt;&gt;&gt; count = CountVectorizer()
&gt;&gt;&gt; docs = np.array([
...        'The sun is shining',
...        'The weather is sweet',
...        'The sun is shining and the weather is sweet'])
&gt;&gt;&gt; bag = count.fit_transform(docs)</pre></div><p class="calibre8">By calling the <code class="email">fit_transform</code> method on <code class="email">CountVectorizer</code>, we constructed the vocabulary of the bag-of-words model and transformed the following three sentences into sparse feature vectors:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">'The sun is shining'</code></li><li class="listitem"><code class="email">'The weather is sweet'</code></li><li class="listitem"><code class="email">'The sun is shining, the weather is sweet, and one and one is two'</code></li></ul></div><p class="calibre8">Now let's print the contents of the vocabulary to get a better understanding of the underlying concepts:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print(count.vocabulary_)
{'and': 0,
 'two': 7,
 'shining': 3,
 'one': 2,
 'sun': 4,
 'weather': 8,
 'the': 6,
 'sweet': 5,
 'is': 1}</pre></div><p class="calibre8">As we can see from executing the preceding command, the vocabulary is stored in a Python dictionary that maps the unique words to integer indices. Next, let's print the feature vectors that we just created:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print(bag.toarray())
[[0 1 0 1 1 0 1 0 0]
 [0 1 0 0 0 1 1 0 1]
 [2 3 2 1 1 1 2 1 1]]</pre></div><p class="calibre8">Each index position in the feature vectors shown here corresponds to the integer values that are stored as dictionary items in the <code class="email">CountVectorizer</code> vocabulary. For example, the first feature at index position <code class="email">0</code> resembles the count of the word <code class="email">'and'</code>, which only occurs in the last document, and the word <code class="email">'is'</code>, at index position <code class="email">1</code> (the second feature in the document vectors), <a id="calibre_link-1625" class="calibre1"></a>occurs in all three sentences. These values in <a id="calibre_link-1626" class="calibre1"></a>the feature vectors are also called <a id="calibre_link-1627" class="calibre1"></a>the <span class="strong"><strong class="calibre2">raw term frequencies</strong></span>: <span class="strong"><img src="images/00059.jpeg" alt="Transforming words into feature vectors" class="calibre14" /></span>&mdash;the number of times a term <span class="strong"><em class="calibre9">t</em></span> occurs in a document <span class="strong"><em class="calibre9">d</em></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1628" class="calibre1"></a>Note</h3><p class="calibre8">The sequence of items in the bag-of-words model that we just created is also called the <span class="strong"><strong class="calibre2">1-gram</strong></span> or <span class="strong"><strong class="calibre2">unigram</strong></span> model&mdash;each item or token in the vocabulary represents<a id="calibre_link-1629" class="calibre1"></a> a single<a id="calibre_link-1630" class="calibre1"></a> word. More generally, the contiguous sequences of items in NLP&mdash;words, letters, or symbols&mdash;are also called <span class="strong"><strong class="calibre2">n-grams</strong></span>. The choice<a id="calibre_link-1631" class="calibre1"></a> of the number <span class="strong"><em class="calibre9">n</em></span> in the n-gram model depends on the particular application; for example, a study by Kanaris and others revealed that n-grams of size 3 and 4 yield good performances in anti-spam filtering of email messages (<span class="strong"><em class="calibre9">Words versus character n-grams for anti-spam filtering</em></span>, <span class="strong"><em class="calibre9">Ioannis Kanaris</em></span>, <span class="strong"><em class="calibre9">Konstantinos Kanaris</em></span>, <span class="strong"><em class="calibre9">Ioannis Houvardas</em></span>, and <span class="strong"><em class="calibre9">Efstathios Stamatatos</em></span>, <span class="strong"><em class="calibre9">International Journal on Artificial Intelligence Tools</em></span>, <span class="strong"><em class="calibre9">World Scientific Publishing Company</em></span>, 16(06): 1047-1067, <span class="strong"><em class="calibre9">2007</em></span>). To summarize the concept of the n-gram representation, the 1-gram and 2-gram representations of our first document "the sun is shining" would be constructed as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">1-gram: "the", "sun", "is", "shining"</li><li class="listitem">2-gram: "the sun", "sun is", "is shining"</li></ul></div><p class="calibre8">The <code class="email">CountVectorizer</code> class in scikit-learn allows us to use different n-gram models via its <code class="email">ngram_range</code> parameter. While a 1-gram representation is used by default, we could switch to a 2-gram representation by initializing a new <code class="email">CountVectorizer</code> instance with <code class="email">ngram_range=(2,2)</code>.</p></div></div></div></div>

<div id="calibre_link-483" class="calibre">
<div class="book" title="Introducing the bag-of-words model">
<div class="book" title="Assessing word relevancy via term frequency-inverse document frequency"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1632"><a id="calibre_link-325" class="calibre1"></a>Assessing word relevancy via term frequency-inverse document frequency</h2></div></div></div><p class="calibre8">When we are<a id="calibre_link-1633" class="calibre1"></a> analyzing <a id="calibre_link-1634" class="calibre1"></a>text data, we often encounter words that occur across multiple documents from both classes. These frequently occurring words typically don't contain useful or discriminatory information. In this subsection, we will learn about a useful technique called <span class="strong"><strong class="calibre2">term frequency-inverse document frequency</strong></span> (<span class="strong"><strong class="calibre2">tf-idf</strong></span>) that can be used to downweight these frequently occurring words in the feature vectors. The tf-idf can be defined as the product of the term frequency and the inverse document frequency:</p><div class="mediaobject"><img src="images/00071.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here the <span class="strong"><em class="calibre9">tf(t, d)</em></span> is the term frequency that we introduced in the previous section, and <span class="strong"><em class="calibre9">idf(t, d)</em></span> is the inverse document frequency and can be calculated as follows:</p><div class="mediaobject"><img src="images/00115.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here <span class="strong"><img src="images/00174.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre14" /></span> is the total number of documents, and <span class="strong"><em class="calibre9">df(d, t)</em></span> is the number of documents <span class="strong"><em class="calibre9">d</em></span> that contain the term <span class="strong"><em class="calibre9">t</em></span>. Note that adding the constant <span class="strong"><em class="calibre9">1</em></span> to the denominator is optional and serves the purpose of assigning a non-zero value to terms that occur in all training samples; the <span class="strong"><em class="calibre9">log</em></span> is used to ensure that low document frequencies are not given too much weight.</p><p class="calibre8">The scikit-learn library<a id="calibre_link-1635" class="calibre1"></a> implements <a id="calibre_link-1636" class="calibre1"></a>yet another transformer, the <code class="email">TfidfTransformer</code> class, that takes the raw term frequencies from the <code class="email">CountVectorizer</code> class as input and transforms them into tf-idfs:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfTransformer
&gt;&gt;&gt; tfidf = TfidfTransformer(use_idf=True,
...                          norm='l2',
...                          smooth_idf=True)
&gt;&gt;&gt; np.set_printoptions(precision=2)
&gt;&gt;&gt; print(tfidf.fit_transform(count.fit_transform(docs))
...       .toarray())
[[ 0.    0.43  0.    0.56  0.56  0.    0.43  0.    0.  ]
 [ 0.    0.43  0.    0.    0.    0.56  0.43  0.    0.56]
 [ 0.5   0.45  0.5   0.19  0.19  0.19  0.3   0.25  0.19]]</pre></div><p class="calibre8">As we saw in the previous subsection, the word <code class="email">'is'</code> had the largest term frequency in the third document, being the most frequently occurring word. However, after transforming the same feature vector into tf-idfs, we see that the word <code class="email">'is'</code> is now associated with a relatively small tf-idf (<code class="email">0.45</code>) in the third document, since it is also present in the first and second document and thus is unlikely to contain any useful discriminatory information.</p><p class="calibre8">However, if we'd manually calculated the tf-idfs of the individual terms in our feature vectors, we'd notice that <code class="email">TfidfTransformer</code> calculates the tf-idfs slightly differently compared to the standard textbook equations that we defined previously. The equations for the inverse document frequency implemented in scikit-learn is computed as follows:</p><div class="mediaobject"><img src="images/00106.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similarly, the tf-idf computed in scikit-learn deviates slightly from the default equation we defined earlier:</p><div class="mediaobject"><img src="images/00117.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">While it is also more <a id="calibre_link-1637" class="calibre1"></a>typical to normalize<a id="calibre_link-1638" class="calibre1"></a> the raw term frequencies before calculating the tf-idfs, <code class="email">TfidfTransformer</code> class normalizes the tf-idfs directly. By default (<code class="email">norm='l2'</code>), scikit-learn's <code class="email">TfidfTransformer</code> applies the L2-normalization, which returns a vector of length 1 by dividing an un-normalized feature vector <span class="strong"><strong class="calibre2">v</strong></span> by its L2-norm:</p><div class="mediaobject"><img src="images/00129.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To make sure that we understand how <code class="email">TfidfTransformer</code> works, let's walk through an example and calculate the tf-idf of the word <code class="email">'is'</code> in the third document.</p><p class="calibre8">The word <code class="email">'is'</code> has a term frequency of 3 (<span class="strong"><em class="calibre9">tf=3</em></span>) in the third document, and the document frequency of this term is 3 since the term <code class="email">'is'</code> occurs in all three documents (<span class="strong"><em class="calibre9">df=3</em></span>). Thus, we can calculate the inverse document frequency as follows:</p><div class="mediaobject"><img src="images/00394.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now, in order to calculate the tf-idf, we simply need to add <span class="strong"><em class="calibre9">1</em></span> to the inverse document frequency and multiply it by the term frequency:</p><div class="mediaobject"><img src="images/00453.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">If we repeated<a id="calibre_link-1639" class="calibre1"></a> this calculation <a id="calibre_link-1640" class="calibre1"></a>for all terms in the third document, we'd obtain the following tf-idf vectors: <span class="strong"><em class="calibre9">[3.39, 3.0, 3.39, 1.29, 1.29, 1.29, 2.0, 1.69, 1.29]</em></span>. However, notice that the values in this feature vector are different from the values that we obtained from <code class="email">TfidfTransformer</code> that we used previously. The final step that we are missing in this tf-idf calculation is the L2-normalization, which can be applied as follows:</p><div class="mediaobject"><img src="images/00167.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00176.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00192.jpeg" alt="Assessing word relevancy via term frequency-inverse document frequency" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, the results now match the results returned by scikit-learn's <code class="email">TfidfTransformer</code>, and since we now understand how tf-idfs are calculated, let's proceed to the next section and apply those concepts to the movie review dataset.</p></div></div></div>

<div id="calibre_link-489" class="calibre">
<div class="book" title="Introducing the bag-of-words model">
<div class="book" title="Cleaning text data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1641"><a id="calibre_link-326" class="calibre1"></a>Cleaning text data</h2></div></div></div><p class="calibre8">In the previous subsections, we learned about the bag-of-words model, term bag-of-words<a id="calibre_link-1642" class="calibre1"></a> model, term frequencies, and tf-idfs. However, the first important step&mdash;before we build our bag-of-words model&mdash;is to clean the text data by stripping it of all unwanted characters. To illustrate why this is important, let's display the last 50 characters from the first document in the reshuffled movie review dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df.loc[0, 'review'][-50:]
'is seven.&lt;br /&gt;&lt;br /&gt;Title (Brazil): Not Available'</pre></div><p class="calibre8">As we can see here, the text contains HTML markup as well as punctuation and other non-letter characters. While HTML markup does not contain much useful semantics, punctuation marks can represent useful, additional information in certain NLP contexts. However, for simplicity, <a id="calibre_link-1643" class="calibre1"></a>we will now remove all punctuation marks except for emoticon characters such as :) since those are certainly useful for sentiment analysis. To accomplish this task, we will <a id="calibre_link-1644" class="calibre1"></a>use Python's <span class="strong"><strong class="calibre2">regular expression</strong></span> (<span class="strong"><strong class="calibre2">regex</strong></span>) library, <code class="email">re</code>, as shown here:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import re
&gt;&gt;&gt; def preprocessor(text):
...     text = re.sub('&lt;[^&gt;]*&gt;', '', text)
...     emoticons = re.findall('(?::|;|=)(?:-)?(?:\)|\(|D|P)',
...                            text)
...     text = (re.sub('[\W]+', ' ', text.lower()) +
...             ' '.join(emoticons).replace('-', ''))
...     return text</pre></div><p class="calibre8">Via the first regex <code class="email">&lt;[^&gt;]*&gt;</code> in the preceding code section, we tried to remove all of the HTML markup from the movie reviews. Although many programmers generally advise against the use of regex to parse HTML, this regex should be sufficient to <span class="strong"><em class="calibre9">clean</em></span> this particular dataset. After we removed the HTML markup, we used a slightly more complex regex to find emoticons, which we temporarily stored as <code class="email">emoticons</code>. Next, we removed all non-word characters from the text via the regex <code class="email">[\W]+</code> and converted the text into lowercase characters.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1645" class="calibre1"></a>Note</h3><p class="calibre8">In the context of this analysis, we assume that the capitalization of a word&mdash;for example, whether it appears at the beginning of a sentence&mdash;does not contain semantically relevant information. However, note that there are exceptions, for instance, we remove the notation of proper names. But again, in the context of this analysis, it is a simplifying assumption that the letter case does not contain information that is relevant for sentiment analysis.</p></div><p class="calibre8">Eventually, we added the temporarily stored <code class="email">emoticons</code> to the end of the processed document string. Additionally, we removed the <span class="strong"><em class="calibre9">nose</em></span> character (<code class="email">-</code>) from the emoticons for consistency.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1646" class="calibre1"></a>Note</h3><p class="calibre8">Although regular expressions offer an efficient and convenient approach to searching for characters in a string, they also come with a steep learning curve. Unfortunately, an in-depth discussion of regular expressions is beyond the scope of this book. However, you can find a great tutorial on the Google Developers portal<a id="calibre_link-1647" class="calibre1"></a> at <a class="calibre1" href="https://developers.google.com/edu/python/regular-expressions">https://developers.google.com/edu/python/regular-expressions</a> or check out the official <a id="calibre_link-1648" class="calibre1"></a>documentation of Python's <code class="email">re</code> module at <a class="calibre1" href="https://docs.python.org/3.6/library/re.html">https://docs.python.org/3.6/library/re.html</a>.</p></div><p class="calibre8">Although the addition of the emoticon characters to the end of the cleaned document strings may not look like the most elegant approach, we shall note that the order of the words doesn't matter in our bag-of-words model if our vocabulary consists of only one-word tokens. But before <a id="calibre_link-1649" class="calibre1"></a>we talk more about the splitting of documents into individual terms, words, or tokens, let's confirm that our preprocessor works correctly:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; preprocessor(df.loc[0, 'review'][-50:])
'is seven title brazil not available'
&gt;&gt;&gt; preprocessor("&lt;/a&gt;This :) is :( a test :-)!")
'this is a test :) :( :)'</pre></div><p class="calibre8">Lastly, since we will make use of the <span class="strong"><em class="calibre9">cleaned</em></span> text data over and over again during the next sections, let us now apply our <code class="email">preprocessor</code> function to all the movie reviews in our <code class="email">DataFrame</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df['review'] = df['review'].apply(preprocessor)</pre></div></div></div></div>

<div id="calibre_link-586" class="calibre">
<div class="book" title="Introducing the bag-of-words model">
<div class="book" title="Processing documents into tokens"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1650"><a id="calibre_link-327" class="calibre1"></a>Processing documents into tokens</h2></div></div></div><p class="calibre8">After successfully <a id="calibre_link-1651" class="calibre1"></a>preparing the movie review dataset, we<a id="calibre_link-1652" class="calibre1"></a> now need to think about how to split the text corpora into individual elements. One way to <span class="strong"><em class="calibre9">tokenize</em></span> documents is to split them into individual words by splitting the cleaned documents at its whitespace characters:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def tokenizer(text):
...    return text.split()
&gt;&gt;&gt; tokenizer('runners like running and thus they run')
['runners', 'like', 'running', 'and', 'thus', 'they', 'run']</pre></div><p class="calibre8">In the context of tokenization, another useful <a id="calibre_link-1653" class="calibre1"></a>technique is <span class="strong"><strong class="calibre2">word stemming</strong></span>, which is the process of transforming a word into its root form. It allows us to map related words to the same stem. The original stemming algorithm was developed by Martin F. Porter in 1979 and is hence known as <a id="calibre_link-1654" class="calibre1"></a>the <span class="strong"><strong class="calibre2">Porter stemmer</strong></span> algorithm (<span class="strong"><em class="calibre9">An algorithm for suffix stripping</em></span>, <span class="strong"><em class="calibre9">Martin F. Porter</em></span>, <span class="strong"><em class="calibre9">Program: Electronic Library and Information Systems</em></span>, 14(3): 130&ndash;137, <span class="strong"><em class="calibre9">1980</em></span>). The <span class="strong"><strong class="calibre2">Natural Language Toolkit</strong></span> (<span class="strong"><strong class="calibre2">NLTK</strong></span>, <a class="calibre1" href="http://www.nltk.org">http://www.nltk.org</a>) for Python<a id="calibre_link-1655" class="calibre1"></a> implements the Porter stemming algorithm, which we will use in the following code section. In order to install the NLTK, you can simply execute <code class="email">conda install nltk</code> or <code class="email">pip install nltk</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1656" class="calibre1"></a>Note</h3><p class="calibre8">Although the NLTK is not the focus of the chapter, I highly recommend that you visit the NLTK website as well as read the official NLTK book, which is freely available at <a class="calibre1" href="http://www.nltk.org/book/">http://www.nltk.org/book/</a>, if you are interested in more advanced applications in NLP.</p></div><p class="calibre8">The following code shows how to use the Porter stemming algorithm:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from nltk.stem.porter import PorterStemmer
&gt;&gt;&gt; porter = PorterStemmer()
&gt;&gt;&gt; def tokenizer_porter(text):
...    return [porter.stem(word) for word in text.split()]
&gt;&gt;&gt; tokenizer_porter('runners like running and thus they run')
['runner', 'like', 'run', 'and', 'thu', 'they', 'run']</pre></div><p class="calibre8">Using the <code class="email">PorterStemmer</code> from the <code class="email">nltk</code> package, we modified our <code class="email">tokenizer</code> function to<a id="calibre_link-1657" class="calibre1"></a> reduce words to their root form, which was<a id="calibre_link-1658" class="calibre1"></a> illustrated by the simple preceding example where the word <code class="email">'running'</code> was <span class="strong"><em class="calibre9">stemmed</em></span> to its root form <code class="email">'run'</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1659" class="calibre1"></a>Note</h3><p class="calibre8">The Porter stemming algorithm is probably the oldest and simplest stemming algorithm. Other popular stemming algorithms include the<a id="calibre_link-1660" class="calibre1"></a> newer <span class="strong"><strong class="calibre2">Snowball stemmer</strong></span> (Porter2 or English stemmer) and the <span class="strong"><strong class="calibre2">Lancaster stemmer</strong></span> (Paice/Husk stemmer), which is faster but also more aggressive than the Porter<a id="calibre_link-1661" class="calibre1"></a> stemmer. These alternative stemming algorithms are also available through the NLTK package (<a class="calibre1" href="http://www.nltk.org/api/nltk.stem.html">http://www.nltk.org/api/nltk.stem.html</a>).</p><p class="calibre8">While stemming can create non-real words, such as <code class="email">'thu'</code> (from <code class="email">'thus'</code>), as shown in the previous example, a technique called <span class="strong"><strong class="calibre2">lemmatization</strong></span>
<a id="calibre_link-1662" class="calibre1"></a> aims to obtain the canonical (grammatically correct) forms of individual words&mdash;the so-called <span class="strong"><strong class="calibre2">lemmas</strong></span>. However, lemmatization is computationally more difficult and<a id="calibre_link-1663" class="calibre1"></a> expensive compared to stemming and, in practice, it has been observed that stemming and lemmatization have little impact on the performance of text classification (<span class="strong"><em class="calibre9">Influence of Word Normalization on Text Classification</em></span>, <span class="strong"><em class="calibre9">Michal Toman</em></span>, <span class="strong"><em class="calibre9">Roman Tesar</em></span>, and <span class="strong"><em class="calibre9">Karel Jezek</em></span>, Proceedings of InSciT, pages 354&ndash;358, <span class="strong"><em class="calibre9">2006</em></span>).</p></div><p class="calibre8">Before we jump into the next section, where we will train a machine learning model using the bag-of-words model, let's briefly talk about another useful topic called <span class="strong"><strong class="calibre2">stop-word removal</strong></span>. Stop-words are <a id="calibre_link-1664" class="calibre1"></a>simply those words that are extremely common in all sorts of texts and probably bear no (or only little) useful information that can be used to distinguish between different classes of documents. Examples of stop-words are <span class="strong"><em class="calibre9">is</em></span>, <span class="strong"><em class="calibre9">and</em></span>, <span class="strong"><em class="calibre9">has</em></span>, and <span class="strong"><em class="calibre9">like</em></span>. Removing stop-words can be useful if we are working with raw or normalized term frequencies rather than tf-idfs, which are already downweighting frequently occurring words.</p><p class="calibre8">In order to remove stop-words from the movie reviews, we will use the set of 127 English stop-words that is available from the NLTK library, which can be obtained by calling the <code class="email">nltk.download</code> function:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import nltk

&gt;&gt;&gt; nltk.download('stopwords')</pre></div><p class="calibre8">After we <a id="calibre_link-1665" class="calibre1"></a>download the stop-words set, we can load and <a id="calibre_link-1666" class="calibre1"></a>apply the English stop-word set as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from nltk.corpus import stopwords

&gt;&gt;&gt; stop = stopwords.words('english')
&gt;&gt;&gt; [w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]

['runner', 'like', 'run', 'run', 'lot']</pre></div></div></div></div>

<div id="calibre_link-504" class="calibre"><div class="book" title="Training a logistic regression model for document classification" id="calibre_link-110"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1667"><a id="calibre_link-1668" class="calibre1"></a>Training a logistic regression model for document classification</h1></div></div></div><p class="calibre8">In this section, we will<a id="calibre_link-1669" class="calibre1"></a> train a logistic<a id="calibre_link-1670" class="calibre1"></a> regression model to classify the movie reviews into <span class="strong"><em class="calibre9">positive</em></span> and <span class="strong"><em class="calibre9">negative</em></span> reviews. First, we will divide the <code class="email">DataFrame</code> of cleaned text documents into 25,000 documents for training and 25,000 documents for testing:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train = df.loc[:25000, 'review'].values
&gt;&gt;&gt; y_train = df.loc[:25000, 'sentiment'].values
&gt;&gt;&gt; X_test = df.loc[25000:, 'review'].values
&gt;&gt;&gt; y_test = df.loc[25000:, 'sentiment'].values</pre></div><p class="calibre8">Next, we will use a <code class="email">GridSearchCV</code> object to find the optimal set of parameters for our logistic regression model using 5-fold stratified cross-validation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import GridSearchCV
&gt;&gt;&gt; from sklearn.pipeline import Pipeline
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfVectorizer

&gt;&gt;&gt; tfidf = TfidfVectorizer(strip_accents=None,
...                         lowercase=False,
...                         preprocessor=None)
&gt;&gt;&gt; param_grid = [{'vect__ngram_range': [(1,1)],
...               'vect__stop_words': [stop, None],
...               'vect__tokenizer': [tokenizer,
...                                   tokenizer_porter],
...               'clf__penalty': ['l1', 'l2'],
...               'clf__C': [1.0, 10.0, 100.0]},
...             {'vect__ngram_range': [(1,1)],
...               'vect__stop_words': [stop, None],
...               'vect__tokenizer': [tokenizer,
...                                   tokenizer_porter],
...               'vect__use_idf':[False],
...               'vect__norm':[None],
...               'clf__penalty': ['l1', 'l2'],
...               'clf__C': [1.0, 10.0, 100.0]}
...             ]
&gt;&gt;&gt; lr_tfidf = Pipeline([('vect', tfidf),
...                     ('clf',
...                      LogisticRegression(random_state=0))])
&gt;&gt;&gt; gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,
...                           scoring='accuracy',
...                           cv=5, verbose=1,
...                           n_jobs=1)
&gt;&gt;&gt; gs_lr_tfidf.fit(X_train, y_train)</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1671" class="calibre1"></a>Tip</h3><p class="calibre8">Please note that it is highly recommended to set <code class="email">n_jobs=-1</code> (instead of <code class="email">n_jobs=1</code>) in the previous code example to utilize all available cores on your machine and speed up the grid search. However, some Windows users reported issues when running the previous code with the <code class="email">n_jobs=-1</code> setting related to pickling the t<code class="email">okenizer</code> and <code class="email">tokenizer_porter</code> functions for multiprocessing on Windows. Another workaround would be to replace those two functions, <code class="email">[tokenizer, tokenizer_porter]</code>, with <code class="email">[str.split]</code>. However, note that the replacement by the simple <code class="email">str.split</code> would not support stemming.</p></div><p class="calibre8">When we<a id="calibre_link-1672" class="calibre1"></a> initialized <a id="calibre_link-1673" class="calibre1"></a>the <code class="email">GridSearchCV</code> object and its parameter grid using the preceding code, we restricted ourselves to a limited number of parameter combinations, since the number of feature vectors, as well as the large vocabulary, can make the grid search computationally quite expensive. Using a standard desktop computer, our grid search may take up to 40 minutes to complete.</p><p class="calibre8">In the previous code example, we replaced <code class="email">CountVectorizer</code> and <code class="email">TfidfTransformer</code> from the previous subsection with <code class="email">TfidfVectorizer</code>, which combines the latter transformer objects. Our <code class="email">param_grid</code> consisted of two parameter dictionaries. In the first dictionary, we used the <code class="email">TfidfVectorizer</code> with its default settings (<code class="email">use_idf=True</code>, <code class="email">smooth_idf=True</code>, and<code class="email"> norm='l2'</code>) to calculate the tf-idfs; in the second dictionary, we set those parameters to <code class="email">use_idf=False</code>, <code class="email">smooth_idf=False</code>, and <code class="email">norm=None</code> in order to train a model based on raw term frequencies. Furthermore, for the logistic regression classifier itself, we trained models using L2 and L1 regularization via the penalty parameter and compared different regularization strengths by defining a range of values for the inverse-regularization parameter C.</p><p class="calibre8">After the grid <a id="calibre_link-1674" class="calibre1"></a>search has<a id="calibre_link-1675" class="calibre1"></a> finished, we can print the best parameter set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)
Best parameter set: {'clf__C': 10.0, 'vect__stop_words': None, 'clf__penalty': 'l2', 'vect__tokenizer': &lt;function tokenizer at 0x7f6c704948c8&gt;, 'vect__ngram_range': (1, 1)}</pre></div><p class="calibre8">As we can see in the preceding output, we obtained the best grid search results using the regular <code class="email">tokenizer</code> without Porter stemming, no stop-word library, and tf-idfs in combination with a logistic regression classifier that uses L2-regularization with the regularization strength C of <code class="email">10.0</code>.</p><p class="calibre8">Using the best model from this grid search, let's print the average 5-fold cross-validation accuracy scores on the training set and the classification accuracy on the test dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('CV Accuracy: %.3f'
...       % gs_lr_tfidf.best_score_)
CV Accuracy: 0.892
&gt;&gt;&gt; clf = gs_lr_tfidf.best_estimator_
&gt;&gt;&gt; print('Test Accuracy: %.3f'
...     % clf.score(X_test, y_test))
Test Accuracy: 0.899</pre></div><p class="calibre8">The results reveal that our machine learning model can predict whether a movie review is positive or negative with 90 percent accuracy.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1676" class="calibre1"></a>Note</h3><p class="calibre8">A still very popular classifier for text classification is the NaÃ¯ve Bayes classifier, which gained popularity in applications of email spam filtering. NaÃ¯ve Bayes classifiers are easy to implement, computationally efficient, and tend to perform particularly well on relatively small datasets compared to other algorithms. Although we don't discuss NaÃ¯ve Bayes classifiers in this book, the interested reader can find my article about NaÃ¯ve text classification that I made freely available on <span class="strong"><em class="calibre9">arXiv</em></span> (<span class="strong"><em class="calibre9">Naive Bayes and Text Classification I &ndash; Introduction and Theory</em></span>, <span class="strong"><em class="calibre9">S. Raschka</em></span>, <span class="strong"><em class="calibre9">Computing Research Repository (CoRR)</em></span>, abs/1410.5329, <span class="strong"><em class="calibre9">2014</em></span>, <a class="calibre1" href="http://arxiv.org/pdf/1410.5329v3.pdf">http://arxiv.org/pdf/1410.5329v3.pdf</a>).</p></div></div></div>

<div id="calibre_link-479" class="calibre"><div class="book" title="Working with bigger data â online algorithms and out-of-core learning"><div class="book" id="calibre_link-328"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1677"><a id="calibre_link-1678" class="calibre1"></a>Working with bigger data &ndash; online algorithms and out-of-core learning</h1></div></div></div><p class="calibre8">If you executed the code examples in the previous section, you may have noticed that it could be computationally quite expensive to construct the feature vectors for the 50,000 movie review dataset during grid search. In many real-world applications, it is not uncommon to work with even larger datasets that can exceed our computer's memory. Since not everyone<a id="calibre_link-1679" class="calibre1"></a> has access to supercomputer facilities, we will now apply a technique called <span class="strong"><strong class="calibre2">out-of-core learning</strong></span>, which allows us to work with such large datasets by fitting the classifier incrementally on smaller batches of the dataset.</p><p class="calibre8">Back in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, we introduced the concept<a id="calibre_link-1680" class="calibre1"></a> of <span class="strong"><strong class="calibre2">stochastic gradient descent</strong></span>, which is an optimization algorithm that updates the model's weights using one sample at a time. In this section, we will make use of the <code class="email">partial_fit</code> function of the <code class="email">SGDClassifier</code> in scikit-learn to stream the documents directly from our local drive, and train a logistic regression model using small mini-batches of documents.</p><p class="calibre8">First, we define a <code class="email">tokenizer</code> function that cleans the unprocessed text data from the <code class="email">movie_data.csv</code> file that we constructed at the beginning of this chapter and separate it into word tokens while removing stop words:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import re
&gt;&gt;&gt; from nltk.corpus import stopwords
&gt;&gt;&gt; stop = stopwords.words('english')
&gt;&gt;&gt; def tokenizer(text):
...     text = re.sub('&lt;[^&gt;]*&gt;', '', text)
...     emoticons = re.findall('(?::|;|=)(?:-)?(?:\)|\(|D|P)',
...                            text.lower())
...     text = re.sub('[\W]+', ' ', text.lower()) \
...            + ' '.join(emoticons).replace('-', '')
...     tokenized = [w for w in text.split() if w not in stop]
...     return tokenized</pre></div><p class="calibre8">Next, we define a generator function <code class="email">stream_docs</code> that reads in and returns one document at a time:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def stream_docs(path):
...    with open(path, 'r', encoding='utf-8') as csv:
...        next(csv) # skip header
...        for line in csv:
...            text, label = line[:-3], int(line[-2])
...            yield text, label</pre></div><p class="calibre8">To verify that our <code class="email">stream_docs</code> function works correctly, let's read in the first document from the <code class="email">movie_data.csv</code> file, which should return a tuple consisting of the review text as well as the corresponding class label:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; next(stream_docs(path='movie_data.csv'))
('"In 1974, the teenager Martha Moxley ... ',1)</pre></div><p class="calibre8">We will now define a function, <code class="email">get_minibatch</code>, that will take a document stream from the <code class="email">stream_docs</code> function and return a particular number of documents specified by the <code class="email">size</code> parameter:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def get_minibatch(doc_stream, size):
...     docs, y = [], []
...     try:
...         for _ in range(size):
...                 text, label = next(doc_stream)
...                 docs.append(text)
...                 y.append(label)
...     except StopIteration:
...         return None, None
...     return docs, y</pre></div><p class="calibre8">Unfortunately, we can't use <code class="email">CountVectorizer</code> for out-of-core learning since it requires holding the complete vocabulary in memory. Also, <code class="email">TfidfVectorizer</code> needs to keep all the feature vectors of the training dataset in memory to calculate the inverse document frequencies. However, another useful vectorizer for text processing implemented in scikit-learn is <code class="email">HashingVectorizer</code>. <code class="email">HashingVectorizer</code> is data-independent and makes use of the hashing trick via the 32-bit MurmurHash3<a id="calibre_link-1681" class="calibre1"></a> function by Austin Appleby (<a class="calibre1" href="https://sites.google.com/site/murmurhash/">https://sites.google.com/site/murmurhash/</a>):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.feature_extraction.text import HashingVectorizer
&gt;&gt;&gt; from sklearn.linear_model import SGDClassifier
&gt;&gt;&gt; vect = HashingVectorizer(decode_error='ignore',
...                          n_features=2**21,
...                          preprocessor=None,
...                          tokenizer=tokenizer)
&gt;&gt;&gt; clf = SGDClassifier(loss='log', random_state=1, n_iter=1)
&gt;&gt;&gt; doc_stream = stream_docs(path='movie_data.csv')</pre></div><p class="calibre8">You can replace <code class="email">Perceptron(..., n_iter=1, ...)</code> by <code class="email">Perceptron(..., max_iter=1, ...)</code> in scikit-learn versions greater than 0.18. The n_iter parameter is used here deliberately, because scikit-learn 0.18 is still widely used.Using the preceding code, we initialized <code class="email">HashingVectorizer</code> with our tokenizer function and set the number of features to <code class="email">2**21</code>. Furthermore, we reinitialized a logistic regression classifier by setting the <code class="email">loss</code> parameter of the <code class="email">SGDClassifier</code> to <code class="email">'log'</code>&mdash;note that by choosing a large number of features in the <code class="email">HashingVectorizer</code>, we reduce the chance of causing hash collisions, but we also increase the number of coefficients in our logistic regression model. Now comes the really interesting part. Having set up all the complementary functions, we can now start the out-of-core learning using the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pyprind
&gt;&gt;&gt; pbar = pyprind.ProgBar(45)
&gt;&gt;&gt; classes = np.array([0, 1])
&gt;&gt;&gt; for _ in range(45):
...     X_train, y_train = get_minibatch(doc_stream, size=1000)
...     if not X_train:
...         break
...     X_train = vect.transform(X_train)
...     clf.partial_fit(X_train, y_train, classes=classes)
...     pbar.update()
0%                          100%
[##############################] | ETA: 00:00:00
Total time elapsed: 00:00:39</pre></div><p class="calibre8">Again, we made use of the PyPrind package in order to estimate the progress of our learning algorithm. We initialized the progress bar object with <code class="email">45</code> iterations and, in the following <code class="email">for</code> loop, we iterated over <code class="email">45</code> mini-batches of documents where each mini-batch consists of 1,000 documents. Having completed the incremental learning process, we will use the last 5,000 documents to evaluate the performance of our model:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_test, y_test = get_minibatch(doc_stream, size=5000)
&gt;&gt;&gt; X_test = vect.transform(X_test)
&gt;&gt;&gt; print('Accuracy: %.3f' % clf.score(X_test, y_test))
Accuracy: 0.878</pre></div><p class="calibre8">As we can see, the accuracy of the model is approximately 88 percent, slightly below the accuracy that we achieved in the previous section using the grid search for hyperparameter tuning. However, out-of-core learning is very memory efficient and took less than a minute to complete. Finally, we can use the last 5,000 documents to update our model:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; clf = clf.partial_fit(X_test, y_test)</pre></div><p class="calibre8">If you are planning to continue directly with <a class="calibre1" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application" href="#calibre_link-40">Chapter 9</a>, <span class="strong"><em class="calibre9">Embedding a Machine Learning Model into a Web Application</em></span>, I recommend you keep the current Python session open. In the next chapter, we will use the model that we just trained to learn how to save it to disk for later use and embed it into a web application.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1682" class="calibre1"></a>Note</h3><p class="calibre8">A more modern alternative to the bag-of-words model is <span class="strong"><strong class="calibre2">word2vec</strong></span>, an algorithm that Google released in 2013 (<span class="strong"><em class="calibre9">Efficient Estimation of Word Representations in Vector Space</em></span>, <span class="strong"><em class="calibre9">T. Mikolov</em></span>, <span class="strong"><em class="calibre9">K. Chen</em></span>, <span class="strong"><em class="calibre9">G. Corrado</em></span>, and <span class="strong"><em class="calibre9">J. Dean</em></span>, arXiv preprint arXiv:1301.3781, <span class="strong"><em class="calibre9">2013</em></span>). The word2vec algorithm is an unsupervised learning algorithm based on neural networks that attempts to automatically learn the relationship between words. The idea behind word2vec is to put words that have similar meanings into similar clusters, and via clever vector-spacing, the model can reproduce certain words using simple vector math, for example, <span class="strong"><em class="calibre9">king &ndash; man + woman = queen</em></span>.</p><p class="calibre8">The original C-implementation with useful links to the relevant papers and alternative implementations can be found at <a class="calibre1" href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a>.</p></div></div></div>

<div id="calibre_link-25" class="calibre">
<div id="calibre_link-1683" class="calibre10"></div><div class="book" title="Topic modeling with Latent Dirichlet Allocation"><div class="book" id="calibre_link-144"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1684"><a id="calibre_link-1685" class="calibre1"></a>Topic modeling with Latent Dirichlet Allocation</h1></div></div></div><p class="calibre8">Topic modeling describes<a id="calibre_link-1686" class="calibre1"></a> the broad task of assigning topics to unlabelled text documents. For example, a typical application would be the categorization of documents in a large text corpus of newspaper articles where we don't know on which specific page or category they appear in. In applications of topic modeling, we then aim to assign category labels to those articles&mdash;for example, sports, finance, world news, politics, local news, and so forth. Thus, in the context of the broad categories of machine learning that we discussed in <a class="calibre1" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" href="#calibre_link-17">Chapter 1</a>, <span class="strong"><em class="calibre9">Giving Computers the Ability to Learn from Data</em></span>, we can consider topic modeling as a clustering task, a subcategory of unsupervised learning.</p><p class="calibre8">In this section, we will introduce a popular technique for topic modeling called <span class="strong"><strong class="calibre2">Latent Dirichlet Allocation</strong></span> (<span class="strong"><strong class="calibre2">LDA</strong></span>). However, note<a id="calibre_link-1687" class="calibre1"></a> that while Latent Dirichlet Allocation is often abbreviated as LDA, it is not to be confused with Linear discriminant analysis, a supervised dimensionality reduction technique that we introduced in <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1688" class="calibre1"></a>Note</h3><p class="calibre8">LDA is different from the supervised learning approach that we took in this chapter to classify movie reviews as positive and negative. Thus, if you are interested in embedding scikit-learn models into a web application via the Flask framework using the movie reviewer as an example, please feel free to jump to the next chapter and revisit this standalone section on topic modeling later on.</p></div></div></div>

<div id="calibre_link-190" class="calibre">
<div class="book" title="Topic modeling with Latent Dirichlet Allocation">
<div class="book" title="Decomposing text documents with LDA"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1689"><a id="calibre_link-329" class="calibre1"></a>Decomposing text documents with LDA</h2></div></div></div><p class="calibre8">Since the mathematics behind <a id="calibre_link-1690" class="calibre1"></a>LDA is <a id="calibre_link-1691" class="calibre1"></a>quite involved and requires knowledge about Bayesian inference, we will approach this topic from a practitioner's perspective and interpret LDA using layman's terms. However, the interested reader can read more about LDA in the following research paper: <span class="strong"><em class="calibre9">Latent Dirichlet Allocation</em></span>, <span class="strong"><em class="calibre9">David M. Blei</em></span>, <span class="strong"><em class="calibre9">Andrew Y. Ng</em></span>, and <span class="strong"><em class="calibre9">Michael I. Jordan</em></span>, <span class="strong"><em class="calibre9">Journal of Machine Learning Research 3</em></span>, pages: 993-1022, <span class="strong"><em class="calibre9">Jan 2003</em></span>.</p><p class="calibre8">LDA is a generative probabilistic model that tries to find groups of words that appear frequently together across different documents. These frequently appearing words represent our topics, assuming that each document is a mixture of different words. The input to an LDA is the bag-of-words model we discussed earlier in this chapter. Given a bag-of-words matrix as input, LDA decomposes it into two new matrices:</p><div class="book"><ul class="itemizedlist"><li class="listitem">A document to topic matrix</li><li class="listitem">A word to topic matrix</li></ul></div><p class="calibre8">LDA decomposes the bag-of-words matrix in such a way that if we multiply those two matrices together, we would be able to reproduce the input, the bag-of-words matrix, with the lowest possible error. In practice, we are interested in those topics that LDA found in the bag-of-words<a id="calibre_link-1692" class="calibre1"></a> matrix. The <a id="calibre_link-1693" class="calibre1"></a>only downside may be that we must define the number of topics beforehand&mdash;the number of topics is a hyperparameter of LDA that has to be specified manually.</p></div></div></div>

<div id="calibre_link-636" class="calibre">
<div class="book" title="Topic modeling with Latent Dirichlet Allocation">
<div class="book" title="LDA with scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1694"><a id="calibre_link-330" class="calibre1"></a>LDA with scikit-learn</h2></div></div></div><p class="calibre8">In this subsection, we<a id="calibre_link-1695" class="calibre1"></a> will use the <code class="email">LatentDirichletAllocation</code> class implemented in scikit-learn to decompose the movie review dataset and categorize it into different topics. In the following example, we restrict the analysis to 10 different topics, but readers are encouraged to experiment with the hyperparameters of the algorithm to explore the topics that can be found in this dataset further.</p><p class="calibre8">First, we are going to load the dataset into a pandas <code class="email">DataFrame</code> using the local <code class="email">movie_data.csv</code> file of the movie reviews that we have created at the beginning of this chapter:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv('movie_data.csv', encoding='utf-8')</pre></div><p class="calibre8">Next, we are going to use the already familiar <code class="email">CountVectorizer</code> to create the bag-of-words matrix as input to the LDA. For convenience, we will use scikit-learn's built-in English stop word library via <code class="email">stop_words='english'</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.feature_extraction.text import CountVectorizer
&gt;&gt;&gt; count = CountVectorizer(stop_words='english',
...                         max_df=.1,
...                         max_features=5000)
&gt;&gt;&gt; X = count.fit_transform(df['review'].values)</pre></div><p class="calibre8">Notice that we set the maximum document frequency of words to be considered to 10 percent (<code class="email">max_df=.1</code>) to exclude words that occur too frequently across documents. The rationale behind the removal of frequently occurring words is that these might be common words appearing across all documents and are therefore less likely associated with a specific topic category of a given document. Also, we limited the number of words to be considered to the most frequently occurring 5,000 words (<code class="email">max_features=5000</code>), to limit the dimensionality of this dataset so that it improves the inference performed by LDA. However, both <code class="email">max_df=.1</code> and <code class="email">max_features=5000</code> are hyperparameter values that I chose arbitrarily, and readers are encouraged to tune them while comparing the results.</p><p class="calibre8">The following code example demonstrates how to fit a <code class="email">LatentDirichletAllocation</code> estimator to the bag-of-words matrix and infer the 10 different topics from the documents (note that the model fitting can take up to five minutes or more on a laptop or standard desktop computer):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.decomposition import LatentDirichletAllocation
&gt;&gt;&gt; lda = LatentDirichletAllocation(n_topics=10,
...                                 random_state=123,
...                                 learning_method='batch')
&gt;&gt;&gt; X_topics = lda.fit_transform(X)</pre></div><p class="calibre8">By setting <code class="email">learning_method='batch'</code>, we let the <code class="email">lda</code> estimator do its estimation based on all available training data (the bag-of-words matrix) in one iteration, which is slower than the alternative <code class="email">'online'</code> learning method but can lead to more accurate results (setting <code class="email">learning_method='online'</code> is analogous<a id="calibre_link-1696" class="calibre1"></a> to online or mini-batch learning that we discussed in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification,</em></span> and in this chapter).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1697" class="calibre1"></a>Note</h3><p class="calibre8">The scikit-learn library's implementation of LDA uses the <span class="strong"><strong class="calibre2">Expectation-Maximization</strong></span> (<span class="strong"><strong class="calibre2">EM</strong></span>) algorithm<a id="calibre_link-1698" class="calibre1"></a> to update its parameter estimates iteratively. We haven't discussed the EM algorithm in this <a id="calibre_link-1699" class="calibre1"></a>chapter, but if you are curious to learn more, please see the excellent overview on Wikipedia (<a class="calibre1" href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">https://en.wikipedia.org/wiki/Expectation&ndash;maximization_algorithm</a>) and the detailed tutorial on how it is used in LDA in Colorado Reed's tutorial, <span class="strong"><em class="calibre9">Latent Dirichlet Allocation: Towards a Deeper Understanding</em></span>, which is freely available at <a class="calibre1" href="http://obphio.us/pdfs/lda_tutorial.pdf">http://obphio.us/pdfs/lda_tutorial.pdf</a>.</p></div><p class="calibre8">After fitting the LDA, we now have access to the <code class="email">components_</code> attribute of the <code class="email">lda</code> instance, which stores a matrix containing the word importance (here, <code class="email">5000</code>) for each of the 10 topics in increasing order:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lda.components_.shape
(10, 5000)</pre></div><p class="calibre8">To analyze the results, let's print the five most important words for each of the 10 topics. Note that the word importance values are ranked in increasing order. Thus, to print the top five words, we need to sort the <code class="email">topic</code> array in reverse order:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; n_top_words = 5
&gt;&gt;&gt; feature_names = count.get_feature_names()
&gt;&gt;&gt; for topic_idx, topic in enumerate(lda.components_):
...     print("Topic %d:" % (topic_idx + 1))
...     print(" ".join([feature_names[i]
...                     for i in topic.argsort()\
...                         [:-n_top_words - 1:-1]]))</pre></div><div class="informalexample"><pre class="programlisting">Topic 1:
worst minutes awful script stupid
Topic 2:
family mother father children girl
Topic 3:
american war dvd music tv
Topic 4:
human audience cinema art sense
Topic 5:
police guy car dead murder
Topic 6:
horror house sex girl woman
Topic 7:
role performance comedy actor performances
Topic 8:
series episode war episodes tv
Topic 9:
book version original read novel
Topic 10:
action fight guy guys cool</pre></div><p class="calibre8">Based on reading the<a id="calibre_link-1700" class="calibre1"></a> five most important words for each topic, we may guess that the LDA identified the following topics:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Generally bad movies (not really a topic category)</li><li class="listitem" value="2">Movies about families</li><li class="listitem" value="3">War movies</li><li class="listitem" value="4">Art movies</li><li class="listitem" value="5">Crime movies</li><li class="listitem" value="6">Horror movies</li><li class="listitem" value="7">Comedy movies</li><li class="listitem" value="8">Movies somehow related to TV shows</li><li class="listitem" value="9">Movies based on books</li><li class="listitem" value="10">Action movies</li></ol><div class="calibre13"></div></div><p class="calibre8">To confirm that the categories make sense based on the reviews, let's plot three movies from the horror movie category (horror movies belong to category 6 at index position <code class="email">5</code>):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; horror = X_topics[:, 5].argsort()[::-1]
&gt;&gt;&gt; for iter_idx, movie_idx in enumerate(horror[:3]):
...     print('\nHorror movie #%d:' % (iter_idx + 1))
...     print(df['review'][movie_idx][:300], '...')
Horror movie #1:
House of Dracula works from the same basic premise as House of Frankenstein from the year before; namely that Universal's three most famous monsters; Dracula, Frankenstein's Monster and The Wolf Man are appearing in the movie together. Naturally, the film is rather messy therefore, but the fact that ...

Horror movie #2:
Okay, what the hell kind of TRASH have I been watching now? "The Witches' Mountain" has got to be one of the most incoherent and insane Spanish exploitation flicks ever and yet, at the same time, it's also strangely compelling. There's absolutely nothing that makes sense here and I even doubt there  ...

Horror movie #3:
&lt;br /&gt;&lt;br /&gt;Horror movie time, Japanese style. Uzumaki/Spiral was a total freakfest from start to finish. A fun freakfest at that, but at times it was a tad too reliant on kitsch rather than the horror. The story is difficult to summarize succinctly: a carefree, normal teenage girl starts coming fac ...</pre></div><p class="calibre8">Using the preceding<a id="calibre_link-1701" class="calibre1"></a> code example, we printed the first 300 characters from the top three horror movies, and we can see that the reviews&mdash;even though we don't know which exact movie they belong to&mdash;sound like reviews of horror movies (however, one might argue that <code class="email">Horror movie #2</code> could also be a good fit for topic category 1: <span class="strong"><em class="calibre9">Generally bad movies</em></span>).</p></div></div></div>

<div id="calibre_link-657" class="calibre"><div class="book" title="Summary" id="calibre_link-331"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1702"><a id="calibre_link-1703" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, we learned how to use machine learning algorithms to classify text documents based on their polarity, which is a basic task in sentiment analysis in the field of NLP. Not only did we learn how to encode a document as a feature vector using the bag-of-words model, but we also learned how to weight the term frequency by relevance using tf-idf.</p><p class="calibre8">Working with text data can be computationally quite expensive due to the large feature vectors that are created during this process; in the last section, we learned how to utilize out-of-core or incremental learning to train a machine learning algorithm without loading the whole dataset into a computer's memory.</p><p class="calibre8">Lastly, we introduced the concept of topic modeling using LDA to categorize the movie reviews into different categories in unsupervised fashion.</p><p class="calibre8">In the next chapter, we will use our document classifier and learn how to embed it into a web application.</p></div></div>

<div id="calibre_link-54" class="calibre">
<div id="calibre_link-1704" class="calibre10"></div><div class="book" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application"><div class="book" id="calibre_link-40"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1705"><a id="calibre_link-1706" class="calibre1"></a>Chapter&nbsp;9.&nbsp;Embedding a Machine Learning Model into a Web Application</h1></div></div></div><p class="calibre8">In the previous chapters, you learned about the many different machine learning concepts and algorithms that can help us with better and more efficient decision-making. However, machine learning techniques are not limited to offline applications and analysis, and they can be the predictive engine of your web services. For example, popular and useful applications of machine learning models in web applications include spam detection in submission forms, search engines, recommendation systems for media or shopping portals, and many more.</p><p class="calibre8">In this chapter, you will learn how to embed a machine learning model into a web application that can not only classify, but also learn from data in real time. The topics that we will cover are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Saving the current state of a trained machine learning model</li><li class="listitem">Using SQLite databases for data storage</li><li class="listitem">Developing a web application using the popular Flask web framework</li><li class="listitem">Deploying a machine learning application to a public web server</li></ul></div></div></div>

<div id="calibre_link-61" class="calibre">
<div class="book" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application">
<div class="book" title="Serializing fitted scikit-learn estimators"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1707"><a id="calibre_link-332" class="calibre1"></a>Serializing fitted scikit-learn estimators</h1></div></div></div><p class="calibre8">Training a machine<a id="calibre_link-1708" class="calibre1"></a> learning model can be computationally quite expensive, as we have seen in <a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span>. Surely we don't want to train our model every time we close our Python interpreter and want to make a new prediction or reload our web application? One option for model persistence is <a id="calibre_link-1709" class="calibre1"></a>Python's in-built <code class="email">pickle</code> module (<a class="calibre1" href="https://docs.python.org/3.6/library/pickle.html">https://docs.python.org/3.6/library/pickle.html</a>), which allows us to serialize and deserialize Python object structures to compact bytecode so that we can save our classifier in its current state and reload it if we want to classify new samples, without needing the model to learn from the training data all over again. Before you execute the following code, please make sure that you have trained the out-of-core logistic regression model from the last section of <a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span> and have it ready in your current Python session:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pickle
&gt;&gt;&gt; import os
&gt;&gt;&gt; dest = os.path.join('movieclassifier', 'pkl_objects')
&gt;&gt;&gt; if not os.path.exists(dest):
...     os.makedirs(dest)

&gt;&gt;&gt; pickle.dump(stop,
...          open(os.path.join(dest, 'stopwords.pkl'),'wb'),
...          protocol=4)
&gt;&gt;&gt; pickle.dump(clf,
...          open(os.path.join(dest, 'classifier.pkl'), 'wb'),
...          protocol=4)</pre></div><p class="calibre8">Using the preceding code, <a id="calibre_link-1710" class="calibre1"></a>we created a <code class="email">movieclassifier</code> directory where we will later store the files and data for our web application. Within this <code class="email">movieclassifier</code> directory, we created a <code class="email">pkl_objects</code> subdirectory to save the serialized Python objects to our local drive. Via the <code class="email">dump</code> method of the <code class="email">pickle</code> module, we then serialized the trained logistic regression model as well as the stop word set from the <span class="strong"><strong class="calibre2">Natural Language Toolkit</strong></span> (<span class="strong"><strong class="calibre2">NLTK</strong></span>)<a id="calibre_link-1711" class="calibre1"></a> library, so that we don't have to install the NLTK vocabulary on our server.</p><p class="calibre8">The <code class="email">dump</code> method takes as its first argument the object that we want to pickle, and for the second argument we provided an open file object that the Python object will be written to. Via the <code class="email">wb</code> argument inside the <code class="email">open</code> function, we opened the file in binary mode for pickle, and we set <code class="email">protocol=4</code> to choose the latest and most efficient pickle protocol that has been added to Python 3.4, which is compatible with Python 3.4 or newer. If you have problems using <code class="email">protocol=4</code>, please check whether you are using the latest Python 3 version. Alternatively, you may consider choosing a lower protocol number.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1712" class="calibre1"></a>Note</h3><p class="calibre8">Our logistic regression model contains several NumPy arrays, such as the weight vector, and a more efficient way to serialize NumPy arrays is to use the alternative <code class="email">joblib</code> library. To ensure compatibility with the server environment that we will use in later sections, we will use the standard pickle approach. If you are interested, you can find more <a id="calibre_link-1713" class="calibre1"></a>information about <code class="email">joblib</code> at <a class="calibre1" href="http://pythonhosted.org/joblib/">http://pythonhosted.org/joblib/</a>.</p></div><p class="calibre8">We don't need to pickle <code class="email">HashingVectorizer</code>, since it does not need to be fitted. Instead, we can create a new Python script file from which we can import the vectorizer into our current Python session. Now, copy the following code and save it as <code class="email">vectorizer.py</code> in the <code class="email">movieclassifier</code> directory:</p><div class="informalexample"><pre class="programlisting">from sklearn.feature_extraction.text import HashingVectorizer
import re
import os
import pickle

cur_dir = os.path.dirname(__file__)
stop = pickle.load(open(
               os.path.join(cur_dir,
               'pkl_objects',
               'stopwords.pkl'), 'rb'))

def tokenizer(text):
    text = re.sub('&lt;[^&gt;]*&gt;', '', text)
    emoticons = re.findall('(?::|;|=)(?:-)?(?:\)|\(|D|P)',
                           text.lower())
    text = re.sub('[\W]+', ' ', text.lower()) \
                  + ' '.join(emoticons).replace('-', '')
    tokenized = [w for w in text.split() if w not in stop]
    return tokenized

vect = HashingVectorizer(decode_error='ignore',
                         n_features=2**21,
                         preprocessor=None,
                         tokenizer=tokenizer)</pre></div><p class="calibre8">After we have<a id="calibre_link-1714" class="calibre1"></a> pickled the Python objects and created the <code class="email">vectorizer.py</code> file, it would now be a good idea to restart our Python interpreter or IPython Notebook kernel to test if we can deserialize the objects without error.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1715" class="calibre1"></a>Note</h3><p class="calibre8">However, please note that unpickling data from an untrusted source can be a potential security risk, since the <code class="email">pickle</code> module is not secured against malicious code. Since <code class="email">pickle</code> was designed to serialize arbitrary objects, the unpickling process will execute code that has been stored in a pickle file. Thus, if you receive pickle files from an untrusted source (for example, by downloading them from the internet), please proceed with extra care and unpickle the items in a virtual environment and/or on a non-essential machine that does not store important data that no one except you should have access to.</p></div><p class="calibre8">From your Terminal, navigate to the <code class="email">movieclassifier</code> directory, start a new Python session and execute the following code to verify that you can import the <code class="email">vectorizer</code> and unpickle the classifier:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pickle
&gt;&gt;&gt; import re
&gt;&gt;&gt; import os
&gt;&gt;&gt; from vectorizer import vect
&gt;&gt;&gt; clf = pickle.load(open(
...        os.path.join('pkl_objects',
...                     'classifier.pkl'), 'rb'))</pre></div><p class="calibre8">After we have <a id="calibre_link-1716" class="calibre1"></a>successfully loaded the <code class="email">vectorizer</code> and unpickled the classifier, we can now use these objects to preprocess document samples and make predictions about their sentiment:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; label = {0:'negative', 1:'positive'}

&gt;&gt;&gt; example = ['I love this movie']
&gt;&gt;&gt; X = vect.transform(example)
&gt;&gt;&gt; print('Prediction: %s\nProbability: %.2f%%' %\
...       (label[clf.predict(X)[0]],
...        np.max(clf.predict_proba(X))*100))
Prediction: positive
Probability: 91.56%</pre></div><p class="calibre8">Since our classifier returns the class labels as integers, we defined a simple Python dictionary to map these integers to their sentiment. We then used <code class="email">HashingVectorizer</code> to transform the simple example document into a word vector <code class="email">X</code>. Finally, we used the <code class="email">predict</code> method of the logistic regression classifier to predict the class label, as well as the <code class="email">predict_proba</code> method to return the corresponding probability of our prediction. Note that the <code class="email">predict_proba</code> method call returns an array with a probability value for each unique class label. Since the class label with the largest probability corresponds to the class label that is returned by the <code class="email">predict</code> call, we used the <code class="email">np.max</code> function to return the probability of the predicted class.</p></div></div></div>

<div id="calibre_link-98" class="calibre"><div class="book" title="Setting up an SQLite database for data storage" id="calibre_link-108"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1717"><a id="calibre_link-1718" class="calibre1"></a>Setting up an SQLite database for data storage</h1></div></div></div><p class="calibre8">In this section, we will <a id="calibre_link-1719" class="calibre1"></a>set up a simple SQLite database to <a id="calibre_link-1720" class="calibre1"></a>collect optional feedback about the predictions from users of the web application. We can use this feedback to update our classification model. SQLite is an open source SQL database engine that doesn't require a separate server to operate, which makes it ideal for smaller projects and simple web applications. Essentially, a SQLite database can be understood as a single, self-contained database file that allows us to directly access storage files.</p><p class="calibre8">Furthermore, SQLite doesn't require any system-specific configuration and is supported by all common operating systems. It has gained a reputation for being very reliable as it is used by popular companies such as Google, Mozilla, Adobe, Apple, Microsoft, and many more. If you want to<a id="calibre_link-1721" class="calibre1"></a> learn more about SQLite, I recommend you visit the official website at <a class="calibre1" href="http://www.sqlite.org">http://www.sqlite.org</a>.</p><p class="calibre8">Fortunately, following<a id="calibre_link-1722" class="calibre1"></a> Python's <span class="strong"><em class="calibre9">batteries included </em></span>philosophy, there<a id="calibre_link-1723" class="calibre1"></a> is already an API in the Python standard library, <code class="email">sqlite3</code>, which <a id="calibre_link-1724" class="calibre1"></a>allows us to work with SQLite databases (for more information about <code class="email">sqlite3</code>, please visit <a class="calibre1" href="https://docs.python.org/3.6/library/sqlite3.html">https://docs.python.org/3.6/library/sqlite3.html</a>).</p><p class="calibre8">By executing the following code, we will create a new SQLite database inside the <code class="email">movieclassifier</code> directory and store two example movie reviews:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import sqlite3
&gt;&gt;&gt; import os

&gt;&gt;&gt; if os.path.exists('reviews.sqlite'):
...     os.remove('reviews.sqlite')
&gt;&gt;&gt; conn = sqlite3.connect('reviews.sqlite')
&gt;&gt;&gt; c = conn.cursor()
&gt;&gt;&gt; c.execute('CREATE TABLE review_db'\
...           ' (review TEXT, sentiment INTEGER, date TEXT)')

&gt;&gt;&gt; example1 = 'I love this movie'
&gt;&gt;&gt; c.execute("INSERT INTO review_db"\
...           " (review, sentiment, date) VALUES"\
...           " (?, ?, DATETIME('now'))", (example1, 1))

&gt;&gt;&gt; example2 = 'I disliked this movie'
&gt;&gt;&gt; c.execute("INSERT INTO review_db"\
...           " (review, sentiment, date) VALUES"\
...           " (?, ?, DATETIME('now'))", (example2, 0))
&gt;&gt;&gt; conn.commit()
&gt;&gt;&gt; conn.close()</pre></div><p class="calibre8">Following the preceding code example, we created a connection (<code class="email">conn</code>) to a SQLite database file by calling the <code class="email">connect</code> method of the <code class="email">sqlite3</code> library, which created the new database file <code class="email">reviews.sqlite</code> in the <code class="email">movieclassifier</code> directory if it didn't already exist. Please note that SQLite doesn't implement a replace function for existing tables; you need to delete the database file manually from your file browser if you want to execute the code a second time.</p><p class="calibre8">Next, we created a cursor via the <code class="email">cursor</code> method, which allows us to traverse over the database records using the versatile SQL syntax. Via the first <code class="email">execute</code> call, we then created a new database table, <code class="email">review_db</code>. We used this to store and access database entries. Along with <code class="email">review_db</code>, we also created three columns in this database table: <code class="email">review</code>, <code class="email">sentiment</code>, and <code class="email">date</code>. We used these to store two example movie reviews and respective class labels (sentiments).</p><p class="calibre8">Using the <code class="email">DATETIME('now')</code> SQL command, we also added date and timestamps to our entries. In addition to the timestamps, we used the question mark symbols (<code class="email">?</code>) to pass the movie review texts (<code class="email">example1</code> and <code class="email">example2</code>) and the corresponding class labels (<code class="email">1</code> and <code class="email">0</code>) as positional arguments to the <code class="email">execute</code> method, as members of a tuple. Lastly, we called the <code class="email">commit</code> method to save the changes that we made to the database and closed the connection via the <code class="email">close</code> method.</p><p class="calibre8">To check if the entries<a id="calibre_link-1725" class="calibre1"></a> have been stored in the database table <a id="calibre_link-1726" class="calibre1"></a>correctly, we will now reopen the connection to the database and use the SQL <code class="email">SELECT</code> command to fetch all rows in the database table that have been committed between the beginning of the year 2017 and today:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; conn = sqlite3.connect('reviews.sqlite')
&gt;&gt;&gt; c = conn.cursor()
&gt;&gt;&gt; c.execute("SELECT * FROM review_db WHERE date"\
...     " BETWEEN '2017-01-01 00:00:00' AND DATETIME('now')")
&gt;&gt;&gt; results = c.fetchall()

&gt;&gt;&gt; conn.close()
&gt;&gt;&gt; print(results)
[('I love this movie', 1, '2017-04-24 00:14:38'), 
 ('I disliked this movie', 0, '2017-04-24 00:14:38')</pre></div><p class="calibre8">Alternatively, we could also use the free Firefox browser plugin<a id="calibre_link-1727" class="calibre1"></a> SQLite Manager (available at <a class="calibre1" href="https://addons.mozilla.org/en-US/firefox/addon/sqlite-manager/">https://addons.mozilla.org/en-US/firefox/addon/sqlite-manager/</a>), which offers a nice GUI interface for working with SQLite databases, as shown in the following figure:</p><div class="mediaobject"><img src="images/00662.jpeg" alt="Setting up an SQLite database for data storage" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-131" class="calibre">
<div id="calibre_link-1728" class="calibre10"></div><div class="book" title="Developing a web application with Flask"><div class="book" id="calibre_link-67"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1729"><a id="calibre_link-1730" class="calibre1"></a>Developing a web application with Flask</h1></div></div></div><p class="calibre8">Having prepared the code <a id="calibre_link-1731" class="calibre1"></a>for classifying movie reviews in the previous <a id="calibre_link-1732" class="calibre1"></a>subsection, let's discuss the basics of the Flask web framework to develop our web application. After Armin Ronacher's initial release of Flask in 2010, the framework has gained huge popularity over the years, and examples of popular applications that make use of Flask include LinkedIn and Pinterest. Since Flask is written in Python, it provides us Python programmers with a convenient interface for embedding existing Python code, such as our movie classifier.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1733" class="calibre1"></a>Note</h3><p class="calibre8">Flask is also<a id="calibre_link-1734" class="calibre1"></a> known as a <span class="strong"><strong class="calibre2">microframework</strong></span>, which means that its core is kept lean and simple but can<a id="calibre_link-1735" class="calibre1"></a> be easily extended with other libraries. Although the learning curve of the lightweight Flask API is not nearly as steep as those of other popular Python web frameworks, such as Django, I encourage you to take a look at the official<a id="calibre_link-1736" class="calibre1"></a> Flask documentation at <a class="calibre1" href="http://flask.pocoo.org/docs/0.12/">http://flask.pocoo.org/docs/0.12/</a> to learn more about its functionality.</p></div><p class="calibre8">If the Flask library is not already installed in your current Python environment, you can simply install it via <code class="email">conda</code> or <code class="email">pip</code> from your Terminal (at the time of writing, the latest stable release was version 0.12.1):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">conda install flask</strong></span>
<span class="strong"><strong class="calibre2"># or: pip install flask</strong></span>
</pre></div></div></div>

<div id="calibre_link-155" class="calibre">
<div class="book" title="Developing a web application with Flask">
<div class="book" title="Our first Flask web application"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1737"><a id="calibre_link-333" class="calibre1"></a>Our first Flask web application</h2></div></div></div><p class="calibre8">In this subsection, we will develop a <a id="calibre_link-1738" class="calibre1"></a>very simple web application to become more familiar with the Flask API before we implement our movie classifier. This first application we are going to build consists of a simple web page with a form field that lets us enter a name. After submitting the name to the web application, it will render it on a new page. While this is a very simple example of a web application, it helps with building intuition about how to store and pass variables and values between the different parts of our code within the Flask framework.</p><p class="calibre8">First, we create a directory tree:</p><div class="informalexample"><pre class="programlisting">1st_flask_app_1/
    app.py
    templates/
        first_app.html</pre></div><p class="calibre8">The <code class="email">app.py</code> file will contain the main code that will be executed by the Python interpreter to run the Flask web application. The <code class="email">templates</code> directory is the directory in which Flask will look for static HTML files for rendering in the web browser. Let's now take a look at the contents of <code class="email">app.py</code>:</p><div class="informalexample"><pre class="programlisting">from flask import Flask, render_template

app = Flask(__name__)
@app.route('/')
def index():
   return render_template('first_app.html')

if __name__ == '__main__':
   app.run()</pre></div><p class="calibre8">After looking at the previous code example, let's discuss the individual pieces step by step:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">We ran our <a id="calibre_link-1739" class="calibre1"></a>application as a single module; thus we initialized a new Flask instance with the argument <code class="email">__name__</code> to let Flask know that it can find the HTML template folder (<code class="email">templates</code>) in the same directory where it is located.</li><li class="listitem" value="2">Next, we used the route decorator (<code class="email">@app.route('/')</code>) to specify the URL that should trigger the execution of the <code class="email">index</code> function.</li><li class="listitem" value="3">Here, our <code class="email">index</code> function simply rendered the <code class="email">first_app.html</code> HTML file, which is located in the <code class="email">templates</code> folder.</li><li class="listitem" value="4">Lastly, we used the <code class="email">run</code> function to only run the application on the server when this script is directly executed by the Python interpreter, which we ensured using the <code class="email">if</code> statement with<code class="email"> __name__ == '__main__'</code>.</li></ol><div class="calibre13"></div></div><p class="calibre8">Now, let's take a look at the contents of the <code class="email">first_app.html</code> file:</p><div class="informalexample"><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;First app&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div&gt;Hi, this is my first Flask web app!&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1740" class="calibre1"></a>Note</h3><p class="calibre8">If you are not familiar with the HTML syntax yet, I recommend you visit <a class="calibre1" href="https://developer.mozilla.org/en-US/docs/Web/HTML">https://developer.mozilla.org/en-US/docs/Web/HTML</a> for useful tutorials for learning the basics of HTML.</p></div><p class="calibre8">Here, we have simply filled an empty HTML template file with a <code class="email">&lt;div&gt;</code> element (a block level element) that contains this sentence: <code class="email">Hi, this is my first Flask web app!</code>.</p><p class="calibre8">Conveniently, Flask allows us to run our applications locally, which is useful for developing and testing web applications before we deploy them on a public web server. Now, let's start our web application by executing the command from the Terminal inside the <code class="email">1st_flask_app_1</code> directory:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">python3 app.py</strong></span>
</pre></div><p class="calibre8">We should see a line such <a id="calibre_link-1741" class="calibre1"></a>as the following displayed in the Terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">* Running on http://127.0.0.1:5000/</strong></span>
</pre></div><p class="calibre8">This line contains the address of our local server. We can enter this address in our web browser to see the web application in action. If everything has executed correctly, we should see a simple website with the content <code class="email">Hi, this is my first Flask web app!</code> as shown in the following figure:</p><div class="mediaobject"><img src="images/00213.jpeg" alt="Our first Flask web application" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-174" class="calibre">
<div class="book" title="Developing a web application with Flask">
<div class="book" title="Form validation and rendering"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1742"><a id="calibre_link-334" class="calibre1"></a>Form validation and rendering</h2></div></div></div><p class="calibre8">In this subsection, we will<a id="calibre_link-1743" class="calibre1"></a> extend our simple Flask web application<a id="calibre_link-1744" class="calibre1"></a> with HTML form elements to learn how to collect data from a user using the<a id="calibre_link-1745" class="calibre1"></a> WTForms library (<a class="calibre1" href="https://wtforms.readthedocs.org/en/latest/">https://wtforms.readthedocs.org/en/latest/</a>), which can be installed via <code class="email">conda</code> or <code class="email">pip</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">conda install wtforms</strong></span>
<span class="strong"><strong class="calibre2"># or pip install wtforms</strong></span>
</pre></div><p class="calibre8">This web application will prompt a user to type in his or her name into a text field, as shown in the following screenshot:</p><div class="mediaobject"><img src="images/00227.jpeg" alt="Form validation and rendering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">After the submission <a id="calibre_link-1746" class="calibre1"></a>button (<span class="strong"><strong class="calibre2">Say Hello</strong></span>) has been clicked and the<a id="calibre_link-1747" class="calibre1"></a> form is validated, a new HTML page will be rendered to display the user's name:</p><div class="mediaobject"><img src="images/00844.jpeg" alt="Form validation and rendering" class="calibre11" /></div><p class="calibre12"> </p><div class="book" title="Setting up the directory structure"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-335" class="calibre1"></a>Setting up the directory structure</h3></div></div></div><p class="calibre8">The new directory <a id="calibre_link-1748" class="calibre1"></a>structure that we need to set up for this application looks like this:</p><div class="informalexample"><pre class="programlisting">1st_flask_app_2/
       app.py
       static/
           style.css
       templates/
           _formhelpers.html
           first_app.html
           hello.html</pre></div><p class="calibre8">The following are the<a id="calibre_link-1749" class="calibre1"></a> contents of our modified <code class="email">app.py</code> file:</p><div class="informalexample"><pre class="programlisting">from flask import Flask, render_template, request
from wtforms import Form, TextAreaField, validators

app = Flask(__name__)

class HelloForm(Form):
    sayhello = TextAreaField('',[validators.DataRequired()])

@app.route('/')
def index():
    form = HelloForm(request.form)
    return render_template('first_app.html', form=form)

@app.route('/hello', methods=['POST'])
def hello():
    form = HelloForm(request.form)
    if request.method == 'POST' and form.validate():
        name = request.form['sayhello']
        return render_template('hello.html', name=name)
    return render_template('first_app.html', form=form)
if __name__ == '__main__':
    app.run(debug=True)</pre></div><p class="calibre8">Let's discuss what the previous code does step by step:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Using <code class="email">wtforms</code>, we extended the <code class="email">index</code> function with a text field that we will embed in our start page using the <code class="email">TextAreaField</code> class, which automatically checks whether a user has provided valid input text or not.</li><li class="listitem" value="2">Furthermore, we defined a new function, <code class="email">hello</code>, which will render an HTML page <code class="email">hello.html</code> after validating the HTML form.</li><li class="listitem" value="3">Here, we used the <code class="email">POST</code> method to transport the form data to the server in the message body. Finally, by setting the <code class="email">debug=True</code> argument inside the <code class="email">app.run</code> method, we further activated Flask's debugger. This is a useful feature for developing new web applications.</li></ol><div class="calibre13"></div></div></div><div class="book" title="Implementing a macro using the Jinja2 templating engine"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-336" class="calibre1"></a>Implementing a macro using the Jinja2 templating engine</h3></div></div></div><p class="calibre8">Now, we will<a id="calibre_link-1750" class="calibre1"></a> implement a generic macro in the <code class="email">_formhelpers.html</code> file via the Jinja2 templating engine, which we will later import in our <code class="email">first_app.html</code> file to render the text field:</p><div class="informalexample"><pre class="programlisting">{% macro render_field(field) %}
  &lt;dt&gt;{{ field.label }}
  &lt;dd&gt;{{ field(**kwargs)|safe }}
  {% if field.errors %}
    &lt;ul class=errors&gt;
    {% for error in field.errors %}
      &lt;li&gt;{{ error }}&lt;/li&gt;
    {% endfor %}
    &lt;/ul&gt;
  {% endif %}
  &lt;/dd&gt;
  &lt;/dt&gt;
{% endmacro %}</pre></div><p class="calibre8">An in-depth <a id="calibre_link-1751" class="calibre1"></a>discussion about the Jinja2 templating language is beyond the scope of this book. However, you can find a comprehensive documentation of <a id="calibre_link-1752" class="calibre1"></a>the Jinja2 syntax at <a class="calibre1" href="http://jinja.pocoo.org">http://jinja.pocoo.org</a>.</p></div><div class="book" title="Adding style via CSS"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-337" class="calibre1"></a>Adding style via CSS</h3></div></div></div><p class="calibre8">Next, we set up a<a id="calibre_link-1753" class="calibre1"></a> simple <span class="strong"><strong class="calibre2">Cascading Style Sheet</strong></span> (<span class="strong"><strong class="calibre2">CSS</strong></span>) file, <code class="email">style.css</code>, to demonstrate how the look and feel of HTML documents can be modified. We<a id="calibre_link-1754" class="calibre1"></a> have to save the following CSS file, which will simply double the font size of our HTML body elements, in a subdirectory called <code class="email">static</code>, which is the default directory where Flask looks for static files such as CSS. The file content is as follows:</p><div class="informalexample"><pre class="programlisting">body {
     font-size: 2em;
}</pre></div><p class="calibre8">The following are the contents of the modified <code class="email">first_app.html</code> file that will now render a text form where a user can enter a name:</p><div class="informalexample"><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;First app&lt;/title&gt;
      &lt;link rel="stylesheet" href="{{ url_for('static',
       filename='style.css') }}"&gt;
  &lt;/head&gt;
  &lt;body&gt;
    {% from "_formhelpers.html" import render_field %}
    &lt;div&gt;What's your name?&lt;/div&gt;
    &lt;form method=post action="/hello"&gt;
      &lt;dl&gt;
        {{ render_field(form.sayhello) }}
      &lt;/dl&gt;
      &lt;input type=submit value='Say Hello' name='submit_btn'&gt;
    &lt;/form&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div><p class="calibre8">In the header section of <code class="email">first_app.html</code>, we loaded the CSS file. It should now alter the size of all text elements in the HTML body. In the HTML body section, we imported the form macro from <code class="email">_formhelpers.html</code>, and we rendered the <code class="email">sayhello</code> form that we specified in the <code class="email">app.py</code> file. Furthermore, we added a button to the same form element so that a user can <a id="calibre_link-1755" class="calibre1"></a>submit the text field entry.</p></div><div class="book" title="Creating the result page"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-338" class="calibre1"></a>Creating the result page</h3></div></div></div><p class="calibre8">Lastly, we will create <a id="calibre_link-1756" class="calibre1"></a>a <code class="email">hello.html</code> file that will be rendered via the <code class="email">render_template('hello.html', name=name)</code> line return inside the <code class="email">hello</code> function, which we defined in the <code class="email">app.py</code> script to display the text that a user submitted via the text field. The file content is as follows:</p><div class="informalexample"><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;First app&lt;/title&gt;
      &lt;link rel="stylesheet" href="{{ url_for('static',
       filename='style.css') }}"&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div&gt;Hello {{ name }}&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div><p class="calibre8">Having set up our modified Flask web application, we can run it locally by executing the following command from the application's main directory, and we can view the result in our web browser at <code class="email">http://127.0.0.1:5000/</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">python3 app.py</strong></span>
</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1757" class="calibre1"></a>Note</h3><p class="calibre8">If you are new to web development, some of those concepts may seem very complicated at first sight. In that case, I encourage you to simply set up the preceding files in a directory on your hard drive and examine them closely. You will see that the Flask web framework is relatively straightforward and much simpler than it might initially appear! Also, for more help, don't forget to consult the excellent Flask documentation and examples at <a class="calibre1" href="http://flask.pocoo.org/docs/0.12/">http://flask.pocoo.org/docs/0.12/</a>.</p></div></div></div></div></div>

<div id="calibre_link-461" class="calibre">
<div id="calibre_link-1758" class="calibre10"></div><div class="book" title="Turning the movie review classifier into a web application"><div class="book" id="calibre_link-339"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1759"><a id="calibre_link-1760" class="calibre1"></a>Turning the movie review classifier into a web application</h1></div></div></div><p class="calibre8">Now that we are<a id="calibre_link-1761" class="calibre1"></a> somewhat familiar with the basics of Flask web development, let's advance to the next step and implement our movie classifier into a web application. In this section, we will develop a web application that will first prompt a user to enter a movie review, as shown in the following screenshot:</p><div class="mediaobject"><img src="images/00911.jpeg" alt="Turning the movie review classifier into a web application" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">After the review has been submitted, the user will see a new page that shows the predicted class label and the probability of the prediction. Furthermore, the user will be able to provide feedback about this prediction by clicking on the <span class="strong"><strong class="calibre2">Correct</strong></span> or <span class="strong"><strong class="calibre2">Incorrect</strong></span> button, as shown in the following screenshot:</p><div class="mediaobject"><img src="images/00255.jpeg" alt="Turning the movie review classifier into a web application" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">If a user clicked on<a id="calibre_link-1762" class="calibre1"></a> either the <span class="strong"><strong class="calibre2">Correct</strong></span> or <span class="strong"><strong class="calibre2">Incorrect</strong></span> button, our classification model will be updated with respect to the user's feedback. Furthermore, we will also store the movie review text provided by the user as well as the suggested class label, which can be inferred from the button click, in a SQLite database for future reference. (Alternatively, a user could skip the update step and click the <span class="strong"><strong class="calibre2">Submit another review</strong></span> button to submit another review.)</p><p class="calibre8">The third page that the user will see after clicking on one of the feedback buttons is a simple <span class="strong"><em class="calibre9">thank you </em></span>screen with a <span class="strong"><strong class="calibre2">Submit another review</strong></span> button that redirects the user back to the start page. This is shown in the following screenshot:</p><div class="mediaobject"><img src="images/00274.jpeg" alt="Turning the movie review classifier into a web application" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1763" class="calibre1"></a>Note</h3><p class="calibre8">Before we take a closer look at the code implementation of this web application, I encourage you to take a look at the live demo that I uploaded at <a class="calibre1" href="http://raschkas.pythonanywhere.com">http://raschkas.pythonanywhere.com</a> to get a better understanding of what we are trying to accomplish in this section.</p></div></div></div>

<div id="calibre_link-492" class="calibre">
<div class="book" title="Turning the movie review classifier into a web application">
<div class="book" title="Files and folders â looking at the directory tree"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1764"><a id="calibre_link-340" class="calibre1"></a>Files and folders &ndash; looking at the directory tree</h2></div></div></div><p class="calibre8">To start with <a id="calibre_link-1765" class="calibre1"></a>the big picture, let's take a look at the directory tree that we are going to create for this movie classification application, which is shown here:</p><div class="mediaobject"><img src="images/00125.jpeg" alt="Files and folders â looking at the directory tree" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the previous section of this chapter, we already created the <code class="email">vectorizer.py</code> file, the SQLite database <code class="email">reviews.sqlite</code>, and the <code class="email">pkl_objects</code> subdirectory with the pickled Python objects.</p><p class="calibre8">The <code class="email">app.py</code> file in the main directory is the Python script that contains our Flask code, and we will use the <code class="email">review.sqlite</code> database file (which we created earlier in this chapter) to store the movie reviews that are being submitted to our web application. The <code class="email">templates</code> subdirectory contains the HTML templates that will be rendered by Flask and displayed in the browser, and the <code class="email">static</code> subdirectory will contain a simple CSS file to adjust the look of the rendered HTML code.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1766" class="calibre1"></a>Note</h3><p class="calibre8">A separate directory containing the movie review classifier application with the code discussed in this section is provided with the code examples for this book, which you can either obtain directly from Packt or download from GitHub at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition/">https://github.com/rasbt/python-machine-learning-book-2nd-edition/</a>. The code in this section can be found in the<code class="email">.../code/ch09/movieclassifier</code> subdirectory.</p></div></div></div></div>

<div id="calibre_link-93" class="calibre">
<div class="book" title="Turning the movie review classifier into a web application">
<div class="book" title="Implementing the main application as app.py"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1767"><a id="calibre_link-341" class="calibre1"></a>Implementing the main application as app.py</h2></div></div></div><p class="calibre8">Since the <code class="email">app.py</code> file is<a id="calibre_link-1768" class="calibre1"></a> rather long, we will conquer it in two steps. The first section of <code class="email">app.py</code> imports the Python modules and objects that we are going to need, as well as the code to unpickle and set up our classification model:</p><div class="informalexample"><pre class="programlisting">from flask import Flask, render_template, request
from wtforms import Form, TextAreaField, validators
import pickle
import sqlite3
import os
import numpy as np

# import HashingVectorizer from local dir
from vectorizer import vect

app = Flask(__name__)

######## Preparing the Classifier
cur_dir = os.path.dirname(__file__)
clf = pickle.load(open(os.path.join(cur_dir,
                 'pkl_objects',
                 'classifier.pkl'), 'rb'))
db = os.path.join(cur_dir, 'reviews.sqlite')

def classify(document):
    label = {0: 'negative', 1: 'positive'}
    X = vect.transform([document])
    y = clf.predict(X)[0]
    proba = np.max(clf.predict_proba(X))
    return label[y], proba

def train(document, y):
    X = vect.transform([document])
    clf.partial_fit(X, [y])

def sqlite_entry(path, document, y):
    conn = sqlite3.connect(path)
    c = conn.cursor()
    c.execute("INSERT INTO review_db (review, sentiment, date)"\
    " VALUES (?, ?, DATETIME('now'))", (document, y))
    conn.commit()
    conn.close()</pre></div><p class="calibre8">This first part of the <code class="email">app.py</code> script should look very familiar to us by now. We simply imported the <code class="email">HashingVectorizer</code> and unpickled the logistic regression classifier. Next, we defined a <code class="email">classify</code> function to return the predicted class label as well as the corresponding probability prediction of a given text document. The <code class="email">train</code> function can be used to update the<a id="calibre_link-1769" class="calibre1"></a> classifier, given that a document and a class label are provided.</p><p class="calibre8">Using the <code class="email">sqlite_entry</code> function, we can store a submitted movie review in our SQLite database along with its class label and timestamp for our personal records. Note that the <code class="email">clf</code> object will be reset to its original, pickled state if we restart the web application. At the end of this chapter, you will learn how to use the data that we collect in the SQLite database to update the classifier permanently.</p><p class="calibre8">The concepts in the second part of the <code class="email">app.py</code> script should also look quite familiar to us:</p><div class="informalexample"><pre class="programlisting">######## Flask
class ReviewForm(Form):
    moviereview = TextAreaField('',
                                [validators.DataRequired(),
                                validators.length(min=15)])

@app.route('/')
def index():
    form = ReviewForm(request.form)
    return render_template('reviewform.html', form=form)

@app.route('/results', methods=['POST'])
def results():
    form = ReviewForm(request.form)
    if request.method == 'POST' and form.validate():
        review = request.form['moviereview']
        y, proba = classify(review)
        return render_template('results.html',
                                content=review,
                                prediction=y,
                                probability=round(proba*100, 2))
    return render_template('reviewform.html', form=form)

@app.route('/thanks', methods=['POST'])
def feedback():
    feedback = request.form['feedback_button']
    review = request.form['review']
    prediction = request.form['prediction']

    inv_label = {'negative': 0, 'positive': 1}
    y = inv_label[prediction]
    if feedback == 'Incorrect':
        y = int(not(y))
    train(review, y)
    sqlite_entry(db, review, y)
    return render_template('thanks.html')

if __name__ == '__main__':
    app.run(debug=True)</pre></div><p class="calibre8">We defined a <code class="email">ReviewForm</code> class that instantiates a <code class="email">TextAreaField</code>, which will be rendered in<a id="calibre_link-1770" class="calibre1"></a> the <code class="email">reviewform.html</code> template file (the landing page of our web application). This, in turn, is rendered by the <code class="email">index</code> function. With the <code class="email">validators.length(min=15)</code> parameter, we require the user to enter a review that contains at least 15 characters. Inside the <code class="email">results</code> function, we fetch the contents of the submitted web form and pass it on to our classifier to predict the sentiment of the movie classifier, which will then be displayed in the rendered <code class="email">results.html</code> template.</p><p class="calibre8">The <code class="email">feedback</code> function, which we implemented in <code class="email">app.py</code> in the previous subsection, may look a little bit complicated at first glance. It essentially fetches the predicted class label from the <code class="email">results.html</code> template if a user clicked on the <span class="strong"><strong class="calibre2">Correct</strong></span> or <span class="strong"><strong class="calibre2">Incorrect</strong></span> feedback button, and transforms the predicted sentiment back into an integer class label that will be used to update the classifier via the <code class="email">train</code> function, which we implemented in the first section of the <code class="email">app.py</code> script. Also, a new entry to the SQLite database will be made via the <code class="email">sqlite_entry</code> function if feedback was provided, and eventually the <code class="email">thanks.html</code> template will be rendered to thank the user for the feedback.</p></div></div></div>

<div id="calibre_link-101" class="calibre">
<div class="book" title="Turning the movie review classifier into a web application">
<div class="book" title="Setting up the review form"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1771"><a id="calibre_link-342" class="calibre1"></a>Setting up the review form</h2></div></div></div><p class="calibre8">Next, let's take a <a id="calibre_link-1772" class="calibre1"></a>look at the <code class="email">reviewform.html</code> template, which constitutes the starting page of our application:</p><div class="informalexample"><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Movie Classification&lt;/title&gt;
      &lt;link rel="stylesheet"
       href="{{ url_for('static', filename='style.css') }}"&gt;
  &lt;/head&gt;
  &lt;body&gt;

    &lt;h2&gt;Please enter your movie review:&lt;/h2&gt;

    {% from "_formhelpers.html" import render_field %}

    &lt;form method=post action="/results"&gt;
      &lt;dl&gt;
        {{ render_field(form.moviereview, cols='30', rows='10') }}
      &lt;/dl&gt;
      &lt;div&gt;
        &lt;input type=submit value='Submit review'
        name='submit_btn'&gt;
      &lt;/div&gt;
    &lt;/form&gt;

  &lt;/body&gt;
&lt;/html&gt;</pre></div><p class="calibre8">Here, we simply<a id="calibre_link-1773" class="calibre1"></a> imported the same <code class="email">_formhelpers.html</code> template that we defined in the <span class="strong"><em class="calibre9">Form validation and rendering</em></span> section earlier in this chapter. The <code class="email">render_field</code> function of this macro is used to render a <code class="email">TextAreaField</code> where a user can provide a movie review and submit it via the <span class="strong"><strong class="calibre2">Submit review</strong></span> button displayed at the bottom of the page. This <code class="email">TextAreaField</code> is 30 columns wide and 10 rows tall, and would look like this:</p><div class="mediaobject"><img src="images/00185.jpeg" alt="Setting up the review form" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-113" class="calibre">
<div class="book" title="Turning the movie review classifier into a web application">
<div class="book" title="Creating a results page template"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1774"><a id="calibre_link-343" class="calibre1"></a>Creating a results page template</h2></div></div></div><p class="calibre8">Our next <a id="calibre_link-1775" class="calibre1"></a>template, <code class="email">results.html</code>, looks a little bit more interesting:</p><div class="informalexample"><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Movie Classification&lt;/title&gt;
      &lt;link rel="stylesheet"
      href="{{ url_for('static', filename='style.css') }}"&gt;
  &lt;/head&gt;
  &lt;body&gt;

    &lt;h3&gt;Your movie review:&lt;/h3&gt;
    &lt;div&gt;{{ content }}&lt;/div&gt;

    &lt;h3&gt;Prediction:&lt;/h3&gt;
    &lt;div&gt;This movie review is &lt;strong&gt;{{ prediction }}&lt;/strong&gt;
    (probability: {{ probability }}%).&lt;/div&gt;

    &lt;div id='button'&gt;
      &lt;form action="/thanks" method="post"&gt;
        &lt;input type=submit value='Correct'
        name='feedback_button'&gt;
        &lt;input type=submit value='Incorrect'
        name='feedback_button'&gt;
        &lt;input type=hidden value='{{ prediction }}'
        name='prediction'&gt;
        &lt;input type=hidden value='{{ content }}' name='review'&gt;
      &lt;/form&gt;
    &lt;/div&gt;

    &lt;div id='button'&gt;
      &lt;form action="/"&gt;
       &lt;input type=submit value='Submit another review'&gt;
      &lt;/form&gt;
    &lt;/div&gt;

  &lt;/body&gt;
&lt;/html&gt;</pre></div><p class="calibre8">First, we <a id="calibre_link-1776" class="calibre1"></a>inserted the submitted review, as well as the results of the prediction, in the corresponding fields <code class="email">{{ content }}</code>, <code class="email">{{ prediction }}</code>, and <code class="email">{{ probability }}</code>. You may notice that we used the <code class="email">{{ content }}</code> and <code class="email">{{ prediction }}</code> placeholder variables a second time in the form that contains the <span class="strong"><strong class="calibre2">Correct</strong></span> and <span class="strong"><strong class="calibre2">Incorrect</strong></span> buttons. This is a workaround to <code class="email">POST</code> those values back to the server to update the classifier and store the review in case the user clicks on one of those two buttons.</p><p class="calibre8">Furthermore, we imported a CSS file (<code class="email">style.css</code>) at the beginning of the <code class="email">results.html</code> file. The setup of this file is quite simple; it limits the width of the contents of this web application to 600 pixels and moves the <span class="strong"><strong class="calibre2">Incorrect</strong></span> and <span class="strong"><strong class="calibre2">Correct</strong></span> buttons labeled with the div ID <code class="email">button</code> down by 20 pixels:</p><div class="informalexample"><pre class="programlisting">body{
  width:600px;
}

.button{
  padding-top: 20px;
}</pre></div><p class="calibre8">This CSS file is merely a placeholder, so please feel free to adjust it to adjust the look and feel of the web application to your liking.</p><p class="calibre8">The last HTML file we will implement for our web application is the <code class="email">thanks.html</code> template. As the name suggests, it simply provides a nice <span class="strong"><em class="calibre9">thank you </em></span>message to the user after providing feedback via the <span class="strong"><strong class="calibre2">Correct</strong></span> or <span class="strong"><strong class="calibre2">Incorrect</strong></span>
 button. Furthermore, we will put a <span class="strong"><strong class="calibre2">Submit another review</strong></span> button at the bottom of this page, which will redirect the user to the starting page. The contents of the <code class="email">thanks.html</code> file are as follows:</p><div class="informalexample"><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Movie Classification&lt;/title&gt;
      &lt;link rel="stylesheet"
      href="{{ url_for('static', filename='style.css') }}"&gt;
  &lt;/head&gt;
  &lt;body&gt;

    &lt;h3&gt;Thank you for your feedback!&lt;/h3&gt;

    &lt;div id='button'&gt;
      &lt;form action="/"&gt;
        &lt;input type=submit value='Submit another review'&gt;
      &lt;/form&gt;
    &lt;/div&gt;

  &lt;/body&gt;
&lt;/html&gt;</pre></div><p class="calibre8">Now, it would be a <a id="calibre_link-1777" class="calibre1"></a>good idea to start the web application locally from our Terminal via the following command before we advance to the next subsection and deploy it on a public web server:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">python3 app.py</strong></span>
</pre></div><p class="calibre8">After we have finished testing our application, we also shouldn't forget to remove the <code class="email">debug=True</code> argument in the <code class="email">app.run()</code> command of our <code class="email">app.py</code> script.</p></div></div></div>

<div id="calibre_link-569" class="calibre">
<div id="calibre_link-1778" class="calibre10"></div><div class="book" title="Deploying the web application to a public server" id="calibre_link-344"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1779"><a id="calibre_link-1780" class="calibre1"></a>Deploying the web application to a public server</h1></div></div></div><p class="calibre8">After we have tested the <a id="calibre_link-1781" class="calibre1"></a>web application locally, we are <a id="calibre_link-1782" class="calibre1"></a>now ready to deploy our web application onto a public web server. For this tutorial, we will be using the PythonAnywhere web hosting service, which specializes in the hosting of Python web applications and makes it extremely simple and hassle-free. Furthermore, PythonAnywhere offers a beginner account option that lets us run a single web application free of charge.</p></div></div>

<div id="calibre_link-119" class="calibre">
<div class="book" title="Deploying the web application to a public server" id="calibre_link-1783">
<div class="book" title="Creating a PythonAnywhere account"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1784"><a id="calibre_link-345" class="calibre1"></a>Creating a PythonAnywhere account</h2></div></div></div><p class="calibre8">To create a new PythonAnywhere account, we visit <a id="calibre_link-1785" class="calibre1"></a>the website<a id="calibre_link-1786" class="calibre1"></a> at <a class="calibre1" href="https://www.pythonanywhere.com/">https://www.pythonanywhere.com/</a> and click on the <span class="strong"><strong class="calibre2">Pricing &amp; signup</strong></span> link that is located in the top-right corner. Next, we click on the <span class="strong"><strong class="calibre2">Create a Beginner account</strong></span> button where we need to provide a username, password, and valid email address. After we have read and agreed to the terms and conditions, we should have a new account.</p><p class="calibre8">Unfortunately, the free beginner account doesn't allow us to access the remote server via the SSH protocol from our Terminal. Thus, we need to use the PythonAnywhere web interface to manage our web application. But before we can upload our local application files to the server, we need to create a new web application for our PythonAnywhere account. After we click on the <span class="strong"><strong class="calibre2">Dashboard</strong></span> button in the top-right corner, we have access to the control panel shown at the top of the page. Next, we click on the <span class="strong"><strong class="calibre2">Web</strong></span> tab that is now visible at the top of the page. We proceed by clicking on the <span class="strong"><strong class="calibre2">+Add a new web app</strong></span> button on the left, which lets us create a new Python 3.5 Flask web application that we name <code class="email">movieclassifier</code>.</p></div></div></div>

<div id="calibre_link-126" class="calibre">
<div class="book" title="Deploying the web application to a public server" id="calibre_link-1787">
<div class="book" title="Uploading the movie classifier application"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1788"><a id="calibre_link-346" class="calibre1"></a>Uploading the movie classifier application</h2></div></div></div><p class="calibre8">After creating a new <a id="calibre_link-1789" class="calibre1"></a>application for our PythonAnywhere account, we head over to the <span class="strong"><strong class="calibre2">Files</strong></span> tab, to upload the files from our local <code class="email">movieclassifier</code> directory using the PythonAnywhere web interface. After uploading the web application files that we created locally on our computer, we should have a <code class="email">movieclassifier</code> directory in our PythonAnywhere account. It contains the same directories and files as our local <code class="email">movieclassifier</code> directory has, as shown in the following screenshot:</p><div class="mediaobject"><img src="images/00296.jpeg" alt="Uploading the movie classifier application" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Lastly, we head over to the <span class="strong"><strong class="calibre2">Web</strong></span> tab one more time and click on the <span class="strong"><strong class="calibre2">Reload &lt;username&gt;.pythonanywhere.com</strong></span> button to propagate the changes and refresh our web application. Finally, <a id="calibre_link-1790" class="calibre1"></a>our web application should now be up and running and publicly available via <code class="email">&lt;username&gt;.pythonanywhere.com</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1791" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Troubleshooting</strong></span>
</p><p class="calibre8">Unfortunately, web servers can be quite sensitive to the tiniest problems in our web application. If you are experiencing problems with running the web application on PythonAnywhere and are receiving error messages in your browser, you can check the server and error logs, which can be accessed from the <span class="strong"><strong class="calibre2">Web</strong></span> tab in your PythonAnywhere account, to better diagnose the problem.</p></div></div></div></div>

<div id="calibre_link-135" class="calibre">
<div class="book" title="Deploying the web application to a public server" id="calibre_link-1792">
<div class="book" title="Updating the movie classifier"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1793"><a id="calibre_link-347" class="calibre1"></a>Updating the movie classifier</h2></div></div></div><p class="calibre8">While our predictive<a id="calibre_link-1794" class="calibre1"></a> model is updated on the fly whenever a user provides feedback about the classification, the updates to the <code class="email">clf</code> object will be reset if the web server crashes or restarts. If we reload the web application, the <code class="email">clf</code> object will be reinitialized from the <code class="email">classifier.pkl</code> pickle file. One option to apply the updates permanently would be to pickle the <code class="email">clf</code> object once again after each update. However, this would become computationally very inefficient with a growing number of users, and could corrupt the pickle file if users provide feedback simultaneously.</p><p class="calibre8">An alternative<a id="calibre_link-1795" class="calibre1"></a> solution is to update the predictive model from the feedback data that is being collected in the SQLite database. One option would be to download the SQLite database from the PythonAnywhere server, update the <code class="email">clf</code> object locally on our computer, and upload the new pickle file to PythonAnywhere. To update the classifier locally on our computer, we create an <code class="email">update.py</code> script file in the <code class="email">movieclassifier</code> directory with the following contents:</p><div class="informalexample"><pre class="programlisting">import pickle
import sqlite3
import numpy as np
import os

# import HashingVectorizer from local dir
from vectorizer import vect

def update_model(db_path, model, batch_size=10000):

    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    c.execute('SELECT * from review_db')

    results = c.fetchmany(batch_size)
    while results:
        data = np.array(results)
        X = data[:, 0]
        y = data[:, 1].astype(int)

        classes = np.array([0, 1])
        X_train = vect.transform(X)
        model.partial_fit(X_train, y, classes=classes)
        results = c.fetchmany(batch_size)

    conn.close()
    return model

cur_dir = os.path.dirname(__file__)

clf = pickle.load(open(os.path.join(cur_dir,
                  'pkl_objects',
                  'classifier.pkl'), 'rb'))
db = os.path.join(cur_dir, 'reviews.sqlite')

clf = update_model(db_path=db, model=clf, batch_size=10000)

# Uncomment the following lines if you are sure that
# you want to update your classifier.pkl file
# permanently.

# pickle.dump(clf, open(os.path.join(cur_dir,
#             'pkl_objects', 'classifier.pkl'), 'wb')
#             , protocol=4)</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1796" class="calibre1"></a>Note</h3><p class="calibre8">A separate directory containing the movie review classifier application with the update functionality discussed in this chapter comes with the code examples for this book, which you can either obtain directly from Packt or download from GitHub at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition/">https://github.com/rasbt/python-machine-learning-book-2nd-edition/</a>. The code in this section is located in the<code class="email">.../code/ch09/movieclassifier_with_update</code> subdirectory.</p></div><p class="calibre8">The <code class="email">update_model</code> function <a id="calibre_link-1797" class="calibre1"></a>will fetch entries from the SQLite database in batches of 10,000 entries at a time, unless the database contains fewer entries. Alternatively, we could also fetch one entry at a time by using <code class="email">fetchone</code> instead of <code class="email">fetchmany</code>, which would be computationally very inefficient. However, keep in mind that using the alternative <code class="email">fetchall</code> method could be a problem if we are working with large datasets that exceed the computer or server's memory capacity.</p><p class="calibre8">Now that we have created the <code class="email">update.py</code> script, we could also upload it to the <code class="email">movieclassifier</code> directory on PythonAnywhere, and import the <code class="email">update_model</code> function in the main application script <code class="email">app.py</code> to update the classifier from the SQLite database every time we restart the web application. In order to do so, we just need to add a line of code to import the <code class="email">update_model</code> function from the <code class="email">update.py</code> script at the top of <code class="email">app.py</code>:</p><div class="informalexample"><pre class="programlisting"># import update function from local dir
from update import update_model</pre></div><p class="calibre8">We then need to call the <code class="email">update_model</code> function in the main application body:</p><div class="informalexample"><pre class="programlisting">   ...
   if __name__ == '__main__':
       clf = update_model(db_path=db,
                          model=clf,  
                          batch_size=10000)
   ...</pre></div><p class="calibre8">As discussed, the modification in the previous code snippet will update the pickle file on PythonAnywhere. However, in practice, we do not often have to restart our web application, and it would make sense to validate the user feedback in the SQLite database prior to the update to make <a id="calibre_link-1798" class="calibre1"></a>sure the feedback is valuable information for the classifier.</p></div></div></div>

<div id="calibre_link-146" class="calibre"><div class="book" title="Summary" id="calibre_link-348"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1799"><a id="calibre_link-1800" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, you learned about many useful and practical topics that extend our knowledge of machine learning theory. You learned how to serialize a model after training and how to load it for later use cases. Furthermore, we created a SQLite database for efficient data storage and created a web application that lets us make our movie classifier available to the outside world.</p><p class="calibre8">Throughout this book, we have really discussed a lot about machine learning concepts, best practices, and supervised models for classification. In the next chapter, we will take a look at another subcategory of supervised learning, regression analysis, which lets us predict outcome variables on a continuous scale, in contrast to the categorical class labels of the classification models that we have been working with so far.</p></div></div>

<div id="calibre_link-660" class="calibre">
<div id="calibre_link-1801" class="calibre10"></div><div class="book" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" id="calibre_link-41"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1802"><a id="calibre_link-1803" class="calibre1"></a>Chapter&nbsp;10.&nbsp;Predicting Continuous Target Variables with Regression Analysis</h1></div></div></div><p class="calibre8">Throughout the previous chapters, you learned a lot about the main concepts behind <span class="strong"><strong class="calibre2">supervised learning</strong></span> and trained many different models for classification tasks to predict group memberships or categorical variables. In this chapter, we will dive into another subcategory of supervised learning: <span class="strong"><strong class="calibre2">regression analysis</strong></span>.</p><p class="calibre8">Regression models are used to predict target variables on a continuous scale, which makes them attractive for addressing many questions in science as well as applications in industry, such as understanding relationships between variables, evaluating trends, or making forecasts. One example would be predicting the sales of a company in future months.</p><p class="calibre8">In this chapter, we will discuss the main concepts of regression models and cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Exploring and visualizing datasets</li><li class="listitem">Looking at different approaches to implement linear regression models</li><li class="listitem">Training regression models that are robust to outliers</li><li class="listitem">Evaluating regression models and diagnosing common problems</li><li class="listitem">Fitting regression models to nonlinear data</li></ul></div></div></div>

<div id="calibre_link-45" class="calibre">
<div class="book" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" id="calibre_link-1804">
<div class="book" title="Introducing linear regression"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1805"><a id="calibre_link-349" class="calibre1"></a>Introducing linear regression</h1></div></div></div><p class="calibre8">The<a id="calibre_link-1806" class="calibre1"></a> goal of linear regression is to model the relationship between one or multiple features and a continuous target variable. As discussed in <a class="calibre1" title="ChapterÂ 1.Â Giving Computers the Ability to Learn from Data" href="#calibre_link-17">Chapter 1</a>, <span class="strong"><em class="calibre9">Giving Computers the Ability to Learn from Data</em></span>, regression analysis is a subcategory of supervised machine learning. In contrast to classification&mdash;another subcategory of supervised learning&mdash;regression analysis aims to predict outputs on a continuous scale rather than categorical class labels.</p><p class="calibre8">In the following<a id="calibre_link-1807" class="calibre1"></a> subsections, we will introduce the most basic type of linear regression, simple linear regression, and relate it to the more general, multivariate case (linear regression with multiple features).</p></div></div></div>

<div id="calibre_link-63" class="calibre">
<div class="book" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" id="calibre_link-1808">
<div class="book" title="Introducing linear regression">
<div class="book" title="Simple linear regression"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1809"><a id="calibre_link-350" class="calibre1"></a>Simple linear regression</h2></div></div></div><p class="calibre8">The goal <a id="calibre_link-1810" class="calibre1"></a>of simple (<span class="strong"><strong class="calibre2">univariate</strong></span>) linear<a id="calibre_link-1811" class="calibre1"></a> regression is to model the relationship between a single <a id="calibre_link-1812" class="calibre1"></a>feature (<span class="strong"><strong class="calibre2">explanatory variable</strong></span> <span class="strong"><em class="calibre9">x</em></span>) and a continuous valued <span class="strong"><strong class="calibre2">response</strong></span> (<span class="strong"><strong class="calibre2">target variable</strong></span> <span class="strong"><em class="calibre9">y</em></span>). The equation<a id="calibre_link-1813" class="calibre1"></a> of a<a id="calibre_link-1814" class="calibre1"></a> linear model with one<a id="calibre_link-1815" class="calibre1"></a> explanatory variable is defined as follows:</p><div class="mediaobject"><img src="images/00308.jpeg" alt="Simple linear regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, the weight <span class="strong"><img src="images/00347.jpeg" alt="Simple linear regression" class="calibre14" /></span> represents the <span class="strong"><em class="calibre9">y</em></span>-axis intercept and <span class="strong"><img src="images/00395.jpeg" alt="Simple linear regression" class="calibre14" /></span> is the weight coefficient of the explanatory variable. Our goal is to learn the weights of the linear equation to describe the relationship between the explanatory variable and the target variable, which can then be used to predict the responses of new explanatory variables that were not part of the training dataset.</p><p class="calibre8">Based on the linear equation that we defined previously, linear regression can be understood as finding the best-fitting straight line through the sample points, as shown in the following figure:</p><div class="mediaobject"><img src="images/00338.jpeg" alt="Simple linear regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This best-fitting line is <a id="calibre_link-1816" class="calibre1"></a>also called<a id="calibre_link-1817" class="calibre1"></a> the <span class="strong"><strong class="calibre2">regression line</strong></span>, and the <a id="calibre_link-1818" class="calibre1"></a>vertical lines from the regression line to the sample points are the<a id="calibre_link-1819" class="calibre1"></a> so-called <span class="strong"><strong class="calibre2">offsets</strong></span> or <span class="strong"><strong class="calibre2">residuals</strong></span>&mdash;the errors<a id="calibre_link-1820" class="calibre1"></a> of our prediction.</p></div></div></div></div>

<div id="calibre_link-103" class="calibre">
<div class="book" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" id="calibre_link-1821">
<div class="book" title="Introducing linear regression">
<div class="book" title="Multiple linear regression"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1822"><a id="calibre_link-351" class="calibre1"></a>Multiple linear regression</h2></div></div></div><p class="calibre8">The<a id="calibre_link-1823" class="calibre1"></a> special case of linear regression with one explanatory variable that we introduced in the previous subsection is also called <span class="strong"><strong class="calibre2">simple linear regression</strong></span>. Of course, we can also generalize the linear regression model to multiple explanatory variables; this process is<a id="calibre_link-1824" class="calibre1"></a> called <span class="strong"><strong class="calibre2">multiple linear regression</strong></span>:</p><div class="mediaobject"><img src="images/00350.jpeg" alt="Multiple linear regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00347.jpeg" alt="Multiple linear regression" class="calibre14" /></span> is the <span class="strong"><em class="calibre9">y</em></span>-axis intercept with <span class="strong"><img src="images/00358.jpeg" alt="Multiple linear regression" class="calibre14" /></span>.</p><p class="calibre8">The following figure<a id="calibre_link-1825" class="calibre1"></a> shows how the two-dimensional, fitted hyperplane of a multiple linear regression model with two features could look:</p><div class="mediaobject"><img src="images/00604.jpeg" alt="Multiple linear regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, visualizing <a id="calibre_link-1826" class="calibre1"></a>multiple linear regression fits in three-dimensional scatter plot are already challenging to interpret when looking at static figures. Since we have no good means of visualizing hyperplanes with two dimensions in a scatterplot (multiple linear regression models fit to datasets with three or more features), the examples and visualizations in this chapter will mainly focus on the univariate case, using simple linear regression. However, simple and multiple linear regression are based on the same concepts and the same evaluation techniques; the code implementations that we will discuss in this chapter are also compatible with both types of regression model.</p></div></div></div></div>

<div id="calibre_link-137" class="calibre">
<div id="calibre_link-1827" class="calibre10"></div><div class="book" title="Exploring the Housing dataset"><div class="book" id="calibre_link-80"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1828"><a id="calibre_link-1829" class="calibre1"></a>Exploring the Housing dataset</h1></div></div></div><p class="calibre8">Before we <a id="calibre_link-1830" class="calibre1"></a>implement our first linear regression model, we will introduce a new dataset, the Housing dataset, which contains information about houses in the suburbs of Boston collected by D. Harrison and D.L. Rubinfeld in 1978. The Housing dataset <a id="calibre_link-1831" class="calibre1"></a>has been made freely available and is included in the code bundle of this book. The dataset has been recently removed from  the UCI Machine Learning Repository but is  available online at <a class="calibre1" href="https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/housing.data.txt">https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/housing.data.txt</a>. As with each new dataset, it is always helpful to explore the data through a simple visualization, to get a better feeling of what we are working with.</p></div></div>

<div id="calibre_link-166" class="calibre">
<div class="book" title="Exploring the Housing dataset">
<div class="book" title="Loading the Housing dataset into a data frame"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1832"><a id="calibre_link-352" class="calibre1"></a>Loading the Housing dataset into a data frame</h2></div></div></div><p class="calibre8">In this section, we will<a id="calibre_link-1833" class="calibre1"></a> load the Housing dataset using the<a id="calibre_link-1834" class="calibre1"></a> pandas <code class="email">read_csv</code> function, which is fast and versatile&mdash;a recommended tool for working with tabular data stored in a plaintext format.</p><p class="calibre8">The features of the 506 samples in the Housing dataset are summarized here, taken from the original source that was previously shared on <a class="calibre1" href="https://archive.ics.uci.edu/ml/datasets/Housing">https://archive.ics.uci.edu/ml/datasets/Housing</a>:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">CRIM</code>: Per capita crime rate by town</li><li class="listitem"><code class="email">ZN</code>: Proportion of residential land zoned for lots over 25,000 sq. ft.</li><li class="listitem"><code class="email">INDUS</code>: Proportion of non-retail business acres per town</li><li class="listitem"><code class="email">CHAS</code>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li><li class="listitem"><code class="email">NOX</code>: Nitric oxide concentration (parts per 10 million)</li><li class="listitem"><code class="email">RM</code>: Average number of rooms per dwelling</li><li class="listitem"><code class="email">AGE</code>: Proportion of owner-occupied units built prior to 1940</li><li class="listitem"><code class="email">DIS</code>: Weighted distances to five Boston employment centers</li><li class="listitem"><code class="email">RAD</code>: Index of accessibility to radial highways</li><li class="listitem"><code class="email">TAX</code>: Full-value property tax rate per $10,000</li><li class="listitem"><code class="email">PTRATIO</code>: Pupil-teacher ratio by town</li><li class="listitem"><code class="email">B</code>: 1000(Bk - 0.63)^2, where <span class="strong"><em class="calibre9">Bk</em></span> is the proportion of [people of African American descent] by town</li><li class="listitem"><code class="email">LSTAT</code>: Percentage of  lower status of the population</li><li class="listitem"><code class="email">MEDV</code>: Median value of owner-occupied homes in $1000s</li></ul></div><p class="calibre8">For the rest of this chapter, we will regard the house prices (<code class="email">MEDV</code>) as our target variable&mdash;the variable that we want to predict using one or more of the 13 explanatory variables. Before we explore this dataset further, let us copy it from the UCI repository into a pandas DataFrame:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv('https://raw.githubusercontent.com/rasbt/'
...                  'python-machine-learning-book-2nd-edition'
...                  '/master/code/ch10/housing.data.txt',
...                  header=None,
...                  sep='\s+')
&gt;&gt;&gt; df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS',
...               'NOX', 'RM', 'AGE', 'DIS', 'RAD',
...               'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']
&gt;&gt;&gt; df.head()</pre></div><p class="calibre8">To confirm that the<a id="calibre_link-1835" class="calibre1"></a> dataset was loaded successfully, we displayed <a id="calibre_link-1836" class="calibre1"></a>the first five lines of the dataset, as shown in the following figure:</p><div class="mediaobject"><img src="images/00665.jpeg" alt="Loading the Housing dataset into a data frame" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1837" class="calibre1"></a>Note</h3><p class="calibre8">You can find a copy of the Housing dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the web link <a class="calibre1" href="https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/housing.data.txt">https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/housing.data.txt</a> is temporarily unavailable. For instance, to load the Housing dataset from a local directory, you can replace these lines:</p><div class="informalexample"><pre class="programlisting">df = pd.read_csv('https://raw.githubusercontent.com/rasbt/'
             'python-machine-learning-book-2nd-edition'
             '/master/code/ch10/housing.data.txt',
             sep='\s+')</pre></div><p class="calibre8">Replace them in the following code example with this:</p><div class="informalexample"><pre class="programlisting">
<code class="email"> </code>df = pd.read_csv('./housing.data.txt'), sep='\s+')</pre></div></div></div></div></div>

<div id="calibre_link-176" class="calibre">
<div class="book" title="Exploring the Housing dataset">
<div class="book" title="Visualizing the important characteristics of a dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1838"><a id="calibre_link-353" class="calibre1"></a>Visualizing the important characteristics of a dataset</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Exploratory Data Analysis</strong></span> (<span class="strong"><strong class="calibre2">EDA</strong></span>) is <a id="calibre_link-1839" class="calibre1"></a>an important and recommended first step <a id="calibre_link-1840" class="calibre1"></a>prior to the training of a machine learning model. In the rest of this section, we will use some simple yet useful techniques from the graphical EDA toolbox that may help us to visually detect the presence of outliers, the distribution of the data, and the relationships between features.</p><p class="calibre8">First, we will create a <span class="strong"><strong class="calibre2">scatterplot matrix</strong></span> that allows us to visualize the pair-wise correlations between the different features in this dataset in one place. To plot the scatterplot matrix, we will use the <code class="email">pairplot</code> function from the Seaborn library<a id="calibre_link-1841" class="calibre1"></a> (<a class="calibre1" href="http://stanford.edu/~mwaskom/software/seaborn/">http://stanford.edu/~mwaskom/software/seaborn/</a>), which is a Python library for drawing statistical plots based on Matplotlib.</p><p class="calibre8">You can install the <code class="email">seaborn</code> package via <code class="email">conda install seaborn</code> or <code class="email">pip install seaborn</code>. After the installation is complete, you can import the package and create the scatterplot matrix as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; import seaborn as sns
&gt;&gt;&gt; cols = ['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV']
&gt;&gt;&gt; sns.pairplot(df[cols], size=2.5)
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the following figure, the scatterplot matrix provides us with a useful graphical summary of the relationships in a dataset:</p><div class="mediaobject"><img src="images/00388.jpeg" alt="Visualizing the important characteristics of a dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Due to space <a id="calibre_link-1842" class="calibre1"></a>constraints and in the interest of readability, we only plotted five columns from the dataset: <code class="email">LSTAT</code>, <code class="email">INDUS</code>, <code class="email">NOX</code>, <code class="email">RM</code>, and <code class="email">MEDV</code>. However, you are encouraged to create a scatterplot matrix of the whole <code class="email">DataFrame</code> to explore the dataset further by choosing different column names in the previous <code class="email">sns.pairplot</code> call, or include all variables in the scatterplot matrix by omitting the column selector (<code class="email">sns.pairplot(df)</code>).</p><p class="calibre8">Using this scatterplot matrix, we can now quickly eyeball how the data is distributed and whether it contains outliers. For example, we can see that there is a linear relationship between <code class="email">RM</code> and house prices, <code class="email">MEDV</code> (the fifth column of the fourth row). Furthermore, we can see in the histogram&mdash;the lower-right subplot in the scatter plot matrix&mdash;that the <code class="email">MEDV</code> variable seems to be normally distributed but contains several outliers.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1843" class="calibre1"></a>Note</h3><p class="calibre8">Note that in contrast to common belief, training a linear regression model does not require that the explanatory or target variables are normally distributed. The normality assumption is only a requirement for certain statistics and hypothesis tests that are beyond the scope of this book (<span class="strong"><em class="calibre9">Introduction to Linear Regression Analysis,</em></span> <span class="strong"><em class="calibre9">Montgomery</em></span>, <span class="strong"><em class="calibre9">Douglas C. Montgomery</em></span>, <span class="strong"><em class="calibre9">Elizabeth A. Peck</em></span>, and <span class="strong"><em class="calibre9">G. Geoffrey Vining</em></span>, <span class="strong"><em class="calibre9">Wiley</em></span>, <span class="strong"><em class="calibre9">2012</em></span>, pages: 318-319).</p></div></div></div></div>

<div id="calibre_link-463" class="calibre">
<div class="book" title="Exploring the Housing dataset">
<div class="book" title="Looking at relationships using a correlation matrix"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1844"><a id="calibre_link-354" class="calibre1"></a>Looking at relationships using a correlation matrix</h2></div></div></div><p class="calibre8">In the previous section, we<a id="calibre_link-1845" class="calibre1"></a> visualized the data distributions of the Housing dataset variables in the form of histograms and scatter plots. Next, we will create a correlation matrix to quantify and summarize linear relationships between variables. A correlation matrix is closely related to the <a id="calibre_link-1846" class="calibre1"></a>covariance matrix that we have seen in the section about <span class="strong"><strong class="calibre2">Principal Component Analysis</strong></span> (<span class="strong"><strong class="calibre2">PCA</strong></span>) in <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>. Intuitively, we can interpret the correlation matrix as a rescaled version of the covariance matrix. In fact, the correlation matrix is identical to a covariance matrix computed from standardized features.</p><p class="calibre8">The correlation matrix is a<a id="calibre_link-1847" class="calibre1"></a> square matrix that contains the <span class="strong"><strong class="calibre2">Pearson product-moment correlation coefficient</strong></span>
<a id="calibre_link-1848" class="calibre1"></a> (often abbreviated as <span class="strong"><strong class="calibre2">Pearson's r</strong></span>), which measure the linear dependence between pairs of features. The correlation coefficients are in the range -1 to 1. Two features have a perfect positive correlation if <span class="strong"><img src="images/00399.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span>, no correlation if <span class="strong"><img src="images/00409.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span>, and a perfect negative correlation if <span class="strong"><img src="images/00425.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span>. As mentioned previously, Pearson's correlation coefficient can simply be calculated as the covariance between two features <span class="strong"><em class="calibre9">x</em></span> and <span class="strong"><em class="calibre9">y</em></span> (numerator) divided by the product of their standard deviations (denominator):</p><div class="mediaobject"><img src="images/00434.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00446.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span> denotes the sample mean of the corresponding feature, <span class="strong"><img src="images/00659.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span> is the covariance between the features <span class="strong"><em class="calibre9">x</em></span> and <span class="strong"><em class="calibre9">y</em></span>, and <span class="strong"><img src="images/00027.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span>and <span class="strong"><img src="images/00602.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span> are the features' standard deviations.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1849" class="calibre1"></a>Note</h3><p class="calibre8">We can show that the covariance between a pair of standardized features is in fact equal to their linear correlation coefficient. To show this, let us first standardize the features <span class="strong"><em class="calibre9">x</em></span> and <span class="strong"><em class="calibre9">y</em></span> to obtain their <span class="strong"><em class="calibre9">z</em></span>-scores, which we will denote as <span class="strong"><img src="images/00490.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span> and <span class="strong"><img src="images/00502.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre14" /></span>, respectively:</p><div class="mediaobject1"><img src="images/00514.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Remember that we compute the (population) covariance between two features as follows:</p><p class="calibre8"> </p><div class="mediaobject1"><img src="images/00523.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
</p><p class="calibre8">Since <a id="calibre_link-1850" class="calibre1"></a>standardization centers a feature variable at mean zero, we can now calculate the covariance between the scaled features as follows:</p><div class="mediaobject1"><img src="images/00529.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Through resubstitution, we then get the following result:</p><div class="mediaobject1"><img src="images/00540.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00553.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Finally, we can simplify this equation as follows:</p><div class="mediaobject1"><img src="images/00614.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p></div><p class="calibre8">In the following code <a id="calibre_link-1851" class="calibre1"></a>example, we will use NumPy's <code class="email">corrcoef</code> function on the five feature columns that we previously visualized in the scatterplot matrix, and we will use Seaborn's <code class="email">heatmap</code> function to plot the correlation matrix array as a heat map:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; cm = np.corrcoef(df[cols].values.T)
&gt;&gt;&gt; sns.set(font_scale=1.5)
&gt;&gt;&gt; hm = sns.heatmap(cm, 
...            cbar=True,
...            annot=True, 
...            square=True,
...            fmt='.2f',
...            annot_kws={'size': 15},
...            yticklabels=cols,
...            xticklabels=cols)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting figure, the correlation matrix provides us with another useful summary graphic that can help us to select features based on their respective linear correlations:</p><div class="mediaobject"><img src="images/00677.jpeg" alt="Looking at relationships using a correlation matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To fit a <a id="calibre_link-1852" class="calibre1"></a>linear regression model, we are interested in those features that have a high correlation with our target variable <code class="email">MEDV</code>. Looking at the previous correlation matrix, we see that our target variable <code class="email">MEDV</code> shows the largest correlation with the <code class="email">LSTAT</code> variable (<code class="email">-0.74</code>); however, as you might remember from inspecting the scatterplot matrix, there is a clear nonlinear relationship between <code class="email">LSTAT</code> and <code class="email">MEDV</code>. On the other hand, the correlation between <code class="email">RM</code> and <code class="email">MEDV</code> is also relatively high (<code class="email">0.70</code>). Given the linear relationship between these two variables that we observed in the scatterplot, <code class="email">RM</code> seems to be a good choice for an exploratory variable to introduce the concepts of a simple linear regression model in the following section.</p></div></div></div>

<div id="calibre_link-494" class="calibre">
<div id="calibre_link-1853" class="calibre10"></div><div class="book" title="Implementing an ordinary least squares linear regression model"><div class="book" id="calibre_link-9"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1854"><a id="calibre_link-1855" class="calibre1"></a>Implementing an ordinary least squares linear regression model</h1></div></div></div><p class="calibre8">At the beginning of<a id="calibre_link-1856" class="calibre1"></a> this chapter, we mentioned that linear regression can be understood as obtaining the best-fitting straight line through the sample points of our training data. However, we have neither defined the term <span class="strong"><strong class="calibre2">best-fitting</strong></span> nor <a id="calibre_link-1857" class="calibre1"></a>have we discussed the different techniques of fitting such a model. In the following subsections, we will fill in the missing pieces of this puzzle using the <span class="strong"><strong class="calibre2">Ordinary Least Squares</strong></span> (<span class="strong"><strong class="calibre2">OLS</strong></span>) method<a id="calibre_link-1858" class="calibre1"></a> (sometimes also called <span class="strong"><strong class="calibre2">linear least squares</strong></span>) to estimate the parameters of the linear regression line that <a id="calibre_link-1859" class="calibre1"></a>minimizes the sum of the squared vertical distances (residuals or errors) to the sample points.</p></div></div>

<div id="calibre_link-184" class="calibre">
<div class="book" title="Implementing an ordinary least squares linear regression model">
<div class="book" title="Solving regression for regression parameters with gradient descent"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1860"><a id="calibre_link-355" class="calibre1"></a>Solving regression for regression parameters with gradient descent</h2></div></div></div><p class="calibre8">Consider our implementation<a id="calibre_link-1861" class="calibre1"></a> of the <span class="strong"><strong class="calibre2">ADAptive LInear NEuron</strong></span> (<span class="strong"><strong class="calibre2">Adaline</strong></span>)<a id="calibre_link-1862" class="calibre1"></a> from <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>; we remember that the artificial neuron uses a linear activation<a id="calibre_link-1863" class="calibre1"></a> function. Also, we defined a cost function <span class="strong"><img src="images/00585.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre14" /></span>, which we minimized to learn the weights via optimization algorithms, such as <span class="strong"><strong class="calibre2">Gradient Descent</strong></span> (<span class="strong"><strong class="calibre2">GD</strong></span>) <a id="calibre_link-1864" class="calibre1"></a>and <span class="strong"><strong class="calibre2">Stochastic Gradient Descent</strong></span> (<span class="strong"><strong class="calibre2">SGD</strong></span>)<a id="calibre_link-1865" class="calibre1"></a>. This cost function in Adaline is the <span class="strong"><strong class="calibre2">Sum of Squared Errors</strong></span> (<span class="strong"><strong class="calibre2">SSE</strong></span>), which <a id="calibre_link-1866" class="calibre1"></a>is identical to the cost function that we use for OLS:</p><div class="mediaobject"><img src="images/00595.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00608.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre14" /></span> is the predicted value <span class="strong"><img src="images/00926.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre14" /></span> (note that the term <span class="strong"><img src="images/00628.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre14" /></span> is just used for convenience to derive the update rule of GD). Essentially, OLS regression can be understood as Adaline without the unit step function so that we obtain continuous target values instead of the class labels <code class="email">-1</code> and <code class="email">1</code>. To demonstrate this, let us take the GD implementation of Adaline from <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span> and remove the unit step function to implement our first linear regression model:</p><div class="informalexample"><pre class="programlisting">class LinearRegressionGD(object):

    def __init__(self, eta=0.001, n_iter=20):
        self.eta = eta
        self.n_iter = n_iter

    def fit(self, X, y):
        self.w_ = np.zeros(1 + X.shape[1])
        self.cost_ = []

        for i in range(self.n_iter):
            output = self.net_input(X)
            errors = (y - output)
            self.w_[1:] += self.eta * X.T.dot(errors)
            self.w_[0] += self.eta * errors.sum()
            cost = (errors**2).sum() / 2.0
            self.cost_.append(cost)
        return self

    def net_input(self, X):
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def predict(self, X):
        return self.net_input(X)</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1867" class="calibre1"></a>Note</h3><p class="calibre8">If you need a refresher about how the weights are being updated&mdash;taking a step into the opposite direction of the gradient&mdash;please revisit the <span class="strong"><em class="calibre9">Adaptive linear neurons and the convergence of learning</em></span> section in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>.</p></div><p class="calibre8">To see <a id="calibre_link-1868" class="calibre1"></a>our <code class="email">LinearRegressionGD</code> regressor in action, let's<a id="calibre_link-1869" class="calibre1"></a> use the <code class="email">RM</code> (number of rooms) variable from the Housing dataset as the explanatory variable and train a model that can predict <code class="email">MEDV</code> (house prices). Furthermore, we will standardize the variables for better convergence of the GD algorithm. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X = df[['RM']].values
&gt;&gt;&gt; y = df['MEDV'].values
&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; sc_x = StandardScaler()
&gt;&gt;&gt; sc_y = StandardScaler()
&gt;&gt;&gt; X_std = sc_x.fit_transform(X)
&gt;&gt;&gt; y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()
&gt;&gt;&gt; lr = LinearRegressionGD()
&gt;&gt;&gt; lr.fit(X_std, y_std)</pre></div><p class="calibre8">Notice the <a id="calibre_link-1870" class="calibre1"></a>workaround regarding <code class="email">y_std</code>, using <code class="email">np.newaxisx</code> and <code class="email">flatten</code>. Most transformers in scikit-learn expect data to be stored<a id="calibre_link-1871" class="calibre1"></a> in two-dimensional arrays. In the previous code example, the use of <code class="email">np.newaxis</code> in <code class="email">y[:, np.newaxis]</code> added a new dimension to the array. Then, after the <code class="email">StandardScaler</code> returned the scaled variable, we converted it back to the original one-dimensional array representation using the <code class="email">flatten()</code> method for our convenience.</p><p class="calibre8">We discussed in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span> that it is always a good idea to plot the cost as a function of the number of epochs passes over the training dataset when we are using optimization algorithms, such as gradient descent, to check the algorithm converged to a cost minimum (here, a <span class="strong"><em class="calibre9">global</em></span> cost minimum):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; sns.reset_orig() # resets matplotlib style
&gt;&gt;&gt; plt.plot(range(1, lr.n_iter+1), lr.cost_)
&gt;&gt;&gt; plt.ylabel('SSE')
&gt;&gt;&gt; plt.xlabel('Epoch')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the following plot, the GD algorithm converged after the fifth epoch:</p><div class="mediaobject"><img src="images/00643.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Next, let's visualize<a id="calibre_link-1872" class="calibre1"></a> how well the linear<a id="calibre_link-1873" class="calibre1"></a> regression line fits the training data. To do so, we will define a simple helper function that will plot a scatterplot of the training samples and add the regression line:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def lin_regplot(X, y, model):
...     plt.scatter(X, y, c='steelblue', edgecolor='white', s=70)
...     plt.plot(X, model.predict(X), color='black', lw=2)
...     return None</pre></div><p class="calibre8">Now, we will use this <code class="email">lin_regplot</code> function to plot the number of rooms against house price:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lin_regplot(X_std, y_std, lr)
&gt;&gt;&gt; plt.xlabel('Average number of rooms [RM] (standardized)')
&gt;&gt;&gt; plt.ylabel('Price in $1000s [MEDV] (standardized)')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the following plot, the linear regression line reflects the general trend that house prices tend to increase with the number of rooms:</p><div class="mediaobject"><img src="images/00654.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although this<a id="calibre_link-1874" class="calibre1"></a> observation makes <a id="calibre_link-1875" class="calibre1"></a>intuitive sense, the data also tells us that the number of rooms does not explain the house prices very well in many cases. Later in this chapter, we will discuss how to quantify the performance of a regression model. Interestingly, we also observe that several data points lined up at <span class="strong"><img src="images/00671.jpeg" alt="Solving regression for regression parameters with gradient descent" class="calibre14" /></span>, which suggests that the prices may have been clipped. In certain applications, it may also be important to report the predicted outcome variables on their original scale. To scale the predicted price outcome back onto the <code class="email">Price in $1000s</code> axis, we can simply apply the <code class="email">inverse_transform</code> method of the <code class="email">StandardScaler</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; num_rooms_std = sc_x.transform([5.0]) 
&gt;&gt;&gt; price_std = lr.predict(num_rooms_std)
&gt;&gt;&gt; print("Price in $1000s: %.3f" % \
...       sc_y.inverse_transform(price_std))
Price in $1000s: 10.840</pre></div><p class="calibre8">In this code example, we used the previously trained linear regression model to predict the price of a house with five rooms. According to our model, such a house is worth $10,840.</p><p class="calibre8">On a side note, it is<a id="calibre_link-1876" class="calibre1"></a> also worth mentioning<a id="calibre_link-1877" class="calibre1"></a> that we technically don't have to update the weights of the intercept if we are working with standardized variables since the <span class="strong"><em class="calibre9">y</em></span>-axis intercept is always 0 in those cases. We can quickly confirm this by printing the weights:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Slope: %.3f' % lr.w_[1])
Slope: 0.695
&gt;&gt;&gt; print('Intercept: %.3f' % lr.w_[0])
Intercept: -0.000</pre></div></div></div></div>

<div id="calibre_link-186" class="calibre">
<div class="book" title="Implementing an ordinary least squares linear regression model">
<div class="book" title="Estimating coefficient of a regression model via scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1878"><a id="calibre_link-356" class="calibre1"></a>Estimating coefficient of a regression model via scikit-learn</h2></div></div></div><p class="calibre8">In the previous section, we<a id="calibre_link-1879" class="calibre1"></a> implemented a working <a id="calibre_link-1880" class="calibre1"></a>model for regression analysis; however, in a real-world application we may be interested in more efficient implementations. For example many of scikit-learn's estimators for regression make use of<a id="calibre_link-1881" class="calibre1"></a> the <span class="strong"><strong class="calibre2">LIBLINEAR</strong></span> library, advanced optimization algorithms, and other code optimizations that work better with unstandardized variables, which is sometimes desirable for certain applications:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import LinearRegression
&gt;&gt;&gt; slr = LinearRegression()
&gt;&gt;&gt; slr.fit(X, y)
&gt;&gt;&gt; print('Slope: %.3f' % slr.coef_[0])
Slope: 9.102
&gt;&gt;&gt; print('Intercept: %.3f' % slr.intercept_)
Intercept: -34.671</pre></div><p class="calibre8">As we can see from executing this code, scikit-learn's <code class="email">LinearRegression</code> model, fitted with the unstandardized <code class="email">RM</code> and <code class="email">MEDV</code> variables, yielded different model coefficients. Let's compare it to our GD implementation by plotting <code class="email">MEDV</code> against <code class="email">RM</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lin_regplot(X, y, slr)
&gt;&gt;&gt; plt.xlabel('Average number of rooms [RM] (standardized)')
&gt;&gt;&gt; plt.ylabel('Price in $1000s [MEDV] (standardized)')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Now, when we plot the training data and our fitted model by executing this code, we can see that the overall result looks identical to our GD implementation:</p><div class="mediaobject"><img src="images/00689.jpeg" alt="Estimating coefficient of a regression model via scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1882" class="calibre1"></a>Note</h3><p class="calibre8">As an <a id="calibre_link-1883" class="calibre1"></a>alternative to using machine learning <a id="calibre_link-1884" class="calibre1"></a>libraries, there is also a closed-form solution for solving OLS involving a system of linear equations that can be found in most introductory statistics textbooks:</p><p class="calibre8"> </p><div class="mediaobject1"><img src="images/00703.jpeg" alt="Estimating coefficient of a regression model via scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
</p><p class="calibre8">We can implement it in Python as follows:</p><div class="informalexample"><pre class="programlisting"># adding a column vector of "ones"
&gt;&gt;&gt; Xb = np.hstack((np.ones((X.shape[0], 1)), X))
&gt;&gt;&gt; w = np.zeros(X.shape[1])
&gt;&gt;&gt; z = np.linalg.inv(np.dot(Xb.T, Xb))
&gt;&gt;&gt; w = np.dot(z, np.dot(Xb.T, y))
&gt;&gt;&gt; print('Slope: %.3f' % w[1])
Slope: 9.102
&gt;&gt;&gt; print('Intercept: %.3f' % w[0])
Intercept: -34.671</pre></div><p class="calibre8">The advantage of<a id="calibre_link-1885" class="calibre1"></a> this method is that it is<a id="calibre_link-1886" class="calibre1"></a> guaranteed to find the optimal solution analytically. However, if we are working with very large datasets, it can be computationally too expensive to invert the matrix in this<a id="calibre_link-1887" class="calibre1"></a> formula (sometimes also called the <span class="strong"><strong class="calibre2">normal equation</strong></span>) or the sample matrix may be singular (non-invertible), which is why we may prefer iterative methods in certain cases.</p><p class="calibre8">If you are interested in more information on how to obtain normal equations, I recommend you take a look at Dr. Stephen Pollock's chapter <span class="strong"><em class="calibre9">The Classical Linear Regression Model</em></span> from his lectures at the University of Leicester, which is available for free at: <a class="calibre1" href="http://www.le.ac.uk/users/dsgp1/COURSES/MESOMET/ECMETXT/06mesmet.pdf">http://www.le.ac.uk/users/dsgp1/COURSES/MESOMET/ECMETXT/06mesmet.pdf</a>.</p></div></div></div></div>

<div id="calibre_link-545" class="calibre"><div class="book" title="Fitting a robust regression model using RANSAC"><div class="book" id="calibre_link-357"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1888"><a id="calibre_link-1889" class="calibre1"></a>Fitting a robust regression model using RANSAC</h1></div></div></div><p class="calibre8">Linear regression models<a id="calibre_link-1890" class="calibre1"></a> can be heavily impacted by the <a id="calibre_link-1891" class="calibre1"></a>presence of outliers. In certain situations, a very small subset of our data can have a big effect on the estimated model coefficients. There are many statistical tests that can be used to detect outliers, which are beyond the scope of the book. However, removing outliers always requires our own judgment as data scientists as well as our domain knowledge.</p><p class="calibre8">As an alternative to throwing out outliers, we will look at a robust method of regression using<a id="calibre_link-1892" class="calibre1"></a> the <span class="strong"><strong class="calibre2">RANdom SAmple Consensus</strong></span> (<span class="strong"><strong class="calibre2">RANSAC</strong></span>) algorithm, which fits a regression model to a subset of the data, the <a id="calibre_link-1893" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">inliers</strong></span>.</p><p class="calibre8">We can summarize the iterative RANSAC algorithm as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Select a random number of samples to be inliers and fit the model.</li><li class="listitem" value="2">Test all other data points against the fitted model and add those points that fall within a user-given tolerance to the inliers.</li><li class="listitem" value="3">Refit the model using all inliers.</li><li class="listitem" value="4">Estimate the error of the fitted model versus the inliers.</li><li class="listitem" value="5">Terminate the algorithm if the performance meets a certain user-defined threshold or if a fixed number of iterations were reached; go back to step 1 otherwise.</li></ol><div class="calibre13"></div></div><p class="calibre8">Let us now wrap our linear model in the RANSAC algorithm using scikit-learn's <code class="email">RANSACRegressor</code> class:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import RANSACRegressor
&gt;&gt;&gt; ransac = RANSACRegressor(LinearRegression(), 
...                          max_trials=100, 
...                          min_samples=50, 
...                          loss='absolute_loss', 
...                          residual_threshold=5.0, 
...                          random_state=0)
&gt;&gt;&gt; ransac.fit(X, y)</pre></div><p class="calibre8">We set the maximum<a id="calibre_link-1894" class="calibre1"></a> number of iterations of the <code class="email">RANSACRegressor</code> to 100, and using <code class="email">min_samples=50</code>, we set the minimum number of the<a id="calibre_link-1895" class="calibre1"></a> randomly chosen samples to be at least 50. Using the <code class="email">'absolute_loss'</code> as an argument for the <code class="email">residual_metric</code> parameter, the algorithm computes absolute vertical distances between the fitted line and the sample points. By setting the <code class="email">residual_threshold</code> parameter to <code class="email">5.0</code>, we only allowed samples to be included in the inlier set if their vertical distance to the fitted line is within 5 distance units, which works well on this particular dataset.</p><p class="calibre8">By default, scikit-learn uses the <span class="strong"><strong class="calibre2">MAD</strong></span> estimate to select the inlier threshold, where MAD stands for the <span class="strong"><strong class="calibre2">Median Absolute Deviation</strong></span> of the<a id="calibre_link-1896" class="calibre1"></a> target values <code class="email">y</code>. However, the choice of an appropriate value for the inlier threshold is problem-specific, which is one disadvantage of RANSAC. Many different approaches have been developed in recent years to select a good inlier threshold automatically. You can find a detailed discussion in: <span class="strong"><em class="calibre9">Automatic Estimation of the Inlier Threshold in Robust Multiple Structures Fitting</em></span>, <span class="strong"><em class="calibre9">R. Toldo</em></span>, <span class="strong"><em class="calibre9">A. Fusiello's</em></span>, <span class="strong"><em class="calibre9">Springer</em></span>, <span class="strong"><em class="calibre9">2009</em></span> (in Image Analysis and Processing&ndash;ICIAP 2009, pages: 123-131).</p><p class="calibre8">After we fit the RANSAC model, let's obtain the inliers and outliers from the fitted RANSAC-linear regression model and plot them together with the linear fit:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; inlier_mask = ransac.inlier_mask_
&gt;&gt;&gt; outlier_mask = np.logical_not(inlier_mask)
&gt;&gt;&gt; line_X = np.arange(3, 10, 1)
&gt;&gt;&gt; line_y_ransac = ransac.predict(line_X[:, np.newaxis])
&gt;&gt;&gt; plt.scatter(X[inlier_mask], y[inlier_mask],
...             c='steelblue', edgecolor='white', 
...             marker='o', label='Inliers')
&gt;&gt;&gt; plt.scatter(X[outlier_mask], y[outlier_mask],
...             c='limegreen', edgecolor='white', 
...             marker='s', label='Outliers')
&gt;&gt;&gt; plt.plot(line_X, line_y_ransac, color='black', lw=2)   
&gt;&gt;&gt; plt.xlabel('Average number of rooms [RM]')
&gt;&gt;&gt; plt.ylabel('Price in $1000s [MEDV]')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the<a id="calibre_link-1897" class="calibre1"></a> following scatterplot, the linear regression<a id="calibre_link-1898" class="calibre1"></a> model was fitted on the detected set of inliers, shown as circles:</p><div class="mediaobject"><img src="images/00714.jpeg" alt="Fitting a robust regression model using RANSAC" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">When we print the slope and intercept of the model by executing the following code, we can see that the linear regression line is slightly different from the fit that we obtained in the previous section without using RANSAC:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Slope: %.3f' % ransac.estimator_.coef_[0])
Slope: 10.735
&gt;&gt;&gt; print('Intercept: %.3f' % ransac.estimator_.intercept_)
Intercept: -44.089</pre></div><p class="calibre8">Using RANSAC, we reduced the potential effect of the outliers in this dataset, but we don't know if this approach has a positive effect on the predictive performance for unseen data. Thus, in the next section we will look at different approaches to evaluating a regression model, which is a crucial part of building systems for predictive modeling.</p></div></div>

<div id="calibre_link-571" class="calibre"><div class="book" title="Evaluating the performance of linear regression models"><div class="book" id="calibre_link-73"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1899"><a id="calibre_link-1900" class="calibre1"></a>Evaluating the performance of linear regression models</h1></div></div></div><p class="calibre8">In the previous section, we <a id="calibre_link-1901" class="calibre1"></a>learned how to fit a regression<a id="calibre_link-1902" class="calibre1"></a> model on training data. However, you learned in previous chapters that it is crucial to test the model on data that it hasn't seen during training to obtain a more unbiased estimate of its performance.</p><p class="calibre8">As we remember from <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we want to split our dataset into separate training and test datasets where we use the former to fit the model and the latter to evaluate its performance to generalize to unseen data. Instead of proceeding with the simple regression model, we will now use all variables in the dataset and train a multiple regression model:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X = df.iloc[:, :-1].values
&gt;&gt;&gt; y = df['MEDV'].values
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...       X, y, test_size=0.3, random_state=0)
&gt;&gt;&gt; slr = LinearRegression()
&gt;&gt;&gt; slr.fit(X_train, y_train)
&gt;&gt;&gt; y_train_pred = slr.predict(X_train)
&gt;&gt;&gt; y_test_pred = slr.predict(X_test)</pre></div><p class="calibre8">Since our model uses multiple explanatory variables, we can't visualize the linear regression line (or hyperplane to be precise) in a two-dimensional plot, but we can plot the residuals (the differences or vertical distances between the actual and predicted values) versus the predicted values to diagnose our regression model. <span class="strong"><strong class="calibre2">Residual plots</strong></span> are a commonly used <a id="calibre_link-1903" class="calibre1"></a>graphical tool for diagnosing regression models. They can help detect nonlinearity and outliers, and check whether the errors are randomly distributed.</p><p class="calibre8">Using the following code, we will now plot a residual plot where we simply subtract the true target variables from our predicted responses:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(y_train_pred,  y_train_pred - y_train,
...             c='steelblue', marker='o', edgecolor='white',
...             label='Training data')
&gt;&gt;&gt; plt.scatter(y_test_pred,  y_test_pred - y_test,
...             c='limegreen', marker='s', edgecolor='white',
...             label='Test data')
&gt;&gt;&gt; plt.xlabel('Predicted values')
&gt;&gt;&gt; plt.ylabel('Residuals')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.hlines(y=0, xmin=-10, xmax=50, color='black', lw=2)
&gt;&gt;&gt; plt.xlim([-10, 50])
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the code, we<a id="calibre_link-1904" class="calibre1"></a> should see a residual plot with<a id="calibre_link-1905" class="calibre1"></a> a line passing through the <span class="strong"><em class="calibre9">x</em></span>-axis origin as shown here:</p><div class="mediaobject"><img src="images/00725.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In case of a perfect prediction, the residuals would be exactly zero, which we will probably never encounter in realistic and practical applications. However, for a good regression model, we would expect that the errors are randomly distributed and the residuals should be randomly scattered around the centerline. If we see patterns in a residual plot, it means that our model is unable to capture some explanatory information, which has leaked into the residuals, as we can slightly see in our previous residual plot. Furthermore, we can also use residual plots to detect outliers, which are represented by the points with a large deviation from the centerline.</p><p class="calibre8">Another useful quantitative measure of a model's performance is the so-called <span class="strong"><strong class="calibre2">Mean Squared Error</strong></span> (<span class="strong"><strong class="calibre2">MSE</strong></span>), which is <a id="calibre_link-1906" class="calibre1"></a>simply the averaged <a id="calibre_link-1907" class="calibre1"></a>value of the SSE cost that we minimized to fit the linear<a id="calibre_link-1908" class="calibre1"></a> regression model. The MSE is useful to compare different regression models or for tuning their parameters via grid search and cross-validation, as it normalizes the SSE by the sample size:</p><div class="mediaobject"><img src="images/00729.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's compute the MSE of our training and test predictions:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import mean_squared_error
&gt;&gt;&gt; print('MSE train: %.3f, test: %.3f' % (
...     mean_squared_error(y_train, y_train_pred),
...     mean_squared_error(y_test, y_test_pred)))
MSE train: 19.958, test: 27.196</pre></div><p class="calibre8">We see that the MSE on the training set is 19.96, and the MSE of the test set is much larger, with a value of 27.20, which is an indicator that our model is overfitting the training data.</p><p class="calibre8">Sometimes it may be more useful to<a id="calibre_link-1909" class="calibre1"></a> report the <span class="strong"><strong class="calibre2">coefficient of determination</strong></span> (<span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span>), which can be understood as a standardized version of the MSE, for better interpretability of the model's performance. Or in other words, <span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span> is the fraction of response variance that is captured by the model. The <span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span> value is defined as:</p><div class="mediaobject"><img src="images/00757.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, SSE is the sum of squared errors and SST is the total sum of squares:</p><div class="mediaobject"><img src="images/00771.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In other words, SST is<a id="calibre_link-1910" class="calibre1"></a> simply the variance of the response.</p><p class="calibre8">Let us quickly show that <span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span> is indeed <a id="calibre_link-1911" class="calibre1"></a>just a rescaled version of the MSE:</p><div class="mediaobject"><img src="images/00757.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00681.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00786.jpeg" alt="Evaluating the performance of linear regression models" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">For the training dataset, the <span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span> is bounded between 0 and 1, but it can become negative for the test set. If <span class="strong"><img src="images/00797.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span>, the model fits the data perfectly with a corresponding <span class="strong"><img src="images/00860.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span>.</p><p class="calibre8">Evaluated on the training data, the <span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span> of our model is 0.765, which doesn't sound too bad. However, the <span class="strong"><img src="images/00744.jpeg" alt="Evaluating the performance of linear regression models" class="calibre14" /></span> on the test dataset is only 0.673, which we can compute by executing the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import r2_score
&gt;&gt;&gt; print('R^2 train: %.3f, test: %.3f' % 
...       (r2_score(y_train, y_train_pred),
...        r2_score(y_test, y_test_pred)))
R^2 train: 0.765, test: 0.673</pre></div></div></div>

<div id="calibre_link-197" class="calibre"><div class="book" title="Using regularized methods for regression" id="calibre_link-141"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1912"><a id="calibre_link-1913" class="calibre1"></a>Using regularized methods for regression</h1></div></div></div><p class="calibre8">As we <a id="calibre_link-1914" class="calibre1"></a>discussed in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, regularization is one approach to tackle the problem of <a id="calibre_link-1915" class="calibre1"></a>overfitting by adding additional information, and thereby shrinking the parameter values of the model to induce a penalty <a id="calibre_link-1916" class="calibre1"></a>against complexity. The most popular <a id="calibre_link-1917" class="calibre1"></a>approaches to regularized linear regression are the <a id="calibre_link-1918" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">Ridge Regression</strong></span>, <span class="strong"><strong class="calibre2">Least Absolute Shrinkage and Selection Operator</strong></span> (<span class="strong"><strong class="calibre2">LASSO</strong></span>), and <span class="strong"><strong class="calibre2">Elastic Net</strong></span>.</p><p class="calibre8">Ridge regression is an L2 penalized model where we simply add the squared sum of the weights to our least-squares cost function:</p><div class="mediaobject"><img src="images/00931.jpeg" alt="Using regularized methods for regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here:</p><div class="mediaobject"><img src="images/00834.jpeg" alt="Using regularized methods for regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">By increasing the value of hyperparameter <span class="strong"><img src="images/00847.jpeg" alt="Using regularized methods for regression" class="calibre14" /></span>, we increase the regularization strength and shrink the weights of our model. Please note that we don't regularize the intercept term <span class="strong"><img src="images/00347.jpeg" alt="Using regularized methods for regression" class="calibre14" /></span>.</p><p class="calibre8">An alternative approach that can lead to sparse models is LASSO. Depending on the regularization strength, certain weights can become zero, which also makes LASSO useful as a supervised feature selection technique:</p><div class="mediaobject"><img src="images/00864.jpeg" alt="Using regularized methods for regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here:</p><div class="mediaobject"><img src="images/00884.jpeg" alt="Using regularized methods for regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, a limitation<a id="calibre_link-1919" class="calibre1"></a> of LASSO is that it selects at most <span class="strong"><em class="calibre9">n</em></span> variables <a id="calibre_link-1920" class="calibre1"></a>if <span class="strong"><em class="calibre9">m&gt;n</em></span>. A compromise between Ridge regression and LASSO is Elastic Net, which has an L1 penalty to generate sparsity and an L2 penalty to overcome some of the limitations of LASSO, such as the number of selected variables:</p><div class="mediaobject"><img src="images/00893.jpeg" alt="Using regularized methods for regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Those regularized regression models are all available via scikit-learn, and the usage is similar to the regular regression model except that we have to specify the regularization strength via the parameter <span class="strong"><img src="images/00847.jpeg" alt="Using regularized methods for regression" class="calibre14" /></span>, for example, optimized via k-fold cross-validation.</p><p class="calibre8">A Ridge regression model can be initialized via:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import Ridge
&gt;&gt;&gt; ridge = Ridge(alpha=1.0)</pre></div><p class="calibre8">Note that the regularization strength is regulated by the parameter <code class="email">alpha</code>, which is similar to the parameter <span class="strong"><img src="images/00847.jpeg" alt="Using regularized methods for regression" class="calibre14" /></span>. Likewise, we can initialize a LASSO regressor from the <code class="email">linear_model</code> submodule:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import Lasso
&gt;&gt;&gt; lasso = Lasso(alpha=1.0)</pre></div><p class="calibre8">Lastly, the <code class="email">ElasticNet</code> implementation allows us to vary the L1 to L2 ratio:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.linear_model import ElasticNet
&gt;&gt;&gt; elanet = ElasticNet(alpha=1.0, l1_ratio=0.5)</pre></div><p class="calibre8">For example, if we set the <code class="email">l1_ratio</code> to 1.0, the <code class="email">ElasticNet</code> regressor would be equal to LASSO regression. For <a id="calibre_link-1921" class="calibre1"></a>more detailed information about the different <a id="calibre_link-1922" class="calibre1"></a>implementations of <a id="calibre_link-1923" class="calibre1"></a>linear regression, please see the documentation at <a class="calibre1" href="http://scikit-learn.org/stable/modules/linear_model.html">http://scikit-learn.org/stable/modules/linear_model.html</a>.</p></div></div>

<div id="calibre_link-469" class="calibre">
<div id="calibre_link-1924" class="calibre10"></div><div class="book" title="Turning a linear regression model into a curve â polynomial regression"><div class="book" id="calibre_link-83"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1925"><a id="calibre_link-1926" class="calibre1"></a>Turning a linear regression model into a curve &ndash; polynomial regression</h1></div></div></div><p class="calibre8">In the previous sections, we <a id="calibre_link-1927" class="calibre1"></a>assumed a linear relationship between<a id="calibre_link-1928" class="calibre1"></a> explanatory and response variables. One <a id="calibre_link-1929" class="calibre1"></a>way to account for the violation of linearity assumption is to use a polynomial regression model by adding polynomial terms:</p><div class="mediaobject"><img src="images/00902.jpeg" alt="Turning a linear regression model into a curve â polynomial regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><em class="calibre9">d</em></span> denotes the degree of the polynomial. Although we can use polynomial regression to model a nonlinear relationship, it is still considered a multiple linear regression model because of the linear regression coefficients <span class="strong"><em class="calibre9">w</em></span>. In the following subsections, we will see how we can add such polynomial terms to an existing dataset conveniently and fit a polynomial regression model.</p></div></div>

<div id="calibre_link-473" class="calibre">
<div class="book" title="Turning a linear regression model into a curve â polynomial regression">
<div class="book" title="Adding polynomial terms using scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1930"><a id="calibre_link-358" class="calibre1"></a>Adding polynomial terms using scikit-learn</h2></div></div></div><p class="calibre8">We will now <a id="calibre_link-1931" class="calibre1"></a>learn how to use the <code class="email">PolynomialFeatures</code> transformer<a id="calibre_link-1932" class="calibre1"></a> class from scikit-learn to add a quadratic term (<span class="strong"><em class="calibre9">d = 2</em></span>) to a simple regression problem with one explanatory variable. Then, we compare the polynomial to the linear fit following these steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Add a second degree polynomial term:<div class="informalexample"><pre class="programlisting">from sklearn.preprocessing import PolynomialFeatures
&gt;&gt;&gt; X = np.array([ 258.0, 270.0, 294.0, 320.0, 342.0, 
...              368.0, 396.0, 446.0, 480.0, 586.0])\
...              [:, np.newaxis]
&gt;&gt;&gt; y = np.array([ 236.4, 234.4, 252.8, 298.6, 314.2, 
...               342.2, 360.8, 368.0, 391.2, 390.8])
&gt;&gt;&gt; lr = LinearRegression()
&gt;&gt;&gt; pr = LinearRegression()
&gt;&gt;&gt; quadratic = PolynomialFeatures(degree=2)
&gt;&gt;&gt; X_quad = quadratic.fit_transform(X)</pre></div></li><li class="listitem" value="2">Fit a simple linear<a id="calibre_link-1933" class="calibre1"></a> regression model for <a id="calibre_link-1934" class="calibre1"></a>comparison:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lr.fit(X, y)
&gt;&gt;&gt; X_fit = np.arange(250,600,10)[:, np.newaxis]
&gt;&gt;&gt; y_lin_fit = lr.predict(X_fit)</pre></div></li><li class="listitem" value="3">Fit a multiple regression model on the transformed features for polynomial regression:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; pr.fit(X_quad, y)
&gt;&gt;&gt; y_quad_fit = pr.predict(quadratic.fit_transform(X_fit))</pre></div></li><li class="listitem" value="4">Plot the results:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(X, y, label='training points')
&gt;&gt;&gt; plt.plot(X_fit, y_lin_fit, 
...          label='linear fit', linestyle='--')
&gt;&gt;&gt; plt.plot(X_fit, y_quad_fit,
...          label='quadratic fit')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.show()</pre></div></li></ol><div class="calibre13"></div></div><p class="calibre8">In the resulting plot, we can see that the polynomial fit captures the relationship between the response and explanatory variable much better than the linear fit:</p><div class="mediaobject"><img src="images/00916.jpeg" alt="Adding polynomial terms using scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_lin_pred = lr.predict(X)
&gt;&gt;&gt; y_quad_pred = pr.predict(X_quad)
&gt;&gt;&gt; print('Training MSE linear: %.3f, quadratic: %.3f' % (
...         mean_squared_error(y, y_lin_pred),
...         mean_squared_error(y, y_quad_pred)))
Training MSE linear: 569.780, quadratic: 61.330
&gt;&gt;&gt; print('Training  R^2 linear: %.3f, quadratic: %.3f' % (
...         r2_score(y, y_lin_pred),
...         r2_score(y, y_quad_pred)))
Training  R^2 linear: 0.832, quadratic: 0.982</pre></div><p class="calibre8">As we can see after <a id="calibre_link-1935" class="calibre1"></a>executing the code, the MSE decreased from <a id="calibre_link-1936" class="calibre1"></a>570 (linear fit) to 61 (quadratic fit); also, the coefficient of determination reflects a closer fit of the quadratic model (<span class="strong"><img src="images/00937.jpeg" alt="Adding polynomial terms using scikit-learn" class="calibre14" /></span>) as opposed to the linear fit (<span class="strong"><img src="images/00949.jpeg" alt="Adding polynomial terms using scikit-learn" class="calibre14" /></span>) in this particular toy problem.</p></div></div></div>

<div id="calibre_link-478" class="calibre">
<div class="book" title="Turning a linear regression model into a curve â polynomial regression">
<div class="book" title="Modeling nonlinear relationships in the Housing dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1937"><a id="calibre_link-359" class="calibre1"></a>Modeling nonlinear relationships in the Housing dataset</h2></div></div></div><p class="calibre8">After we learned how to <a id="calibre_link-1938" class="calibre1"></a>construct polynomial <a id="calibre_link-1939" class="calibre1"></a>features to fit nonlinear relationships in a toy problem, let's now take a look at a more concrete example and apply those concepts to the data in the Housing dataset. By executing the following code, we<a id="calibre_link-1940" class="calibre1"></a> will model the relationship<a id="calibre_link-1941" class="calibre1"></a> between house prices and <code class="email">LSTAT</code> (percent lower status of the population) as using <a id="calibre_link-1942" class="calibre1"></a>second degree (quadratic) and third degree (cubic) polynomials and compare it to a linear fit:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X = df[['LSTAT']].values
&gt;&gt;&gt; y = df['MEDV'].values

&gt;&gt;&gt; regr = LinearRegression()

# create quadratic features
&gt;&gt;&gt; quadratic = PolynomialFeatures(degree=2)
&gt;&gt;&gt; cubic = PolynomialFeatures(degree=3)
&gt;&gt;&gt; X_quad = quadratic.fit_transform(X)
&gt;&gt;&gt; X_cubic = cubic.fit_transform(X)

# fit features
&gt;&gt;&gt; X_fit = np.arange(X.min(), X.max(), 1)[:, np.newaxis]

&gt;&gt;&gt; regr = regr.fit(X, y)
&gt;&gt;&gt; y_lin_fit = regr.predict(X_fit)
&gt;&gt;&gt; linear_r2 = r2_score(y, regr.predict(X))

&gt;&gt;&gt; regr = regr.fit(X_quad, y)
&gt;&gt;&gt; y_quad_fit = regr.predict(quadratic.fit_transform(X_fit))
&gt;&gt;&gt; quadratic_r2 = r2_score(y, regr.predict(X_quad))

&gt;&gt;&gt; regr = regr.fit(X_cubic, y)
&gt;&gt;&gt; y_cubic_fit = regr.predict(cubic.fit_transform(X_fit))
&gt;&gt;&gt; cubic_r2 = r2_score(y, regr.predict(X_cubic))


# plot results
&gt;&gt;&gt; plt.scatter(X, y, label='training points', color='lightgray')

&gt;&gt;&gt; plt.plot(X_fit, y_lin_fit,
...          label='linear (d=1), $R^2=%.2f$' % linear_r2,
...          color='blue', 
...          lw=2, 
...          linestyle=':')

&gt;&gt;&gt; plt.plot(X_fit, y_quad_fit,
...          label='quadratic (d=2), $R^2=%.2f$' % quadratic_r2,
...          color='red',
...          lw=2,
...          linestyle='-')

&gt;&gt;&gt; plt.plot(X_fit, y_cubic_fit,
...          label='cubic (d=3), $R^2=%.2f$' % cubic_r2,
...          color='green',
...          lw=2, 
...          linestyle='--')

&gt;&gt;&gt; plt.xlabel('% lower status of the population [LSTAT]')
&gt;&gt;&gt; plt.ylabel('Price in $1000s [MEDV]')
&gt;&gt;&gt; plt.legend(loc='upper right')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The resulting<a id="calibre_link-1943" class="calibre1"></a> plot is <a id="calibre_link-1944" class="calibre1"></a>as follows:</p><div class="mediaobject"><img src="images/00475.jpeg" alt="Modeling nonlinear relationships in the Housing dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, the cubic fit captures the relationship between house prices and LSTAT better than the linear and quadratic fit. However, we should be aware that adding more and more polynomial features increases the complexity of a model and therefore increases the chance of overfitting. Thus, in practice it is always recommended to evaluate the performance of the model on a separate test dataset to estimate the generalization performance.</p><p class="calibre8">In addition, polynomial features are not always the best choice for modeling nonlinear relationships. For example, with some experience or intuition, just looking at the MEDV-LSTAT scatterplot may lead to the hypothesis that a log-transformation of the LSTAT feature variable and the square root of MEDV may project the data onto a linear feature space suitable for a linear regression fit. For instance, my perception is that this relationship between<a id="calibre_link-1945" class="calibre1"></a> the two variables looks quite similar to<a id="calibre_link-1946" class="calibre1"></a> an exponential function:</p><div class="mediaobject"><img src="images/00485.jpeg" alt="Modeling nonlinear relationships in the Housing dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since the natural logarithm of an exponential function is a straight line, I assume that such a log-transformation can be usefully applied here:</p><div class="mediaobject"><img src="images/00464.jpeg" alt="Modeling nonlinear relationships in the Housing dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's test this hypothesis by executing the following code:</p><div class="informalexample"><pre class="programlisting"># transform features
&gt;&gt;&gt; X_log = np.log(X)
&gt;&gt;&gt; y_sqrt = np.sqrt(y)

# fit features
&gt;&gt;&gt; X_fit = np.arange(X_log.min()-1, 
...                   X_log.max()+1, 1)[:, np.newaxis]
&gt;&gt;&gt; regr = regr.fit(X_log, y_sqrt)
&gt;&gt;&gt; y_lin_fit = regr.predict(X_fit)
&gt;&gt;&gt; linear_r2 = r2_score(y_sqrt, regr.predict(X_log))

# plot results
&gt;&gt;&gt; plt.scatter(X_log, y_sqrt,
...             label='training points',
...             color='lightgray')
&gt;&gt;&gt; plt.plot(X_fit, y_lin_fit, 
...          label='linear (d=1), $R^2=%.2f$' % linear_r2,
...          color='blue', 
...          lw=2)
&gt;&gt;&gt; plt.xlabel('log(% lower status of the population [LSTAT])')
&gt;&gt;&gt; plt.ylabel('$\sqrt{Price \; in \; \$1000s \; [MEDV]}$')
&gt;&gt;&gt; plt.legend(loc='lower left')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After transforming the explanatory onto the log space and taking the square root of the target variables, we were able to capture the relationship between the two variables with a linear regression line that seems to fit the data better (<span class="strong"><img src="images/00845.jpeg" alt="Modeling nonlinear relationships in the Housing dataset" class="calibre14" /></span>) than<a id="calibre_link-1947" class="calibre1"></a> any of the polynomial feature <a id="calibre_link-1948" class="calibre1"></a>transformations previously:</p><div class="mediaobject"><img src="images/00912.jpeg" alt="Modeling nonlinear relationships in the Housing dataset" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-662" class="calibre">
<div id="calibre_link-1949" class="calibre10"></div><div class="book" title="Dealing with nonlinear relationships using random forests"><div class="book" id="calibre_link-109"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1950"><a id="calibre_link-1951" class="calibre1"></a>Dealing with nonlinear relationships using random forests</h1></div></div></div><p class="calibre8">In this section, we are <a id="calibre_link-1952" class="calibre1"></a>going to<a id="calibre_link-1953" class="calibre1"></a> take a look at <span class="strong"><strong class="calibre2">random forest</strong></span> regression, which is conceptually different from the previous regression models in this chapter. A random forest, which is an ensemble of multiple <span class="strong"><strong class="calibre2">decision trees</strong></span>, can be understood as the sum of piecewise linear functions in contrast to the global linear and polynomial regression models that we discussed previously. In other words, via the decision tree algorithm, we are subdividing the input space into smaller regions that become more <span class="strong"><em class="calibre9">manageable</em></span>.</p></div></div>

<div id="calibre_link-488" class="calibre">
<div class="book" title="Dealing with nonlinear relationships using random forests">
<div class="book" title="Decision tree regression"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1954"><a id="calibre_link-360" class="calibre1"></a>Decision tree regression</h2></div></div></div><p class="calibre8">An advantage of the <a id="calibre_link-1955" class="calibre1"></a>decision tree algorithm is that it does not require any transformation of the features if we are dealing with nonlinear data. We remember from <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, that we grow a decision tree by iteratively splitting its nodes until the leaves are pure or a stopping criterion is satisfied. When we used decision trees for classification, we defined entropy as a measure of impurity to determine which feature split maximizes the <span class="strong"><strong class="calibre2">Information Gain</strong></span> (<span class="strong"><strong class="calibre2">IG</strong></span>), which can<a id="calibre_link-1956" class="calibre1"></a> be defined as follows for a binary split:</p><div class="mediaobject"><img src="images/00050.jpeg" alt="Decision tree regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><em class="calibre9">x</em></span> is the feature to perform the split, <span class="strong"><img src="images/00067.jpeg" alt="Decision tree regression" class="calibre14" /></span> is the number of samples in the parent node, <span class="strong"><em class="calibre9">I</em></span> is the impurity function, <span class="strong"><img src="images/00126.jpeg" alt="Decision tree regression" class="calibre14" /></span> is the subset of training samples at the parent node, and <span class="strong"><img src="images/00186.jpeg" alt="Decision tree regression" class="calibre14" /></span> and <span class="strong"><img src="images/00095.jpeg" alt="Decision tree regression" class="calibre14" /></span> are the subsets of training samples at the left and right child node after the split. Remember that our goal is to find the feature split that maximizes the information gain; or in other words, we want to find the feature split that reduces the impurities in the child nodes most. In <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span> we discussed Gini impurity and entropy as measures of impurity, which are both useful criteria for classification. To use a decision tree for regression, however, we need an impurity metric that is suitable for continuous variables, so we <a id="calibre_link-1957" class="calibre1"></a>define the impurity measure of a node t as the MSE instead:</p><div class="mediaobject"><img src="images/00107.jpeg" alt="Decision tree regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00118.jpeg" alt="Decision tree regression" class="calibre14" /></span> is the number of training samples at node <span class="strong"><em class="calibre9">t</em></span>, <span class="strong"><img src="images/00396.jpeg" alt="Decision tree regression" class="calibre14" /></span> is the training subset at node <span class="strong"><em class="calibre9">t</em></span>, <span class="strong"><img src="images/00456.jpeg" alt="Decision tree regression" class="calibre14" /></span> is the true target value, and <span class="strong"><img src="images/00153.jpeg" alt="Decision tree regression" class="calibre14" /></span> is the predicted target value (sample mean):</p><div class="mediaobject"><img src="images/00168.jpeg" alt="Decision tree regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the context of decision tree<a id="calibre_link-1958" class="calibre1"></a> regression, the MSE is often also referred to as <span class="strong"><strong class="calibre2">within-node variance</strong></span>, which is why the splitting criterion is also better known as <span class="strong"><strong class="calibre2">variance reduction</strong></span>. To see what the line fit of a decision tree looks like, let us use the <code class="email">DecisionTreeRegressor</code> implemented in scikit-learn to model the nonlinear relationship between the <code class="email">MEDV</code> and <code class="email">LSTAT</code> variables:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.tree import DecisionTreeRegressor
&gt;&gt;&gt; X = df[['LSTAT']].values
&gt;&gt;&gt; y = df['MEDV'].values
&gt;&gt;&gt; tree = DecisionTreeRegressor(max_depth=3)
&gt;&gt;&gt; tree.fit(X, y)
&gt;&gt;&gt; sort_idx = X.flatten().argsort()
&gt;&gt;&gt; lin_regplot(X[sort_idx], y[sort_idx], tree)
&gt;&gt;&gt; plt.xlabel('% lower status of the population [LSTAT]')
&gt;&gt;&gt; plt.ylabel('Price in $1000s [MEDV]')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting plot, the decision tree captures the general trend in the data. However, a limitation of this model is that it does not capture the continuity and differentiability of the desired prediction. In addition, we need to be careful about choosing an appropriate value for the depth of the tree to not overfit or underfit the data; here, a depth of three seemed to be a good choice:</p><div class="mediaobject"><img src="images/00177.jpeg" alt="Decision tree regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the next section, we will <a id="calibre_link-1959" class="calibre1"></a>take a look at a more robust way of fitting regression trees: random forests.</p></div></div></div>

<div id="calibre_link-501" class="calibre">
<div class="book" title="Dealing with nonlinear relationships using random forests">
<div class="book" title="Random forest regression"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1960"><a id="calibre_link-361" class="calibre1"></a>Random forest regression</h2></div></div></div><p class="calibre8">As we learned in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, the random forest algorithm is an<a id="calibre_link-1961" class="calibre1"></a> ensemble technique that combines multiple decision trees. A random forest usually has a better generalization performance than an individual decision tree due to randomness, which helps to decrease the model's variance. Other advantages of random forests are that they are less sensitive to outliers in the dataset and don't require much parameter tuning. The only parameter in random forests that we typically need to experiment with is the number of trees in the ensemble. The basic random forest algorithm for regression is almost identical to the random forest algorithm for classification that we discussed in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, the only difference is that we use the MSE criterion to grow the individual decision trees, and the predicted target variable is calculated as the average prediction over all decision trees.</p><p class="calibre8">Now, let's use all features in the Housing dataset to fit a random forest regression model on 60 percent of the samples and evaluate its performance on the remaining 40 percent. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X = df.iloc[:, :-1].values
&gt;&gt;&gt; y = df['MEDV'].values
&gt;&gt;&gt; X_train, X_test, y_train, y_test =\
...       train_test_split(X, y, 
...                        test_size=0.4, 
...                        random_state=1)

&gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor
&gt;&gt;&gt; forest = RandomForestRegressor(n_estimators=1000, 
...                                criterion='mse', 
...                                random_state=1, 
...                                n_jobs=-1)
&gt;&gt;&gt; forest.fit(X_train, y_train)
&gt;&gt;&gt; y_train_pred = forest.predict(X_train)
&gt;&gt;&gt; y_test_pred = forest.predict(X_test)
&gt;&gt;&gt; print('MSE train: %.3f, test: %.3f' % (
...        mean_squared_error(y_train, y_train_pred),
...        mean_squared_error(y_test, y_test_pred)))
MSE train: 1.642, test: 11.052
&gt;&gt;&gt; print('R^2 train: %.3f, test: %.3f' % (
...        r2_score(y_train, y_train_pred),
...        r2_score(y_test, y_test_pred)))
R^2 train: 0.979, test: 0.878</pre></div><p class="calibre8">Unfortunately, we see that the <a id="calibre_link-1962" class="calibre1"></a>random forest tends to overfit the training data. However, it's still able to explain the relationship between the target and explanatory variables relatively well (<span class="strong"><img src="images/00666.jpeg" alt="Random forest regression" class="calibre14" /></span> on the test dataset).</p><p class="calibre8">Lastly, let us also take a look at the residuals of the prediction:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(y_train_pred,
...             y_train_pred - y_train,
...             c='steelblue',
...             edgecolor='white',
...             marker='o',
...             s=35,
...             alpha=0.9,
...             label='Training data')
&gt;&gt;&gt; plt.scatter(y_test_pred,
...             y_test_pred - y_test,
...             c='limegreen',
...             edgecolor='white',
...             marker='s',
...             s=35,
...             alpha=0.9,
...             label='Test data')
&gt;&gt;&gt; plt.xlabel('Predicted values')
&gt;&gt;&gt; plt.ylabel('Residuals')
&gt;&gt;&gt; plt.legend(loc='upper left')
&gt;&gt;&gt; plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='black')
&gt;&gt;&gt; plt.xlim([-10, 50])
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As it was already summarized<a id="calibre_link-1963" class="calibre1"></a> by the <span class="strong"><img src="images/00200.jpeg" alt="Random forest regression" class="calibre14" /></span> coefficient, we can see that the model fits the training data better than the test data, as indicated by the outliers in the <span class="strong"><em class="calibre9">y</em></span>-axis direction. Also, the distribution of the residuals does not seem to be completely random around the zero center point, indicating that the model is not able to capture all the exploratory information. However, the residual plot indicates a large improvement over the residual plot of the linear model that we plotted earlier in this chapter:</p><div class="mediaobject"><img src="images/00214.jpeg" alt="Random forest regression" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Ideally, our model error should be random or unpredictable. In other words, the error of the predictions should not be related to any of the information contained in the explanatory variables, but should reflect the randomness of the real-world distributions or patterns. If we observe patterns in the prediction errors, for example, by inspecting the residual plot, it means that the residual plots contain predictive information. A common reason for this could be that explanatory information is leaking into those residuals.</p><p class="calibre8">Unfortunately, there is now a universal approach for dealing with non-randomness in residual plots, and it requires experimentation. Depending on the data that is available to us, we may be able to improve the model by transforming variables, tuning the hyperparameters of the learning algorithm, choosing simpler or more complex models, removing outliers, or including<a id="calibre_link-1964" class="calibre1"></a> additional variables.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1965" class="calibre1"></a>Note</h3><p class="calibre8">In <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, we also learned about the kernel trick, which can be used in combination with a <span class="strong"><strong class="calibre2">Support Vector Machine</strong></span> (<span class="strong"><strong class="calibre2">SVM</strong></span>) for<a id="calibre_link-1966" class="calibre1"></a> classification, and is useful if we are dealing with nonlinear problems. Although a discussion is beyond the scope of this book, SVMs can also be used in nonlinear regression tasks. The interested reader can find more information about SVMs for regression in an excellent report: <span class="strong"><em class="calibre9">Support</em></span> <span class="strong"><em class="calibre9">Vector Machines for Classification and Regression,</em></span> <span class="strong"><em class="calibre9">S. R. Gunn and others</em></span>, ISIS technical report, 14, 1998. An SVM regressor<a id="calibre_link-1967" class="calibre1"></a> is also implemented in scikit-learn, and more information about its usage can be found at <a class="calibre1" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR">http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR</a>.</p></div></div></div></div>

<div id="calibre_link-506" class="calibre"><div class="book" title="Summary" id="calibre_link-362"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1968"><a id="calibre_link-1969" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">At the beginning of this chapter, you learned about simple linear regression analysis to model the relationship between a single explanatory variable and a continuous response variable. We then discussed a useful explanatory data analysis technique to look at patterns and anomalies in data, which is an important first step in predictive modeling tasks.</p><p class="calibre8">We built our first model by implementing linear regression using a gradient-based optimization approach. We then saw how to utilize scikit-learn's linear models for regression and also implement a robust regression technique (RANSAC) as an approach for dealing with outliers. To assess the predictive performance of regression models, we computed the mean sum of squared errors and the related <span class="strong"><img src="images/00200.jpeg" alt="Summary" class="calibre14" /></span> metric. Furthermore, we also discussed a useful graphical approach to diagnose problems of regression models: the residual plot.</p><p class="calibre8">After we discussed how regularization can be applied to regression models to reduce the model complexity and avoid overfitting, we also introduced several approaches to model nonlinear relationships including polynomial feature transformation and random forest regressors.</p><p class="calibre8">We have discussed supervised learning, classification, and regression analysis in great detail throughout the previous chapters. In the next chapter, we are going to learn about another interesting subfield of machine learning, unsupervised learning and also we will learn how to use cluster analysis for finding hidden structures in data in the absence of target variables.</p></div></div>

<div id="calibre_link-23" class="calibre">
<div id="calibre_link-1970" class="calibre10"></div><div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis"><div class="book" id="calibre_link-42"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1971"><a id="calibre_link-1972" class="calibre1"></a>Chapter&nbsp;11.&nbsp;Working with Unlabeled Data &ndash; Clustering Analysis</h1></div></div></div><p class="calibre8">In the previous chapters, we used supervised learning techniques to build machine learning models using data where the answer was already known&mdash;the class labels were already available in our training data. In this chapter, we will switch gears and explore cluster analysis, a category of <span class="strong"><strong class="calibre2">unsupervised learning</strong></span> techniques that allows us to discover hidden structures in data where we do not know the right answer upfront. The goal of clustering is to find a natural grouping in data so that items in the same cluster are more similar to each other than to those from different clusters.</p><p class="calibre8">Given its exploratory nature, clustering is an exciting topic and, in this chapter, we will learn about the following concepts, which can help us to organize data into meaningful structures:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Finding centers of similarity using the popular k-means algorithm</li><li class="listitem">Taking a bottom-up approach to building hierarchical clustering trees</li><li class="listitem">Identifying arbitrary shapes of objects using a density-based clustering approach</li></ul></div></div></div>

<div id="calibre_link-619" class="calibre">
<div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis">
<div class="book" title="Grouping objects by similarity using k-means"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-1973"><a id="calibre_link-363" class="calibre1"></a>Grouping objects by similarity using k-means</h1></div></div></div><p class="calibre8">In this section, we will <a id="calibre_link-1974" class="calibre1"></a>learn about one of the most popular <span class="strong"><strong class="calibre2">clustering</strong></span> algorithms, <span class="strong"><strong class="calibre2">k-means</strong></span>, which is widely used in academia as well as in industry. Clustering (or cluster analysis) is a technique that allows us to find groups of similar objects, objects that are more related to each other than to objects in other groups. Examples of business-oriented applications of clustering include the grouping of documents, music, and movies by different topics, or finding customers that share similar interests based on common purchase behaviors as a basis for recommendation engines.</p></div></div></div>

<div id="calibre_link-593" class="calibre">
<div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis">
<div class="book" title="Grouping objects by similarity using k-means">
<div class="book" title="K-means clustering using scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1975"><a id="calibre_link-364" class="calibre1"></a>K-means clustering using scikit-learn</h2></div></div></div><p class="calibre8">As we will see in a moment, the<a id="calibre_link-1976" class="calibre1"></a> k-means algorithm is extremely easy to implement but is also computationally very efficient compared to other clustering algorithms, which might explain its popularity. The k-means algorithm belongs to the category of <span class="strong"><strong class="calibre2">prototype-based clustering</strong></span>. We will discuss two<a id="calibre_link-1977" class="calibre1"></a> other<a id="calibre_link-1978" class="calibre1"></a> categories of clustering, <span class="strong"><strong class="calibre2">hierarchical</strong></span> and <span class="strong"><strong class="calibre2">density-based clustering</strong></span>, later in<a id="calibre_link-1979" class="calibre1"></a> this chapter.</p><p class="calibre8">Prototype-based clustering means that each cluster is represented by a prototype, which can either be<a id="calibre_link-1980" class="calibre1"></a> the <span class="strong"><strong class="calibre2">centroid</strong></span> (<span class="strong"><em class="calibre9">average</em></span>) of similar points with continuous features, or <a id="calibre_link-1981" class="calibre1"></a>the <span class="strong"><strong class="calibre2">medoid</strong></span> (the most <span class="strong"><em class="calibre9">representative</em></span> or most frequently occurring point) in the case of categorical features. While k-means is very good at identifying clusters with a spherical shape, one of the drawbacks of this clustering algorithm is that we have to specify the number of clusters, <span class="strong"><em class="calibre9">k</em></span>, <span class="strong"><em class="calibre9">a priori</em></span>. An inappropriate choice for <span class="strong"><em class="calibre9">k</em></span> can result in poor clustering performance. Later in this chapter, we will discuss the <span class="strong"><strong class="calibre2">elbow</strong></span> method<a id="calibre_link-1982" class="calibre1"></a> and <span class="strong"><strong class="calibre2">silhouette plots</strong></span>, which are useful techniques to evaluate<a id="calibre_link-1983" class="calibre1"></a> the quality of a clustering to help us determine the optimal number of clusters <span class="strong"><em class="calibre9">k</em></span>.</p><p class="calibre8">Although k-means clustering can be applied to data in higher dimensions, we will walk through the following examples using a simple two-dimensional dataset for the purpose of visualization:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.datasets import make_blobs
&gt;&gt;&gt; X, y = make_blobs(n_samples=150,
...                   n_features=2,
...                   centers=3,
...                   cluster_std=0.5,
...                   shuffle=True,
...                   random_state=0)

&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; plt.scatter(X[:,0],
...             X[:,1],
...             c='white',
...             marker='o',
...             edgecolor='black',
...             s=50)
&gt;&gt;&gt; plt.grid()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The dataset that we just created consists of 150 randomly generated points that are roughly grouped into three regions with higher density, which is visualized via a two-dimensional scatterplot:</p><div class="mediaobject"><img src="images/00228.jpeg" alt="K-means clustering using scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In real-world<a id="calibre_link-1984" class="calibre1"></a> applications of clustering, we do not have any ground truth category information (information provided as empirical evidence as opposed to inference) about those samples; otherwise, it would fall into the category of supervised learning. Thus, our goal is to group the samples based on their feature similarities, which can be achieved using the k-means algorithm that can be summarized by the following four steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Randomly pick <span class="strong"><em class="calibre9">k</em></span> centroids from the sample points as initial cluster centers.</li><li class="listitem" value="2">
Assign each sample to the nearest centroid <span class="strong"><img src="images/00922.jpeg" alt="K-means clustering using scikit-learn" class="calibre14" /></span>, <span class="strong"><img src="images/00249.jpeg" alt="K-means clustering using scikit-learn" class="calibre14" /></span>.
</li><li class="listitem" value="3">Move the centroids to the center of the samples that were assigned to it.</li><li class="listitem" value="4">Repeat steps 2 and 3 until the cluster assignments do not change or a user-defined tolerance or maximum number of iterations is reached.</li></ol><div class="calibre13"></div></div><p class="calibre8">Now, the next question is <span class="strong"><em class="calibre9">how do we measure similarity between objects</em></span>? We can define similarity as the opposite of distance, and a commonly used distance for clustering samples with continuous features is the <span class="strong"><strong class="calibre2">squared Euclidean distance</strong></span> between <a id="calibre_link-1985" class="calibre1"></a>two points <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">y</strong></span> in <span class="strong"><em class="calibre9">m</em></span>-dimensional space:</p><div class="mediaobject"><img src="images/00263.jpeg" alt="K-means clustering using scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that, in the preceding equation, the index <span class="strong"><em class="calibre9">j</em></span> refers to the <span class="strong"><em class="calibre9">j</em></span>th dimension (feature column) of the <a id="calibre_link-1986" class="calibre1"></a>sample points <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">y</strong></span>. In the rest of this section, we will use the superscripts <span class="strong"><em class="calibre9">i</em></span> and <span class="strong"><em class="calibre9">j</em></span> to refer to the sample index and cluster index, respectively.</p><p class="calibre8">Based on this Euclidean distance metric, we can describe the k-means algorithm as a simple optimization problem, an iterative approach for minimizing <a id="calibre_link-1987" class="calibre1"></a>the within-cluster <span class="strong"><strong class="calibre2">Sum of Squared Errors</strong></span> (<span class="strong"><strong class="calibre2">SSE</strong></span>), which is sometimes also <a id="calibre_link-1988" class="calibre1"></a>called <span class="strong"><strong class="calibre2">cluster</strong></span> <span class="strong"><strong class="calibre2">inertia</strong></span>:</p><div class="mediaobject"><img src="images/00127.jpeg" alt="K-means clustering using scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here <span class="strong"><img src="images/00187.jpeg" alt="K-means clustering using scikit-learn" class="calibre14" /></span> is the representative point (centroid) for cluster <span class="strong"><em class="calibre9">j</em></span>, and <span class="strong"><img src="images/00288.jpeg" alt="K-means clustering using scikit-learn" class="calibre14" /></span> if the sample <span class="strong"><img src="images/00297.jpeg" alt="K-means clustering using scikit-learn" class="calibre14" /></span> is in cluster <span class="strong"><em class="calibre9">j</em></span>; <span class="strong"><img src="images/00348.jpeg" alt="K-means clustering using scikit-learn" class="calibre14" /></span> otherwise.</p><p class="calibre8">Now that we have learned how the simple k-means algorithm works, let's apply it to our sample dataset using the <code class="email">KMeans</code> class from scikit-learn's <code class="email">cluster</code> module:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.cluster import KMeans
&gt;&gt;&gt; km = KMeans(n_clusters=3, 
...             init='random', 
...             n_init=10,
...             max_iter=300, 
...             tol=1e-04,
...             random_state=0)
&gt;&gt;&gt; y_km = km.fit_predict(X)</pre></div><p class="calibre8">Using the preceding code, we set the number of desired clusters to <code class="email">3</code>; specifying the number of clusters <span class="strong"><em class="calibre9">a priori</em></span> is one of the limitations of k-means. We set <code class="email">n_init=10</code> to run the k-means clustering algorithms 10 times independently with different random centroids to choose the final model as the one with the lowest SSE. Via the <code class="email">max_iter</code> parameter, we specify the maximum number of iterations for each single run (here, <code class="email">300</code>). Note that the k-means <a id="calibre_link-1989" class="calibre1"></a>implementation in scikit-learn stops early if it converges before the maximum number of iterations is reached. However, it is possible that k-means does not reach convergence for a particular run, which can be problematic (computationally expensive) if we choose relatively large values for <code class="email">max_iter</code>. One way to deal with convergence problems is to choose larger values for <code class="email">tol</code>, which is a parameter that controls the tolerance with regard to the changes in the within-cluster sum-squared-error to declare convergence. In the preceding code, we chose a tolerance of <code class="email">1e-04</code> (=0.0001).</p><p class="calibre8">A problem with k-means is that one or more clusters can be empty. Note that this problem does not exist for k-medoids or fuzzy C-means, an algorithm that we will discuss later in this section. However, this problem is accounted for in the current k-means implementation in scikit-learn. If a cluster is empty, the algorithm will search for the sample that is farthest away from the centroid of the empty cluster. Then it will reassign the centroid to be this farthest point.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-1990" class="calibre1"></a>Note</h3><p class="calibre8">When we are applying k-means to real-world data using a Euclidean distance metric, we want to make sure that the features are measured on the same scale and apply z-score standardization or min-max scaling if necessary.</p></div><p class="calibre8">After we predicted the cluster labels <code class="email">y_km</code> and discussed some of the challenges of the k-means algorithm, let's now visualize the clusters that k-means identified in the dataset together with the cluster centroids. These are stored under the <code class="email">cluster_centers_</code> attribute of the fitted <code class="email">KMeans</code> object:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(X[y_km == 0, 0],
...             X[y_km == 0, 1],
...             s=50, c='lightgreen',
...             marker='s', edgecolor='black',
...             label='cluster 1')
&gt;&gt;&gt; plt.scatter(X[y_km == 1, 0],
...             X[y_km == 1, 1],
...             s=50, c='orange',
...             marker='o', edgecolor='black',
...             label='cluster 2')
&gt;&gt;&gt; plt.scatter(X[y_km == 2, 0],
...             X[y_km == 2, 1],
...             s=50, c='lightblue',
...             marker='v', edgecolor='black',
...             label='cluster 3')
&gt;&gt;&gt; plt.scatter(km.cluster_centers_[:, 0],
...             km.cluster_centers_[:, 1],
...             s=250, marker='*',
...             c='red', edgecolor='black',
...             label='centroids')
&gt;&gt;&gt; plt.legend(scatterpoints=1)
&gt;&gt;&gt; plt.grid()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">In the following <a id="calibre_link-1991" class="calibre1"></a>scatterplot, we can see that k-means placed the three centroids at the center of each sphere, which looks like a reasonable grouping given this dataset:</p><div class="mediaobject"><img src="images/00397.jpeg" alt="K-means clustering using scikit-learn" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Although k-means worked well on this toy dataset, we shall highlight another drawback of k-means: we have to specify the number of clusters, <span class="strong"><em class="calibre9">k</em></span>, <span class="strong"><em class="calibre9">a priori</em></span>. The number of clusters to choose may not always be so obvious in real-world applications, especially if we are working with a higher dimensional dataset that cannot be visualized. The other properties of k-means are that clusters do not overlap and are not hierarchical, and we also assume that there is at least one item in each cluster. Later in this chapter, we will encounter different types of clustering algorithms, hierarchical and density-based clustering. Neither type of algorithm requires us to specify the number of clusters upfront or assume spherical structures in our dataset.</p><p class="calibre8">In the next subsection, we will introduce a popular variant of the<a id="calibre_link-1992" class="calibre1"></a> classic k-means algorithm called <span class="strong"><strong class="calibre2">k-means++</strong></span>. While it doesn't address those assumptions and drawbacks of k-means discussed<a id="calibre_link-1993" class="calibre1"></a> in the previous paragraph, it can greatly improve the clustering results through more clever seeding of the initial cluster centers.</p></div></div></div></div>

<div id="calibre_link-31" class="calibre">
<div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis">
<div class="book" title="Grouping objects by similarity using k-means">
<div class="book" title="A smarter way of placing the initial cluster centroids using k-means++"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1994"><a id="calibre_link-365" class="calibre1"></a>A smarter way of placing the initial cluster centroids using k-means++</h2></div></div></div><p class="calibre8">So far, we have discussed the <a id="calibre_link-1995" class="calibre1"></a>classic k-means algorithm that uses a random seed to place the initial centroids, which can sometimes result in bad clusterings or slow convergence if the initial centroids are chosen poorly. One way to address this issue is to run the k-means algorithm multiple times on a dataset and choose the best performing model in terms of the SSE. Another strategy is to place the initial centroids far away from each other via the k-means++ algorithm, which leads to better and more consistent results than the classic k-means (<span class="strong"><em class="calibre9">k-means++: The Advantages of Careful Seeding</em></span>, <span class="strong"><em class="calibre9">D. Arthur</em></span> and <span class="strong"><em class="calibre9">S. Vassilvitskii</em></span> in proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027-1035. Society for Industrial and Applied Mathematics, <span class="strong"><em class="calibre9">2007</em></span>). The initialization in k-means++ can be summarized as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Initialize an empty set <span class="strong"><strong class="calibre2">M</strong></span> to store the <span class="strong"><em class="calibre9">k</em></span> centroids being selected.</li><li class="listitem" value="2">
Randomly choose the first centroid <span class="strong"><img src="images/00457.jpeg" alt="A smarter way of placing the initial cluster centroids using k-means++" class="calibre14" /></span> from the input samples and assign it to <span class="strong"><strong class="calibre2">M</strong></span>.
</li><li class="listitem" value="3">
For each sample <span class="strong"><img src="images/00340.jpeg" alt="A smarter way of placing the initial cluster centroids using k-means++" class="calibre14" /></span> that is not in <span class="strong"><strong class="calibre2">M</strong></span>, find the minimum squared distance <span class="strong"><img src="images/00351.jpeg" alt="A smarter way of placing the initial cluster centroids using k-means++" class="calibre14" /></span> to any of the centroids in <span class="strong"><strong class="calibre2">M</strong></span>.
</li><li class="listitem" value="4">
To randomly select the next centroid <span class="strong"><img src="images/00612.jpeg" alt="A smarter way of placing the initial cluster centroids using k-means++" class="calibre14" /></span>, use a weighted probability distribution equal to <span class="strong"><img src="images/00675.jpeg" alt="A smarter way of placing the initial cluster centroids using k-means++" class="calibre14" /></span>.
</li><li class="listitem" value="5">Repeat steps 2 and 3 until <span class="strong"><em class="calibre9">k</em></span> centroids are chosen.</li><li class="listitem" value="6">Proceed with the classic k-means algorithm.</li></ol><div class="calibre13"></div></div><p class="calibre8">To use k-means++ with<a id="calibre_link-1996" class="calibre1"></a> scikit-learn's <code class="email">KMeans</code> object, we just need to set the <code class="email">init</code> parameter to <code class="email">'k-means++'</code>. In fact, <code class="email">'k-means++'</code> is the default argument to the <code class="email">init</code> parameter, which is strongly recommended in practice. The only reason why we haven't used it in the previous example was to not introduce too many concepts all at once. The rest of this section on k-means will use k-means++, but readers are encouraged to experiment more with the two different approaches (classic k-means via <code class="email">init='random'</code> versus k-means++ via <code class="email">init='k-means++'</code>) for placing the initial cluster centroids.</p></div></div></div></div>

<div id="calibre_link-47" class="calibre">
<div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis">
<div class="book" title="Grouping objects by similarity using k-means">
<div class="book" title="Hard versus soft clustering"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-1997"><a id="calibre_link-366" class="calibre1"></a>Hard versus soft clustering</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Hard clustering</strong></span> describes a<a id="calibre_link-1998" class="calibre1"></a> family of algorithms where each sample in a<a id="calibre_link-1999" class="calibre1"></a> dataset is assigned to exactly one cluster, as in the k-means algorithm that we discussed in the previous subsection. In contrast, algorithms for <span class="strong"><strong class="calibre2">soft clustering</strong></span> (sometimes also called <span class="strong"><strong class="calibre2">fuzzy clustering</strong></span>) assign a<a id="calibre_link-2000" class="calibre1"></a> sample to one or more clusters. A popular example of soft clustering is<a id="calibre_link-2001" class="calibre1"></a> the <span class="strong"><strong class="calibre2">fuzzy C-means</strong></span> (<span class="strong"><strong class="calibre2">FCM</strong></span>) algorithm (also<a id="calibre_link-2002" class="calibre1"></a> called <span class="strong"><strong class="calibre2">soft k-means</strong></span> or <span class="strong"><strong class="calibre2">fuzzy k-means</strong></span>). The original<a id="calibre_link-2003" class="calibre1"></a> idea goes back to the 1970s, when Joseph C. Dunn first proposed an early version of fuzzy clustering to improve k-means (<span class="strong"><em class="calibre9">A Fuzzy Relative of the ISODATA Process and Its Use in Detecting Compact Well-Separated Clusters</em></span>, <span class="strong"><em class="calibre9">J. C. Dunn</em></span>, <span class="strong"><em class="calibre9">1973</em></span>). Almost a decade later, James C. Bedzek published his work on the improvement of the fuzzy clustering algorithm, which is now known as the FCM algorithm (<span class="strong"><em class="calibre9">Pattern Recognition with Fuzzy Objective Function Algorithms</em></span>, <span class="strong"><em class="calibre9">J. C. Bezdek</em></span>, <span class="strong"><em class="calibre9">Springer Science+Business Media</em></span>, <span class="strong"><em class="calibre9">2013</em></span>).</p><p class="calibre8">The FCM procedure is very similar to k-means. However, we replace the hard cluster assignment with probabilities for each point belonging to each cluster. In k-means, we could express the cluster membership of a sample <span class="strong"><em class="calibre9">x</em></span> with a sparse vector of binary values:</p><div class="mediaobject"><img src="images/00379.jpeg" alt="Hard versus soft clustering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, the index position with value 1 indicates the cluster centroid <span class="strong"><img src="images/00457.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span> the sample is assigned to (assuming <span class="strong"><img src="images/00389.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>). In contrast, a membership vector in FCM could be represented as follows:</p><div class="mediaobject"><img src="images/00400.jpeg" alt="Hard versus soft clustering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, each value falls in the range <span class="strong"><em class="calibre9">[0, 1]</em></span> and represents a probability of membership of the respective cluster centroid. The sum of the memberships for a given sample is equal to 1. Similar to the k-means<a id="calibre_link-2004" class="calibre1"></a> algorithm, we can summarize the <a id="calibre_link-2005" class="calibre1"></a>FCM algorithm in four key steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Specify the number of <span class="strong"><em class="calibre9">k</em></span> centroids and randomly assign the cluster memberships for each point.</li><li class="listitem" value="2">
Compute the cluster centroids <span class="strong"><img src="images/00922.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>, <span class="strong"><img src="images/00249.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>.
</li><li class="listitem" value="3">Update the cluster memberships for each point.</li><li class="listitem" value="4">Repeat steps 2 and 3 until the membership coefficients do not change, or a user-defined tolerance or maximum number of iterations is reached.</li></ol><div class="calibre13"></div></div><p class="calibre8">The objective function of FCM&mdash;we abbreviate it as <span class="strong"><img src="images/00923.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>&mdash;looks very similar to the within cluster sum-squared-error that we minimize in k-means:</p><div class="mediaobject"><img src="images/00420.jpeg" alt="Hard versus soft clustering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, note that the membership indicator <span class="strong"><img src="images/00435.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span> is not a binary value as in k-means (<span class="strong"><img src="images/00447.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>), but a real value that denotes the cluster membership probability <span class="strong"><img src="images/00016.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>). You also may have noticed that we added an additional exponent to <span class="strong"><img src="images/00435.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>; the exponent <span class="strong"><em class="calibre9">m</em></span>, any number greater than or equal to<a id="calibre_link-2006" class="calibre1"></a> one (typically <span class="strong"><em class="calibre9">m=2</em></span>), is the<a id="calibre_link-2007" class="calibre1"></a> so-called <span class="strong"><strong class="calibre2">fuzziness coefficient</strong></span> (or simply <span class="strong"><strong class="calibre2">fuzzifier</strong></span>) that controls the degree of <span class="strong"><em class="calibre9">fuzziness</em></span>. The larger the value of <span class="strong"><em class="calibre9">m</em></span> the smaller the cluster membership <span class="strong"><img src="images/00435.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span> becomes, which leads to fuzzier clusters. The cluster <a id="calibre_link-2008" class="calibre1"></a>membership probability itself is<a id="calibre_link-2009" class="calibre1"></a> calculated as follows:</p><div class="mediaobject"><img src="images/00784.jpeg" alt="Hard versus soft clustering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">For example, if we chose three cluster centers as in the previous k-means example, we could calculate the membership of the <span class="strong"><img src="images/00340.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span> sample belonging to the <span class="strong"><img src="images/00457.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span> cluster as follows:</p><div class="mediaobject"><img src="images/00663.jpeg" alt="Hard versus soft clustering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The center <span class="strong"><img src="images/00457.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span> of a cluster itself is calculated as the mean of all samples weighted by the degree to which each sample belongs to that cluster (<span class="strong"><img src="images/00427.jpeg" alt="Hard versus soft clustering" class="calibre14" /></span>):</p><div class="mediaobject"><img src="images/00041.jpeg" alt="Hard versus soft clustering" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Just by looking at the equation to calculate the cluster memberships, it is intuitive to say that each iteration in FCM is <a id="calibre_link-2010" class="calibre1"></a>more expensive than an iteration in<a id="calibre_link-2011" class="calibre1"></a> k-means. However, FCM typically requires fewer iterations overall to reach convergence. Unfortunately, the FCM algorithm is currently not implemented in scikit-learn. However, it has been found in practice that both k-means and FCM produce very similar clustering outputs, as described in a study (<span class="strong"><em class="calibre9">Comparative Analysis of k-means and Fuzzy C-Means Algorithms</em></span>, <span class="strong"><em class="calibre9">S. Ghosh</em></span>, and <span class="strong"><em class="calibre9">S. K. Dubey</em></span>, <span class="strong"><em class="calibre9">IJACSA</em></span>, 4: 35&ndash;38, <span class="strong"><em class="calibre9">2013</em></span>).</p></div></div></div></div>

<div id="calibre_link-55" class="calibre">
<div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis">
<div class="book" title="Grouping objects by similarity using k-means">
<div class="book" title="Using the elbow method to find the optimal number of clusters"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2012"><a id="calibre_link-367" class="calibre1"></a>Using the elbow method to find the optimal number of clusters</h2></div></div></div><p class="calibre8">One of the main <a id="calibre_link-2013" class="calibre1"></a>challenges in unsupervised learning is that we do not know the definitive answer. We don't have the ground truth class labels in our dataset that allow us to apply the techniques that we used in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, in order to evaluate the performance of a supervised model. Thus, to quantify the quality of clustering, we need to use intrinsic metrics&mdash;such as the within-cluster SSE (distortion) that we discussed earlier in this chapter&mdash;to compare the performance of different k-means clusterings. Conveniently, we don't need to compute the within-cluster SSE explicitly when we are using scikit-learn, as it is already accessible via the <code class="email">inertia_</code> attribute after fitting a <code class="email">KMeans</code> model:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print('Distortion: %.2f' % km.inertia_)
Distortion: 72.48</pre></div><p class="calibre8">Based on the within-cluster SSE, we can use a graphical tool, the so-called <span class="strong"><strong class="calibre2">elbow method</strong></span>, to estimate the optimal number of clusters <span class="strong"><em class="calibre9">k</em></span> for a given task. Intuitively, we can say that, if <span class="strong"><em class="calibre9">k</em></span> increases, the distortion will decrease. This is because the samples will be closer to the centroids they are assigned to. The idea behind the elbow method is to identify the value of <span class="strong"><em class="calibre9">k</em></span> where the distortion begins to increase most rapidly, which will become clearer if we plot the distortion for different values of <span class="strong"><em class="calibre9">k</em></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; distortions = []
&gt;&gt;&gt; for i in range(1, 11):
...     km = KMeans(n_clusters=i,
...                 init='k-means++',
...                 n_init=10,
...                 max_iter=300,
...                 random_state=0)
&gt;&gt;&gt;     km.fit(X)
&gt;&gt;&gt;     distortions.append(km.inertia_)
&gt;&gt;&gt; plt.plot(range(1,11), distortions, marker='o')
&gt;&gt;&gt; plt.xlabel('Number of clusters')
&gt;&gt;&gt; plt.ylabel('Distortion')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we <a id="calibre_link-2014" class="calibre1"></a>can see in the following plot, the <span class="strong"><em class="calibre9">elbow</em></span> is located at <span class="strong"><em class="calibre9">k</em></span>=3, which is evidence that <span class="strong"><em class="calibre9">k</em></span>=3 is indeed a good choice for this dataset:</p><div class="mediaobject"><img src="images/00525.jpeg" alt="Using the elbow method to find the optimal number of clusters" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-56" class="calibre">
<div class="book" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis">
<div class="book" title="Grouping objects by similarity using k-means">
<div class="book" title="Quantifying the quality of clustering via silhouette plots"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2015"><a id="calibre_link-368" class="calibre1"></a>Quantifying the quality of clustering via silhouette plots</h2></div></div></div><p class="calibre8">Another intrinsic metric to<a id="calibre_link-2016" class="calibre1"></a> evaluate the quality of a <a id="calibre_link-2017" class="calibre1"></a>clustering is <span class="strong"><strong class="calibre2">silhouette analysis</strong></span>, which can also be applied to clustering algorithms other than k-means that we will discuss later in this chapter. Silhouette analysis can be used as a graphical tool to plot a measure of how tightly grouped the samples in the clusters are. To calculate the <span class="strong"><strong class="calibre2">silhouette coefficient</strong></span> of <a id="calibre_link-2018" class="calibre1"></a>a single sample in our dataset, we can apply the following three steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">
Calculate <a id="calibre_link-2019" class="calibre1"></a>the <span class="strong"><strong class="calibre2">cluster cohesion</strong></span><span class="strong"><img src="images/00581.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> as the average distance between a sample <span class="strong"><img src="images/00340.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> and all other points in the same cluster.
</li><li class="listitem" value="2">
Calculate <a id="calibre_link-2020" class="calibre1"></a>the <span class="strong"><strong class="calibre2">cluster separation</strong></span><span class="strong"><img src="images/00639.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> from the next closest cluster as the average distance between<a id="calibre_link-2021" class="calibre1"></a> the sample <span class="strong"><img src="images/00340.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> and all samples in the nearest cluster.
</li><li class="listitem" value="3">
Calculate the silhouette <span class="strong"><img src="images/00085.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> as the difference between cluster cohesion and separation divided by the greater of the two, as shown here:
<div class="mediaobject"><img src="images/00098.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre11" /></div><p class="calibre26"> </p></li></ol><div class="calibre13"></div></div><p class="calibre8">The silhouette coefficient is bounded in the range -1 to 1. Based on the preceding equation, we can see that the silhouette coefficient is 0 if the cluster separation and cohesion are equal (<span class="strong"><img src="images/00822.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span>. Furthermore, we get close to an ideal silhouette coefficient of 1 if <span class="strong"><img src="images/00890.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span>, since <span class="strong"><img src="images/00639.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> quantifies how dissimilar a sample is to other clusters, and <span class="strong"><img src="images/00581.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span> tells us how similar it is to the other samples in its own cluster.</p><p class="calibre8">The silhouette coefficient is available as <code class="email">silhouette_samples</code> from scikit-learn's <code class="email">metric</code> module, and optionally, the <code class="email">silhouette_scores</code> function can be imported for convenience. The <code class="email">silhouette_scores</code> function calculates the average silhouette coefficient across all samples, which is equivalent to <code class="email">numpy.mean(silhouette_samples(â¦))</code>. By executing the following code, we will now create a plot of<a id="calibre_link-2022" class="calibre1"></a> the silhouette coefficients for a k-means clustering with <span class="strong"><img src="images/00963.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre14" /></span>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; km = KMeans(n_clusters=3,
...             init='k-means++',
...             n_init=10,
...             max_iter=300,
...             tol=1e-04,
...             random_state=0)
&gt;&gt;&gt; y_km = km.fit_predict(X)

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from matplotlib import cm
&gt;&gt;&gt; from sklearn.metrics import silhouette_samples
&gt;&gt;&gt; cluster_labels = np.unique(y_km)
&gt;&gt;&gt; n_clusters = cluster_labels.shape[0]
&gt;&gt;&gt; silhouette_vals = silhouette_samples(X, 
...                                      y_km, 
...                                      metric='euclidean')
&gt;&gt;&gt; y_ax_lower, y_ax_upper = 0, 0
&gt;&gt;&gt; yticks = []
&gt;&gt;&gt; for i, c in enumerate(cluster_labels):
...     c_silhouette_vals = silhouette_vals[y_km == c]
...     c_silhouette_vals.sort()
...     y_ax_upper += len(c_silhouette_vals)
...     color = cm.jet(float(i) / n_clusters)
...     plt.barh(range(y_ax_lower, y_ax_upper),
...              c_silhouette_vals, 
...              height=1.0,
...              edgecolor='none',
...              color=color)
...     yticks.append((y_ax_lower + y_ax_upper) / 2.)
...     y_ax_lower += len(c_silhouette_vals)
&gt;&gt;&gt; silhouette_avg = np.mean(silhouette_vals)
&gt;&gt;&gt; plt.axvline(silhouette_avg,
...             color="red",
...             linestyle="--") 
&gt;&gt;&gt; plt.yticks(yticks, cluster_labels + 1)
&gt;&gt;&gt; plt.ylabel('Cluster')
&gt;&gt;&gt; plt.xlabel('Silhouette coefficient')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Through a visual inspection of the silhouette plot, we can quickly scrutinize the sizes of the different clusters and identify clusters that contain <span class="strong"><em class="calibre9">outliers</em></span>:</p><div class="mediaobject"><img src="images/00144.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, as we can see<a id="calibre_link-2023" class="calibre1"></a> in the preceding silhouette plot, the silhouette coefficients are not even close to <span class="strong"><strong class="calibre2">0</strong></span>, which is in this case an indicator of a <span class="strong"><em class="calibre9">good</em></span> clustering. Furthermore, to summarize the goodness of our clustering, we added the average silhouette coefficient to the plot (dotted line).</p><p class="calibre8">To see what a silhouette plot looks like for a relatively <span class="strong"><em class="calibre9">bad</em></span> clustering, let's seed the k-means algorithm with only two centroids:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; km = KMeans(n_clusters=2, 
...             init='k-means++',
...             n_init=10,
...             max_iter=300,
...             tol=1e-04,
...             random_state=0)
&gt;&gt;&gt; y_km = km.fit_predict(X)

&gt;&gt;&gt; plt.scatter(X[y_km==0,0],
...             X[y_km==0,1],
...             s=50, c='lightgreen',
...             edgecolor='black',
...             marker='s', 
...             label='cluster 1')
&gt;&gt;&gt; plt.scatter(X[y_km==1,0],
...             X[y_km==1,1],
...             s=50,
...             c='orange',
...             edgecolor='black',
...             marker='o', 
...             label='cluster 2')
&gt;&gt;&gt; plt.scatter(km.cluster_centers_[:,0],
...             km.cluster_centers_[:,1],
...             s=250,
...             marker='*',
...             c='red',
...             label='centroids')
&gt;&gt;&gt; plt.legend()
&gt;&gt;&gt; plt.grid()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the<a id="calibre_link-2024" class="calibre1"></a> resulting plot, one of the centroids falls between two of the three spherical groupings of the sample points. Although the clustering does not look completely terrible, it is suboptimal:</p><div class="mediaobject"><img src="images/00156.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Please keep in mind that we typically do not have the luxury of visualizing datasets in two-dimensional scatterplots in real-world problems, since we typically work with data in higher dimensions. So, next, we create the silhouette plot to evaluate the results:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; cluster_labels = np.unique(y_km)
&gt;&gt;&gt; n_clusters = cluster_labels.shape[0]
&gt;&gt;&gt; silhouette_vals = silhouette_samples(X, 
...                                      y_km, 
...                                      metric='euclidean')
&gt;&gt;&gt; y_ax_lower, y_ax_upper = 0, 0
&gt;&gt;&gt; yticks = []
&gt;&gt;&gt; for i, c in enumerate(cluster_labels):
...     c_silhouette_vals = silhouette_vals[y_km == c]
...     c_silhouette_vals.sort()
...     y_ax_upper += len(c_silhouette_vals)
...     color = cm.jet(i / n_clusters)
...     plt.barh(range(y_ax_lower, y_ax_upper), 
...              c_silhouette_vals, 
...              height=1.0, 
...              edgecolor='none', 
...              color=color)
...     yticks.append((y_ax_lower + y_ax_upper) / 2)
...     y_ax_lower += len(c_silhouette_vals)
&gt;&gt;&gt; silhouette_avg = np.mean(silhouette_vals)
&gt;&gt;&gt; plt.axvline(silhouette_avg, color="red", linestyle="--")
&gt;&gt;&gt; plt.yticks(yticks, cluster_labels + 1)
&gt;&gt;&gt; plt.ylabel('Cluster')
&gt;&gt;&gt; plt.xlabel('Silhouette coefficient')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the <a id="calibre_link-2025" class="calibre1"></a>resulting plot, the silhouettes now have visibly different lengths and widths, which is evidence for a relatively <span class="strong"><em class="calibre9">bad</em></span> or at least <span class="strong"><em class="calibre9">suboptimal</em></span> clustering:</p><div class="mediaobject"><img src="images/00171.jpeg" alt="Quantifying the quality of clustering via silhouette plots" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-58" class="calibre">
<div id="calibre_link-2026" class="calibre10"></div><div class="book" title="Organizing clusters as a hierarchical tree"><div class="book" id="calibre_link-12"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2027"><a id="calibre_link-2028" class="calibre1"></a>Organizing clusters as a hierarchical tree</h1></div></div></div><p class="calibre8">In this section, we will<a id="calibre_link-2029" class="calibre1"></a> take a look at an alternative approach to <a id="calibre_link-2030" class="calibre1"></a>prototype-based clustering: <span class="strong"><strong class="calibre2">hierarchical clustering</strong></span>. One advantage of hierarchical clustering algorithms is that it allows us to plot <span class="strong"><strong class="calibre2">dendrograms</strong></span> (visualizations of a binary hierarchical clustering), which can help <a id="calibre_link-2031" class="calibre1"></a>with the interpretation of the results by creating meaningful taxonomies. Another useful advantage of this hierarchical approach is that we do not need to specify the number of clusters up front.</p><p class="calibre8">The two main approaches to hierarchical clustering are <span class="strong"><strong class="calibre2">agglomerative</strong></span>
<a id="calibre_link-2032" class="calibre1"></a> and <span class="strong"><strong class="calibre2">divisive</strong></span> hierarchical clustering. In divisive hierarchical clustering, we start with one cluster <a id="calibre_link-2033" class="calibre1"></a>that encompasses all our samples, and we iteratively split the cluster into smaller clusters until each cluster only contains one sample. In this section, we will focus on agglomerative clustering, which takes the opposite approach. We start with each sample as an individual cluster and merge the closest pairs of clusters until only one cluster remains.</p></div></div>

<div id="calibre_link-60" class="calibre">
<div class="book" title="Organizing clusters as a hierarchical tree">
<div class="book" title="Grouping clusters in bottom-up fashion"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2034"><a id="calibre_link-369" class="calibre1"></a>Grouping clusters in bottom-up fashion</h2></div></div></div><p class="calibre8">The two standard algorithms for <a id="calibre_link-2035" class="calibre1"></a>agglomerative hierarchical<a id="calibre_link-2036" class="calibre1"></a> clustering are <span class="strong"><strong class="calibre2">single linkage</strong></span>
<a id="calibre_link-2037" class="calibre1"></a> and<a id="calibre_link-2038" class="calibre1"></a> <span class="strong"><strong class="calibre2">complete linkage</strong></span>. Using single linkage, we compute the distances between the most similar members for each pair of clusters and merge the two clusters for which the distance between the most similar members is the smallest. The complete linkage approach is similar to single linkage but, instead of comparing the most similar members in each pair of clusters, we compare the most dissimilar members to perform the merge. This is shown in the following diagram:</p><div class="mediaobject"><img src="images/00221.jpeg" alt="Grouping clusters in bottom-up fashion" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2039" class="calibre1"></a>Note</h3><p class="calibre8">Other commonly used algorithms for agglomerative hierarchical clustering include <span class="strong"><strong class="calibre2">average linkage</strong></span> and <span class="strong"><strong class="calibre2">Ward's linkage</strong></span>. In average linkage, we merge the cluster pairs based on the<a id="calibre_link-2040" class="calibre1"></a> minimum<a id="calibre_link-2041" class="calibre1"></a> average distances between all group members in the two clusters. In Ward's linkage, the two clusters that lead to the minimum increase of the total within-cluster SSE are merged.</p></div><p class="calibre8">In this section, we <a id="calibre_link-2042" class="calibre1"></a>will focus on agglomerative clustering <a id="calibre_link-2043" class="calibre1"></a>using the complete linkage approach. Hierarchical complete linkage clustering is an iterative procedure that can be summarized by the following steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Compute the distance matrix of all samples.</li><li class="listitem" value="2">Represent each data point as a singleton cluster.</li><li class="listitem" value="3">Merge the two closest clusters based on the distance between the most dissimilar (distant) members.</li><li class="listitem" value="4">Update the similarity matrix.</li><li class="listitem" value="5">Repeat steps 2-4 until one single cluster remains.</li></ol><div class="calibre13"></div></div><p class="calibre8">Next, we will discuss how to compute the distance matrix (step 1). But first, let's generate some random sample data to work with: the rows represent different observations (IDs 0-4), and the columns are the different features (<code class="email">X</code>, <code class="email">Y</code>, <code class="email">Z</code>) of those samples:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(123)
&gt;&gt;&gt; variables = ['X', 'Y', 'Z']
&gt;&gt;&gt; labels = ['ID_0','ID_1','ID_2','ID_3','ID_4']
&gt;&gt;&gt; X = np.random.random_sample([5,3])*10
&gt;&gt;&gt; df = pd.DataFrame(X, columns=variables, index=labels)
&gt;&gt;&gt; df</pre></div><p class="calibre8">After executing the preceding <a id="calibre_link-2044" class="calibre1"></a>code, we should now see the following data <a id="calibre_link-2045" class="calibre1"></a>frame containing the randomly generated samples:</p><div class="mediaobject"><img src="images/00190.jpeg" alt="Grouping clusters in bottom-up fashion" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-65" class="calibre">
<div class="book" title="Organizing clusters as a hierarchical tree">
<div class="book" title="Performing hierarchical clustering on a distance matrix"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2046"><a id="calibre_link-370" class="calibre1"></a>Performing hierarchical clustering on a distance matrix</h2></div></div></div><p class="calibre8">To calculate the <a id="calibre_link-2047" class="calibre1"></a>distance matrix as input for the<a id="calibre_link-2048" class="calibre1"></a> hierarchical clustering algorithm, we will use the <code class="email">pdist</code> function from SciPy's <code class="email">spatial.distance</code> submodule:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from scipy.spatial.distance import pdist, squareform
&gt;&gt;&gt; row_dist = pd.DataFrame(squareform(
...            pdist(df, metric='euclidean')),
...            columns=labels, index=labels)
&gt;&gt;&gt; row_dist</pre></div><p class="calibre8">Using the preceding code, we calculated the Euclidean distance between each pair of sample points in our dataset based on the features <code class="email">X</code>, <code class="email">Y</code>, and <code class="email">Z</code>. We provided the condensed distance matrix&mdash;returned by <code class="email">pdist</code>&mdash;as input to the <code class="email">squareform</code> function to create a symmetrical matrix of the pair-wise distances as shown here:</p><div class="mediaobject"><img src="images/00203.jpeg" alt="Performing hierarchical clustering on a distance matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Next, we will apply <a id="calibre_link-2049" class="calibre1"></a>the complete linkage agglomeration<a id="calibre_link-2050" class="calibre1"></a> to our clusters using the <code class="email">linkage</code> function from SciPy's <code class="email">cluster.hierarchy</code> submodule, which returns a so-called <span class="strong"><strong class="calibre2">linkage matrix</strong></span>
<a id="calibre_link-2051" class="calibre1"></a>.</p><p class="calibre8">However, before we call the <code class="email">linkage</code> function, let us take a careful look at the function documentation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from scipy.cluster.hierarchy import linkage
&gt;&gt;&gt; help(linkage)
[â¦]
Parameters:
  y : ndarray
    A condensed or redundant distance matrix. A condensed 
    distance matrix is a flat array containing the upper 
    triangular of the distance matrix. This is the form 
    that pdist returns. Alternatively, a collection of m 
    observation vectors in n dimensions may be passed as 
    an m by n array.

  method : str, optional
    The linkage algorithm to use. See the Linkage Methods 
    section below for full descriptions.

  metric : str, optional
    The distance metric to use. See the distance.pdist 
    function for a list of valid distance metrics.

 Returns:
  Z : ndarray
    The hierarchical clustering encoded as a linkage matrix.
[â¦]</pre></div><p class="calibre8">Based on the function <a id="calibre_link-2052" class="calibre1"></a>description, we conclude that <a id="calibre_link-2053" class="calibre1"></a>we can use a condensed distance matrix (upper triangular) from the <code class="email">pdist</code> function as an input attribute. Alternatively, we could also provide the initial data array and use the <code class="email">'euclidean'</code> metric as a function argument in <code class="email">linkage</code>. However, we should not use the <code class="email">squareform</code> distance matrix that we defined earlier, since it would yield different distance values than expected. To sum it up, the three possible scenarios are listed here:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Incorrect approach</strong></span>: Using the <code class="email">squareform</code> distance matrix shown in the following code snippet would lead to incorrect results:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from scipy.cluster.hierarchy import linkage
&gt;&gt;&gt; row_clusters = linkage(row_dist,
...                        method='complete',
...                        metric='euclidean')</pre></div></li><li class="listitem"><span class="strong"><strong class="calibre2">Correct approach</strong></span>: Using the condensed distance matrix as shown in the following code example yields the correct pairwise distance matrix:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; row_clusters = linkage(pdist(df, metric='euclidean'),
...                        method='complete')</pre></div></li><li class="listitem"><span class="strong"><strong class="calibre2">Correct approach</strong></span>: Using the complete input sample matrix as shown in the following code snippet also leads to a correct distance matrix similar to the preceding approach:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; row_clusters = linkage(df.values, 
...                        method='complete', 
...                        metric='euclidean')</pre></div></li></ul></div><p class="calibre8">To take a closer look at the clustering results, we can turn clustering results into a pandas <code class="email">DataFrame</code> (best viewed in a Jupyter Notebook) as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; pd.DataFrame(row_clusters,
...      columns=['row label 1',
...               'row label 2',
...               'distance', 
...               'no. of items in clust.'],
...      index=['cluster %d' %(i+1) for i in
...             range(row_clusters.shape[0])])</pre></div><p class="calibre8">As shown in the following<a id="calibre_link-2054" class="calibre1"></a> screenshot, the linkage matrix consists of several rows where each row represents one merge. The first and second <a id="calibre_link-2055" class="calibre1"></a>columns denote the most dissimilar members in each cluster, and the third row reports the distance between those members. The last column returns the count of the members in each cluster:</p><div class="mediaobject"><img src="images/00217.jpeg" alt="Performing hierarchical clustering on a distance matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now that we have computed the linkage matrix, we can visualize the results in the form of a dendrogram:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from scipy.cluster.hierarchy import dendrogram
# make dendrogram black (part 1/2)
# from scipy.cluster.hierarchy import set_link_color_palette
# set_link_color_palette(['black'])
&gt;&gt;&gt; row_dendr = dendrogram(row_clusters, 
...                       labels=labels,
...                       # make dendrogram black (part 2/2)
...                       # color_threshold=np.inf
...                       )
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.ylabel('Euclidean distance')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">If you are executing the preceding code or reading an ebook version of this book, you will notice that the branches in the resulting dendrogram are shown in different colors. The coloring scheme is derived from a list of Matplotlib colors that are cycled for the distance thresholds in the dendrogram. For example, to display the dendrograms in black, you can uncomment the respective sections that I inserted in the preceding code:</p><div class="mediaobject"><img src="images/00230.jpeg" alt="Performing hierarchical clustering on a distance matrix" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Such a dendrogram<a id="calibre_link-2056" class="calibre1"></a> summarizes the different <a id="calibre_link-2057" class="calibre1"></a>clusters that were formed during the agglomerative hierarchical clustering; for example, we can see that the samples <code class="email">ID_0</code> and <code class="email">ID_4</code>, followed by <code class="email">ID_1</code> and <code class="email">ID_2</code>, are the most similar ones based on the Euclidean distance metric.</p></div></div></div>

<div id="calibre_link-86" class="calibre">
<div class="book" title="Organizing clusters as a hierarchical tree">
<div class="book" title="Attaching dendrograms to a heat map"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2058"><a id="calibre_link-371" class="calibre1"></a>Attaching dendrograms to a heat map</h2></div></div></div><p class="calibre8">In<a id="calibre_link-2059" class="calibre1"></a> practical applications, hierarchical clustering <a id="calibre_link-2060" class="calibre1"></a>dendrograms are often used in combination with a <span class="strong"><strong class="calibre2">heat map</strong></span>, which allows us to represent the individual values in the sample matrix with a color code. In this section, we will discuss how to attach a dendrogram to a heat map plot and order the rows in the heat map correspondingly.</p><p class="calibre8">However, attaching a dendrogram to a heat map can be a little bit tricky, so let's go through this procedure step by step:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">We create a new <code class="email">figure</code> object and define the <span class="strong"><em class="calibre9">x</em></span> axis position, <span class="strong"><em class="calibre9">y</em></span> axis position, width, and height of the dendrogram via the <code class="email">add_axes</code> attribute. Furthermore, we rotate the dendrogram 90 degrees counter-clockwise. The code is as follows:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; fig = plt.figure(figsize=(8,8), facecolor='white')
&gt;&gt;&gt; axd = fig.add_axes([0.09,0.1,0.2,0.6])
&gt;&gt;&gt; row_dendr = dendrogram(row_clusters, orientation='left')
&gt;&gt;&gt; # note: for matplotlib &lt; v1.5.1, please use orientation='right'</pre></div></li><li class="listitem" value="2">Next, we reorder the data in our initial <code class="email">DataFrame</code> according to the clustering labels that can be accessed from the dendrogram object, which is essentially a Python dictionary, via the <code class="email">leaves</code> key. The code is as follows:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df_rowclust = df.iloc[row_dendr['leaves'][::-1]]</pre></div></li><li class="listitem" value="3">Now, we construct the heat map from the reordered <code class="email">DataFrame</code> and position it next to the dendrogram:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; axm = fig.add_axes([0.23,0.1,0.6,0.6])
&gt;&gt;&gt; cax = axm.matshow(df_rowclust, 
...              interpolation='nearest', cmap='hot_r')</pre></div></li><li class="listitem" value="4">Finally, we <a id="calibre_link-2061" class="calibre1"></a>will modify the aesthetics of the<a id="calibre_link-2062" class="calibre1"></a> dendrogram by removing the axis ticks and hiding the axis spines. Also, we will add a color bar and assign the feature and sample names to the <span class="strong"><em class="calibre9">x</em></span> and <span class="strong"><em class="calibre9">y</em></span> axis tick labels, respectively:<div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; axd.set_xticks([])
&gt;&gt;&gt; axd.set_yticks([])
&gt;&gt;&gt; for i in axd.spines.values():
...     i.set_visible(False)
&gt;&gt;&gt; fig.colorbar(cax)
&gt;&gt;&gt; axm.set_xticklabels([''] + list(df_rowclust.columns))
&gt;&gt;&gt; axm.set_yticklabels([''] + list(df_rowclust.index))
&gt;&gt;&gt; plt.show()</pre></div></li></ol><div class="calibre13"></div></div><p class="calibre8">After following the previous steps, the heat map should be displayed with the dendrogram attached:</p><div class="mediaobject"><img src="images/00240.jpeg" alt="Attaching dendrograms to a heat map" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, the <a id="calibre_link-2063" class="calibre1"></a>order of rows in the heat map reflects the <a id="calibre_link-2064" class="calibre1"></a>clustering of the samples in the dendrogram. In addition to a simple dendrogram, the color-coded values of each sample and feature in the heat map provide us with a nice summary of the dataset.</p></div></div></div>

<div id="calibre_link-88" class="calibre">
<div class="book" title="Organizing clusters as a hierarchical tree">
<div class="book" title="Applying agglomerative clustering via scikit-learn"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2065"><a id="calibre_link-372" class="calibre1"></a>Applying agglomerative clustering via scikit-learn</h2></div></div></div><p class="calibre8">In the previous subsection, we saw<a id="calibre_link-2066" class="calibre1"></a> how to perform agglomerative<a id="calibre_link-2067" class="calibre1"></a> hierarchical clustering using SciPy. However, there is also an <code class="email">AgglomerativeClustering</code> implementation in scikit-learn, which allows us to choose the number of clusters that we want to return. This is useful if we want to prune the hierarchical cluster tree. By setting the <code class="email">n_cluster</code> parameter to <code class="email">3</code>, we will now cluster the samples into three groups using the same complete linkage approach based on the Euclidean distance metric, as before:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.cluster import AgglomerativeClustering
&gt;&gt;&gt; ac = AgglomerativeClustering(n_clusters=3,
...                              affinity='euclidean', 
...                              linkage='complete')
&gt;&gt;&gt; labels = ac.fit_predict(X)
&gt;&gt;&gt; print('Cluster labels: %s' % labels)
Cluster labels: [1 0 0 2 1]</pre></div><p class="calibre8">Looking at the predicted cluster labels, we can see that the first and the fifth sample (<code class="email">ID_0</code> and <code class="email">ID_4</code>) were assigned <a id="calibre_link-2068" class="calibre1"></a>to one cluster (label <code class="email">1</code>), and <a id="calibre_link-2069" class="calibre1"></a>the samples <code class="email">ID_1</code> and <code class="email">ID_2</code> were assigned to a second cluster (label <code class="email">0</code>). The sample <code class="email">ID_3</code> was put into its own cluster (label <code class="email">2</code>). Overall, the results are consistent with the results that we observed in the dendrogram. We shall note though that <code class="email">ID_3</code> is more similar to <code class="email">ID_4</code> and <code class="email">ID_0</code> than to <code class="email">ID_1</code> and <code class="email">ID_2</code>, as shown in the preceding dendrogram figure; this is not clear from scikit-learn's clustering results. Let's now rerun the <code class="email">AgglomerativeClustering</code> using <code class="email">n_cluster=2</code> in the following code snippet:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ac = AgglomerativeClustering(n_clusters=2,
...                             affinity='euclidean',
...                             linkage='complete')
&gt;&gt;&gt; labels = ac.fit_predict(X)
&gt;&gt;&gt; print('Cluster labels: %s' % labels)
Cluster labels: [0 1 1 0 0]</pre></div><p class="calibre8">As we can see, in this <span class="strong"><em class="calibre9">pruned</em></span> clustering hierarchy, label <code class="email">ID_3</code> was not assigned to the same cluster as <code class="email">ID_0</code> and <code class="email">ID_4</code>, as expected.</p></div></div></div>

<div id="calibre_link-91" class="calibre"><div class="book" title="Locating regions of high density via DBSCAN"><div class="book" id="calibre_link-53"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2070"><a id="calibre_link-2071" class="calibre1"></a>Locating regions of high density via DBSCAN</h1></div></div></div><p class="calibre8">Although we can't<a id="calibre_link-2072" class="calibre1"></a> cover the vast amount of different clustering algorithms in this chapter, let's at least introduce one more approach to clustering: <span class="strong"><strong class="calibre2">Density-based Spatial Clustering of Applications with Noise</strong></span> (<span class="strong"><strong class="calibre2">DBSCAN</strong></span>), which does not make assumptions about spherical clusters like k-means, nor does it partition the dataset into hierarchies that require a manual cut-off point. As its name implies, density-based clustering assigns cluster labels based on dense regions of points. In DBSCAN, the notion of density is defined as the number of points within a specified radius <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span>.</p><p class="calibre8">According to the DBSCAN algorithm, a special label is assigned to each sample (point) using the following criteria:</p><div class="book"><ul class="itemizedlist"><li class="listitem">
A point is considered a <span class="strong"><strong class="calibre2">core point</strong></span> if at<a id="calibre_link-2073" class="calibre1"></a> least a specified number (MinPts) of neighboring points fall within the specified radius <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span></li><li class="listitem">
A <span class="strong"><strong class="calibre2">border point</strong></span> is a <a id="calibre_link-2074" class="calibre1"></a>point <a id="calibre_link-2075" class="calibre1"></a>that has fewer neighbors than MinPts within <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span>, but lies within the <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span> radius of a core point
</li><li class="listitem">All other points that are neither core nor border points are <a id="calibre_link-2076" class="calibre1"></a>considered <span class="strong"><strong class="calibre2">noise points</strong></span></li></ul></div><p class="calibre8">After labeling the points as core, border, or noise, the DBSCAN algorithm can be summarized in two simple steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">
Form a separate cluster for each core point or connected group of core points (core points are connected if they are no farther away than <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span>).
</li><li class="listitem" value="2">Assign each border point to the cluster of its corresponding core point.</li></ol><div class="calibre13"></div></div><p class="calibre8">To get a better understanding of what the result of DBSCAN can look like before jumping to the implementation, let's summarize what we have just learned about core points, border points, and noise points in the following figure:</p><div class="mediaobject"><img src="images/00582.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">One of the main <a id="calibre_link-2077" class="calibre1"></a>advantages of using DBSCAN is that it does not assume that the clusters have a spherical shape as in k-means. Furthermore, DBSCAN is different from k-means and hierarchical clustering in that it doesn't necessarily assign each point to a cluster but is capable of removing noise points.</p><p class="calibre8">For a more illustrative example, let's create a new dataset of half-moon-shaped structures to compare k-means clustering, hierarchical clustering, and DBSCAN:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.datasets import make_moons
&gt;&gt;&gt; X, y = make_moons(n_samples=200,
...                   noise=0.05,
...                   random_state=0)
&gt;&gt;&gt; plt.scatter(X[:,0], X[:,1])
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the resulting plot, there are two visible, half-moon shaped groups consisting of 100 sample points each:</p><div class="mediaobject"><img src="images/00640.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We will start by using the<a id="calibre_link-2078" class="calibre1"></a> k-means algorithm and complete linkage clustering to see if one of those previously discussed clustering algorithms can successfully identify the half-moon shapes as separate clusters. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))
&gt;&gt;&gt; km = KMeans(n_clusters=2,
...             random_state=0)
&gt;&gt;&gt; y_km = km.fit_predict(X)
&gt;&gt;&gt; ax1.scatter(X[y_km==0,0],
...             X[y_km==0,1],
...             c='lightblue',
...             edgecolor='black',
...             marker='o',
...             s=40,
...             label='cluster 1')
&gt;&gt;&gt; ax1.scatter(X[y_km==1,0],
...             X[y_km==1,1],
...             c='red',
...             edgecolor='black',
...             marker='s',
...             s=40,
...             label='cluster 2')
&gt;&gt;&gt; ax1.set_title('K-means clustering')
&gt;&gt;&gt; ac = AgglomerativeClustering(n_clusters=2,
...                              affinity='euclidean',
...                              linkage='complete')
&gt;&gt;&gt; y_ac = ac.fit_predict(X)
&gt;&gt;&gt; ax2.scatter(X[y_ac==0,0],
...             X[y_ac==0,1],
...             c='lightblue',
...             edgecolor='black',
...             marker='o',
...             s=40,
...             label='cluster 1')
&gt;&gt;&gt; ax2.scatter(X[y_ac==1,0],
...             X[y_ac==1,1],
...             c='red',
...             edgecolor='black',
...             marker='s',
...             s=40,
...             label='cluster 2')
&gt;&gt;&gt; ax2.set_title('Agglomerative clustering')
&gt;&gt;&gt; plt.legend()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">Based on the visualized<a id="calibre_link-2079" class="calibre1"></a> clustering results, we can see that the k-means algorithm is unable to separate the two cluster, and also the hierarchical clustering algorithm was challenged by those complex shapes:</p><div class="mediaobject"><img src="images/00278.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Finally, let us try the DBSCAN algorithm on this dataset to see if it can find the two half-moon-shaped clusters using a density-based approach:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.cluster import DBSCAN
&gt;&gt;&gt; db = DBSCAN(eps=0.2,
...             min_samples=5,
...             metric='euclidean')
&gt;&gt;&gt; y_db = db.fit_predict(X)
&gt;&gt;&gt; plt.scatter(X[y_db==0,0],
...             X[y_db==0,1],
...             c='lightblue',
...             edgecolor='black',
...             marker='o',
...             s=40,
...             label='cluster 1')
&gt;&gt;&gt; plt.scatter(X[y_db==1,0],
...             X[y_db==1,1],
...             c='red',
...             edgecolor='black',
...             marker='s',
...             s=40,
...             label='cluster 2')
&gt;&gt;&gt; plt.legend()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The DBSCAN algorithm<a id="calibre_link-2080" class="calibre1"></a> can successfully detect the half-moon shapes, which highlights one of the strength of DBSCAN: clustering data of arbitrary shapes:</p><div class="mediaobject"><img src="images/00764.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">However, we shall also note some of the disadvantages of DBSCAN. With an increasing number of features in our dataset&mdash;assuming a fixed number of training examples&mdash;the negative effect of the <span class="strong"><strong class="calibre2">curse of dimensionality</strong></span>
<a id="calibre_link-2081" class="calibre1"></a> increases. This is especially a problem if we are using the Euclidean distance metric. However, the problem of the <span class="strong"><em class="calibre9">curse of dimensionality</em></span> is not unique to DBSCAN; it also affects other clustering algorithms that use the Euclidean distance metric, for example, k-means and hierarchical clustering algorithms. In addition, we have two hyperparameters in DBSCAN (MinPts and <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span>) that need to be optimized to yield good clustering results. Finding a good combination of MinPts and <span class="strong"><img src="images/00526.jpeg" alt="Locating regions of high density via DBSCAN" class="calibre14" /></span> can be problematic if the density differences in the dataset are relatively large.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2082" class="calibre1"></a>Note</h3><p class="calibre8">So far, we have seen three of the most fundamental categories of clustering algorithms: prototype-based clustering with k-means, agglomerative hierarchical clustering, and density-based clustering via DBSCAN. However, I also want to mention a fourth class of more advanced clustering algorithms that we have not covered in this chapter: <span class="strong"><strong class="calibre2">graph-based clustering</strong></span>. Probably the most prominent members of the graph-based<a id="calibre_link-2083" class="calibre1"></a> clustering family are the <span class="strong"><strong class="calibre2">spectral clustering</strong></span>
<a id="calibre_link-2084" class="calibre1"></a> algorithms. Although there are many different implementations of spectral clustering, they all have in common that they use the eigenvectors of a similarity or distance matrix to derive the cluster relationships. Since spectral clustering is beyond the scope of this book, you can read the excellent tutorial by Ulrike von Luxburg to learn more about this topic. (<span class="strong"><em class="calibre9">A tutorial on spectral clustering</em></span>, <span class="strong"><em class="calibre9">U. Von Luxburg</em></span>, Statistics and Computing, 17(4): 395&ndash;416, <span class="strong"><em class="calibre9">2007</em></span>). It is freely available from arXiv at <a class="calibre1" href="http://arxiv.org/pdf/0711.0189v1.pdf">http://arxiv.org/pdf/0711.0189v1.pdf</a>.</p></div><p class="calibre8">Note that, in <a id="calibre_link-2085" class="calibre1"></a>practice, it is not always obvious which clustering algorithm will perform best on a given dataset, especially if the data comes in multiple dimensions that make it hard or impossible to visualize. Furthermore, it is important to emphasize that a successful clustering not only depends on the algorithm and its hyperparameters. Rather, the choice of an appropriate distance metric and the use of domain knowledge that can help guide the experimental setup can be even more important.</p><p class="calibre8">In the context of the curse of dimensionality, it is thus common practice to apply dimensionality reduction techniques prior to performing clustering. Such dimensionality reduction techniques for unsupervised datasets include principal component analysis and RBF kernel principal component analysis, which we covered in <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>. Also, it is particularly common to compress datasets down to two-dimensional subspaces, which allows us to visualize the clusters and assigned labels using two-dimensional scatterplots, which are particularly helpful for evaluating the results.</p></div></div>

<div id="calibre_link-96" class="calibre"><div class="book" title="Summary" id="calibre_link-373"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2086"><a id="calibre_link-2087" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, you learned about three different clustering algorithms that can help us with the discovery of hidden structures or information in data. We started this chapter with a prototype-based approach, k-means, which clusters samples into spherical shapes based on a specified number of cluster centroids. Since clustering is an unsupervised method, we do not enjoy the luxury of ground truth labels to evaluate the performance of a model. Thus, we used intrinsic performance metrics such as the elbow method or silhouette analysis as an attempt to quantify the quality of clustering.</p><p class="calibre8">We then looked at a different approach to clustering: agglomerative hierarchical clustering. Hierarchical clustering does not require specifying the number of clusters up front, and the result can be visualized in a dendrogram representation, which can help with the interpretation of the results. The last clustering algorithm that we saw in this chapter was DBSCAN, an algorithm that groups points based on local densities and is capable of handling outliers and identifying non-globular shapes.</p><p class="calibre8">After this excursion into the field of unsupervised learning, it is now about time to introduce some of the most exciting machine learning algorithms for supervised learning: multilayer artificial neural networks. After their recent resurgence, neural networks are once again the hottest topic in machine learning research. Thanks to recently developed deep learning algorithms, neural networks are considered state-of-the-art for many complex tasks such as image classification and speech recognition. In <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, we will construct our own multilayer neural network from scratch. In <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, we will introduce powerful libraries that can help us to train complex network architectures most efficiently.</p></div></div>

<div id="calibre_link-105" class="calibre">
<div id="calibre_link-2088" class="calibre10"></div><div class="book" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch"><div class="book" id="calibre_link-10"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2089"><a id="calibre_link-2090" class="calibre1"></a>Chapter&nbsp;12.&nbsp;Implementing a Multilayer Artificial Neural Network from Scratch</h1></div></div></div><p class="calibre8">As you may know, deep learning is getting a lot of attention from the press and is without any doubt the hottest topic in the machine learning field. Deep learning can be understood as a set of algorithms that were developed to train artificial neural networks with many layers most efficiently. In this chapter, you will learn the basic concepts of artificial neural networks so that you will be well-equipped for the following chapters, which will introduce advanced Python-based deep learning libraries and <span class="strong"><strong class="calibre2">Deep Neural Network</strong></span> (<span class="strong"><strong class="calibre2">DNN</strong></span>) architectures that are particularly well-suited for image and text analyses.</p><p class="calibre8">The topics that we will cover in this chapter are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Getting a conceptual understanding of multilayer neural networks</li><li class="listitem">Implementing the fundamental backpropagation algorithm for neural network training from scratch</li><li class="listitem">Training a basic multilayer neural network for image classification</li></ul></div></div></div>

<div id="calibre_link-114" class="calibre">
<div class="book" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch">
<div class="book" title="Modeling complex functions with artificial neural networks"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2091"><a id="calibre_link-374" class="calibre1"></a>Modeling complex functions with artificial neural networks</h1></div></div></div><p class="calibre8">At the<a id="calibre_link-2092" class="calibre1"></a> beginning of this book, we <a id="calibre_link-2093" class="calibre1"></a>started our journey through machine learning algorithms with artificial neurons in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. Artificial neurons represent the building blocks of the multilayer artificial neural networks that we will discuss in this chapter. The basic concept behind artificial neural networks was built upon hypotheses and models of how the human brain works to solve complex problem tasks. Although<a id="calibre_link-2094" class="calibre1"></a> artificial neural<a id="calibre_link-2095" class="calibre1"></a> networks have gained a lot of popularity in recent years, early studies of neural networks go back to the 1940s when Warren McCulloch and Walter Pitt first described how neurons could work.</p><p class="calibre8">However, in the <a id="calibre_link-2096" class="calibre1"></a>decades that followed the first implementation of the <span class="strong"><strong class="calibre2">McCulloch-Pitt neuron</strong></span> model&mdash;Rosenblatt's perceptron in the 1950s, many researchers and machine learning practitioners slowly began to lose interest in neural networks since no one had a good solution for training a neural network with multiple layers. Eventually, interest in neural networks was rekindled in 1986 when D.E. Rumelhart, G.E. Hinton, and R.J. Williams were involved in the (re)discovery and popularization of the backpropagation algorithm to train neural networks more efficiently, which we will discuss in more detail later in this chapter (<span class="strong"><em class="calibre9">Learning representations by back-propagating errors</em></span>, <span class="strong"><em class="calibre9">David E. Rumelhart</em></span>, <span class="strong"><em class="calibre9">Geoffrey E. Hinton</em></span>, <span class="strong"><em class="calibre9">Ronald J. Williams</em></span>, <span class="strong"><em class="calibre9">Nature</em></span>, 323 (6088): 533&ndash;536, <span class="strong"><em class="calibre9">1986</em></span>). Readers who are interested in the history<a id="calibre_link-2097" class="calibre1"></a> of <span class="strong"><strong class="calibre2">Artificial Intelligence</strong></span> (<span class="strong"><strong class="calibre2">AI</strong></span>), machine learning, and neural networks are also encouraged to read the Wikipedia article on <span class="strong"><em class="calibre9">AI winter</em></span>, which are the periods of time where a large portion of the research community lost interest in the study <a id="calibre_link-2098" class="calibre1"></a>of neural networks (<a class="calibre1" href="https://en.wikipedia.org/wiki/AI_winter">https://en.wikipedia.org/wiki/AI_winter</a>).</p><p class="calibre8">However, neural networks have never been as popular as they are today, thanks to the many major breakthroughs that have been made in the previous decade, which resulted in what we now call deep learning algorithms and architectures&mdash;neural networks that are composed of many layers. Neural networks are a hot topic not only in academic research but also in big technology companies such as Facebook, Microsoft, and Google, who invest heavily in artificial neural networks and deep learning research. As of today, complex neural networks powered by deep learning algorithms are considered state of the art when it comes to complex problem solving such as image and voice recognition. Popular examples of the products in our everyday life that are powered by deep learning are Google's image search and Google Translate&mdash;an application for smartphones that can automatically recognize text in images for real-time translation into more than 20 languages.</p><p class="calibre8">Many exciting applications of DNNs have been developed at major tech companies and the pharmaceutical industry as listed in the following, non-comprehensive list of examples:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Facebook's DeepFace for tagging images (<span class="strong"><em class="calibre9">DeepFace: Closing the Gap to Human-Level Performance in Face Verification</em></span>, <span class="strong"><em class="calibre9">Y. Taigman</em></span>, <span class="strong"><em class="calibre9">M. Yang</em></span>, <span class="strong"><em class="calibre9">M. Ranzato</em></span>, and <span class="strong"><em class="calibre9">L. Wolf</em></span>, IEEE Conference <a id="calibre_link-2099" class="calibre1"></a>on <span class="strong"><strong class="calibre2">Computer Vision and Pattern Recognition</strong></span> (<span class="strong"><strong class="calibre2">CVPR</strong></span>), pages 1701&ndash;1708, <span class="strong"><em class="calibre9">2014</em></span>)</li><li class="listitem">Baidu's DeepSpeech, which is able to handle voice queries in Mandarin (<span class="strong"><em class="calibre9">DeepSpeech: Scaling up end-to-end speech recognition</em></span>, <span class="strong"><em class="calibre9">A. Hannun</em></span>, <span class="strong"><em class="calibre9">C. Case</em></span>, <span class="strong"><em class="calibre9">J. Casper</em></span>, <span class="strong"><em class="calibre9">B. Catanzaro</em></span>, <span class="strong"><em class="calibre9">G. Diamos</em></span>, <span class="strong"><em class="calibre9">E. Elsen</em></span>, <span class="strong"><em class="calibre9">R. Prenger</em></span>, <span class="strong"><em class="calibre9">S. Satheesh</em></span>, <span class="strong"><em class="calibre9">S. Sengupta</em></span>, <span class="strong"><em class="calibre9">A. Coates</em></span>, and <span class="strong"><em class="calibre9">Andrew Y. Ng</em></span>, arXiv preprint arXiv:1412.5567, <span class="strong"><em class="calibre9">2014</em></span>)</li><li class="listitem">Google's new language translation service (<span class="strong"><em class="calibre9">Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</em></span>, arXiv preprint arXiv:1412.5567, <span class="strong"><em class="calibre9">2016</em></span>)</li><li class="listitem">Novel techniques for drug discovery and toxicity prediction (<span class="strong"><em class="calibre9">Toxicity prediction using Deep Learning</em></span>, <span class="strong"><em class="calibre9">T. Unterthiner</em></span>, <span class="strong"><em class="calibre9">A. Mayr</em></span>, <span class="strong"><em class="calibre9">G. Klambauer</em></span>, and <span class="strong"><em class="calibre9">S. Hochreiter</em></span>, arXiv preprint arXiv:1503.01445, <span class="strong"><em class="calibre9">2015</em></span>)</li><li class="listitem">A mobile application that can detect skin cancer with an accuracy similar to professionally trained dermatologists (<span class="strong"><em class="calibre9">Dermatologist-level classification of skin cancer with deep neural networks</em></span>, <span class="strong"><em class="calibre9">A. Esteva</em></span>, <span class="strong"><em class="calibre9">B.Kuprel</em></span>, <span class="strong"><em class="calibre9">R. A. Novoa</em></span>, <span class="strong"><em class="calibre9">J. Ko</em></span>, <span class="strong"><em class="calibre9">S. M. Swetter</em></span>, <span class="strong"><em class="calibre9">H. M. Blau</em></span>, and <span class="strong"><em class="calibre9">S.Thrun</em></span>, in <span class="strong"><em class="calibre9">Nature</em></span> 542, no. 7639, <span class="strong"><em class="calibre9">2017</em></span>, pages 115-118)</li></ul></div></div></div></div>

<div id="calibre_link-117" class="calibre">
<div class="book" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch">
<div class="book" title="Modeling complex functions with artificial neural networks">
<div class="book" title="Single-layer neural network recap"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2100"><a id="calibre_link-375" class="calibre1"></a>Single-layer neural network recap</h2></div></div></div><p class="calibre8">This chapter is all about<a id="calibre_link-2101" class="calibre1"></a> multilayer neural networks, how they work, and how to train them to solve complex problems. However, before we dig deeper into a particular multilayer neural network architecture, let's briefly reiterate some of the concepts of single-layer neural networks that we introduced in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, namely, the <span class="strong"><strong class="calibre2">ADAptive LInear NEuron (Adaline)</strong></span> algorithm, which<a id="calibre_link-2102" class="calibre1"></a> is shown in the following figure:</p><div class="mediaobject"><img src="images/00823.jpeg" alt="Single-layer neural network recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, we implemented the Adaline algorithm to perform binary classification, and we used the gradient descent optimization algorithm to learn the weight coefficients of the model. In every epoch (pass over the training set), we updated the weight vector <span class="strong"><strong class="calibre2">w</strong></span> using the following update rule:</p><div class="mediaobject"><img src="images/00891.jpeg" alt="Single-layer neural network recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In other words, we computed<a id="calibre_link-2103" class="calibre1"></a> the gradient based on the whole training set and updated the weights of the model by taking a step into the opposite direction of the gradient <span class="strong"><img src="images/00964.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span>. In order to find the optimal weights of the model, we optimized an objective function that we defined as the <span class="strong"><strong class="calibre2">Sum of Squared Errors</strong></span> (<span class="strong"><strong class="calibre2">SSE</strong></span>)<a id="calibre_link-2104" class="calibre1"></a> cost function <span class="strong"><img src="images/00964.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span>. Furthermore, we multiplied the gradient by a factor, the learning rate <span class="strong"><img src="images/00330.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span>, which we had to choose carefully to balance the speed of learning against the risk of overshooting the global minimum of the cost function.</p><p class="calibre8">In gradient descent optimization, we updated all weights simultaneously after each epoch, and we defined the partial derivative for each weight <span class="strong"><img src="images/00342.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span> in the weight vector <span class="strong"><strong class="calibre2">w</strong></span> as follows:</p><div class="mediaobject"><img src="images/00164.jpeg" alt="Single-layer neural network recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00222.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span> is the target class label of a particular sample <span class="strong"><img src="images/00369.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span>, and <span class="strong"><img src="images/00382.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span> is the activation of the neuron, which is a linear function in the special case of Adaline. Furthermore, we defined the activation function
<span class="strong"><img src="images/00392.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span> as follows:</p><div class="mediaobject"><img src="images/00431.jpeg" alt="Single-layer neural network recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, the net input <span class="strong"><em class="calibre9">z</em></span> is a linear combination of the weights that are connecting the input to the output layer:</p><div class="mediaobject"><img src="images/00407.jpeg" alt="Single-layer neural network recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">While we used the activation <span class="strong"><img src="images/00423.jpeg" alt="Single-layer neural network recap" class="calibre14" /></span> to compute the gradient update, we implemented a threshold function to squash the continuous valued output into binary class labels for prediction:</p><div class="mediaobject"><img src="images/00438.jpeg" alt="Single-layer neural network recap" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2105" class="calibre1"></a>Note</h3><p class="calibre8">Note that although Adaline consists of two layers, one input layer and one output layer, it is called single-layer network because of its single link between the input and output layers.</p></div><p class="calibre8">Also, we learned about a certain <span class="strong"><em class="calibre9">trick</em></span> to accelerate the model learning, the so-called <span class="strong"><strong class="calibre2">stochastic gradient descent</strong></span> optimization. Stochastic gradient <a id="calibre_link-2106" class="calibre1"></a>descent approximates the cost from a single training sample (online learning) or a small subset of training samples (mini-batch learning). We will make use of this concept <a id="calibre_link-2107" class="calibre1"></a>later in this chapter when we implement and train a multilayer perceptron. Apart from faster learning&mdash;due to the more frequent weight updates compared to gradient descent&mdash;its noisy nature is also regarded as beneficial when training multilayer neural networks with non-linear activation functions, which do not have a convex cost function. Here, the added noise can help to escape local cost minima, but we will discuss this topic in more detail later in this chapter.</p></div></div></div></div>

<div id="calibre_link-123" class="calibre">
<div class="book" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch">
<div class="book" title="Modeling complex functions with artificial neural networks">
<div class="book" title="Introducing the multilayer neural network architecture"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2108"><a id="calibre_link-376" class="calibre1"></a>Introducing the multilayer neural network architecture</h2></div></div></div><p class="calibre8">In this section, you will learn<a id="calibre_link-2109" class="calibre1"></a> how to connect multiple single neurons to a multilayer feedforward neural network; this special type of <span class="strong"><em class="calibre9">fully connected </em></span>network is also <a id="calibre_link-2110" class="calibre1"></a>called <span class="strong"><strong class="calibre2">Multilayer Perceptron</strong></span> (<span class="strong"><strong class="calibre2">MLP</strong></span>). The following figure illustrates the concept of an MLP consisting of three layers:</p><div class="mediaobject"><img src="images/00450.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The MLP depicted in the <a id="calibre_link-2111" class="calibre1"></a>preceding figure has one input layer, one hidden layer, and one output layer. The units in the hidden layer are fully connected to the input layer, and the output layer is fully connected to the hidden layer. If such a network has more than one hidden layer, we also call it<a id="calibre_link-2112" class="calibre1"></a> a <span class="strong"><strong class="calibre2">deep artificial neural network</strong></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2113" class="calibre1"></a>Note</h3><p class="calibre8">We can add an arbitrary number of hidden layers to the MLP to create deeper network architectures. Practically, we can think of the number of layers and units in a neural network as additional hyperparameters that we want to optimize for a given problem task using cross-validation techniques that we discussed in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>.</p><p class="calibre8">However, the error gradients that we will calculate later via backpropagation will become increasingly small as more layers are added to a network. This vanishing gradient problem makes the model learning more challenging. Therefore, special algorithms have been developed to help train such deep neural network structures; this is <a id="calibre_link-2114" class="calibre1"></a>known as <span class="strong"><strong class="calibre2">deep learning</strong></span>.</p></div><p class="calibre8">As shown in the preceding figure, we <a id="calibre_link-2115" class="calibre1"></a>denote the <span class="strong"><em class="calibre9">i</em></span>th activation unit in the <span class="strong"><em class="calibre9">l</em></span>th layer as <span class="strong"><img src="images/00325.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span>. To make the math and code implementations a bit more intuitive, we will not use numerical indices to refer to layers, but we will use the <span class="strong"><em class="calibre9">in</em></span> superscript for the input layer, the <span class="strong"><em class="calibre9">h</em></span> superscript for the hidden layer, and the <span class="strong"><em class="calibre9">o</em></span> superscript for the output layer. For instance, <span class="strong"><img src="images/00375.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> refers to the <span class="strong"><em class="calibre9">i</em></span>th value in the input layer, <span class="strong"><img src="images/00008.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> refers to the <span class="strong"><em class="calibre9">i</em></span>th unit in the hidden layer, and <span class="strong"><img src="images/00495.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> refers to the <span class="strong"><em class="calibre9">i</em></span>th unit in the output layer. Here, the activation units <span class="strong"><img src="images/00504.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> and <span class="strong"><img src="images/00173.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> are<a id="calibre_link-2116" class="calibre1"></a> the <span class="strong"><strong class="calibre2">bias units</strong></span>, which we set equal to <span class="strong"><em class="calibre9">1</em></span>. The activation of the units in the input layer is just its input plus the bias unit:</p><div class="mediaobject"><img src="images/00516.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2117" class="calibre1"></a>Note</h3><p class="calibre8">Later in this chapter, we will implement the multilayer perceptron using separate vectors for the bias unit, which makes the code implementation more efficient and easier to read. This concept is also used by TensorFlow, a deep learning library that we will introduce in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>. However, the mathematical equations that will follow, would appear more complex or convoluted if we had to work with additional variables for the bias. However, note that the computation via appending 1s to the input vector (as shown previously) and using a weight variable as bias is exactly the same as operating with separate bias vectors; it is merely a different convention.</p></div><p class="calibre8">Each unit in layer <span class="strong"><em class="calibre9">l</em></span> is connected to all units in layer <span class="strong"><img src="images/00530.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> via a weight coefficient. For example, the connection between the <span class="strong"><em class="calibre9">k</em></span>th unit in layer <span class="strong"><em class="calibre9">l</em></span> to the <span class="strong"><em class="calibre9">j</em></span>th unit in layer <span class="strong"><img src="images/00530.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span> will be written as <span class="strong"><img src="images/00545.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span>. Referring back to the previous figure, we denote the weight matrix that connects the input to the hidden layer as <span class="strong"><img src="images/00555.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span>, and we write the matrix that connects the hidden layer to the output layer as <span class="strong"><img src="images/00452.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span>.</p><p class="calibre8">While one unit in the output layer would suffice for a binary classification task, we saw a more general form of a neural network in the preceding figure, which allows us to perform multiclass classification via a generalization of the <span class="strong"><strong class="calibre2">One-versus-All</strong></span> (<span class="strong"><strong class="calibre2">OvA</strong></span>) technique. To better understand how this works, remember the one-hot representation of categorical variables that we introduced in <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span>. For example, we can encode the three class labels in the familiar Iris dataset (<span class="strong"><em class="calibre9">0=Setosa</em></span>, <span class="strong"><em class="calibre9">1=Versicolor</em></span>, <span class="strong"><em class="calibre9">2=Virginica</em></span>) as follows:</p><p class="calibre8"> </p><div class="mediaobject"><img src="images/00572.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">
</p><p class="calibre8">This one-hot vector representation allows us to tackle classification tasks with an arbitrary number of unique class labels present in the training set.</p><p class="calibre8">If you are new to neural network <a id="calibre_link-2118" class="calibre1"></a>representations, the indexing notation (subscripts and superscripts) may look a little bit confusing at first. What may seem overly complicated at first will make much more sense in later sections when we vectorize the neural network representation. As introduced earlier, we summarize the weights that connect the input and hidden layers by a matrix <span class="strong"><img src="images/00587.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre14" /></span>, where <span class="strong"><em class="calibre9">d</em></span> is the number of hidden units and <span class="strong"><em class="calibre9">m</em></span> is the number of input units including the bias unit. Since it is important to internalize this notation to follow the concepts later in this chapter, let's summarize what we have just learned in a descriptive illustration of a simplified 3-4-3 multilayer perceptron:</p><div class="mediaobject"><img src="images/00600.jpeg" alt="Introducing the multilayer neural network architecture" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-129" class="calibre">
<div class="book" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch">
<div class="book" title="Modeling complex functions with artificial neural networks">
<div class="book" title="Activating a neural network via forward propagation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2119"><a id="calibre_link-377" class="calibre1"></a>Activating a neural network via forward propagation</h2></div></div></div><p class="calibre8">In this section, we will <a id="calibre_link-2120" class="calibre1"></a>describe the process of <span class="strong"><strong class="calibre2">forward propagation</strong></span> to calculate the output of an MLP model. To understand how it<a id="calibre_link-2121" class="calibre1"></a> fits into the context of learning an MLP model, let's summarize the MLP learning procedure in three simple steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Starting at the input layer, we forward propagate the patterns of the training data through the network to generate an output.</li><li class="listitem" value="2">Based on the network's output, we calculate the error that we want to minimize using a cost function that we will describe later.</li><li class="listitem" value="3">We backpropagate the error, find its derivative with respect to each weight in the network, and update the model.</li></ol><div class="calibre13"></div></div><p class="calibre8">Finally, after we repeat these three steps for multiple epochs and learn the weights of the MLP, we use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation, which we described in the previous section.</p><p class="calibre8">Now, let's walk through the individual steps of forward propagation to generate an output from the patterns in the training data. Since each unit in the hidden layer is connected to all units in the input layers, we first calculate the activation unit of the hidden layer <span class="strong"><img src="images/00660.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> as follows:</p><div class="mediaobject"><img src="images/00618.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00630.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00645.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> is the net input and <span class="strong"><img src="images/00392.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> is the activation function, which has to be differentiable to learn the weights that connect the neurons using a gradient-based approach. To be able to solve complex problems such as image classification, we need non-linear activation functions in our MLP model, for example, the sigmoid (logistic) activation function that we remember from the section about logistic regression in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>:</p><div class="mediaobject"><img src="images/00656.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can remember, the sigmoid function is an <span class="strong"><em class="calibre9">S</em></span>-shaped curve that maps the net input <span class="strong"><em class="calibre9">z</em></span> onto a logistic distribution in the range 0 to 1, which cuts the <span class="strong"><em class="calibre9">y</em></span>-axis at <span class="strong"><em class="calibre9">z = 0</em></span>, as shown in the following graph:</p><div class="mediaobject"><img src="images/00667.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">MLP is a typical <a id="calibre_link-2122" class="calibre1"></a>example of a feedforward <a id="calibre_link-2123" class="calibre1"></a>artificial neural network. The term <span class="strong"><strong class="calibre2">feedforward</strong></span>
<a id="calibre_link-2124" class="calibre1"></a> refers to the fact that each layer serves as the input to the next layer without loops, in contrast to recurrent neural networks&mdash;an architecture that we will discuss later in this chapter and discuss in more detail in <a class="calibre1" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" href="#calibre_link-44">Chapter 16</a>, <span class="strong"><em class="calibre9">Modeling Sequential Data Using Recurrent Neural Networks</em></span>. The term <span class="strong"><em class="calibre9">multilayer perceptron</em></span> may sound a little bit confusing since the artificial neurons in this network architecture are typically sigmoid units, not perceptrons. Intuitively, we can think of the neurons in the MLP as logistic regression units that return values in the continuous range between 0 and 1.</p><p class="calibre8">For purposes of code efficiency and readability, we will now write the activation in a more compact form using the concepts of basic linear algebra, which will allow us to vectorize our code implementation via NumPy rather than writing multiple nested and computationally expensive Python <code class="email">for</code> loops:</p><div class="mediaobject"><img src="images/00687.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00705.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00716.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> is our <span class="strong"><em class="calibre9">1 x m</em></span> dimensional feature vector of a sample <span class="strong"><img src="images/00718.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> plus a bias unit. <span class="strong"><img src="images/00734.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> is an <span class="strong"><em class="calibre9">m x d</em></span> dimensional weight matrix where <span class="strong"><em class="calibre9">d</em></span> is the number of units in the hidden layer. After matrix-vector multiplication, we obtain the <span class="strong"><em class="calibre9">1 x d</em></span> dimensional net input vector <span class="strong"><img src="images/00746.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> to calculate the activation <span class="strong"><img src="images/00759.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> (where <span class="strong"><img src="images/00454.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span>). Furthermore, we can generalize this computation to all <span class="strong"><em class="calibre9">n</em></span> samples in the training set:</p><div class="mediaobject"><img src="images/00776.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00791.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> is now an <span class="strong"><em class="calibre9">n x m</em></span> matrix, and the matrix-matrix multiplication will result in an <span class="strong"><em class="calibre9">n x d</em></span> dimensional net input matrix <span class="strong"><img src="images/00802.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span>. Finally, we apply the activation function <span class="strong"><img src="images/00392.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> to each value in the net input matrix to get the <span class="strong"><em class="calibre9">n x d</em></span> activation matrix <span class="strong"><img src="images/00813.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> for the next layer (here, the output layer):</p><div class="mediaobject"><img src="images/00825.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similarly, we can write<a id="calibre_link-2125" class="calibre1"></a> the activation of the output layer in<a id="calibre_link-2126" class="calibre1"></a> vectorized form for multiple samples:</p><div class="mediaobject"><img src="images/00836.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, we multiply the <span class="strong"><em class="calibre9">d x t</em></span> matrix <span class="strong"><img src="images/00849.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> (<span class="strong"><em class="calibre9">t</em></span> is the number of output units) by the <span class="strong"><em class="calibre9">n x d</em></span> dimensional matrix <span class="strong"><img src="images/00813.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> to obtain the <span class="strong"><em class="calibre9">n x t</em></span> dimensional matrix <span class="strong"><img src="images/00869.jpeg" alt="Activating a neural network via forward propagation" class="calibre14" /></span> (the columns in this matrix represent the outputs for each sample).</p><p class="calibre8">Lastly, we apply the sigmoid activation function to obtain the continuous valued output of our network:</p><div class="mediaobject"><img src="images/00876.jpeg" alt="Activating a neural network via forward propagation" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-138" class="calibre">
<div id="calibre_link-2127" class="calibre10"></div><div class="book" title="Classifying handwritten digits"><div class="book" id="calibre_link-143"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2128"><a id="calibre_link-2129" class="calibre1"></a>Classifying handwritten digits</h1></div></div></div><p class="calibre8">In the previous section, we <a id="calibre_link-2130" class="calibre1"></a>covered a lot of the theory around neural networks, which can be a little bit overwhelming if you are new to this topic. Before we continue with the discussion of the algorithm for learning the weights of the MLP model, backpropagation, let's take a short break from the theory and see a neural network in action.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2131" class="calibre1"></a>Note</h3><p class="calibre8">The neural network theory can be quite complex, thus I want to recommend two additional resources, which cover some of the concepts that we discuss in this chapter in more detail:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Deep Feedforward Networks</em></span>, <span class="strong"><em class="calibre9">Deep Learning</em></span>, <span class="strong"><em class="calibre9">I. Goodfellow</em></span>, <span class="strong"><em class="calibre9">Y. Bengio</em></span>, and <span class="strong"><em class="calibre9">A. Courville</em></span>, <span class="strong"><em class="calibre9">MIT Press</em></span>, <span class="strong"><em class="calibre9">2016</em></span>. (Manuscripts freely accessible at <a class="calibre1" href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>.)</li><li class="listitem"><span class="strong"><em class="calibre9">Pattern Recognition and Machine Learning</em></span>, <span class="strong"><em class="calibre9">C. M. Bishop and others</em></span>, <span class="strong"><em class="calibre9">Volume 1</em></span>. <span class="strong"><em class="calibre9">Springer New York</em></span>, <span class="strong"><em class="calibre9">2006</em></span>.</li></ul></div></div><p class="calibre8">In this section, we will<a id="calibre_link-2132" class="calibre1"></a> implement and train our first multilayer neural network to classify handwritten digits from the popular <span class="strong"><strong class="calibre2">Mixed National Institute of Standards and Technology</strong></span> (<span class="strong"><strong class="calibre2">MNIST</strong></span>) dataset that has been constructed by Yann LeCun and others, and <a id="calibre_link-2133" class="calibre1"></a>serves as a popular benchmark dataset for machine learning algorithms (<span class="strong"><em class="calibre9">Gradient-Based Learning Applied to Document Recognition</em></span>, <span class="strong"><em class="calibre9">Y. LeCun</em></span>, <span class="strong"><em class="calibre9">L. Bottou</em></span>, <span class="strong"><em class="calibre9">Y. Bengio</em></span>, and <span class="strong"><em class="calibre9">P. Haffner</em></span>, Proceedings of the IEEE, 86(11): 2278-2324, <span class="strong"><em class="calibre9">November 1998</em></span>).</p></div></div>

<div id="calibre_link-148" class="calibre">
<div class="book" title="Classifying handwritten digits">
<div class="book" title="Obtaining the MNIST dataset"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2134"><a id="calibre_link-378" class="calibre1"></a>Obtaining the MNIST dataset</h2></div></div></div><p class="calibre8">The MNIST dataset is<a id="calibre_link-2135" class="calibre1"></a> publicly available at <a class="calibre1" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> and consists<a id="calibre_link-2136" class="calibre1"></a> of the following four parts:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Training set images</strong></span>: <code class="email">train-images-idx3-ubyte.gz</code> (9.9 MB, 47 MB unzipped, and 60,000 samples)</li><li class="listitem"><span class="strong"><strong class="calibre2">Training set labels</strong></span>: <code class="email">train-labels-idx1-ubyte.gz</code> (29 KB, 60 KB unzipped, and 60,000 labels)</li><li class="listitem"><span class="strong"><strong class="calibre2">Test set images</strong></span>: <code class="email">t10k-images-idx3-ubyte.gz</code> (1.6 MB, 7.8 MB, unzipped and 10,000 samples)</li><li class="listitem"><span class="strong"><strong class="calibre2">Test set labels</strong></span>: <code class="email">t10k-labels-idx1-ubyte.gz</code> (5 KB, 10 KB unzipped, and 10,000 labels)</li></ul></div><p class="calibre8">The MNIST dataset was constructed from two datasets of the US <span class="strong"><strong class="calibre2">National Institute of Standards and Technology</strong></span> (<span class="strong"><strong class="calibre2">NIST</strong></span>). The <a id="calibre_link-2137" class="calibre1"></a>training set consists of handwritten digits from 250 different people, 50 percent high school students, and 50 percent employees from the Census Bureau. Note that the test set contains handwritten digits from different people following the same split. After downloading the files, I recommend that you unzip the files using the Unix/Linux <code class="email">gzip</code> tool from the Terminal for efficiency, using the following command in your local MNIST download directory:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">gzip *ubyte.gz -d</strong></span>
</pre></div><p class="calibre8">Alternatively, you could use your favorite unzipping tool if you are working with a machine running on Microsoft Windows. The images are stored in byte format, and we will read them into NumPy arrays that we will use to train and test our MLP implementation. In order to do that, we will define the following helper function:</p><div class="informalexample"><pre class="programlisting">import os
import struct
import numpy as np

def load_mnist(path, kind='train'):
    """Load MNIST data from `path`"""
    labels_path = os.path.join(path,
                               '%s-labels-idx1-ubyte' % kind)
    images_path = os.path.join(path,
                               '%s-images-idx3-ubyte' % kind)
        
    with open(labels_path, 'rb') as lbpath:
        magic, n = struct.unpack('&gt;II',
                                 lbpath.read(8))
        labels = np.fromfile(lbpath,
                             dtype=np.uint8)

    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack("&gt;IIII",
                                               imgpath.read(16))
        images = np.fromfile(imgpath,
                             dtype=np.uint8).reshape(
                             len(labels), 784)
        images = ((images / 255.) - .5) * 2

    return images, labels</pre></div><p class="calibre8">The <code class="email">load_mnist</code> function<a id="calibre_link-2138" class="calibre1"></a> returns two arrays, the first being an <span class="strong"><em class="calibre9">n x m</em></span> dimensional NumPy array (<code class="email">images</code>), where <span class="strong"><em class="calibre9">n</em></span> is the number of samples and <span class="strong"><em class="calibre9">m</em></span> is the number of features (here, pixels). The training dataset consists of 60,000 training digits and the test set contains 10,000 samples, respectively. The images in the MNIST dataset consist of 28 x 28 pixels, and each pixel is represented by a gray scale intensity value. Here, we unroll the 28 x 28 pixels into one-dimensional row vectors, which represent the rows in our <code class="email">images</code> array (784 per row or image). The second array (<code class="email">labels</code>) returned by the <code class="email">load_mnist</code> function contains the corresponding target variable, the class labels (integers 0-9) of the handwritten digits.</p><p class="calibre8">The way we read in the image might seem a little bit strange at first:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; magic, n = struct.unpack('&gt;II', lbpath.read(8))
&gt;&gt;&gt; labels = np.fromfile(lbpath, dtype=np.int8)</pre></div><p class="calibre8">To understand how those two lines of code work, let's take a look at the dataset description from the MNIST website:</p><div class="informalexample"><pre class="programlisting">[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........ 
xxxx     unsigned byte   ??               label</pre></div><p class="calibre8">Using the two preceding<a id="calibre_link-2139" class="calibre1"></a> lines of code, we first read in the magic number, which is a description of the file protocol as well as the number of items (<code class="email">n</code>) from the file buffer before we read the following bytes into a NumPy array using the <code class="email">fromfile</code> method. The <code class="email">fmt</code> parameter value <code class="email">'&gt;II'</code> that we passed as an argument to <code class="email">struct.unpack</code> can be composed into the two following parts:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">&gt;</code>: This is big-endian&mdash;it defines the order in which a sequence of bytes is stored; if you are unfamiliar with the terms big-endian and little-endian, you can find an excellent article <a id="calibre_link-2140" class="calibre1"></a>about <span class="strong"><em class="calibre9">Endianness</em></span> on Wikipedia: <a class="calibre1" href="https://en.wikipedia.org/wiki/Endianness">https://en.wikipedia.org/wiki/Endianness</a></li><li class="listitem"><code class="email">I</code>: This is an unsigned integer</li></ul></div><p class="calibre8">Finally, we also normalized the pixels values in MNIST to the range -1 to 1 (originally 0 to 255) via the following code line:</p><div class="informalexample"><pre class="programlisting">images = ((images / 255.) - .5) * 2</pre></div><p class="calibre8">The reason behind this is that gradient-based optimization is much more stable under these conditions as discussed in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>. Note that we scaled the images on a pixel-by-pixel basis, which is different from the feature scaling approach that we took in previous chapters. Previously, we derived scaling parameters from the training set and used these to scale each column in the training set and test set. However, when working with image pixels, centering them at zero and rescaling them to a [-1, 1] range is also common and usually works well in practice.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2141" class="calibre1"></a>Note</h3><p class="calibre8">Another recently developed trick to improve convergence in gradient-based optimization through input scaling is batch normalization, which is an advanced topic that we will not cover in this book. However, if you are interested in deep learning applications and research, I highly recommend that you read more about batch normalization in the excellent research article <span class="strong"><em class="calibre9">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</em></span> by Sergey Ioffe and Christian Szegedy (2015, <a class="calibre1" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>).</p></div><p class="calibre8">By executing the <a id="calibre_link-2142" class="calibre1"></a>following code, we will now load the 60,000 training instances as well as the 10,000 test samples from the local directory where we unzipped the MNIST dataset (in the following code snippet, it is assumed that the downloaded MNIST files were unzipped to the same directory in which this code was executed):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train, y_train = load_mnist('', kind='train')
&gt;&gt;&gt; print('Rows: %d, columns: %d'
...       % (X_train.shape[0], X_train.shape[1]))
Rows: 60000, columns: 784

&gt;&gt;&gt; X_test, y_test = load_mnist('', kind='t10k')
&gt;&gt;&gt; print('Rows: %d, columns: %d'
...       % (X_test.shape[0], X_test.shape[1]))
Rows: 10000, columns: 784</pre></div><p class="calibre8">To get an idea of how those images in MNIST look, let's visualize examples of the digits 0-9 after reshaping the 784-pixel vectors from our feature matrix into the original 28 Ã 28 image that we can plot via Matplotlib's <code class="email">imshow</code> function:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt

&gt;&gt;&gt; fig, ax = plt.subplots(nrows=2, ncols=5,
...                        sharex=True, sharey=True)
&gt;&gt;&gt; ax = ax.flatten()
&gt;&gt;&gt; for i in range(10):
...     img = X_train[y_train == i][0].reshape(28, 28)
...     ax[i].imshow(img, cmap='Greys')

&gt;&gt;&gt; ax[0].set_xticks([])
&gt;&gt;&gt; ax[0].set_yticks([])
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">We should now see a plot of the 2 x 5 subfigures showing a representative image of each unique digit:</p><div class="mediaobject"><img src="images/00895.jpeg" alt="Obtaining the MNIST dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In addition, let's also <a id="calibre_link-2143" class="calibre1"></a>plot multiple examples of the same digit to see how different the handwriting really is:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; fig, ax = plt.subplots(nrows=5,
...                        ncols=5,
...                        sharex=True,
...                        sharey=True)
&gt;&gt;&gt; ax = ax.flatten()
&gt;&gt;&gt; for i in range(25):
...     img = X_train[y_train == 7][i].reshape(28, 28)
...     ax[i].imshow(img, cmap='Greys')
&gt;&gt;&gt; ax[0].set_xticks([])
&gt;&gt;&gt; ax[0].set_yticks([])
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">After executing the code, we should now see the first 25 variants of the digit 7:</p><div class="mediaobject"><img src="images/00904.jpeg" alt="Obtaining the MNIST dataset" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">After we've gone through all the<a id="calibre_link-2144" class="calibre1"></a> previous steps, it is a good idea to save the scaled images in a format that we can load more quickly into a new Python session to avoid the overhead of reading in and processing the data again. When we are working with NumPy arrays, an efficient yet most convenient method to save multidimensional arrays to disk is <a id="calibre_link-2145" class="calibre1"></a>NumPy's <code class="email">savez</code> function (the official documentation can be found here: <a class="calibre1" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html">https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html</a>).</p><p class="calibre8">In short, the <code class="email">savez</code> function is <a id="calibre_link-2146" class="calibre1"></a>analogous to Python's <code class="email">pickle</code> module that we used in <a class="calibre1" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application" href="#calibre_link-40">Chapter 9</a>, <span class="strong"><em class="calibre9">Embedding a Machine Learning Model into a Web Application</em></span>, but optimized for storing NumPy arrays. The <code class="email">savez</code> function produces zipped archives of our data, producing <code class="email">.npz</code> files that contain files in the <code class="email">.npy</code> format; if you want to learn more about this format, you can find a nice explanation, including a discussion about advantages and disadvantages, in the NumPy documentation: <a class="calibre1" href="https://docs.scipy.org/doc/numpy/neps/npy-format.html">https://docs.scipy.org/doc/numpy/neps/npy-format.html</a>. Further, instead of using <code class="email">savez</code>, we will use <code class="email">savez_compressed</code>, which uses the same syntax as <code class="email">savez</code>, but further compresses the output file down to substantially smaller file sizes (approximately 22 MB versus approximately 400 MB in this case). The following code snippet will save both the training and test datasets to the archive file <code class="email">'mnist_scaled.npz'</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; np.savez_compressed('mnist_scaled.npz',
...                     X_train=X_train,
...                     y_train=y_train,
...                     X_test=X_test,
...                     y_test=y_test)</pre></div><p class="calibre8">After we created the <code class="email">.npz</code> files, we can load the preprocessed MNIST image arrays using NumPy's <code class="email">load</code> function as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; mnist = np.load('mnist_scaled.npz')</pre></div><p class="calibre8">The <code class="email">mnist</code> variable now<a id="calibre_link-2147" class="calibre1"></a> references to an object that can access the four data arrays as we provided them keyword arguments to the <code class="email">savez_compressed</code> function, which are listed under the files attribute list of the <code class="email">mnist</code> object:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; mnist.files
['X_train', 'y_train', 'X_test', 'y_test']</pre></div><p class="calibre8">For instance, to load the training data into our current Python session, we will access the <code class="email">'X_train'</code> array as follows (similar to a Python dictionary):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train = mnist['X_train']</pre></div><p class="calibre8">Using a list comprehension, we can retrieve all four data arrays as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train, y_train, X_test, y_test = [mnist[f] for 
...                                     f in mnist.files]</pre></div><p class="calibre8">Note that while the preceding <code class="email">np.savez_compressed</code> and <code class="email">np.load</code> examples are not essential for executing the code in this chapter, it serves as a demonstration of how to save and load NumPy arrays conveniently and efficiently.</p></div></div></div>

<div id="calibre_link-150" class="calibre">
<div class="book" title="Classifying handwritten digits">
<div class="book" title="Implementing a multilayer perceptron"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2148"><a id="calibre_link-379" class="calibre1"></a>Implementing a multilayer perceptron</h2></div></div></div><p class="calibre8">In this subsection, we will now<a id="calibre_link-2149" class="calibre1"></a> implement the code of an MLP with one input, one hidden, and one output layers to classify the images in the MNIST dataset. I have tried to keep the code as simple as possible. However, it may seem a little bit complicated at first, and I encourage you to download the sample code for this chapter from the Packt Publishing website or from GitHub (<a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition">https://github.com/rasbt/python-machine-learning-book-2nd-edition</a>) so that you can view this MLP implementation annotated with comments and syntax highlighting for better readability.</p><p class="calibre8">If you are not running the code from the accompanying Jupyter Notebook file or don't have access to the internet, I recommend that you copy the <code class="email">NeuralNetMLP</code> code from this chapter into a Python script file in your current working directory, for example, <code class="email">neuralnet.py</code>, which you can then import into your current Python session via the following command:</p><div class="informalexample"><pre class="programlisting">from neuralnet import NeuralNetMLP</pre></div><p class="calibre8">The code will contain parts that<a id="calibre_link-2150" class="calibre1"></a> we have not talked about yet, such as the backpropagation algorithm, but most of the code should look familiar to you based on the Adaline implementation in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, and the discussion of forward propagation in earlier sections.</p><p class="calibre8">Do not worry if not all of the code makes immediate sense to you; we will follow up on certain parts later in this chapter. However, going over the code at this stage can make it easier to follow the theory later.</p><p class="calibre8">The following is the implementation of a multilayer perceptron:</p><div class="informalexample"><pre class="programlisting">import numpy as np
import sys

class NeuralNetMLP(object):
    """ Feedforward neural network / Multi-layer perceptron classifier.

    Parameters

    ------------
    n_hidden : int (default: 30)
        Number of hidden units.
    l2 : float (default: 0.)
        Lambda value for L2-regularization.
        No regularization if l2=0. (default)
    epochs : int (default: 100)
        Number of passes over the training set.
    eta : float (default: 0.001)
        Learning rate.
    shuffle : bool (default: True)
        Shuffles training data every epoch
        if True to prevent circles.
    minibatch_size : int (default: 1)
        Number of training samples per minibatch.
    seed : int (default: None)
        Random seed for initializing weights and shuffling.

    Attributes
    -----------
    eval_ : dict
      Dictionary collecting the cost, training accuracy,
      and validation accuracy for each epoch during training.

    """
    def __init__(self, n_hidden=30,
                 l2=0., epochs=100, eta=0.001,
                 shuffle=True, minibatch_size=1, seed=None):

        self.random = np.random.RandomState(seed)
        self.n_hidden = n_hidden
        self.l2 = l2
        self.epochs = epochs
        self.eta = eta
        self.shuffle = shuffle
        self.minibatch_size = minibatch_size

    def _onehot(self, y, n_classes):
        """Encode labels into one-hot representation

        Parameters
        ------------
        y : array, shape = [n_samples]
            Target values.

        Returns
        -----------
        onehot : array, shape = (n_samples, n_labels)

        """
        onehot = np.zeros((n_classes, y.shape[0]))
        for idx, val in enumerate(y.astype(int)):
            onehot[val, idx] = 1.
        return onehot.T

    def _sigmoid(self, z):
        """Compute logistic function (sigmoid)"""
        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))

    def _forward(self, X):
        """Compute forward propagation step"""

        # step 1: net input of hidden layer
        # [n_samples, n_features] dot [n_features, n_hidden]
        # -&gt; [n_samples, n_hidden]
        z_h = np.dot(X, self.w_h) + self.b_h

        # step 2: activation of hidden layer
        a_h = self._sigmoid(z_h)

        # step 3: net input of output layer
        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]
        # -&gt; [n_samples, n_classlabels]

        z_out = np.dot(a_h, self.w_out) + self.b_out

        # step 4: activation output layer
        a_out = self._sigmoid(z_out)

        return z_h, a_h, z_out, a_out

    def _compute_cost(self, y_enc, output):
        """Compute cost function.

        Parameters
        ----------
        y_enc : array, shape = (n_samples, n_labels)
            one-hot encoded class labels.
        output : array, shape = [n_samples, n_output_units]
            Activation of the output layer (forward propagation)

        Returns
        ---------
        cost : float
            Regularized cost

        """
        L2_term = (self.l2 *
                   (np.sum(self.w_h ** 2.) +
                    np.sum(self.w_out ** 2.)))

        term1 = -y_enc * (np.log(output))
        term2 = (1. - y_enc) * np.log(1. - output)
        cost = np.sum(term1 - term2) + L2_term
        return cost

    def predict(self, X):
        """Predict class labels

        Parameters
        -----------
        X : array, shape = [n_samples, n_features]
            Input layer with original features.

        Returns:
        ----------
        y_pred : array, shape = [n_samples]
            Predicted class labels.

        """
        z_h, a_h, z_out, a_out = self._forward(X)
        y_pred = np.argmax(z_out, axis=1)
        return y_pred

    def fit(self, X_train, y_train, X_valid, y_valid):
        """ Learn weights from training data.

        Parameters
        -----------
        X_train : array, shape = [n_samples, n_features]
            Input layer with original features.
        y_train : array, shape = [n_samples]
            Target class labels.
        X_valid : array, shape = [n_samples, n_features]
            Sample features for validation during training
        y_valid : array, shape = [n_samples]
            Sample labels for validation during training

        Returns:
        ----------
        self

        """
        n_output = np.unique(y_train).shape[0] # no. of class 
                                               #labels

        n_features = X_train.shape[1]

        ########################
        # Weight initialization
        ########################

        # weights for input -&gt; hidden
        self.b_h = np.zeros(self.n_hidden)
        self.w_h = self.random.normal(loc=0.0, scale=0.1,
                                      size=(n_features,
                                            self.n_hidden))

        # weights for hidden -&gt; output
        self.b_out = np.zeros(n_output)
        self.w_out = self.random.normal(loc=0.0, scale=0.1,
                                        size=(self.n_hidden,
                                              n_output))

        epoch_strlen = len(str(self.epochs))  # for progr. format.
        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': \
                      []}

        y_train_enc = self._onehot(y_train, n_output)

        # iterate over training epochs
        for i in range(self.epochs):

            # iterate over minibatches
            indices = np.arange(X_train.shape[0])

            if self.shuffle:
                self.random.shuffle(indices)

            for start_idx in range(0, indices.shape[0] -\
                                   self.minibatch_size +\
                                   1, self.minibatch_size):
                batch_idx = indices[start_idx:start_idx +\
                                    self.minibatch_size]

                # forward propagation
                z_h, a_h, z_out, a_out = \
                    self._forward(X_train[batch_idx])

                ##################
                # Backpropagation
                ##################

                # [n_samples, n_classlabels]
                sigma_out = a_out - y_train_enc[batch_idx]

                # [n_samples, n_hidden]
                sigmoid_derivative_h = a_h * (1. - a_h)

                # [n_samples, n_classlabels] dot [n_classlabels,
                #                                 n_hidden]
                # -&gt; [n_samples, n_hidden]
                sigma_h = (np.dot(sigma_out, self.w_out.T) *
                           sigmoid_derivative_h)

                # [n_features, n_samples] dot [n_samples,
                #                             n_hidden]
                # -&gt; [n_features, n_hidden]
                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)
                grad_b_h = np.sum(sigma_h, axis=0)

                # [n_hidden, n_samples] dot [n_samples,
                #                            n_classlabels]
                # -&gt; [n_hidden, n_classlabels]
                grad_w_out = np.dot(a_h.T, sigma_out)
                grad_b_out = np.sum(sigma_out, axis=0)

                # Regularization and weight updates
                delta_w_h = (grad_w_h + self.l2*self.w_h)
                delta_b_h = grad_b_h # bias is not regularized
                self.w_h -= self.eta * delta_w_h
                self.b_h -= self.eta * delta_b_h

                delta_w_out = (grad_w_out + self.l2*self.w_out)
                delta_b_out = grad_b_out # bias is not regularized
                self.w_out -= self.eta * delta_w_out
                self.b_out -= self.eta * delta_b_out

            #############
            # Evaluation
            #############

            # Evaluation after each epoch during training
            z_h, a_h, z_out, a_out = self._forward(X_train)
            
            cost = self._compute_cost(y_enc=y_train_enc,
                                      output=a_out)

            y_train_pred = self.predict(X_train)
            y_valid_pred = self.predict(X_valid)

            train_acc = ((np.sum(y_train ==
                          y_train_pred)).astype(np.flo<span class="strong">at) /
                         X_train.shape[0])
            valid_acc = ((np.sum(y_valid ==
                          y_valid_pred)).astype(np.float) /
                         X_valid.shape[0])

            sys.stderr.write('\r%0*d/%d | Cost: %.2f '
                             '| Train/Valid Acc.: %.2f%%/%.2f%% '
                              %
                             (epoch_strlen, i+1, self.epochs,
                              cost,
                              train_acc*100, valid_acc*100))
            sys.stderr.flush()

            self.eval_['cost'].append(cost)
            self.eval_['train_acc'].append(train_acc)
            self.eval_['valid_acc'].append(valid_acc)

        return self</span></pre></div><p class="calibre8">Once you're done with executing this code, let's <a id="calibre_link-2151" class="calibre1"></a>now initialize a new 784-100-10 MLP&mdash;a neural network with 784 input units (<code class="email">n_features</code>), 100 hidden units (<code class="email">n_hidden</code>), and 10 output units (<code class="email">n_output</code>):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt;nn = NeuralNetMLP(n_hidden=100,
...                  l2=0.01,
...                  epochs=200,
...                  eta=0.0005,
...                  minibatch_size=100,
...                  shuffle=True,
...                  seed=1)</pre></div><p class="calibre8">If you read through the <code class="email">NeuralNetMLP</code> code, you've probably already guessed what these parameters are for. Here, you find a short summary of these:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">l2</code>: This is the <span class="strong"><img src="images/00918.jpeg" alt="Implementing a multilayer perceptron" class="calibre14" /></span> parameter for L2 regularization to decrease the degree of overfitting.
</li><li class="listitem"><code class="email">epochs</code>: This is the number of passes over the training set.</li><li class="listitem"><code class="email">eta</code>: This is the learning rate <span class="strong"><img src="images/00330.jpeg" alt="Implementing a multilayer perceptron" class="calibre14" /></span>.
</li><li class="listitem"><code class="email">shuffle</code>: This is for shuffling the training set prior to every epoch to prevent that the algorithm gets stuck in circles.</li><li class="listitem"><code class="email">seed</code>: This is a random seed for shuffling and weight initialization.</li><li class="listitem"><code class="email">minibatch_size</code>: This is the number of training samples in each mini-batch when splitting of the training data in each epoch for stochastic gradient descent. The gradient is computed for each mini-batch separately instead of the entire training data for faster learning.</li></ul></div><p class="calibre8">Next, we train the MLP using 55,000 samples from the already shuffled MNIST training dataset and use the remaining 5,000 samples for validation during training. Note that training the neural network may take up to 5 minutes on standard desktop computer hardware.</p><p class="calibre8">As you may have noticed from the preceding code implementation, we implemented the <code class="email">fit</code> method so that it takes four input arguments: training images, training labels, validation images, and validation labels. In neural network training, it is really useful to already compare training and validation accuracy during training, which helps us judge whether the network model performs well, given the architecture and hyperparameters.</p><p class="calibre8">In general, training (deep) neural networks is relatively expensive compared with the other models we discussed so far. Thus, we want to stop it early in certain circumstances and start over with<a id="calibre_link-2152" class="calibre1"></a> different hyperparameter settings. Alternatively, if we find that it increasingly tends to overfit the training data (noticeable by an increasing gap between training and validation set performance), we may want to stop the training early as well.</p><p class="calibre8">Now, to start the training, we execute the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; nn.fit(X_train=X_train[:55000],
...       y_train=y_train[:55000],
...       X_valid=X_train[55000:],
...       y_valid=y_train[55000:])
200/200 | Cost: 5065.78 | Train/Valid Acc.: 99.28%/97.98%</pre></div><p class="calibre8">In our <code class="email">NeuralNetMLP</code> implementation, we also defined an <code class="email">eval_</code> attribute that collects the cost, training, and validation accuracy for each epoch so that we can visualize the results using Matplotlib:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; plt.plot(range(nn.epochs), nn.eval_['cost'])
&gt;&gt;&gt; plt.ylabel('Cost')
&gt;&gt;&gt; plt.xlabel('Epochs')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The preceding code plots the cost over the 200 epochs, as shown in the following graph:</p><div class="mediaobject"><img src="images/00933.jpeg" alt="Implementing a multilayer perceptron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, the cost <a id="calibre_link-2153" class="calibre1"></a>decreased substantially during the first 100 epochs and seems to slowly converge in the last 100 epochs. However, the small slope between epoch <code class="email">175</code> and epoch <code class="email">200</code> indicates that the cost would further decrease with a training over additional epochs.</p><p class="calibre8">Next, let's take a look at the training and validation accuracy:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.plot(range(nn.epochs), nn.eval_['train_acc'],
...          label='training')
&gt;&gt;&gt; plt.plot(range(nn.epochs), nn.eval_['valid_acc'],
...          label='validation', linestyle='--')
&gt;&gt;&gt; plt.ylabel('Accuracy')
&gt;&gt;&gt; plt.xlabel('Epochs')
&gt;&gt;&gt; plt.legend()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The preceding code examples plot those accuracy values over the 200 training epochs, as shown in the following figure:</p><div class="mediaobject"><img src="images/00951.jpeg" alt="Implementing a multilayer perceptron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The plot reveals that the<a id="calibre_link-2154" class="calibre1"></a> gap between training and validation accuracy increases the more epochs we train the network. At approximately the 50th epoch, the training and validation accuracy values are equal, and then, the network starts overfitting the training data.</p><p class="calibre8">Note that this example was chosen deliberately to illustrate the effect of overfitting and demonstrate why it is useful to compare the validation and training accuracy values during training. One way to decrease the effect of overfitting is to increase the regularization strength&mdash;for example, by setting <code class="email">l2=0.1</code>. Another useful technique to tackle overfitting in neural networks, dropout, will be covered in <a class="calibre1" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks" href="#calibre_link-20">Chapter 15</a>, <span class="strong"><em class="calibre9">Classifying Images with Deep Convolutional Neural Networks</em></span>.</p><p class="calibre8">Finally, let's evaluate the generalization performance of the model by calculating the prediction accuracy on the test set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_test_pred = nn.predict(X_test)
&gt;&gt;&gt; acc = (np.sum(y_test == y_test_pred)
...       .astype(np.float) / X_test.shape[0])
&gt;&gt;&gt; print('Training accuracy: %.2f%%' % (acc * 100))
Test accuracy: 97.54%</pre></div><p class="calibre8">Despite the slight overfitting on the training data, our relatively simple one-hidden layer neural network achieved a relatively good performance on the test dataset, similar to the validation set accuracy (97.98 percent).</p><p class="calibre8">To further fine-tune the model, we could change the number of hidden units, values of the regularization parameters, and the learning rate or use various other tricks that have been developed over the years but are beyond the scope of this book. In <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span>, you will learn about a different neural network architecture that is known for its good performance on image datasets. Also, the chapter will introduce additional performance-enhancing tricks such as adaptive learning rates, momentum learning, and dropout.</p><p class="calibre8">Lastly, let's take a look at some of the images that our MLP struggles with:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; miscl_img = X_test[y_test != y_test_pred][:25]
&gt;&gt;&gt; correct_lab = y_test[y_test != y_test_pred][:25]
&gt;&gt;&gt; miscl_lab= y_test_pred[y_test != y_test_pred][:25]

&gt;&gt;&gt; fig, ax = plt.subplots(nrows=5,
...                        ncols=5,
...                        sharex=True,
...                        sharey=True,)
&gt;&gt;&gt; ax = ax.flatten()
&gt;&gt;&gt; for i in range(25):
...     img = miscl_img[i].reshape(28, 28)
...     ax[i].imshow(img,
...                  cmap='Greys',
...                  interpolation='nearest')
...     ax[i].set_title('%d) t: %d p: %d'
...                     % (i+1, correct_lab[i], miscl_lab[i]))

&gt;&gt;&gt; ax[0].set_xticks([])
&gt;&gt;&gt; ax[0].set_yticks([])
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">We should now see a 5 x 5 subplot<a id="calibre_link-2155" class="calibre1"></a> matrix where the first number in the subtitles indicates the plot index, the second number represents the true class label (<code class="email">t</code>), and the third number stands for the predicted class label (<code class="email">p</code>):</p><div class="mediaobject"><img src="images/00477.jpeg" alt="Implementing a multilayer perceptron" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see in the <a id="calibre_link-2156" class="calibre1"></a>preceding figure, some of those images are even challenging for us humans to classify correctly. For example, the <code class="email">6</code> in subplot <code class="email">8</code> really looks like a carelessly drawn <code class="email">0</code>, and the <code class="email">8</code> in subplot <code class="email">23</code> could be a <code class="email">9</code> due to the narrow lower part combined with the bold line.</p></div></div></div>

<div id="calibre_link-151" class="calibre">
<div id="calibre_link-2157" class="calibre10"></div><div class="book" title="Training an artificial neural network"><div class="book" id="calibre_link-18"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2158"><a id="calibre_link-2159" class="calibre1"></a>Training an artificial neural network</h1></div></div></div><p class="calibre8">Now that we have seen a neural network <a id="calibre_link-2160" class="calibre1"></a>in action and have gained a basic understanding of how it works by looking over the code, let's dig a little bit deeper into some of the concepts, such as the logistic cost function and the backpropagation algorithm that we implemented to learn the weights.</p></div></div>

<div id="calibre_link-154" class="calibre">
<div class="book" title="Training an artificial neural network">
<div class="book" title="Computing the logistic cost function"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2161"><a id="calibre_link-380" class="calibre1"></a>Computing the logistic cost function</h2></div></div></div><p class="calibre8">The logistic cost <a id="calibre_link-2162" class="calibre1"></a>function that we implemented as the <code class="email">_compute_cost</code> method is actually pretty simple to follow since it is the same cost function that we described in the logistic regression section in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>:</p><div class="mediaobject"><img src="images/00479.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00466.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> is the sigmoid activation of the <span class="strong"><em class="calibre9">i</em></span>th sample in the dataset, which we compute in the forward propagation step:</p><div class="mediaobject"><img src="images/00368.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Again, note that in this context, the superscript <span class="strong"><em class="calibre9">[i]</em></span> is an index for training samples, not layers.</p><p class="calibre8">Now, let's add a regularization term, which allows us to reduce the degree of overfitting. As you recall from earlier chapters, the L2 regularization term is defined as follows (remember that we don't regularize the bias units):</p><div class="mediaobject"><img src="images/00381.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">By adding the L2 <a id="calibre_link-2163" class="calibre1"></a>regularization term to our logistic cost function, we obtain the following equation:</p><div class="mediaobject"><img src="images/00391.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since we implemented an MLP for multiclass classification that returns an output vector of <span class="strong"><em class="calibre9">t</em></span> elements that we need to compare to the <span class="strong"><em class="calibre9">t x 1</em></span> dimensional target vector in the one-hot encoding representation, for example, the activation of the third layer and the target class (here, class 2) for a particular sample may look like this:</p><div class="mediaobject"><img src="images/00402.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Thus, we need to generalize the logistic cost function to all <span class="strong"><em class="calibre9">t</em></span> activation units in our network. Thus, the cost function (without the regularization term) becomes the following:</p><div class="mediaobject"><img src="images/00697.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, again, the superscript <span class="strong"><em class="calibre9">(i)</em></span> is the index of a particular sample in our training set.</p><p class="calibre8">The following generalized <a id="calibre_link-2164" class="calibre1"></a>regularization term may look a little bit complicated at first, but here we are just calculating the sum of all weights of an <span class="strong"><em class="calibre9">l</em></span> layer (without the bias term) that we added to the first column:</p><div class="mediaobject"><img src="images/00422.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, u<sub class="calibre27">1</sub> refers to the number of units in a given layer <span class="strong"><em class="calibre9">l</em></span>, and the following expression represents the penalty term:</p><div class="mediaobject"><img src="images/00437.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Remember that our goal is to minimize the cost function <span class="strong"><img src="images/00449.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span>; thus we need to calculate the partial derivative of the parameters <span class="strong"><strong class="calibre2">W</strong></span> with respect to each weight for every layer in the network:</p><div class="mediaobject"><img src="images/00007.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the next section, we will talk about the backpropagation algorithm, which allows us to calculate those partial derivatives to minimize the cost function.</p><p class="calibre8">Note that <span class="strong"><img src="images/00511.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> consists of multiple matrices. In a multilayer perceptron with one hidden unit, we have the weight matrix <span class="strong"><img src="images/00568.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span>, which connects the input to the hidden layer, and <span class="strong"><img src="images/00624.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span>, which connects the hidden layer to the output layer. An intuitive visualization of the three-dimensional tensor <span class="strong"><img src="images/00511.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> is provided in the following figure:</p><div class="mediaobject"><img src="images/00693.jpeg" alt="Computing the logistic cost function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In this simplified figure, it<a id="calibre_link-2165" class="calibre1"></a> may seem that both <span class="strong"><img src="images/00568.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> and <span class="strong"><img src="images/00624.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> have the same number of rows and columns, which is typically not the case unless we initialize an MLP with the same number of hidden units, output units, and input features.</p><p class="calibre8">If this sounds confusing, stay tuned for the next section, where we will discuss the dimensionality of <span class="strong"><img src="images/00568.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> and <span class="strong"><img src="images/00624.jpeg" alt="Computing the logistic cost function" class="calibre14" /></span> in more detail in the context of the backpropagation algorithm. Also, I want to encourage you to read through the code of the <code class="email">NeuralNetMLP</code> again, which I annotated with helpful comments about the dimensionality with regard to the different matrices and vector transformations. You can obtain the annotated code either from Packt or the book's GitHub repository at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition">https://github.com/rasbt/python-machine-learning-book-2nd-edition</a>.</p></div></div></div>

<div id="calibre_link-157" class="calibre">
<div class="book" title="Training an artificial neural network">
<div class="book" title="Developing your intuition for backpropagation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2166"><a id="calibre_link-381" class="calibre1"></a>Developing your intuition for backpropagation</h2></div></div></div><p class="calibre8">Although backpropagation was<a id="calibre_link-2167" class="calibre1"></a> rediscovered and popularized more than 30 years ago (<span class="strong"><em class="calibre9">Learning representations by back-propagating errors</em></span>, <span class="strong"><em class="calibre9">D. E. Rumelhart</em></span>, <span class="strong"><em class="calibre9">G. E. Hinton</em></span>, and <span class="strong"><em class="calibre9">R. J. Williams</em></span>, <span class="strong"><em class="calibre9">Nature</em></span>, 323: 6088, pages 533&ndash;536, <span class="strong"><em class="calibre9">1986</em></span>), it still remains one of the most widely used algorithms to train artificial neural networks very efficiently. If you are interested in additional references regarding the history of backpropagation, Juergen Schmidhuber wrote a nice survey article, <span class="strong"><em class="calibre9">Who Invented Backpropagation?</em></span>, which you can find online at <a class="calibre1" href="http://people.idsia.ch/~juergen/who-invented-backpropagation.html">http://people.idsia.ch/~juergen/who-invented-backpropagation.html</a>.</p><p class="calibre8">In this section, I intend to provide<a id="calibre_link-2168" class="calibre1"></a> a short and intuitive summary and the bigger picture of how this fascinating algorithm works before we dive into more mathematical details. In essence, we can think of backpropagation as a very computationally efficient approach to compute the partial derivatives of a complex cost function in multilayer neural networks. Here, our goal is to use those derivatives to learn the weight coefficients for parameterizing such a multilayer artificial neural network. The challenge in the parameterization of neural networks is that we are typically dealing with a very large number of weight coefficients in a high-dimensional feature space. In contrast to cost functions of single-layer neural networks such as Adaline or logistic regression, which we have seen in previous chapters, the error surface of a neural network cost function is not convex or smooth with respect to the parameters. There are many bumps in this high-dimensional cost surface (local minima) that we have to overcome in order to find the global minimum of the cost function.</p><p class="calibre8">You may recall the concept of the chain rule from your introductory calculus classes. The chain rule is an approach to compute the derivative of a complex, nested function, such as <span class="strong"><em class="calibre9">f(g(x))</em></span>, as follows:</p><div class="mediaobject"><img src="images/00052.jpeg" alt="Developing your intuition for backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Similarly, we can use the chain rule for an arbitrarily long function composition. For example, let's assume that we have five different functions, <span class="strong"><em class="calibre9">f (x)</em></span>, <span class="strong"><em class="calibre9">g(x)</em></span>, <span class="strong"><em class="calibre9">h(x)</em></span>, <span class="strong"><em class="calibre9">u(x)</em></span>, and <span class="strong"><em class="calibre9">v(x)</em></span>, and let <span class="strong"><em class="calibre9">F</em></span> be the function composition: <span class="strong"><em class="calibre9">F(x) = f(g(h(u(v(x)))))</em></span>. Applying the chain rule, we can compute the derivative of this function as follows:</p><div class="mediaobject"><img src="images/00807.jpeg" alt="Developing your intuition for backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the context of computer algebra, a set of techniques has been developed to solve such problems very efficiently, which is also known <a id="calibre_link-2169" class="calibre1"></a>as <span class="strong"><strong class="calibre2">automatic differentiation</strong></span>. If you are interested in learning more about automatic differentiation in machine learning applications, I recommend that you read A. G. Baydin and B. A. Pearlmutter's article <span class="strong"><em class="calibre9">Automatic Differentiation of Algorithms for Machine Learning</em></span>, arXiv preprint arXiv:1404.7456, <span class="strong"><em class="calibre9">2014</em></span>, which is freely available on arXiv at <a class="calibre1" href="http://arxiv.org/pdf/1404.7456.pdf">http://arxiv.org/pdf/1404.7456.pdf</a>.</p><p class="calibre8">Automatic differentiation comes with two modes, the forward and reverse modes; backpropagation is simply just a special case of reverse mode automatic differentiation. The key point is that applying the chain rule in the forward mode can be quite expensive since we would have to multiply large matrices for each layer (Jacobians) that we eventually multiply by a vector to obtain the output. The trick of reverse mode is that we start from right to left: we multiply a matrix by a vector, which yields another vector that is multiplied by the next matrix and so on. Matrix-vector multiplication is computationally much cheaper than matrix-matrix multiplication, which is why backpropagation is one of the<a id="calibre_link-2170" class="calibre1"></a> most popular algorithms used in neural network training.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2171" class="calibre1"></a>Note</h3><p class="calibre8">To fully understand backpropagation, we need to borrow certain concepts from differential calculus, which is beyond the scope of this book. However, I have written a review chapter of the most fundamental concepts, which you might find useful in this context. It discusses function derivatives, partial derivatives, gradients, and the Jacobian. I <a id="calibre_link-2172" class="calibre1"></a>made this text freely accessible at <a class="calibre1" href="https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf">https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf</a>. If you are unfamiliar with calculus or need a brief refresher, consider reading this text as an additional supporting resource before reading the next section.</p></div></div></div></div>

<div id="calibre_link-164" class="calibre">
<div class="book" title="Training an artificial neural network">
<div class="book" title="Training neural networks via backpropagation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2173"><a id="calibre_link-382" class="calibre1"></a>Training neural networks via backpropagation</h2></div></div></div><p class="calibre8">In this section, we will go<a id="calibre_link-2174" class="calibre1"></a> through the math of backpropagation to <a id="calibre_link-2175" class="calibre1"></a>understand how you can learn the weights in a neural network very efficiently. Depending on how comfortable you are with mathematical representations, the following equations may seem relatively complicated at first.</p><p class="calibre8">In a previous section, we saw how to calculate the cost as the difference between the activation of the last layer and the target class label. Now, we will see how the backpropagation algorithm works to update the weights in our MLP model from a mathematical perspective, which we implemented in the <code class="email"># Backpropagation</code> section inside the <code class="email">fit</code> method. As we recall from the beginning of this chapter, we first need to apply forward propagation in order to obtain the activation of the output layer, which we formulated as follows:</p><div class="mediaobject"><img src="images/00871.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00942.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00097.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00081.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Concisely, we just forward-propagate the input features through the connection in the network, as shown in the following illustration:</p><div class="mediaobject"><img src="images/00139.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In backpropagation, we<a id="calibre_link-2176" class="calibre1"></a> propagate the error from right to left. We <a id="calibre_link-2177" class="calibre1"></a>start by calculating the error vector of the output layer:</p><div class="mediaobject"><img src="images/00197.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><strong class="calibre2">y</strong></span> is the vector of the true class labels (the corresponding variable in the <code class="email">NeuralNetMLP</code> code is <code class="email">sigma_out</code>).</p><p class="calibre8">Next, we calculate the error term of the hidden layer:</p><div class="mediaobject"><img src="images/00143.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00155.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> is simply the derivative of the sigmoid activation function, which we computed as <code class="email">sigmoid_derivative_h = a_h * (1. - a_h)</code> in the <code class="email">fit</code> method of the <code class="email">NeuralNetMLP</code>:</p><div class="mediaobject"><img src="images/00170.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that the <span class="strong"><img src="images/00406.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> symbol means element-wise multiplication in this context.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2178" class="calibre1"></a>Note</h3><p class="calibre8">Although it is not important to follow the next equations, you may be curious how I obtained the derivative of the activation function; I have summarized the derivation step by step here:</p><div class="mediaobject1"><img src="images/00189.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00202.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00216.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00229.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00695.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00251.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject1"><img src="images/00809.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p></div><p class="calibre8">Next, we <a id="calibre_link-2179" class="calibre1"></a>compute the <span class="strong"><img src="images/00872.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> layer error <a id="calibre_link-2180" class="calibre1"></a>matrix (<code class="email">sigma_h</code>) as follows:</p><div class="mediaobject"><img src="images/00944.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To better understand how we computed this <span class="strong"><img src="images/00872.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> term, let's walk through it in more detail. In the preceding equation, we used the transpose <span class="strong"><img src="images/00290.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> of the <span class="strong"><em class="calibre9">h x t</em></span>-dimensional matrix <span class="strong"><img src="images/00084.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span>. Here, <span class="strong"><em class="calibre9">t</em></span> is the number of output class labels and <span class="strong"><em class="calibre9">h</em></span> is the number of hidden units. The matrix multiplication between the <span class="strong"><em class="calibre9">n x t</em></span>-dimensional <span class="strong"><img src="images/00142.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> matrix and the <span class="strong"><em class="calibre9">t x h</em></span>-dimensional matrix <span class="strong"><img src="images/00290.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span>, results in an <span class="strong"><em class="calibre9">n x t</em></span>-dimensional matrix that we multiplied<a id="calibre_link-2181" class="calibre1"></a> elementwise by the sigmoid derivative<a id="calibre_link-2182" class="calibre1"></a> of the same dimension to obtain the <span class="strong"><em class="calibre9">n x t</em></span>-dimensional matrix <span class="strong"><img src="images/00872.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span>.</p><p class="calibre8">Eventually, after obtaining the <span class="strong"><img src="images/00199.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> terms, we can now write the derivation of the cost function as follows:</p><div class="mediaobject"><img src="images/00329.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00337.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Next, we need to accumulate the partial derivative of every node in each layer and the error of the node in the next layer. However, remember that we need to compute <span class="strong"><img src="images/00416.jpeg" alt="Training neural networks via backpropagation" class="calibre14" /></span> for every sample in the training set. Thus, it is easier to implement it as a vectorized version like in our <code class="email">NeuralNetMLP</code> code implementation:</p><div class="mediaobject"><img src="images/00341.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00367.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">And after we have accumulated the partial derivatives, we can add the regularization term:</p><div class="mediaobject"><img src="images/00419.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The two previous mathematical equations correspond to the code variables <code class="email">delta_w_h</code>, <code class="email">delta_b_h</code>, <code class="email">delta_w_out</code>, and <code class="email">delta_b_out</code> in <code class="email">NeuralNetMLP</code>.</p><p class="calibre8">Lastly, after we have computed the gradients, we can now update the weights by taking an opposite step towards the gradient for each layer <span class="strong"><em class="calibre9">l</em></span>:</p><div class="mediaobject"><img src="images/00051.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This is implemented as follows:</p><div class="informalexample"><pre class="programlisting">self.w_h -= self.eta * delta_w_h
self.b_h -= self.eta * delta_b_h
self.w_out -= self.eta * delta_w_out
self.b_out -= self.eta * delta_b_out</pre></div><p class="calibre8">To bring <a id="calibre_link-2183" class="calibre1"></a>everything together, let's summarize <a id="calibre_link-2184" class="calibre1"></a>backpropagation in the following figure:</p><div class="mediaobject"><img src="images/00068.jpeg" alt="Training neural networks via backpropagation" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-167" class="calibre"><div class="book" title="About the convergence in neural networks" id="calibre_link-78"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2185"><a id="calibre_link-2186" class="calibre1"></a>About the convergence in neural networks</h1></div></div></div><p class="calibre8">You might be wondering why we did not<a id="calibre_link-2187" class="calibre1"></a> use regular gradient descent but instead used mini-batch learning to train our neural network for the handwritten digit classification. You may recall our discussion on stochastic gradient descent that we used to implement online learning. In online learning, we compute the gradient based on a single training example (<span class="strong"><em class="calibre9">k = 1</em></span>) at a time to perform the weight update. Although this is a stochastic approach, it often leads to very accurate solutions with a much faster convergence than regular gradient descent. Mini-batch learning is a special form of stochastic gradient descent where we compute the gradient based on a subset <span class="strong"><em class="calibre9">k </em></span>of the <span class="strong"><em class="calibre9">n</em></span> training samples with <span class="strong"><em class="calibre9">1 &lt; k &lt; n</em></span>. Mini-batch learning has the advantage over online learning that we can make use of our vectorized implementations to improve computational efficiency. However, we can update the weights much faster than in regular gradient descent. Intuitively, you can think of mini-batch learning as predicting the voter turnout of a <a id="calibre_link-2188" class="calibre1"></a>presidential election from a poll by asking only a representative subset of the population rather than asking the entire population (which would be equal to running the actual election).</p><p class="calibre8">Multilayer neural networks are much harder to train than simpler algorithms such as Adaline, logistic regression, or support vector machines. In multilayer neural networks, we typically have hundreds, thousands, or even billions of weights that we need to optimize. Unfortunately, the output function has a rough surface and the optimization algorithm can easily become trapped in local minima, as shown in the following figure:</p><div class="mediaobject"><img src="images/00578.jpeg" alt="About the convergence in neural networks" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that this representation is extremely simplified since our neural network has many dimensions; it makes it impossible to visualize the actual cost surface for the human eye. Here, we only show the cost surface for a single weight on the <span class="strong"><em class="calibre9">x</em></span>-axis. However, the main message is that we do not want our algorithm to get trapped in local minima. By increasing the learning rate, we can more readily escape such local minima. On the other hand, we also increase the chance of overshooting the global optimum if the learning rate is too large. Since we initialize the weights randomly, we start with a solution to the optimization problem that is typically hopelessly wrong.</p></div></div>

<div id="calibre_link-168" class="calibre"><div class="book" title="A few last words about the neural network implementation" id="calibre_link-182"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2189"><a id="calibre_link-2190" class="calibre1"></a>A few last words about the neural network implementation</h1></div></div></div><p class="calibre8">You may be wondering why we went through all of this theory just to implement a simple multilayer artificial network that can classify handwritten digits instead of using an open source Python machine learning library. In fact, we will introduce more complex neural network models in the next chapters, which we will train using the open source TensorFlow<a id="calibre_link-2191" class="calibre1"></a> library (<a class="calibre1" href="https://www.tensorflow.org">https://www.tensorflow.org</a>). Although the from scratch implementation in this chapter seems a bit tedious at first, it was a good exercise for understanding the basics behind backpropagation and neural network training, and a basic understanding of algorithms is crucial for applying machine learning techniques appropriately and successfully.</p><p class="calibre8">Now that you have learned how feedforward neural networks work, we are ready to explore more sophisticated deep neural networks, such as TensorFlow <a id="calibre_link-2192" class="calibre1"></a>and Keras (<a class="calibre1" href="https://keras.io">https://keras.io</a>), which allow us to construct neural networks more efficiently, as we will see in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>. Over the past two years, since its release in November 2015, TensorFlow has gained a lot of popularity among machine learning researchers, who use it to construct deep neural networks because of its<a id="calibre_link-2193" class="calibre1"></a> ability to optimize mathematical expressions for computations on multi dimensional arrays utilizing <span class="strong"><strong class="calibre2">Graphical Processing Units</strong></span> (<span class="strong"><strong class="calibre2">GPUs</strong></span>). While TensorFlow can be considered a low-level deep learning library, simplifying API such as Keras have been developed that make the construction of common deep learning models even more convenient, which we will see in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>. </p></div></div>

<div id="calibre_link-172" class="calibre"><div class="book" title="Summary" id="calibre_link-383"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2194"><a id="calibre_link-2195" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, you have learned the basic concepts behind multilayer artificial neural networks, which are currently the hottest topics in machine learning research. In <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>, we started our journey with simple single-layer neural network structures and now we have connected multiple neurons to a powerful neural network architecture to solve complex problems such as handwritten digit recognition. We demystified the popular backpropagation algorithm, which is one of the building blocks of many neural network models that are used in deep learning. After learning about the backpropagation algorithm in this chapter, we are well-equipped for exploring more complex deep neural network architectures. In the remaining chapters, we will introduce TensorFlow, an open source library geared towards deep learning, which allows us to implement and train multilayer neural networks more efficiently. </p></div></div>

<div id="calibre_link-178" class="calibre">
<div id="calibre_link-2196" class="calibre10"></div><div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow"><div class="book" id="calibre_link-16"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2197"><a id="calibre_link-2198" class="calibre1"></a>Chapter&nbsp;13.&nbsp;Parallelizing Neural Network Training with TensorFlow</h1></div></div></div><p class="calibre8">In this chapter, we'll move on from the mathematical foundations of machine learning and deep learning to introducing TensorFlow. TensorFlow is one of the most popular deep learning libraries currently available, and it can let us implement neural networks much more efficiently than any of our previous NumPy implementations. In this chapter, we'll start using TensorFlow and see how it brings significant benefits to training performance.</p><p class="calibre8">This chapter begins the next stage of our journey into training machine learning and deep learning, and we'll explore the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">How TensorFlow improves training performance</li><li class="listitem">Working with TensorFlow to write optimized machine learning code</li><li class="listitem">Using TensorFlow high-level APIs to build a multilayer neural network</li><li class="listitem">Choosing activation functions for artificial neural networks</li><li class="listitem">Introducing Keras, a high-level wrapper around TensorFlow, for implementing common deep learning architectures most conveniently</li></ul></div></div></div>

<div id="calibre_link-185" class="calibre">
<div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow">
<div class="book" title="TensorFlow and training performance"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2199"><a id="calibre_link-384" class="calibre1"></a>TensorFlow and training performance</h1></div></div></div><p class="calibre8">TensorFlow <a id="calibre_link-2200" class="calibre1"></a>can speed up our machine learning tasks significantly. To understand how it can do this, let's begin by discussing some of the performance challenges we typically run into when we run expensive calculations on our hardware.</p><p class="calibre8">The performance of<a id="calibre_link-2201" class="calibre1"></a> computer processors has, of course, been improving continuously over recent years, and that's allowed us to train more powerful and complex learning systems, and so to improve the predictive performance of our machine learning models. Even the cheapest desktop computer hardware that's available right now comes with processing units that have multiple cores.</p><p class="calibre8">Also, in the previous chapters, we saw that many functions in scikit-learn allowed us to spread those computations over multiple processing units. However, by default, Python is limited to execution on one core due to <a id="calibre_link-2202" class="calibre1"></a>the <span class="strong"><strong class="calibre2">Global Interpreter Lock</strong></span> (<span class="strong"><strong class="calibre2">GIL</strong></span>). So, although we, indeed, take advantage of its multiprocessing library to distribute our computations over multiple cores, we still have to consider that the most advanced desktop hardware rarely comes with more than 8 or 16 such cores.</p><p class="calibre8">If we recall from <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, where we<a id="calibre_link-2203" class="calibre1"></a> implemented a very simple multilayer perceptron with only one hidden layer consisting of 100 units, we had to optimize approximately 80,000 weight parameters (<span class="strong"><em class="calibre9">[784*100 + 100] + [100 * 10] + 10 = 79,510</em></span>) to learn a model for a very simple image classification task. The images in MNIST are rather small (28 x 28 pixels), and we can only imagine the explosion in the number of parameters if we want to add additional hidden layers or work with images that have higher pixel densities.</p><p class="calibre8">Such a task would quickly become unfeasible for a single processing unit. The question then becomes&mdash;how can we tackle such problems more effectively?</p><p class="calibre8">The obvious solution to this problem is to use GPUs, which are real work horses. You can think of a graphics card as a small computer cluster inside your machine. Another advantage is that modern GPUs are relatively cheap compared to the state-of-the-art CPUs, as we can see in the following overview:</p><div class="mediaobject"><img src="images/00636.jpeg" alt="TensorFlow and training performance" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The sources for the information in the table are the following websites:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><a class="calibre1" href="https://www.intel.com/content/www/us/en/products/processors/core/x-series/i7-6900k.html">https://www.intel.com/content/www/us/en/products/processors/core/x-series/i7-6900k.html</a></li><li class="listitem"><a class="calibre1" href="https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/">https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/</a></li></ul></div><p class="calibre8">(Date: August 2017)</p><p class="calibre8">At 70 percent of the price of a modern CPU, we can get a GPU that has 450 times more cores and is capable of around 15 times more floating-point calculations per second. So, what is holding us back from utilizing GPUs for our machine learning tasks?</p><p class="calibre8">The challenge is that writing code to target GPUs is not as simple as executing Python code in our interpreter. There are special packages, such as CUDA and OpenCL, that allow us to target the GPU. However, writing code in CUDA or OpenCL is probably not the most convenient environment for implementing and running machine learning algorithms. The good news is that this is what TensorFlow was developed for!</p></div></div></div>

<div id="calibre_link-187" class="calibre">
<div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow">
<div class="book" title="TensorFlow and training performance">
<div class="book" title="What is TensorFlow?"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2204"><a id="calibre_link-385" class="calibre1"></a>What is TensorFlow?</h2></div></div></div><p class="calibre8">TensorFlow is a <a id="calibre_link-2205" class="calibre1"></a>scalable and multiplatform programming interface for implementing and running machine learning algorithms, including convenience wrappers for deep learning.</p><p class="calibre8">TensorFlow was developed by the researchers and engineers of the Google Brain team; and while the main development is led by a team of researchers and software engineers at Google, its development also involves many contributions from the open source community. TensorFlow was initially built for only internal use at Google, but it was subsequently released in November 2015 under a permissive open source license.</p><p class="calibre8">To improve the performance of training machine learning models, TensorFlow allows execution on both CPUs and GPUs. However, its greatest performance capabilities can be discovered when using GPUs. TensorFlow supports CUDA-enabled GPUs officially. Support for OpenCL-enabled devices is still experimental. However, OpenCL will likely be officially supported in near future.</p><p class="calibre8">TensorFlow currently supports frontend interfaces for a number of programming languages. Lucky for us as Python users, TensorFlow's Python API is currently the most complete API, thereby attracting many machine learning and deep learning practitioners. Furthermore, TensorFlow has an official API in C++.</p><p class="calibre8">The APIs in other languages, such as Java, Haskell, Node.js, and Go, are not stable yet, but the open source community and TensorFlow developers are constantly improving them. TensorFlow computations rely on constructing a directed graph for representing the data flow. Even though building the graph may sound complicated, TensorFlow comes with high-level APIs that has made it very easy.</p></div></div></div></div>

<div id="calibre_link-191" class="calibre">
<div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow">
<div class="book" title="TensorFlow and training performance">
<div class="book" title="How we will learn TensorFlow"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2206"><a id="calibre_link-386" class="calibre1"></a>How we will learn TensorFlow</h2></div></div></div><p class="calibre8">We'll learn first of all about <a id="calibre_link-2207" class="calibre1"></a>the low-level TensorFlow API. While implementing models at this level can be a little bit cumbersome at first, the advantage of the low-level API is that it gives us more flexibility as programmers to combine the basic operations and develop complex machine learning models. Starting from TensorFlow version 1.1.0, high-level APIs are added on top of the low-level API (for instance, the so-called Layers and Estimators APIs), which allow building and prototyping models much faster.</p><p class="calibre8">After learning about the low-level API, we will move forward to explore two high-level APIs, namely TensorFlow <span class="strong"><strong class="calibre2">Layers</strong></span> and <span class="strong"><strong class="calibre2">Keras</strong></span>. However, let's begin by taking our first steps with TensorFlow <a id="calibre_link-2208" class="calibre1"></a>low-level API, and ease ourselves into how everything works.</p></div></div></div></div>

<div id="calibre_link-195" class="calibre">
<div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow">
<div class="book" title="TensorFlow and training performance">
<div class="book" title="First steps with TensorFlow"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2209"><a id="calibre_link-387" class="calibre1"></a>First steps with TensorFlow</h2></div></div></div><p class="calibre8">In this section, we'll take our <a id="calibre_link-2210" class="calibre1"></a>first steps in using the low-level TensorFlow API. Depending on how your system is set up, you can typically just use Python's <code class="email">pip</code> installer and install TensorFlow from PyPI by executing the following from your Terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip install tensorflow</strong></span>
</pre></div><p class="calibre8">In case you want to use GPUs, the CUDA Toolkit as well as the NVIDIA cuDNN library need to be installed; then you can install TensorFlow with GPU support, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip install tensorflow-gpu</strong></span>
</pre></div><p class="calibre8">TensorFlow is under active development; therefore, every couple of months, newer versions are released with significant changes. At the time of writing this chapter, the latest TensorFlow version is 1.3.0. You can verify your TensorFlow version from your Terminal, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">python -c 'import tensorflow as tf; print(tf.__version__)'</strong></span>
</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2211" class="calibre1"></a>Note</h3><p class="calibre8">If you should experience problems with the installation procedure, I recommend you to read more about system- and <a id="calibre_link-2212" class="calibre1"></a>platform-specific recommendations that are provided at <a class="calibre1" href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a>. Note that all the code in this chapter can be run on your CPU; using a GPU is entirely optional but recommended if you want to fully enjoy the benefits of TensorFlow. If you have a graphics card, refer to the installation page to set it up appropriately. In addition, you may find this TensorFlow-GPU setup guide helpful, which explains how to install the NVIDIA graphics card drivers, CUDA, and cuDNN on Ubuntu (not required but recommended requirements for running TensorFlow on a GPU): <a class="calibre1" href="https://sebastianraschka.com/pdf/books/dlb/appendix_h_cloud-computing.pdf">https://sebastianraschka.com/pdf/books/dlb/appendix_h_cloud-computing.pdf</a>.</p></div><p class="calibre8">TensorFlow is built around a computation graph composed of a set of nodes. Each node represents an operation that may have zero or more input or output. The values that flow through the edges of the computation graph are <a id="calibre_link-2213" class="calibre1"></a>called <span class="strong"><strong class="calibre2">tensors</strong></span>.</p><p class="calibre8">Tensors can be understood as a generalization of scalars, vectors, matrices, and so on. More concretely, a scalar can be defined as a rank-0 tensor, a vector as a rank-1 tensor, a matrix as a rank-2 tensor, and matrices stacked in a third dimension as rank-3 tensors.</p><p class="calibre8">Once a computation graph is built, the graph can be launched in a TensorFlow <code class="email">Session</code> for executing different nodes of the graph. In <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span>, we will cover the steps in building the computation graph and launching the graph in a session in more detail.</p><p class="calibre8">As a warm-up exercise, we will start with the use of simple scalars from TensorFlow to compute a net input <span class="strong"><em class="calibre9">z</em></span> of a sample point <span class="strong"><em class="calibre9">x</em></span> in a one-dimensional dataset with weight <span class="strong"><em class="calibre9">w</em></span> and bias <span class="strong"><em class="calibre9">b</em></span>:</p><div class="mediaobject"><img src="images/00096.jpeg" alt="First steps with TensorFlow" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The following<a id="calibre_link-2214" class="calibre1"></a> code shows the implementation of this equation in the low-level TensorFlow API:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf

## create a graph
g = tf.Graph()
with g.as_default():
    x = tf.placeholder(dtype=tf.float32,
                       shape=(None), name='x')
    w = tf.Variable(2.0, name='weight')
    b = tf.Variable(0.7, name='bias')

    z = w*x + b

    init = tf.global_variables_initializer()
## create a session and pass in graph g
with tf.Session(graph=g) as sess:
    ## initialize w and b:
    sess.run(init)
    ## evaluate z:
    for t in [1.0, 0.6, -1.8]:
        print('x=%4.1f --&gt; z=%4.1f'%(
              t, sess.run(z, feed_dict={x:t})))</pre></div><p class="calibre8">After executing the previous code, you should see the following output:</p><div class="informalexample"><pre class="programlisting">x= 1.0 --&gt; z= 2.7
x= 0.6 --&gt; z= 1.9
x=-1.8 --&gt; z=-2.9</pre></div><p class="calibre8">This was pretty straightforward, right? In general, when we develop a model in the TensorFlow low-level API, we need to define placeholders for input data (<code class="email">x</code>, <code class="email">y</code>, and sometimes other tunable parameters); then, define the weight matrices and build the model from input to output. If this is an optimization problem, we should define the loss or cost function and determine which optimization algorithm to use. TensorFlow will create a graph that contains all the symbols that we have defined as nodes in this graph.</p><p class="calibre8">Here, we created a <a id="calibre_link-2215" class="calibre1"></a>placeholder for <code class="email">x</code> with <code class="email">shape=(None)</code>. This allows us to feed the values in an element-by-element form and as a batch of input data at once, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     sess.run(init)
...     print(sess.run(z, feed_dict={x:[1., 2., 3.]}))

[ 2.70000005  4.69999981  6.69999981]</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2216" class="calibre1"></a>Note</h3><p class="calibre8">Note that we are omitting Python's command-line prompt in several places in this chapter to improve the readability of long code examples by avoiding unnecessary text wrapping; this is because TensorFlow's function and method names can be very verbose.</p><p class="calibre8">Also, note that the official TensorFlow style guide<a id="calibre_link-2217" class="calibre1"></a> (<a class="calibre1" href="https://www.tensorflow.org/community/style_guide">https://www.tensorflow.org/community/style_guide</a>) recommends using two-character spacing for code indents. However, we chose four characters for indents as it is more consistent with the official Python style guide and also helps in displaying the code syntax highlighting in many text editors correctly as well as the accompanying Jupyter code notebooks at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition">https://github.com/rasbt/python-machine-learning-book-2nd-edition</a>.</p></div></div></div></div></div>

<div id="calibre_link-465" class="calibre">
<div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow">
<div class="book" title="TensorFlow and training performance">
<div class="book" title="Working with array structures"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2218"><a id="calibre_link-388" class="calibre1"></a>Working with array structures</h2></div></div></div><p class="calibre8">Let's discuss how to use<a id="calibre_link-2219" class="calibre1"></a> array structures in TensorFlow. By executing <a id="calibre_link-2220" class="calibre1"></a>the following code, we will create a simple rank-3 tensor of size <span class="strong"><img src="images/00108.jpeg" alt="Working with array structures" class="calibre14" /></span>, reshape it, and calculate the column sums using TensorFlow's optimized expressions. Since we do not know the batch size a priori, we specify <code class="email">None</code> for the batch size in the argument for the <code class="email">shape</code> parameter of the placeholder <code class="email">x</code>:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf
import numpy as np

g = tf.Graph()
with g.as_default():
    x = tf.placeholder(dtype=tf.float32,
                       shape=(None, 2, 3),
                       name='input_x')

    x2 = tf.reshape(x, shape=(-1, 6),
                    name='x2')

    ## calculate the sum of each column
    xsum = tf.reduce_sum(x2, axis=0, name='col_sum')

    ## calculate the mean of each column
    xmean = tf.reduce_mean(x2, axis=0, name='col_mean')

with tf.Session(graph=g) as sess:
    x_array = np.arange(18).reshape(3, 2, 3)

    print('input shape: ', x_array.shape)
    print('Reshaped:\n',
          sess.run(x2, feed_dict={x:x_array}))
    print('Column Sums:\n',
          sess.run(xsum, feed_dict={x:x_array}))
    print('Column Means:\n',
          sess.run(xmean, feed_dict={x:x_array}))</pre></div><p class="calibre8">The output <a id="calibre_link-2221" class="calibre1"></a>shown after<a id="calibre_link-2222" class="calibre1"></a> executing the preceding code is given here:</p><div class="informalexample"><pre class="programlisting">input shape:  (3, 2, 3)
Reshaped:
 [[  0.   1.   2.   3.   4.   5.]
  [  6.   7.   8.   9.  10.  11.]
  [ 12.  13.  14.  15.  16.  17.]]

Column Sums:
  [ 18.  21.  24.  27.  30.  33.]

Column Means:
  [  6.   7.   8.   9.  10.  11.]</pre></div><p class="calibre8">In this example, we worked with three functions&mdash;<code class="email">tf.reshape</code>, <code class="email">tf.reduce_sum</code>, and <code class="email">tf.reduce_mean</code>. Note that for reshaping, we used the value <code class="email">-1</code> for the first dimension. This is because we do not know the value of batch size; when reshaping a tensor, if you use <code class="email">-1</code> for a specific dimension, the size of that dimension will be computed according to the total size of the tensor and the remaining dimension. Therefore, <code class="email">tf.reshape(tensor, shape=(-1,))</code> can be used to flatten a tensor.</p><p class="calibre8">Feel free to explore other TensorFlow functions<a id="calibre_link-2223" class="calibre1"></a> from the official documentation at <a class="calibre1" href="https://www.TensorFlow.org/api_docs/python/tf">https://www.TensorFlow.org/api_docs/python/tf</a>.</p></div></div></div></div>

<div id="calibre_link-470" class="calibre">
<div class="book" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow">
<div class="book" title="TensorFlow and training performance">
<div class="book" title="Developing a simple model with the low-level TensorFlow API"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2224"><a id="calibre_link-389" class="calibre1"></a>Developing a simple model with the low-level TensorFlow API</h2></div></div></div><p class="calibre8">Now that we have <a id="calibre_link-2225" class="calibre1"></a>familiarized ourselves <a id="calibre_link-2226" class="calibre1"></a>with TensorFlow, let's take a look at a really practical example and implement <span class="strong"><strong class="calibre2">Ordinary Least Squares</strong></span> (<span class="strong"><strong class="calibre2">OLS</strong></span>) <a id="calibre_link-2227" class="calibre1"></a>regression. For a quick refresher on regression analysis, refer to <a class="calibre1" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" href="#calibre_link-41">Chapter 10</a>, <span class="strong"><em class="calibre9">Predicting Continuous Target Variables with Regression Analysis</em></span>.</p><p class="calibre8">Let's start by creating a small one-dimensional toy dataset with <code class="email">10</code> training samples:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; X_train = np.arange(10).reshape((10, 1))
&gt;&gt;&gt; y_train = np.array([1.0, 1.3, 3.1,
...                     2.0, 5.0, 6.3,
...                     6.6, 7.4, 8.0,
...                     9.0])</pre></div><p class="calibre8">Given this dataset, we want to train a linear regression model to predict the output <span class="strong"><em class="calibre9">y</em></span> from the input <span class="strong"><em class="calibre9">x</em></span>. Let's implement this model in a class, which we name <code class="email">TfLinreg</code>. For this, we would need two placeholders&mdash;one for the input <span class="strong"><em class="calibre9">x</em></span> and one for <span class="strong"><em class="calibre9">y</em></span> for feeding the data into our model. Next, we need to define the trainable variables&mdash;weights <span class="strong"><em class="calibre9">w</em></span> and bias <span class="strong"><em class="calibre9">b</em></span>.</p><p class="calibre8">Then, we can define the linear regression model as <span class="strong"><img src="images/00096.jpeg" alt="Developing a simple model with the low-level TensorFlow API" class="calibre14" /></span>, followed by defining the cost function to be <a id="calibre_link-2228" class="calibre1"></a>the <span class="strong"><strong class="calibre2">Mean of Squared Error</strong></span> (<span class="strong"><strong class="calibre2">MSE</strong></span>). To learn the weight parameters of the model, we use the gradient descent optimizer. The code is as follows:</p><div class="informalexample"><pre class="programlisting">class TfLinreg(object):
    def __init__(self, x_dim, learning_rate=0.01,
                 random_seed=None):
        self.x_dim = x_dim
        self.learning_rate = learning_rate
        self.g = tf.Graph()
        ## build the model
        with self.g.as_default():
            ## set graph-level random-seed
            tf.set_random_seed(random_seed)
            
            self.build()
            ## create initializer
            self.init_op = tf.global_variables_initializer()
        
    def build(self):
        ## define placeholders for inputs
        self.X = tf.placeholder(dtype=tf.float32,
                                shape=(None, self.x_dim),
                                name='x_input')
        self.y = tf.placeholder(dtype=tf.float32,
                                shape=(None),
                                name='y_input')
        print(self.X)
        print(self.y)
        ## define weight matrix and bias vector
        w = tf.Variable(tf.zeros(shape=(1)),
                        name='weight')
        b = tf.Variable(tf.zeros(shape=(1)),
                        name="bias")
        print(w)
        print(b)

        self.z_net = tf.squeeze(w*self.X + b,
                                name='z_net')
        print(self.z_net)
        
        sqr_errors = tf.square(self.y - self.z_net,
                               name='sqr_errors')
        print(sqr_errors)
        self.mean_cost = tf.reduce_mean(sqr_errors,
                                        name='mean_cost')
        
        optimizer = tf.train.GradientDescentOptimizer(
                    learning_rate=self.learning_rate,
                    name='GradientDescent')
        self.optimizer = optimizer.minimize(self.mean_cost)</pre></div><p class="calibre8">So far, we have <a id="calibre_link-2229" class="calibre1"></a>defined a class to<a id="calibre_link-2230" class="calibre1"></a> construct our model. We will create an instance of this class and call it <code class="email">lrmodel</code>, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; lrmodel = TfLinreg(x_dim=X_train.shape[1], learning_rate=0.01)</pre></div><p class="calibre8">The <code class="email">print</code> statements that we wrote in the <code class="email">build</code> method will display information about six nodes in the graph&mdash;<code class="email">X</code>, <code class="email">y</code>, <code class="email">w</code>, <code class="email">b</code>, <code class="email">z_net</code>, and <code class="email">sqr_errors</code>&mdash;with their names and shapes.</p><p class="calibre8">These <code class="email">print</code> statements are optionally given for practice; however, inspecting the shapes of variables can be very helpful in debugging complex models. The following lines are printed when constructing the model:</p><div class="informalexample"><pre class="programlisting">Tensor("x_input:0", shape=(?, 1), dtype=float32)
Tensor("y_input:0", dtype=float32)
&lt;tf.Variable 'weight:0' shape=(1,) dtype=float32_ref&gt;
&lt;tf.Variable 'bias:0' shape=(1,) dtype=float32_ref&gt;
Tensor("z_net:0", dtype=float32)
Tensor("sqr_errors:0", dtype=float32)</pre></div><p class="calibre8">The next step is to implement a training function to learn the weights of the linear regression model. Note that <code class="email">b</code> is the bias unit (the <span class="strong"><em class="calibre9">y</em></span>-axis intercept at <span class="strong"><em class="calibre9">x = 0</em></span>).</p><p class="calibre8">For training, we<a id="calibre_link-2231" class="calibre1"></a> implement a separate <a id="calibre_link-2232" class="calibre1"></a>function that needs a TensorFlow session, a model instance, training data, and the number of epochs as input arguments. In this function, first we initialize the variables in the TensorFlow session using the <code class="email">init_op</code> operation defined in the model. Then, we iterate and call the <code class="email">optimizer</code> operation of the model while feeding the training data. This function will return a list of training costs as a side product:</p><div class="informalexample"><pre class="programlisting">def train_linreg(sess, model, X_train, y_train, num_epochs=10):
    ## initialiaze all variables: W and b
    sess.run(model.init_op)
    
    training_costs = []
    for i in range(num_epochs):
        _, cost = sess.run([model.optimizer, model.mean_cost],
                           feed_dict={model.X:X_train,
                                      model.y:y_train})
        training_costs.append(cost)
        
    return training_costs</pre></div><p class="calibre8">So, now we can create a new TensorFlow session to launch the <code class="email">lrmodel.g</code> graph and pass all the required arguments to the <code class="email">train_linreg</code> function for training:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; sess = tf.Session(graph=lrmodel.g)
&gt;&gt;&gt; training_costs = train_linreg(sess, lrmodel, X_train, y_train)</pre></div><p class="calibre8">Let's visualize the training costs after these 10 epochs to see whether the model is converged or not:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; plt.plot(range(1,len(training_costs) + 1), training_costs)
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.xlabel('Epoch')
&gt;&gt;&gt; plt.ylabel('Training Cost')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the following plot, this simple model converges very quickly after a few epochs:</p><div class="mediaobject"><img src="images/00119.jpeg" alt="Developing a simple model with the low-level TensorFlow API" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">So far so good. Looking <a id="calibre_link-2233" class="calibre1"></a>at the cost<a id="calibre_link-2234" class="calibre1"></a> function, it seems that we built a working regression model from this particular dataset. Now, let's compile a new function to make predictions based on the input features. For this function, we need the TensorFlow session, the model, and the test dataset:</p><div class="informalexample"><pre class="programlisting">def predict_linreg(sess, model, X_test):
    y_pred = sess.run(model.z_net,
                      feed_dict={model.X:X_test})
    return y_pred</pre></div><p class="calibre8">Implementing a predict function was pretty straightforward; just running <code class="email">z_net</code> defined in the graph computes the predicted output values. Next, let's plot the linear regression fit on the training data:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; plt.scatter(X_train, y_train,
...             marker='s', s=50,
...             label='Training Data')
&gt;&gt;&gt; plt.plot(range(X_train.shape[0]),
...          predict_linreg(sess, lrmodel, X_train),
...          color='gray', marker='o',
...          markersize=6, linewidth=3,
...          label='LinReg Model')
&gt;&gt;&gt; plt.xlabel('x')
&gt;&gt;&gt; plt.ylabel('y')
&gt;&gt;&gt; plt.legend()
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see in the<a id="calibre_link-2235" class="calibre1"></a> resulting plot, our <a id="calibre_link-2236" class="calibre1"></a>model fits the training data points appropriately:</p><div class="mediaobject"><img src="images/00886.jpeg" alt="Developing a simple model with the low-level TensorFlow API" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-474" class="calibre">
<div id="calibre_link-2237" class="calibre10"></div><div class="book" title="Training neural networks efficiently with high-level TensorFlow APIs"><div class="book" id="calibre_link-76"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2238"><a id="calibre_link-2239" class="calibre1"></a>Training neural networks efficiently with high-level TensorFlow APIs</h1></div></div></div><p class="calibre8">In this section, we will <a id="calibre_link-2240" class="calibre1"></a>take a look at two<a id="calibre_link-2241" class="calibre1"></a> high-level TensorFlow APIs&mdash;the Layers API (<code class="email">tensorflow.layers</code> or <code class="email">tf.layers</code>) and the Keras API (<code class="email">tensorflow.contrib.keras</code>).</p><p class="calibre8">Keras can be installed as a separate package. It supports Theano or TensorFlow as backend (for more information, refer to the official website of Keras<a id="calibre_link-2242" class="calibre1"></a> at <a class="calibre1" href="https://keras.io/">https://keras.io/</a>).</p><p class="calibre8">However, after the release of TensorFlow 1.1.0, Keras has been added to the TensorFlow <code class="email">contrib</code> submodule. It is very likely that the Keras subpackage will be moved outside the experimental <code class="email">contrib</code> submodule and become one of the main TensorFlow submodules soon.</p></div></div>

<div id="calibre_link-481" class="calibre">
<div class="book" title="Training neural networks efficiently with high-level TensorFlow APIs">
<div class="book" title="Building multilayer neural networks using TensorFlow&apos;s Layers API"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2243"><a id="calibre_link-390" class="calibre1"></a>Building multilayer neural networks using TensorFlow's Layers API</h2></div></div></div><p class="calibre8">To see what neural <a id="calibre_link-2244" class="calibre1"></a>network <a id="calibre_link-2245" class="calibre1"></a>training via the <code class="email">tensorflow.layers</code> (<code class="email">tf.layers</code>) high-level API looks like, let's implement a multilayer perceptron to classify the handwritten digits from the MNIST dataset, which we introduced in the previous chapter. The MNIST dataset<a id="calibre_link-2246" class="calibre1"></a> can be downloaded from <a class="calibre1" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> in four parts, as listed here:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Training set images</strong></span>: <code class="email">train-images-idx3-ubyte.gz</code> (9.5 MB)</li><li class="listitem"><span class="strong"><strong class="calibre2">Training set labels</strong></span>: <code class="email">train-labels-idx1-ubyte.gz</code> (32 KB)</li><li class="listitem"><span class="strong"><strong class="calibre2">Test set images</strong></span>: <code class="email">t10k-images-idx3-ubyte.gz</code> (1.6 MB)</li><li class="listitem"><span class="strong"><strong class="calibre2">Test set labels</strong></span>: <code class="email">t10k-labels-idx1-ubyte.gz</code> (8.0 KB)</li></ul></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2247" class="calibre1"></a>Note</h3><p class="calibre8">Note that TensorFlow also provides the same dataset as follows:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data</pre></div><p class="calibre8">However, we work with the MNIST dataset as an external dataset to learn all the steps of data preprocessing separately. This way, you would learn what you need to do with your own dataset.</p></div><p class="calibre8">After <a id="calibre_link-2248" class="calibre1"></a>downloading and<a id="calibre_link-2249" class="calibre1"></a> unzipping the archives, we place the files in the <code class="email">mnist</code> directory in our current working directory so that we can load the training as well as the test dataset, using the <code class="email">load_mnist(path, kind)</code> function we implemented previously in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>.</p><p class="calibre8">Then, the dataset will be loaded as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## loading the data
&gt;&gt;&gt; X_train, y_train = load_mnist('./mnist/', kind='train')
&gt;&gt;&gt; print('Rows: %d,  Columns: %d' %(X_train.shape[0],
...                                  X_train.shape[1]))
Rows: 60000,  Columns: 784
&gt;&gt;&gt; X_test, y_test = load_mnist('./mnist/', kind='t10k')
&gt;&gt;&gt; print('Rows: %d,  Columns: %d' %(X_test.shape[0],
...                                  X_test.shape[1]))
Rows: 10000,  Columns: 784
&gt;&gt;&gt; ## mean centering and normalization:
&gt;&gt;&gt; mean_vals = np.mean(X_train, axis=0)
&gt;&gt;&gt; std_val = np.std(X_train)
&gt;&gt;&gt;
&gt;&gt;&gt; X_train_centered = (X_train - mean_vals)/std_val
&gt;&gt;&gt; X_test_centered = (X_test - mean_vals)/std_val
&gt;&gt;&gt;
&gt;&gt;&gt; del X_train, X_test
&gt;&gt;&gt;
&gt;&gt;&gt; print(X_train_centered.shape, y_train.shape)
(60000, 784) (60000,)
&gt;&gt;&gt; print(X_test_centered.shape, y_test.shape)
(10000, 784) (10000,)</pre></div><p class="calibre8">Now we can start building our model. We will start by creating two placeholders, named <code class="email">tf_x</code> and <code class="email">tf_y</code>, and then build a multilayer perceptron as in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, but with three fully connected layers.</p><p class="calibre8">However, we will replace the logistic units in the hidden layer with hyperbolic tangent activation functions (<code class="email">tanh</code>), replace the logistic function in the output layer with <code class="email">softmax</code>, and add an additional hidden layer.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2250" class="calibre1"></a>Note</h3><p class="calibre8">The <code class="email">tanh</code> and <code class="email">softmax</code> functions are new activation functions. We will learn more about these activation functions in the next section: <span class="strong"><em class="calibre9">Choosing activation functions for multilayer neural networks</em></span>.</p></div><div class="informalexample"><pre class="programlisting">import tensorflow as tf

n_features = X_train_centered.shape[1]
n_classes = 10
random_seed = 123
np.random.seed(random_seed)

g = tf.Graph()
with g.as_default():
    tf.set_random_seed(random_seed)
    tf_x = tf.placeholder(dtype=tf.float32,
                       shape=(None, n_features),
                       name='tf_x')

    tf_y = tf.placeholder(dtype=tf.int32,
                        shape=None, name='tf_y')
    y_onehot = tf.one_hot(indices=tf_y, depth=n_classes)

    h1 = tf.layers.dense(inputs=tf_x, units=50,
                         activation=tf.tanh,
                         name='layer1')

    h2 = tf.layers.dense(inputs=h1, units=50,
                         activation=tf.tanh,
                         name='layer2')

    logits = tf.layers.dense(inputs=h2,
                             units=10,
                             activation=None,
                             name='layer3')

    predictions = {
        'classes' : tf.argmax(logits, axis=1,
                              name='predicted_classes'),
        'probabilities' : tf.nn.softmax(logits,
                              name='softmax_tensor')
    }</pre></div><p class="calibre8">Next, we<a id="calibre_link-2251" class="calibre1"></a> define the cost functions<a id="calibre_link-2252" class="calibre1"></a> and add an operator for initializing the model variables as well as an optimization operator:</p><div class="informalexample"><pre class="programlisting">## define cost function and optimizer:
with g.as_default():
    cost = tf.losses.softmax_cross_entropy(
            onehot_labels=y_onehot, logits=logits)

    optimizer = tf.train.GradientDescentOptimizer(
            learning_rate=0.001)

    train_op = optimizer.minimize(
            loss=cost)

    init_op = tf.global_variables_initializer()</pre></div><p class="calibre8">Before we start training the network, we need a way to generate batches of data. For this, we implement the following function that returns a generator:</p><div class="informalexample"><pre class="programlisting">def create_batch_generator(X, y, batch_size=128, shuffle=False):
    X_copy = np.array(X)
    y_copy = np.array(y)
    
    if shuffle:
        data = np.column_stack((X_copy, y_copy))
        np.random.shuffle(data)
        X_copy = data[:, :-1]
        y_copy = data[:, -1].astype(int)
    
    for i in range(0, X.shape[0], batch_size):
        yield (X_copy[i:i+batch_size, :], y_copy[i:i+batch_size])</pre></div><p class="calibre8">Next, we can create a <a id="calibre_link-2253" class="calibre1"></a>new TensorFlow <a id="calibre_link-2254" class="calibre1"></a>session, initialize all the variables in our network, and train it. We also display the average training loss after each epoch monitors the learning process later:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## create a session to launch the graph
&gt;&gt;&gt; sess =  tf.Session(graph=g)
&gt;&gt;&gt; ## run the variable initialization operator
&gt;&gt;&gt; sess.run(init_op)
&gt;&gt;&gt;
&gt;&gt;&gt; ## 50 epochs of training:
&gt;&gt;&gt; for epoch in range(50):
...     training_costs = []
...     batch_generator = create_batch_generator(
...             X_train_centered, y_train,
...             batch_size=64, shuffle=True)
...     for batch_X, batch_y in batch_generator:
...         ## prepare a dict to feed data to our network:
...         feed = {tf_x:batch_X, tf_y:batch_y}
...         _, batch_cost = sess.run([train_op, cost], feed_dict=feed)
...         training_costs.append(batch_cost)
...     print(' -- Epoch %2d  '
...           'Avg. Training Loss: %.4f' % (
...               epoch+1, np.mean(training_costs)
...     ))


 -- Epoch  1  Avg. Training Loss: 1.5573
 -- Epoch  2  Avg. Training Loss: 1.2532
 -- Epoch  3  Avg. Training Loss: 1.0854
 -- Epoch  4  Avg. Training Loss: 0.9738

 [â¦]
 -- Epoch 49  Avg. Training Loss: 0.3527
 -- Epoch 50  Avg. Training Loss: 0.3498</pre></div><p class="calibre8">The training<a id="calibre_link-2255" class="calibre1"></a> process may take a <a id="calibre_link-2256" class="calibre1"></a>couple of minutes. Finally, we can use the trained model to do predictions on the test dataset:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## do prediction on the test set:
&gt;&gt;&gt; feed = {tf_x : X_test_centered}
&gt;&gt;&gt; y_pred = sess.run(predictions['classes'],
...                   feed_dict=feed)
&gt;&gt;&gt;
&gt;&gt;&gt; print('Test Accuracy: %.2f%%' % (
...       100*np.sum(y_pred == y_test)/y_test.shape[0]))

Test Accuracy: 93.89%</pre></div><p class="calibre8">We can see that by leveraging high-level APIs, we can quickly build a model and test it. Therefore, a high-level API is very useful for prototyping our ideas and quickly checking the results.</p><p class="calibre8">Next, we will develop a similar classification model for MNIST using Keras, which is another high-level TensorFlow API.</p></div></div></div>

<div id="calibre_link-485" class="calibre">
<div class="book" title="Training neural networks efficiently with high-level TensorFlow APIs">
<div class="book" title="Developing a multilayer neural network with Keras"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2257"><a id="calibre_link-391" class="calibre1"></a>Developing a multilayer neural network with Keras</h2></div></div></div><p class="calibre8">The development of <a id="calibre_link-2258" class="calibre1"></a>Keras started in the early months <a id="calibre_link-2259" class="calibre1"></a>of 2015. As of today, it has evolved into one of the most popular and widely used libraries that is built on top of Theano and TensorFlow.</p><p class="calibre8">Similar to TensorFlow, the Keras allows us to utilize our GPUs to accelerate neural network training. One of its prominent features is that it has a very intuitive and user-friendly API, which allows us to implement neural networks in only a few lines of code.</p><p class="calibre8">Keras was first released as a standalone API that could leverage Theano as a backend, and the support for TensorFlow was added later. Keras is also integrated into TensorFlow from version 1.1.0. Therefore, if you have TensorFlow version 1.1.0, no more installation is needed for Keras. For more information about Keras, visit the<a id="calibre_link-2260" class="calibre1"></a> official website at <a class="calibre1" href="http://keras.io">http://keras.io</a>.</p><p class="calibre8">Currently, Keras is part of the <code class="email">contrib</code> module (which contains packages developed by contributors to TensorFlow and is considered experimental code). In future releases of TensorFlow, it may be moved to become a separate <a id="calibre_link-2261" class="calibre1"></a>module in the TensorFlow main API. For more information, visit the documentation on the TensorFlow website at <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/contrib/keras">https://www.tensorflow.org/api_docs/python/tf/contrib/keras</a>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2262" class="calibre1"></a>Note</h3><p class="calibre8">Note that you may have to change the code from <code class="email">import tensorflow.contrib.keras as keras</code> to <code class="email">import tensorflow.keras as keras</code> in future versions of TensorFlow in the following code examples.</p></div><p class="calibre8">On the following pages, we will walk through the code examples for using Keras step by step. Using the same functions described in the previous section, we need to load the data as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train, y_train = load_mnist('mnist/', kind='train')
&gt;&gt;&gt; print('Rows: %d,  Columns: %d' %(X_train.shape[0],
...                                  X_train.shape[1]))
&gt;&gt;&gt; X_test, y_test = load_mnist('mnist/', kind='t10k')
&gt;&gt;&gt; print('Rows: %d,  Columns: %d' %(X_test.shape[0],
...                                  X_test.shape[1]))
Rows: 10000,  Columns: 784
&gt;&gt;&gt;
&gt;&gt;&gt; ## mean centering and normalization:
&gt;&gt;&gt; mean_vals = np.mean(X_train, axis=0)
&gt;&gt;&gt; std_val = np.std(X_train)
&gt;&gt;&gt;
&gt;&gt;&gt; X_train_centered = (X_train - mean_vals)/std_val
&gt;&gt;&gt; X_test_centered = (X_test - mean_vals)/std_val
&gt;&gt;&gt;
&gt;&gt;&gt; del X_train, X_test
&gt;&gt;&gt;
&gt;&gt;&gt; print(X_train_centered.shape, y_train.shape)
(60000, 784) (60000,)
&gt;&gt;&gt; print(X_test_centered.shape, y_test.shape)
(10000, 784) (10000,)</pre></div><p class="calibre8">First, let's set the random seed for NumPy and TensorFlow so that we get consistent results:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import tensorflow.contrib.keras as keras

&gt;&gt;&gt; np.random.seed(123)
&gt;&gt;&gt; tf.set_random_seed(123)</pre></div><p class="calibre8">To continue with the preparation of the training data, we need to convert the class labels (integers 0-9) into the one-hot format. Fortunately, Keras provides a convenient tool for this:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_train_onehot = keras.utils.to_categorical(y_train)
&gt;&gt;&gt;
&gt;&gt;&gt; print('First 3 labels: ', y_train[:3])
First 3 labels:  [5 0 4]
&gt;&gt;&gt; print('\nFirst 3 labels (one-hot):\n', y_train_onehot[:3])
First 3 labels (one-hot):
 [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]</pre></div><p class="calibre8">Now, we can get to the <a id="calibre_link-2263" class="calibre1"></a>interesting part and implement <a id="calibre_link-2264" class="calibre1"></a>a neural network. Briefly, we will have three layers, where the first two layers each have 50 hidden units with the <code class="email">tanh</code> activation function and the last layer has 10 layers for the 10 class labels and uses <code class="email">softmax</code> to give the probability of each class. Keras makes these tasks very simple, as you can see in the following code implementation:</p><div class="informalexample"><pre class="programlisting">model = keras.models.Sequential()

model.add(
    keras.layers.Dense(
        units=50,
        input_dim=X_train_centered.shape[1],
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        activation='tanh'))

model.add(
    keras.layers.Dense(
        units=50,
        input_dim=50,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        activation='tanh'))

model.add(
    keras.layers.Dense(
        units=y_train_onehot.shape[1],
        input_dim=50,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        activation='softmax'))


sgd_optimizer = keras.optimizers.SGD(
        lr=0.001, decay=1e-7, momentum=.9)

model.compile(optimizer=sgd_optimizer,
              loss='categorical_crossentropy')</pre></div><p class="calibre8">First, we initialize a new <a id="calibre_link-2265" class="calibre1"></a>model using the <code class="email">Sequential</code> class to<a id="calibre_link-2266" class="calibre1"></a> implement a feedforward neural network. Then, we can add as many layers to it as we like. However, since the first layer that we add is the input layer, we have to make sure that the <code class="email">input_dim</code> attribute matches the number of features (columns) in the training set (784 features or pixels in the neural network implementation).</p><p class="calibre8">Also, we have to make sure that the number of output units (<code class="email">units</code>) and input units (<code class="email">input_dim</code>) of two consecutive layers match. In the preceding example, we added two hidden layers with 50 hidden units plus one bias unit each. The number of units in the output layer should be equal to the number of unique class labels&mdash;the number of columns in the one-hot-encoded class label array.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2267" class="calibre1"></a>Note</h3><p class="calibre8">Note that we used a new initialization algorithm for weight matrices by setting <code class="email">kernel_initializer= 'glorot_uniform'</code>. Glorot initialization (also known as Xavier initialization) is a more robust way of initialization for deep neural networks (<span class="strong"><em class="calibre9">Understanding the difficulty of training deep feedforward neural networks</em></span>, <span class="strong"><em class="calibre9">Xavier Glorot</em></span> and <span class="strong"><em class="calibre9">Yoshua Bengio</em></span>, in <span class="strong"><em class="calibre9">Artificial Intelligence and Statistics</em></span>, volume 9, pages: 249-256. <span class="strong"><em class="calibre9">2010</em></span>). The biases are initialized to zero, which is more common, and in fact the default setting in Keras. We will discuss this weight initialization scheme in more detail in <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper - The Mechanics of TensorFlow</em></span>.</p></div><p class="calibre8">Before we can compile our model, we also have to define an optimizer. In the preceding example, we chose a stochastic gradient descent optimization, which we are already familiar with from previous chapters. Furthermore, we can set values for the weight decay constant and momentum learning to adjust the learning rate at each epoch as discussed in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artifiial Neural Network from Scratch</em></span>. Lastly, we set the cost (or loss) function to <code class="email">categorical_crossentropy</code>.</p><p class="calibre8">The binary cross-entropy is just a technical term for the cost function in the logistic regression, and the categorical cross-entropy is its generalization for multiclass predictions via softmax, which we will cover in the section Estimating class probabilities in multiclass classification via the softmax function later in this chapter.</p><p class="calibre8">After compiling the<a id="calibre_link-2268" class="calibre1"></a> model, we can now train it by calling<a id="calibre_link-2269" class="calibre1"></a> the <code class="email">fit</code> method. Here, we are using mini-batch stochastic gradient with a batch size of 64 training samples per batch. We train the MLP over 50 epochs, and we can follow the optimization of the cost function during training by setting <code class="email">verbose=1</code>.</p><p class="calibre8">The <code class="email">validation_split</code> parameter is especially handy since it will reserve 10 percent of the training data (here, 6,000 samples) for validation after each epoch so that we can monitor whether the model is overfitting during training:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; history = model.fit(X_train_centered, y_train_onehot,
...                     batch_size=64, epochs=50,
...                     verbose=1,
...                     validation_split=0.1)

Train on 54000 samples, validate on 6000 samples
Epoch 1/50
54000/54000 [==============================] - 3s - loss: 0.7247 - val_loss: 0.3616
Epoch 2/50
54000/54000 [==============================] - 3s - loss: 0.3718 - val_loss: 0.2815
Epoch 3/50
54000/54000 [==============================] - 3s - loss: 0.3087 - val_loss: 0.2447

[â¦]
Epoch 50/50
54000/54000 [==============================] - 3s - loss: 0.0485 - val_loss: 0.1174</pre></div><p class="calibre8">Printing the value of the cost function is extremely useful during training. This is because we can quickly spot whether the cost is decreasing during training and stop the algorithm earlier, if otherwise, to tune the hyperparameter values.</p><p class="calibre8">To predict the class labels, we can then use the <code class="email">predict_classes</code> method to return the class labels directly as integers:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_train_pred = model.predict_classes(X_train_centered, verbose=0)
&gt;&gt;&gt; print('First 3 predictions: ', y_train_pred[:3])
First 3 predictions:  [5 0 4]</pre></div><p class="calibre8">Finally, let's print the model accuracy on training and test sets:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_train_pred = model.predict_classes(X_train_centered,
...                                      verbose=0)
&gt;&gt;&gt; correct_preds = np.sum(y_train == y_train_pred, axis=0)
&gt;&gt;&gt; train_acc = correct_preds / y_train.shape[0]
&gt;&gt;&gt;
&gt;&gt;&gt; print('First 3 predictions: ', y_train_pred[:3])
First 3 predictions:  [5 0 4]
&gt;&gt;&gt;
&gt;&gt;&gt; print('Training accuracy: %.2f%%' % (train_acc * 100))
Training accuracy: 98.88%
&gt;&gt;&gt;
&gt;&gt;&gt; y_test_pred = model.predict_classes(X_test_centered,
...                                     verbose=0)
&gt;&gt;&gt; correct_preds = np.sum(y_test == y_test_pred, axis=0)
&gt;&gt;&gt; test_acc = correct_preds / y_test.shape[0]
&gt;&gt;&gt; print('Test accuracy: %.2f%%' % (test_acc * 100))
Test accuracy: 96.04%</pre></div><p class="calibre8">Note that this is<a id="calibre_link-2270" class="calibre1"></a> just a very simple neural network <a id="calibre_link-2271" class="calibre1"></a>without optimized tuning parameters. If you are interested in playing more with Keras, feel free to further tweak the learning rate, momentum, weight decay, and number of hidden units.</p></div></div></div>

<div id="calibre_link-496" class="calibre">
<div id="calibre_link-2272" class="calibre10"></div><div class="book" title="Choosing activation functions for multilayer networks"><div class="book" id="calibre_link-3"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2273"><a id="calibre_link-2274" class="calibre1"></a>Choosing activation functions for multilayer networks</h1></div></div></div><p class="calibre8">For simplicity, we have<a id="calibre_link-2275" class="calibre1"></a> only discussed the sigmoid <a id="calibre_link-2276" class="calibre1"></a>activation function in the context of multilayer feedforward neural networks so far; we used it in the hidden layer as well as the output layer in the multilayer perceptron implementation in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artifiial Neural Network from Scratch</em></span>.</p><p class="calibre8">Although we referred to this activation function as a sigmoid function&mdash;as it is commonly called in literature&mdash;the more precise definition would be a <span class="strong"><em class="calibre9">logistic function</em></span> or <span class="strong"><em class="calibre9">negative log-likelihood function</em></span>. In the following subsections, you will learn more about alternative sigmoidal functions that are useful for implementing multilayer neural networks.</p><p class="calibre8">Technically, we can <a id="calibre_link-2277" class="calibre1"></a>use any function as an activation<a id="calibre_link-2278" class="calibre1"></a> function in multilayer neural networks as long as it is differentiable. We can even use linear activation functions, such as in Adaline (<a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>). However, in practice, it would not be very useful to use linear activation functions for both hidden and output layers since we want to introduce nonlinearity in a typical artificial neural network to be able to tackle complex problems. The sum of linear functions yields a linear function after all.</p><p class="calibre8">The logistic activation function that we used in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, probably mimics the concept of a neuron in a brain most closely&mdash;we can think of it as the probability of whether a neuron fires or not.</p><p class="calibre8">However, logistic activation functions can be problematic if we have highly negative input since the output of the sigmoid function would be close to zero in this case. If the sigmoid function returns output that are close to zero, the neural network would learn very slowly and it becomes more likely that it gets trapped in the local minima during training. This is why people often prefer a hyperbolic tangent as an activation function in hidden layers.</p><p class="calibre8">Before we discuss what a hyperbolic tangent looks like, let's briefly recapitulate some of the basics of the logistic function and look at a generalization that makes it more useful for multilabel classification problems.</p></div></div>

<div id="calibre_link-502" class="calibre">
<div class="book" title="Choosing activation functions for multilayer networks">
<div class="book" title="Logistic function recap"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2279"><a id="calibre_link-392" class="calibre1"></a>Logistic function recap</h2></div></div></div><p class="calibre8">As we mentioned in the<a id="calibre_link-2280" class="calibre1"></a> introduction to this section, the logistic function, often just called the sigmoid function, is in fact a special case of a sigmoid function. Recall from the section on logistic regression in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, that we can use a logistic function to model the probability that sample <span class="strong"><em class="calibre9">x</em></span> belongs to the positive class (class 1) in a binary classification task. The given net input <span class="strong"><em class="calibre9">z</em></span> is shown in the following equation:</p><div class="mediaobject"><img src="images/00959.jpeg" alt="Logistic function recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The logistic function will compute the following:</p><div class="mediaobject"><img src="images/00154.jpeg" alt="Logistic function recap" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that <span class="strong"><img src="images/00169.jpeg" alt="Logistic function recap" class="calibre14" /></span> is the bias unit (<span class="strong"><em class="calibre9">y</em></span>-axis intercept, which means <span class="strong"><img src="images/00178.jpeg" alt="Logistic function recap" class="calibre14" /></span>). To provide a more concrete example, let's assume a model for a two-dimensional data point <span class="strong"><em class="calibre9">x</em></span> and a model with the following weight coefficients assigned to the <span class="strong"><em class="calibre9">w</em></span> vector:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; X = np.array([1, 1.4, 2.5]) ## first value must be 1
&gt;&gt;&gt; w = np.array([0.4, 0.3, 0.5])

&gt;&gt;&gt; def net_input(X, w):
...     return np.dot(X, w)
...
&gt;&gt;&gt; def logistic(z):
...     return 1.0 / (1.0 + np.exp(-z))
...
&gt;&gt;&gt; def logistic_activation(X, w):
...     z = net_input(X, w)
...     return logistic(z)
...
&gt;&gt;&gt; print('P(y=1|x) = %.3f' % logistic_activation(X, w))
P(y=1|x) = 0.888</pre></div><p class="calibre8">If we calculate the net <a id="calibre_link-2281" class="calibre1"></a>input and use it to activate a logistic neuron with those particular feature values and weight coefficients, we get a value of <code class="email">0.888</code>, which we can interpret as 88.8 percent probability that this particular sample <span class="strong"><em class="calibre9">x</em></span> belongs to the positive class.</p><p class="calibre8">In <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, we used the one-hot-encoding technique to compute the values in the output layer consisting of multiple logistic activation units. However, as we will demonstrate with the following code example, an output layer consisting of multiple logistic activation units does not produce meaningful, interpretable probability values:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; # W : array with shape = (n_output_units, n_hidden_units+1)
... #     note that the first column are the bias units
...
&gt;&gt;&gt; W = np.array([[1.1, 1.2, 0.8, 0.4],
...               [0.2, 0.4, 1.0, 0.2],
...               [0.6, 1.5, 1.2, 0.7]])
&gt;&gt;&gt;
&gt;&gt;&gt; # A : data array with shape = (n_hidden_units + 1, n_samples)
... #     note that the first column of this array must be 1
...
&gt;&gt;&gt; A = np.array([[1, 0.1, 0.4, 0.6]])
&gt;&gt;&gt;
&gt;&gt;&gt; Z = np.dot(W, A[0])
&gt;&gt;&gt; y_probas = logistic(Z)
&gt;&gt;&gt; print('Net Input: \n', Z)
Net Input:
 [ 1.78  0.76  1.65]
&gt;&gt;&gt; print('Output Units:\n', y_probas)
Output Units:
 [ 0.85569687  0.68135373  0.83889105]</pre></div><p class="calibre8">As we can see in the <a id="calibre_link-2282" class="calibre1"></a>output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum up to 1. However, this is in fact not a big concern if we only use our model to predict the class labels, not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; y_class = np.argmax(Z, axis=0)
&gt;&gt;&gt; print('Predicted class label: %d' % y_class)
Predicted class label: 0</pre></div><p class="calibre8">In certain contexts, it can be useful to compute meaningful class probabilities for multiclass predictions. In the next section, we will take a look at a generalization of the logistic function, the <code class="email">softmax</code> function, which can help us with this task.</p></div></div></div>

<div id="calibre_link-508" class="calibre">
<div class="book" title="Choosing activation functions for multilayer networks">
<div class="book" title="Estimating class probabilities in multiclass classification via the softmax function"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2283"><a id="calibre_link-393" class="calibre1"></a>Estimating class probabilities in multiclass classification via the softmax function</h2></div></div></div><p class="calibre8">In the previous section, we <a id="calibre_link-2284" class="calibre1"></a>saw how we could obtain a class label using the <code class="email">argmax</code> function. The <code class="email">softmax</code> function is in fact a soft form of the <code class="email">argmax</code> function; instead of giving a single class index, it <a id="calibre_link-2285" class="calibre1"></a>provides <a id="calibre_link-2286" class="calibre1"></a>the probability of each class. Therefore, it allows us to compute meaningful class probabilities in multiclass settings (multinomial logistic regression).</p><p class="calibre8">In <code class="email">softmax</code>, the probability of a particular sample with net input <span class="strong"><em class="calibre9">z</em></span> belonging to the <span class="strong"><em class="calibre9">i</em></span>th class can be computed with a normalization term in the denominator, that is, the sum of all <span class="strong"><em class="calibre9">M</em></span> linear functions:</p><div class="mediaobject"><img src="images/00211.jpeg" alt="Estimating class probabilities in multiclass classification via the softmax function" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To see <code class="email">softmax</code> in action, let's code it up in Python:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def softmax(z):
...     return np.exp(z) / np.sum(np.exp(z))
...
&gt;&gt;&gt; y_probas = softmax(Z)
&gt;&gt;&gt; print('Probabilities:\n', y_probas)
Probabilities:
 [ 0.44668973&nbsp; 0.16107406&nbsp; 0.39223621]

&gt;&gt;&gt; np.sum(y_probas)
1.0</pre></div><p class="calibre8">As we can see, the <a id="calibre_link-2287" class="calibre1"></a>predicted <a id="calibre_link-2288" class="calibre1"></a>class probabilities <a id="calibre_link-2289" class="calibre1"></a>now sum up to 1, as we would expect. It is also notable that the predicted class label is the same as when we applied the <code class="email">argmax</code> function to the logistic output. Intuitively, it may help to think of the <code class="email">softmax</code> function as a <span class="strong"><em class="calibre9">normalized</em></span> output that is useful to obtain meaningful class-membership predictions in multiclass settings.</p></div></div></div>

<div id="calibre_link-24" class="calibre">
<div class="book" title="Choosing activation functions for multilayer networks">
<div class="book" title="Broadening the output spectrum using a hyperbolic tangent"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2290"><a id="calibre_link-394" class="calibre1"></a>Broadening the output spectrum using a hyperbolic tangent</h2></div></div></div><p class="calibre8">Another sigmoid function that is often used in the hidden layers of artificial neural networks is<a id="calibre_link-2291" class="calibre1"></a> the <span class="strong"><strong class="calibre2">hyperbolic tangent</strong></span> (commonly known as <span class="strong"><strong class="calibre2">tanh</strong></span>), which <a id="calibre_link-2292" class="calibre1"></a>can be interpreted as a<a id="calibre_link-2293" class="calibre1"></a> rescaled version of the logistic function:</p><div class="mediaobject"><img src="images/00201.jpeg" alt="Broadening the output spectrum using a hyperbolic tangent" class="calibre11" /></div><p class="calibre12"> </p><div class="mediaobject"><img src="images/00215.jpeg" alt="Broadening the output spectrum using a hyperbolic tangent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The advantage of the hyperbolic tangent over the logistic function is that it has a broader output spectrum and ranges in the open interval (-1, 1), which can improve the convergence of the back propagation algorithm (<span class="strong"><em class="calibre9">Neural Networks for Pattern Recognition</em></span>, <span class="strong"><em class="calibre9">C. M. Bishop</em></span>, <span class="strong"><em class="calibre9">Oxford University Press</em></span>, pages: 500-501, <span class="strong"><em class="calibre9">1995</em></span>).</p><p class="calibre8">In contrast, the logistic function returns an output signal that ranges in the open interval (0, 1). For an intuitive comparison of the logistic function and the hyperbolic tangent, let's plot the two sigmoid functions:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt

&gt;&gt;&gt; def tanh(z):
...     e_p = np.exp(z)
...     e_m = np.exp(-z)
...     return (e_p - e_m) / (e_p + e_m)

&gt;&gt;&gt; z = np.arange(-5, 5, 0.005)
&gt;&gt;&gt; log_act = logistic(z)
&gt;&gt;&gt; tanh_act = tanh(z)
&gt;&gt;&gt; plt.ylim([-1.5, 1.5])
&gt;&gt;&gt; plt.xlabel('net input $z$')
&gt;&gt;&gt; plt.ylabel('activation $\phi(z)$')
&gt;&gt;&gt; plt.axhline(1, color='black', linestyle=':')
&gt;&gt;&gt; plt.axhline(0.5, color='black', linestyle=':')
&gt;&gt;&gt; plt.axhline(0, color='black', linestyle=':')
&gt;&gt;&gt; plt.axhline(-0.5, color='black', linestyle=':')
&gt;&gt;&gt; plt.axhline(-1, color='black', linestyle=':')
&gt;&gt;&gt; plt.plot(z, tanh_act,
...          linewidth=3, linestyle='--',
...          label='tanh')
&gt;&gt;&gt; plt.plot(z, log_act,
...          linewidth=3,
...          label='logistic')
&gt;&gt;&gt; plt.legend(loc='lower right')
&gt;&gt;&gt; plt.tight_layout()
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">As we can see, the <a id="calibre_link-2294" class="calibre1"></a>shapes of the two <a id="calibre_link-2295" class="calibre1"></a>sigmoidal curves look very similar; however, the <code class="email">tanh</code> function has <span class="strong"><img src="images/00226.jpeg" alt="Broadening the output spectrum using a hyperbolic tangent" class="calibre14" /></span> larger output space than the <code class="email">logistic</code> function:</p><div class="mediaobject"><img src="images/00241.jpeg" alt="Broadening the output spectrum using a hyperbolic tangent" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that we<a id="calibre_link-2296" class="calibre1"></a> implemented the <code class="email">logistic</code> and <code class="email">tanh</code> functions verbosely for the purpose of illustration. In practice, we can use NumPy's <code class="email">tanh</code> function to achieve the same results:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; tanh_act = np.tanh(z)</pre></div><p class="calibre8">In addition, the logistic <a id="calibre_link-2297" class="calibre1"></a>function is available in SciPy's special module:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from scipy.special import expit
&gt;&gt;&gt; log_act = expit(z)</pre></div></div></div></div>

<div id="calibre_link-27" class="calibre">
<div class="book" title="Choosing activation functions for multilayer networks">
<div class="book" title="Rectified linear unit activation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2298"><a id="calibre_link-395" class="calibre1"></a>Rectified linear unit activation</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Rectified Linear Unit</strong></span> (<span class="strong"><strong class="calibre2">ReLU</strong></span>) is<a id="calibre_link-2299" class="calibre1"></a> another activation function that is often used in deep neural networks. Before we understand ReLU, we should step back and understand the vanishing gradient problem of tanh and logistic activations.</p><p class="calibre8">To understand this problem, let's assume that we initially have the net input <span class="strong"><img src="images/00250.jpeg" alt="Rectified linear unit activation" class="calibre14" /></span>, which changes to <span class="strong"><img src="images/00264.jpeg" alt="Rectified linear unit activation" class="calibre14" /></span>. Computing the tanh activation, we get <span class="strong"><img src="images/00579.jpeg" alt="Rectified linear unit activation" class="calibre14" /></span> and <span class="strong"><img src="images/00637.jpeg" alt="Rectified linear unit activation" class="calibre14" /></span>, which shows no change in the output.</p><p class="calibre8">This means the derivative of activations with respect to net input diminishes as <span class="strong"><em class="calibre9">z</em></span> becomes large. As a result, learning weights during the training phase become very slow because the gradient terms may be very close to zero. ReLU activation addresses this issue. Mathematically, ReLU is defined as follows:</p><div class="mediaobject"><img src="images/00289.jpeg" alt="Rectified linear unit activation" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">ReLU is still a <a id="calibre_link-2300" class="calibre1"></a>nonlinear function that is good for learning complex functions with neural networks. Besides this, the derivative of ReLU, with respect to its input, is always 1 for positive input values. Therefore, it solves the problem of vanishing gradients, making it suitable for deep neural networks. We will use the ReLU activation function in the next chapter as an activation function for multilayer convolutional neural networks.</p><p class="calibre8">Now that we know more about the different activation functions that are commonly used in artificial neural networks, let's conclude this section with an overview of the different activation functions that we encountered in this book:</p><div class="mediaobject"><img src="images/00298.jpeg" alt="Rectified linear unit activation" class="calibre11" /></div><p class="calibre12"> </p></div></div></div>

<div id="calibre_link-22" class="calibre"><div class="book" title="Summary" id="calibre_link-396"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2301"><a id="calibre_link-2302" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, you learned how to use TensorFlow, an open source library for numerical computations with a special focus on deep learning. While TensorFlow is more inconvenient to use compared to NumPy, due to its additional complexity to support GPUs, it allows us to define and train large, multilayer neural networks very efficiently.</p><p class="calibre8">Also, you learned about the TensorFlow API to build complex machine learning and neural network models and run them efficiently. First, we explored programming in the low-level TensorFlow API. Implementing models at this level may be tedious when we have to program at the level of matrix-vector multiplications and define every detail of each operation. However, the advantage is that this allows us as developers to combine such basic operations and build more complex models. Furthermore, we discussed how TensorFlow allows us to utilize the GPUs for training and testing big neural networks to speed up the computations. Without the use of GPUs, training some networks would typically need months of computation!</p><p class="calibre8">We then explored two high-level APIs that make building neural network models a lot easier compared to the low-level API. Specifically, we used TensorFlow Layers and Keras to build the multilayer neural network and learned how to build models using those APIs.</p><p class="calibre8">Finally, you learned about different activation functions and understood their behaviors and applications. Specifically, in this chapter, we saw tanh, softmax, and ReLU. In <span class="strong"><em class="calibre9">Chapter 12</em></span>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>, we started with implementing a simple <span class="strong"><strong class="calibre2">Multilayer Perceptron</strong></span> (<span class="strong"><strong class="calibre2">MLP</strong></span>) to classify a handwritten image in the MNIST dataset. While the low-level implementation from scratch was helpful to illustrate the core concepts of a multilayer neural network, such as the forward pass and backpropagation, training neural networks using NumPy is very inefficient and impractical for large networks.</p><p class="calibre8">In the next chapter, we'll continue our journey and dive deeper into TensorFlow, and we'll find ourselves working with graph and session objects. Along the way, we'll learn many new concepts, such as placeholders, variables, and saving and restoring models in TensorFlow.</p></div></div>

<div id="calibre_link-482" class="calibre">
<div id="calibre_link-2303" class="calibre10"></div><div class="book" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" id="calibre_link-43"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2304"><a id="calibre_link-2305" class="calibre1"></a>Chapter&nbsp;14.&nbsp;Going Deeper &ndash; The Mechanics of TensorFlow</h1></div></div></div><p class="calibre8">In <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, we trained a multilayer perceptron to classify MNIST digits, using various aspects of the TensorFlow Python API. That was a great way to dive us straight into some hands-on experience with TensorFlow neural network training and machine learning.</p><p class="calibre8">In this chapter, we'll now shift our focus squarely on to TensorFlow itself, and explore in detail the impressive mechanics and features that TensorFlow offers:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Key features and advantages of TensorFlow</li><li class="listitem">TensorFlow ranks and tensors</li><li class="listitem">Understanding and working with TensorFlow graphs</li><li class="listitem">Working with TensorFlow variables</li><li class="listitem">TensorFlow operations with different scopes</li><li class="listitem">Common tensor transformations: working with ranks, shapes, and types</li><li class="listitem">Transforming tensors as multidimensional arrays</li><li class="listitem">Saving and restoring a model in TensorFlow</li><li class="listitem">Visualizing neural network graphs with TensorBoard</li></ul></div><p class="calibre8">We'll stay hands-on in this chapter, of course, and implement graphs throughout the chapter to explore the main TensorFlow features and concepts. Along the way, we'll also revisit a regression model, explore neural network graph visualization with TensorBoard, and suggest some ways that you could explore visualizing more of the graphs that you'll make through this chapter.</p></div></div>

<div id="calibre_link-520" class="calibre">
<div class="book" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" id="calibre_link-2306">
<div class="book" title="Key features of TensorFlow"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2307"><a id="calibre_link-397" class="calibre1"></a>Key features of TensorFlow</h1></div></div></div><p class="calibre8">TensorFlow <a id="calibre_link-2308" class="calibre1"></a>gives us a scalable, multiplatform <a id="calibre_link-2309" class="calibre1"></a>programming interface for implementing and running machine learning algorithms. The TensorFlow API has been relatively stable and mature since its 1.0 release in 2017. There are other deep learning libraries available, but they are still very experimental by comparison.</p><p class="calibre8">A key feature of TensorFlow that we already noted in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, is its ability to work with single or multiple GPUs. This allows users to train machine learning models very efficiently on large-scale systems.</p><p class="calibre8">TensorFlow has strong growth drivers. Its development is funded and supported by Google, and so a large team of software engineers work on improvements continuously. TensorFlow also has strong support from open source developers, who avidly contribute and provide user feedback. This has made the TensorFlow library more useful to both academic researchers and developers in their industry. A further consequence of these factors is that TensorFlow has extensive documentation and tutorials to help new users.</p><p class="calibre8">Last but not least among these key features, TensorFlow supports mobile deployment, which makes it a very suitable tool for production.</p></div></div></div>

<div id="calibre_link-523" class="calibre">
<div id="calibre_link-2310" class="calibre10"></div><div class="book" title="TensorFlow ranks and tensors" id="calibre_link-398"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2311"><a id="calibre_link-2312" class="calibre1"></a>TensorFlow ranks and tensors</h1></div></div></div><p class="calibre8">The TensorFlow <a id="calibre_link-2313" class="calibre1"></a>library lets users define <a id="calibre_link-2314" class="calibre1"></a>operations and functions over tensors as computational graphs. Tensors are a generalizable mathematical notation for multidimensional arrays holding data values, where the dimensionality of a tensor is typically referred to as its <span class="strong"><strong class="calibre2">rank</strong></span>.</p><p class="calibre8">We've worked mostly, so far, with tensors of rank zero to two. For instance, a scalar, a single number such as an integer or float, is a tensor of rank 0. A vector is a tensor of rank 1, and a matrix is a tensor of rank 2. But, it doesn't stop here. The tensor notation can be generalized to higher dimensions&mdash;as we'll see in the next chapter, when we work with an input of rank 3 and weight tensors of rank 4 to support images with multiple color channels.</p><p class="calibre8">To make the concept of a <span class="strong"><strong class="calibre2">tensor</strong></span> more intuitive, consider the following figure, which represents tensors of ranks 0 and 1 in the first row, and tensors of ranks 2 and 3 in the second row:</p><div class="mediaobject"><img src="images/00821.jpeg" alt="TensorFlow ranks and tensors" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-527" class="calibre">
<div class="book" title="TensorFlow ranks and tensors" id="calibre_link-2315">
<div class="book" title="How to get the rank and shape of a tensor"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2316"><a id="calibre_link-399" class="calibre1"></a>
<span class="strong"><strong class="calibre2">How to get the rank and shape of a tensor</strong></span>
</h2></div></div></div><p class="calibre8">We can use the <code class="email">tf.rank</code> function to <a id="calibre_link-2317" class="calibre1"></a>get the rank<a id="calibre_link-2318" class="calibre1"></a> of a tensor. It is important to note that <code class="email">tf.rank</code> will return a tensor as output, and in order to get the actual value, we will need to evaluate that tensor.</p><p class="calibre8">In addition to the tensor rank, we can also get the shape of a TensorFlow tensor (similar to the shape of a NumPy array). For example, if <code class="email">X</code> is a tensor, we can get its shape using <code class="email">X.get_shape()</code>, which will return an object of a special class called <code class="email">TensorShape</code>.</p><p class="calibre8">We can print the <a id="calibre_link-2319" class="calibre1"></a>shape and use it directly <a id="calibre_link-2320" class="calibre1"></a>for the shape argument when creating other tensors. However, we <span class="strong"><strong class="calibre2">cannot</strong></span> index or slice this object directly. If we want to index or slice different elements of this object, then we can convert it into a Python list, using the <code class="email">as_list</code> method of the tensor class.</p><p class="calibre8">See the following examples on how to use the <code class="email">tf.rank</code> function and the <code class="email">get_shape</code> method of a tensor. The following code example illustrates how to retrieve the rank and shape of the tensor objects in a TensorFlow session:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; ## define the computation graph
&gt;&gt;&gt; with g.as_default():
...     ## define tensors t1, t2, t3
...     t1 = tf.constant(np.pi)
...     t2 = tf.constant([1, 2, 3, 4])
...     t3 = tf.constant([[1, 2], [3, 4]])
...
...     ## get their ranks
...     r1 = tf.rank(t1)
...     r2 = tf.rank(t2)
...     r3 = tf.rank(t3)
...
...     ## get their shapes
...     s1 = t1.get_shape()
...     s2 = t2.get_shape()
...     s3 = t3.get_shape()
...     print('Shapes:', s1, s2, s3)
Shapes: [] (4,) (2, 2)
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     print('Ranks:',
...           r1.eval(),
...           r2.eval(),
...           r3.eval())

Ranks: 0 1 2</pre></div><p class="calibre8">As we can see, the rank of the <code class="email">t1</code> tensor is 0 since it is just a scalar (corresponding to the <code class="email">[]</code> shape). The rank of the <code class="email">t2</code> vector is 1, and since it has four elements, its shape is the one-element tuple <code class="email">(4, )</code>. Lastly, the shape of the 2 Ã 2 matrix <code class="email">t3</code> is 2; thus, its corresponding shape is given by the <code class="email">(2, 2)</code> tuple.</p></div></div></div>

<div id="calibre_link-560" class="calibre"><div class="book" title="Understanding TensorFlow&apos;s computation graphs" id="calibre_link-75"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2321"><a id="calibre_link-2322" class="calibre1"></a>Understanding TensorFlow's computation graphs</h1></div></div></div><p class="calibre8">TensorFlow relies on <a id="calibre_link-2323" class="calibre1"></a>building a <a id="calibre_link-2324" class="calibre1"></a>computation graph at its core, and it uses this computation graph to derive relationships between tensors from the input all the way to the output. Let's say, we have rank 0 (scalar) and tensors <span class="strong"><em class="calibre9">a</em></span>, <span class="strong"><em class="calibre9">b</em></span>, and <span class="strong"><em class="calibre9">c</em></span> and we want to evaluate <span class="strong"><img src="images/00889.jpeg" alt="Understanding TensorFlow&apos;s computation graphs" class="calibre14" /></span>. This evaluation can be represented as a computation graph, as shown in the following figure:</p><div class="mediaobject"><img src="images/00962.jpeg" alt="Understanding TensorFlow&apos;s computation graphs" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As we can see, the computation graph is simply a network of nodes. Each node resembles an operation, which applies a function to its input tensor or tensors and returns zero or more tensors as the output.</p><p class="calibre8">TensorFlow builds this <a id="calibre_link-2325" class="calibre1"></a>computation graph and <a id="calibre_link-2326" class="calibre1"></a>uses it to compute the gradients accordingly. The individual steps for building and compiling such a computation graph in TensorFlow are as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Instantiate a new, empty computation graph.</li><li class="listitem" value="2">Add nodes (tensors and operations) to the computation graph.</li><li class="listitem" value="3">Execute the graph:<div class="book"><ol class="orderedlist1"><li class="listitem" value="1">Start a new session</li><li class="listitem" value="2">Initialize the variables in the graph</li><li class="listitem" value="3">Run the computation graph in this session</li></ol><div class="calibre13"></div></div></li></ol><div class="calibre13"></div></div><p class="calibre8">So let's create a graph for evaluating <span class="strong"><img src="images/00889.jpeg" alt="Understanding TensorFlow&apos;s computation graphs" class="calibre14" /></span>, as shown in the previous figure, where <span class="strong"><em class="calibre9">a</em></span>, <span class="strong"><em class="calibre9">b</em></span>, and <span class="strong"><em class="calibre9">c</em></span> are scalars (single numbers). Here, we define them as TensorFlow constants. A graph can be created by calling <code class="email">tf.Graph()</code>, then nodes can be added to it as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; 
&gt;&gt;&gt; with g.as_default():
...     a = tf.constant(1, name='a')
...     b = tf.constant(2, name='b')
...     c = tf.constant(3, name='c')
...
...     z = 2*(a-b) + c</pre></div><p class="calibre8">In this code, we added nodes to the <code class="email">g</code> graph using <code class="email">with g.as_default()</code>. If we do not explicitly create a graph, there is always a default graph, and therefore, all the nodes are added to the default graph. In this book, we try to avoid working with the default graph for clarity. This approach is especially useful when we are developing code in a Jupyter notebook, as we avoid piling up unwanted nodes in the default graph by accident.</p><p class="calibre8">A TensorFlow <a id="calibre_link-2327" class="calibre1"></a>session is an environment <a id="calibre_link-2328" class="calibre1"></a>in which the operations and tensors of a graph can be executed. A session object is created by calling <code class="email">tf.Session</code> that can receive an existing graph (here, <code class="email">g</code>) as an argument, as in <code class="email">tf.Session(graph=g)</code>; otherwise, it will launch the default graph, which might be empty.</p><p class="calibre8">After launching a graph in a TensorFlow session, we can execute its nodes; that is, evaluating its tensors or executing its operators. Evaluating each individual tensor involves calling its <code class="email">eval</code> method inside the current session. When evaluating a specific tensor in the graph, TensorFlow has to execute all the preceding nodes in the graph until it reaches that particular one. In case there are one or more placeholders, they would need to be fed, as we'll see later in the next section.</p><p class="calibre8">Quite similarly, executing operations can be done using a session's <code class="email">run</code> method. In the previous example, <code class="email">train_op</code> is an operator that does not return any tensor. This operator can be executed as <code class="email">train_op.run()</code>. Furthermore, there is a universal way of running both tensors and operators: <code class="email">tf.Session().run()</code>. Using this method, as we'll see later on as well, multiple tensors and operators can be placed in a list or tuple. As a result, <code class="email">tf.Session().run()</code> will return a list or tuple of the same size.</p><p class="calibre8">Here, we will launch the previous graph in a TensorFlow session and evaluate the tensor <code class="email">z</code> as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     print('2*(a-b)+c =&gt; ', sess.run(z))
2*(a-b)+c =&gt;  1</pre></div><p class="calibre8">Remember that we define tensors and operations in a computation graph context within TensorFlow. A <a id="calibre_link-2329" class="calibre1"></a>TensorFlow session is <a id="calibre_link-2330" class="calibre1"></a>then used to execute the operations in the graph and fetch and evaluate the results.</p><p class="calibre8">In this section, we saw how to define a computation graph, how to add nodes to it, and how to evaluate the tensors in a graph within a TensorFlow session. We'll now take a deeper look into the different types of nodes that can appear in a computation graph, including placeholders and variables. Along the way, we'll see some other operators that do not return a tensor as the output.</p></div></div>

<div id="calibre_link-590" class="calibre">
<div id="calibre_link-2331" class="calibre10"></div><div class="book" title="Placeholders in TensorFlow" id="calibre_link-400"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2332"><a id="calibre_link-2333" class="calibre1"></a>Placeholders in TensorFlow</h1></div></div></div><p class="calibre8">TensorFlow has special <a id="calibre_link-2334" class="calibre1"></a>mechanisms for feeding data. One of these mechanisms is the use of placeholders, which are predefined tensors with specific types and shapes.</p><p class="calibre8">These tensors are added to the <a id="calibre_link-2335" class="calibre1"></a>computation graph using the <code class="email">tf.placeholder</code> function, and they do not contain any data. However, upon the execution of certain nodes in the graph, these placeholders need to be fed with data arrays.</p><p class="calibre8">In the following sections, we'll see how to define placeholders in a graph and how to feed them with data values upon execution.</p></div></div>

<div id="calibre_link-535" class="calibre">
<div class="book" title="Placeholders in TensorFlow" id="calibre_link-2336">
<div class="book" title="Defining placeholders"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2337"><a id="calibre_link-401" class="calibre1"></a>Defining placeholders</h2></div></div></div><p class="calibre8">As you now know, placeholders <a id="calibre_link-2338" class="calibre1"></a>are defined using the <code class="email">tf.placeholder</code> function. When we define placeholders, we need to decide what their shape and type should be, according to the shape and type of the data that will be fed through them upon execution.</p><p class="calibre8">Let's start with a simple example. In the following code, we will define the same graph that was shown in the previous section for evaluating <span class="strong"><img src="images/00889.jpeg" alt="Defining placeholders" class="calibre14" /></span>. This time, however, we use placeholders for the scalars <span class="strong"><em class="calibre9">a</em></span>, <span class="strong"><em class="calibre9">b</em></span>, and <span class="strong"><em class="calibre9">c</em></span>. Also, we store the intermediate tensors associated with <span class="strong"><img src="images/00339.jpeg" alt="Defining placeholders" class="calibre14" /></span> and <span class="strong"><img src="images/00352.jpeg" alt="Defining placeholders" class="calibre14" /></span>, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     tf_a = tf.placeholder(tf.int32, shape=[],
...                           name='tf_a')
...     tf_b = tf.placeholder(tf.int32, shape=[],
...                           name='tf_b')
...     tf_c = tf.placeholder(tf.int32, shape=[],
...                           name='tf_c')
...
...     r1 = tf_a-tf_b
...     r2 = 2*r1
...     z  = r2 + tf_c</pre></div><p class="calibre8">In this code, we defined three<a id="calibre_link-2339" class="calibre1"></a> placeholders, named <code class="email">tf_a</code>, <code class="email">tf_b</code>, and <code class="email">tf_c</code>, using type <code class="email">tf.int32</code> (32-bit integers) and set their shape via <code class="email">shape=[]</code> since they are scalars (tensors of rank 0). In the current book, we always precede the placeholder objects with <code class="email">tf_</code> for clarity and to be able to distinguish them from other tensors.</p><p class="calibre8">Note that in the previous code example, we were dealing with scalars, and therefore, their shapes were specified as <code class="email">shape=[]</code>. However, it is very straightforward to define placeholders of higher dimensions. For example, a rank 3 placeholder of type <code class="email">float</code> and shape 3 x 4 x 5 can be defined as <code class="email">tf.placeholder(dtype=tf.float32, shape=[2, 3, 4])</code>.</p></div></div></div>

<div id="calibre_link-615" class="calibre">
<div class="book" title="Placeholders in TensorFlow" id="calibre_link-2340">
<div class="book" title="Feeding placeholders with data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2341"><a id="calibre_link-402" class="calibre1"></a>Feeding placeholders with data</h2></div></div></div><p class="calibre8">When we execute a <a id="calibre_link-2342" class="calibre1"></a>node in the graph, we need to create a python <span class="strong"><strong class="calibre2">dictionary</strong></span> to feed the values of placeholders with data arrays. We do this according to the type and shape of the placeholders. This dictionary is passed as the input argument <code class="email">feed_dict</code> to a session's<code class="email"> run</code> method.</p><p class="calibre8">In the previous graph, we added three placeholders of the type <code class="email">tf.int32</code> to feed scalars for computing <span class="strong"><em class="calibre9">z</em></span>. Now, in order to evaluate the result tensor <code class="email">z</code>, we can feed arbitrary integer values (here, <code class="email">1</code>, <code class="email">2</code>, and <code class="email">3</code>) to the placeholders, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     feed = {tf_a: 1,
...             tf_b: 2,
...             tf_c: 3}
...     print('z:',
...           sess.run(z, feed_dict=feed))
z: 1</pre></div><p class="calibre8">This means that having extra arrays for placeholders does not cause any error; it is just redundant to do so. However, if a placeholder is needed for the execution of a particular node, and is not provided via the <code class="email">feed_dict</code> argument, it will cause a runtime error.</p></div></div></div>

<div id="calibre_link-542" class="calibre">
<div class="book" title="Placeholders in TensorFlow" id="calibre_link-2343">
<div class="book" title="Defining placeholders for data arrays with varying batchsizes"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2344"><a id="calibre_link-403" class="calibre1"></a>Defining placeholders for data arrays with varying batchsizes</h2></div></div></div><p class="calibre8">Sometimes, when we are <a id="calibre_link-2345" class="calibre1"></a>developing a neural network model, we may deal with mini-batches of data that have different sizes. For example, we may train a neural network with a specific mini-batch size, but we want to use the network to make predictions on one or more data input.</p><p class="calibre8">A useful feature of placeholders is that we can specify <code class="email">None</code> for the dimension that is varying in size. For example, we can create a placeholder of rank 2, where the first dimension is unknown (or may vary), as shown here:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g.as_default():
...     tf_x = tf.placeholder(tf.float32,
...                           shape=[None, 2],
...                           name='tf_x')
...     
...     x_mean = tf.reduce_mean(tf_x,
...                             axis=0,
...                             name='mean')</pre></div><p class="calibre8">Then, we can evaluate <code class="email">x_mean</code> with two <a id="calibre_link-2346" class="calibre1"></a>
<a id="calibre_link-2347" class="calibre1"></a>different input, <code class="email">x1</code> and <code class="email">x2</code>, which are NumPy arrays of shape <code class="email">(5, 2)</code> and <code class="email">(10, 2)</code>, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(123)
&gt;&gt;&gt; np.set_printoptions(precision=2)
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     x1 = np.random.uniform(low=0, high=1,
...                            size=(5, 2))
...     print('Feeding data with shape ', x1.shape)
...     print('Result:', sess.run(x_mean,
...                               feed_dict={tf_x: x1}))
...     x2 = np.random.uniform(low=0, high=1,
...                            size=(10,2))
...     print('Feeding data with shape', x2.shape)
...     print('Result:', sess.run(x_mean,
...                               feed_dict={tf_x: x2}))</pre></div><p class="calibre8">This prints the following output:</p><div class="informalexample"><pre class="programlisting">Feeding data with shape (5, 2)
Result: [ 0.62  0.47]
Feeding data with shape (10, 2)
Result: [ 0.46  0.49]</pre></div><p class="calibre8">Lastly, if we try printing the object <code class="email">tf_x</code>, we will get <code class="email">Tensor("tf_x:0", shape=(?, 2), dtype=float32)</code>, which shows that the shape of this tensor is <code class="email">(?, 2)</code>.</p></div></div></div>

<div id="calibre_link-651" class="calibre">
<div id="calibre_link-2348" class="calibre10"></div><div class="book" title="Variables in TensorFlow"><div class="book" id="calibre_link-34"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2349"><a id="calibre_link-2350" class="calibre1"></a>Variables in TensorFlow</h1></div></div></div><p class="calibre8">In the context of TensorFlow, variables are a special <a id="calibre_link-2351" class="calibre1"></a>type of tensor objects that allow us to store and update the parameters of our models in a TensorFlow session during training. The following sections explain how we can define variables in a graph, initialize those variables in a session, organize variables via the so-called variable scope, and reuse existing variables.</p></div></div>

<div id="calibre_link-550" class="calibre">
<div class="book" title="Variables in TensorFlow">
<div class="book" title="Defining variables"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2352"><a id="calibre_link-404" class="calibre1"></a>Defining variables</h2></div></div></div><p class="calibre8">TensorFlow <a id="calibre_link-2353" class="calibre1"></a>variables store the parameters of a model that can be updated during training, for example, the weights in the input, hidden, and output layers of a neural network. When we define a variable, we need to initialize it with a tensor of values. Feel free to read more about TensorFlow variables at <a class="calibre1" href="https://www.tensorflow.org/programmers_guide/variables">https://www.tensorflow.org/programmers_guide/variables</a>.</p><p class="calibre8">TensorFlow provides two ways for defining variables:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">tf.Variable(&lt;initial-value&gt;, name="variable-name")</code></li><li class="listitem"><code class="email">tf.get_variable(name, ...)</code></li></ul></div><p class="calibre8">The first one, <code class="email">tf.Variable</code>, is a class that creates an object for a new variable and adds it to the graph. Note that <code class="email">tf.Variable</code> does not have an explicit way to determine <code class="email">shape</code> and <code class="email">dtype</code>; the shape and type are set to be the same as those of the initial values.</p><p class="calibre8">The second option, <code class="email">tf.get_variable</code>, can be used to <span class="strong"><strong class="calibre2">reuse</strong></span> an existing variable with a given name (if the name exists in the graph) or create a new one if the name does not exist. In this case, the name becomes critical; that's probably why it has to be placed as the first argument to this function. Furthermore, <code class="email">tf.get_variable</code> provides an explicit way to set <code class="email">shape</code> and <code class="email">dtype</code>; these parameters are only required when creating a new variable, not reusing existing ones.</p><p class="calibre8">The advantage of <code class="email">tf.get_variable</code> over <code class="email">tf.Variable</code> is twofold: <code class="email">tf.get_variable</code> allows us to reuse existing variables it already uses the popular Xavier/Glorot initialization scheme by default.</p><p class="calibre8">Besides the initializer, the <code class="email">get_variable</code> function provides other parameters to control the tensor, such as adding a regularizer for the variable. If you are interested in learning more about these parameters, feel free to read the documentation of <code class="email">tf.get_variable</code> at <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/get_variable">https://www.tensorflow.org/api_docs/python/tf/get_variable</a>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2354" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Xavier (or Glorot) initialization</strong></span>
</p><p class="calibre8">In the early <a id="calibre_link-2355" class="calibre1"></a>development of deep learning, it was observed that random uniform or random normal weight initialization could often result in a poor performance of the model during training.</p><p class="calibre8">In 2010, Xavier Glorot and Yoshua Bengio investigated the effect of initialization and proposed a novel, more robust initialization scheme to facilitate the training of deep networks.</p><p class="calibre8">The general idea behind Xavier initialization is to roughly balance the variance of the gradients across different layers. Otherwise, one layer may get too much attention during training while the other layer lags behind.</p><p class="calibre8">According to the research paper by Glorot and Bengio, if we want to initialize the weights from uniform distribution, we should choose the interval of this uniform distribution as follows:</p><div class="mediaobject1"><img src="images/00161.jpeg" alt="Defining variables" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00219.jpeg" alt="Defining variables" class="calibre14" /></span> is the number of input neurons that are multiplied with the weights, and <span class="strong"><img src="images/00380.jpeg" alt="Defining variables" class="calibre14" /></span> is the number of output neurons that feed into the next layer. For initializing the weights from Gaussian (normal) distribution, the authors recommend choosing the standard deviation of this Gaussian to be <span class="strong"><img src="images/00390.jpeg" alt="Defining variables" class="calibre14" /></span>.</p><p class="calibre8">TensorFlow supports Xavier initialization in both uniform and normal distributions of weights. The documentation provides detailed information about using Xavier initialization with TensorFlow: <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/xavier_initializer">https://www.tensorflow.org/api_docs/python/tf/contrib/layers/xavier_initializer</a>.</p><p class="calibre8">For more information about Glorot and Bengio's initialization scheme, including the mathematical derivation and proof, read their original paper (<span class="strong"><em class="calibre9">Understanding the difficulty of deep feedforward neural networks</em></span>, <span class="strong"><em class="calibre9">Xavier Glorot and Yoshua Bengio</em></span>, <span class="strong"><em class="calibre9">2010</em></span>), which is freely available at <a class="calibre1" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a>.</p></div><p class="calibre8">In either initialization <a id="calibre_link-2356" class="calibre1"></a>technique, it's important to note that the initial values are not set until we launch the graph in <code class="email">tf.Session</code> and explicitly run the initializer operator in that session. In fact, the required memory for a graph is not allocated until we initialize the variables in a TensorFlow session.</p><p class="calibre8">Here is an example of creating a variable object where the initial values are created from a NumPy array. The <code class="email">dtype</code> data type of this tensor is <code class="email">tf.int64</code>, which is automatically <span class="strong"><strong class="calibre2">inferred</strong></span> from its NumPy array input:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; g1 = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g1.as_default():
...     w = tf.Variable(np.array([[1, 2, 3, 4],
...                               [5, 6, 7, 8]]), name='w')
...     print(w)
&lt;tf.Variable 'w:0' shape=(2, 4) dtype=int64_ref&gt;</pre></div></div></div></div>

<div id="calibre_link-554" class="calibre">
<div class="book" title="Variables in TensorFlow">
<div class="book" title="Initializing variables"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2357"><a id="calibre_link-405" class="calibre1"></a>Initializing variables</h2></div></div></div><p class="calibre8">Here, it is critical to<a id="calibre_link-2358" class="calibre1"></a> understand that tensors defined as variables are not allocated in memory and contain no values until they are initialized. Therefore, before executing any node in the computation graph, we <span class="strong"><em class="calibre9">must</em></span> initialize the variables that are within the path to the node that we want to execute.</p><p class="calibre8">This initialization process refers to allocating memory for the associated tensors and assigning their initial values. TensorFlow provides a function named <code class="email">tf.global_variables_initializer</code> that returns an operator for initializing all the variables that exist in a computation graph. Then, executing this operator will initialize the variables as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g1) as sess:
...     sess.run(tf.global_variables_initializer())
...     print(sess.run(w))

[[1 2 3 4]
 [5 6 7 8]]</pre></div><p class="calibre8">We can also store this operator in an object such as <code class="email">init_op = tf.global_variables_initializer()</code> and execute this operator later using <code class="email">sess.run(init_op)</code> or <code class="email">init_op.run()</code>. However, we need to make sure that this operator is created after we define all the variables.</p><p class="calibre8">For example, in the <a id="calibre_link-2359" class="calibre1"></a>following code, we define the variable <code class="email">w1</code>, then we define the operator <code class="email">init_op</code>, followed by the variable <code class="email">w2</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; g2 = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g2.as_default():
...     w1 = tf.Variable(1, name='w1')
...     init_op = tf.global_variables_initializer()
...     w2 = tf.Variable(2, name='w2')</pre></div><p class="calibre8">Now, let's evaluate <code class="email">w1</code> as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g2) as sess:
...     sess.run(init_op)
...     print('w1:', sess.run(w1))
w1: 1</pre></div><p class="calibre8">This works fine. Now, let's try evaluating <code class="email">w2</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g2) as sess:
...     sess.run(init_op)
...     print('w2:', sess.run(w2))
FailedPreconditionError
Attempting to use uninitialized value w2
    [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"](w2)]]</pre></div><p class="calibre8">As shown in the code example, executing the graph raises an error because <code class="email">w2</code> was not initialized via <code class="email">sess.run(init_op)</code>, and therefore, couldn't be evaluated. The operator <code class="email">init_op</code> was defined prior to adding <code class="email">w2</code> to the graph; thus, executing <code class="email">init_op</code> will not initialize <code class="email">w2</code>.</p></div></div></div>

<div id="calibre_link-559" class="calibre">
<div class="book" title="Variables in TensorFlow">
<div class="book" title="Variable scope"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2360"><a id="calibre_link-406" class="calibre1"></a>Variable scope</h2></div></div></div><p class="calibre8">In this subsection, we're going to discuss <span class="strong"><em class="calibre9">scoping</em></span>, which is an <a id="calibre_link-2361" class="calibre1"></a>important concept in TensorFlow, and especially useful if we are constructing large neural network graphs.</p><p class="calibre8">With variable scopes, we can organize the variables into separate subparts. When we create a variable scope, the name of operations and tensors that are created within that scope are prefixed with that scope, and those scopes can further be nested. For example, if we have two subnetworks, where each subnetwork has several layers, we can define two scopes named <code class="email">'net_A'</code> and <code class="email">'net_B'</code>, respectively. Then, each layer will be defined within one of these scopes.</p><p class="calibre8">Let's see how the <a id="calibre_link-2362" class="calibre1"></a>variable names will turn out in the following code example:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g.as_default():
...     with tf.variable_scope('net_A'):
...         with tf.variable_scope('layer-1'):
...             w1 = tf.Variable(tf.random_normal(
...                 shape=(10,4)), name='weights')
...         with tf.variable_scope('layer-2'):
...             w2 = tf.Variable(tf.random_normal(
...                 shape=(20,10)), name='weights')
...     with tf.variable_scope('net_B'):
...         with tf.variable_scope('layer-1'):
...             w3 = tf.Variable(tf.random_normal(
...                 shape=(10,4)), name='weights')
... 
...     print(w1)
...     print(w2)
...     print(w3)


&lt;tf.Variable 'net_A/layer-1/weights:0' shape=(10, 4) dtype=float32_ref&gt;
&lt;tf.Variable 'net_A/layer-2/weights:0' shape=(20, 10) dtype=float32_ref&gt;
&lt;tf.Variable 'net_B/layer-1/weights:0' shape=(10, 4) dtype=float32_ref&gt;</pre></div><p class="calibre8">Notice that the variable names are now prefixed with their nested scopes, separated by the forward slash (<code class="email">/</code>) symbol.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2363" class="calibre1"></a>Note</h3><p class="calibre8">For more information about variable scoping, read the documentation at <a class="calibre1" href="https://www.tensorflow.org/programmers_guide/variable_scope">https://www.tensorflow.org/programmers_guide/variable_scope</a> and <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">https://www.tensorflow.org/api_docs/python/tf/variable_scope</a>.</p></div></div></div></div>

<div id="calibre_link-124" class="calibre">
<div class="book" title="Variables in TensorFlow">
<div class="book" title="Reusing variables"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2364"><a id="calibre_link-407" class="calibre1"></a>Reusing variables</h2></div></div></div><p class="calibre8">Let's imagine<a id="calibre_link-2365" class="calibre1"></a> that we're developing a somewhat complex neural network model that has a classifier whose input data comes from more than one source. For example, we'll assume that we have data <span class="strong"><img src="images/00401.jpeg" alt="Reusing variables" class="calibre14" /></span> coming from source <span class="strong"><em class="calibre9">A</em></span> and data <span class="strong"><img src="images/00428.jpeg" alt="Reusing variables" class="calibre14" /></span> comes from source <span class="strong"><em class="calibre9">B</em></span>. In this example, we will design our graph in such a way that it will use the data from only one source as input tensor to build the network. Then, we can feed the data from the other source to the same classifier.</p><p class="calibre8">In the following example, we assume that data from source A is fed through placeholder, and source B is the output of a generator network. We will build by calling the <code class="email">build_generator</code> function within the <code class="email">generator</code> scope, then we will add a classifier by calling <code class="email">build_classifier</code> within the <code class="email">classifier</code> scope:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; 
&gt;&gt;&gt; ###########################
... ##   Helper functions    ##
... ###########################
&gt;&gt;&gt; 
&gt;&gt;&gt; def build_classifier(data, labels, n_classes=2):
...     data_shape = data.get_shape().as_list()
...     weights = tf.get_variable(name='weights',
...                               shape=(data_shape[1],
...                                      n_classes),
...                               dtype=tf.float32)
...     bias = tf.get_variable(name='bias',
...                            initializer=tf.zeros(
...                                      shape=n_classes))
...     logits = tf.add(tf.matmul(data, weights),
...                     bias,
...                     name='logits')
...     return logits, tf.nn.softmax(logits)
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; def build_generator(data, n_hidden):
...     data_shape = data.get_shape().as_list()
...     w1 = tf.Variable(
...         tf.random_normal(shape=(data_shape[1],
...                                 n_hidden)),
...         name='w1')
...     b1 = tf.Variable(tf.zeros(shape=n_hidden),
...                      name='b1')
...     hidden = tf.add(tf.matmul(data, w1), b1,
...                     name='hidden_pre-activation')
...     hidden = tf.nn.relu(hidden, 'hidden_activation')
...         
...     w2 = tf.Variable(
...         tf.random_normal(shape=(n_hidden,
...                                 data_shape[1])),
...         name='w2')
...     b2 = tf.Variable(tf.zeros(shape=data_shape[1]),
...                      name='b2')
...     output = tf.add(tf.matmul(hidden, w2), b2,
...                     name = 'output')
...     return output, tf.nn.sigmoid(output)
&gt;&gt;&gt;
&gt;&gt;&gt; ###########################
... ##  Build the graph      ##
... ###########################
&gt;&gt;&gt;
&gt;&gt;&gt; batch_size=64
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g.as_default():
...     tf_X = tf.placeholder(shape=(batch_size, 100),
...                           dtype=tf.float32,
...                           name='tf_X')
...
...     ## build the generator
...     with tf.variable_scope('generator'):
...         gen_out1 = build_generator(data=tf_X,
...                                    n_hidden=50)
...     
...     ## build the classifier
...     with tf.variable_scope('classifier') as scope:
...         ## classifier for the original data:
...         cls_out1 = build_classifier(data=tf_X,
...                                     labels=tf.ones(
...                                         shape=batch_size))
...         
...         ## reuse the classifier for generated data
...         scope.reuse_variables()
...         cls_out2 = build_classifier(data=gen_out1[1],
...                                     labels=tf.zeros(
...                                         shape=batch_size))</pre></div><p class="calibre8">Notice that we have called the <code class="email">build_classifier</code> function two times. The first call causes the building of the network. Then, we call <code class="email">scope.reuse_variables()</code> and call that function again. As a result, the second call does not create new variables; instead, it reuses the same <a id="calibre_link-2366" class="calibre1"></a>variables. Alternatively, we could reuse the variables by specifying the <code class="email">reuse=True</code> parameter, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g.as_default():
...     tf_X = tf.placeholder(shape=(batch_size, 100),
...                           dtype=tf.float32,
...                           name='tf_X')
...     ## build the generator
...     with tf.variable_scope('generator'):
...         gen_out1 = build_generator(data=tf_X,
...                                    n_hidden=50)
...     
...     ## build the classifier
...     with tf.variable_scope('classifier'):
...         ## classifier for the original data:
...         cls_out1 = build_classifier(data=tf_X,
...                                     labels=tf.ones(
...                                         shape=batch_size))
...         
...     with tf.variable_scope('classifier', reuse=True):
...         ## reuse the classifier for generated data
...         cls_out2 = build_classifier(data=gen_out1[1],
...                                     labels=tf.zeros(
...                                         shape=batch_size))</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2367" class="calibre1"></a>Note</h3><p class="calibre8">While we have discussed how to define computational graphs and variables in TensorFlow, a detailed discussion of how we can compute gradients in a computational graph is beyond the scope of this book, where we use TensorFlow's convenient optimizer classes that perform backpropagation automatically for us. If you are interested in learning more about the computation of gradients in computational graphs and the different ways to compute them in TensorFlow, please refer to the PyData talk by Sebastian Raschka at <a class="calibre1" href="https://github.com/rasbt/pydata-annarbor2017-dl-tutorial">https://github.com/rasbt/pydata-annarbor2017-dl-tutorial</a>.</p></div></div></div></div>

<div id="calibre_link-573" class="calibre"><div class="book" title="Building a regression model"><div class="book" id="calibre_link-408"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2368"><a id="calibre_link-2369" class="calibre1"></a>Building a regression model</h1></div></div></div><p class="calibre8">Since we've explored <a id="calibre_link-2370" class="calibre1"></a>placeholders and variables, let's build an example model for regression analysis, similar to the one we created in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, where our goal is to implement a linear regression model: <span class="strong"><img src="images/00421.jpeg" alt="Building a regression model" class="calibre14" /></span>.</p><p class="calibre8">In this model, <span class="strong"><em class="calibre9">w</em></span> and <span class="strong"><em class="calibre9">b</em></span> are the two parameters of this simple regression model that need to be defined as variables. Note that <span class="strong"><em class="calibre9">x</em></span> is the input to the model, which we can define as a placeholder. Furthermore, recall that for training this model, we need to formulate a cost function. Here, we use the <span class="strong"><strong class="calibre2">Mean Squared Error</strong></span> (<span class="strong"><strong class="calibre2">MSE</strong></span>) cost function that we defined in <a class="calibre1" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" href="#calibre_link-41">Chapter 10</a>, <span class="strong"><em class="calibre9">Predicting Continuous Target Variables with Regression Analysis</em></span> <span class="strong"><img src="images/00436.jpeg" alt="Building a regression model" class="calibre14" /></span>.</p><p class="calibre8">Here, <span class="strong"><em class="calibre9">y</em></span> is the true value, which is given as the input to this model for training. Therefore, we need to define <span class="strong"><em class="calibre9">y</em></span> as a placeholder as well. Finally, <span class="strong"><img src="images/00448.jpeg" alt="Building a regression model" class="calibre14" /></span> is the prediction output, which will be computed using TensorFlow operations&mdash;<code class="email">tf.matmul</code> and <code class="email">tf.add</code>. Recall that TensorFlow operations return zero or more tensors; here, <code class="email">tf.matmul</code> and <code class="email">tf.add</code> return one tensor.</p><p class="calibre8">We can also use the overloaded operator <code class="email">+</code> for adding two tensors; however, the advantage of <code class="email">tf.add</code> is that we can provide an additional name for the resulting tensor via the <code class="email">name</code> parameter.</p><p class="calibre8">So, let's summarize all our <a id="calibre_link-2371" class="calibre1"></a>tensors with their mathematical notations and coding naming, as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Input <span class="strong"><em class="calibre9">x</em></span>: <code class="email">tf_x</code> defined as a placeholder</li><li class="listitem">Input <span class="strong"><em class="calibre9">y</em></span>: <code class="email">tf_y</code> defined as a placeholder</li><li class="listitem">Model parameter <span class="strong"><em class="calibre9">w</em></span>: <code class="email">weight</code> defined as a variable</li><li class="listitem">Model parameter <span class="strong"><em class="calibre9">b</em></span>: <code class="email">bias</code> defined as a variable</li><li class="listitem">
Model output <span class="strong"><img src="images/00448.jpeg" alt="Building a regression model" class="calibre14" /></span>: <code class="email">y_hat</code> returned by the TensorFlow operations to compute the prediction using the regression model
</li></ul></div><p class="calibre8">The code to implement this simple regression model is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; 
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; 
&gt;&gt;&gt; with g.as_default():
...     tf.set_random_seed(123)
...     ## placeholders
...     tf_x = tf.placeholder(shape=(None),
...                           dtype=tf.float32,
...                           name='tf_x')
...     tf_y = tf.placeholder(shape=(None),
...                           dtype=tf.float32,
...                           name='tf_y')
...     
...     ## define the variable (model parameters)
...     weight = tf.Variable(
...         tf.random_normal(
...             shape=(1, 1),
...             stddev=0.25)),
...         name='weight')
...     bias = tf.Variable(0.0, name='bias')
...     
...     ## build the model
...     y_hat = tf.add(weight * tf_x, bias,
...                    name='y_hat')
...     
...     ## compute the cost
...     cost = tf.reduce_mean(tf.square(tf_y - y_hat),
...                           name='cost')
... 
...     ## train the model
...     optim = tf.train.GradientDescentOptimizer(
...         learning_rate=0.001)
...     train_op = optim.minimize(cost, name='train_op')</pre></div><p class="calibre8">Now that we've <a id="calibre_link-2372" class="calibre1"></a>built the graph, our next steps are to create a session to launch the graph and train the model. But before we go further, let's see how we can evaluate tensors and execute operations. We'll create a random regression data with one feature, using the <code class="email">make_random_data</code> function and visualizing the data:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## create a random toy dataset for regression
&gt;&gt;&gt; 
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt;
&gt;&gt;&gt; def make_random_data():
...     x = np.random.uniform(low=-2, high=4, size=200)
...     y = []
...     for t in x:
...         r = np.random.normal(loc=0.0,
...                              scale=(0.5 + t*t/3),
...                              size=None)
...         y.append(r)
...     return  x, 1.726*x -0.84 + np.array(y)
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; x, y = make_random_data()
&gt;&gt;&gt;
&gt;&gt;&gt; plt.plot(x, y, 'o')
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The following figure shows the random regression data that we generated:</p><div class="mediaobject"><img src="images/00017.jpeg" alt="Building a regression model" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now we're ready; let's train the <a id="calibre_link-2373" class="calibre1"></a>previous model. Let's start by creating a TensorFlow session object called <code class="email">sess</code>. Then, we want to initialize our variables which, as we saw, we can do with <code class="email">sess.run(tf.global_variables_initializer())</code>. After this, we can create a <code class="email">for</code> loop to execute the train operator and calculate the training cost at the same time.</p><p class="calibre8">So let's combine the two tasks, the first to execute an operator, and the second to evaluate a tensor, into one <code class="email">sess.run</code> method call. The code for this is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## train/test splits
&gt;&gt;&gt; x_train, y_train = x[:100], y[:100]
&gt;&gt;&gt; x_test, y_test = x[100:], y[100:]
&gt;&gt;&gt; 
&gt;&gt;&gt;
&gt;&gt;&gt; n_epochs = 500
&gt;&gt;&gt; training_costs = []
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     sess.run(tf.global_variables_initializer())
...     
...     ## train the model for n_epochs
...     for e in range(n_epochs):
...         c, _ = sess.run([cost, train_op],
...                         feed_dict={tf_x: x_train,
...                                    tf_y: y_train})
...         training_costs.append(c)
...         if not e % 50:
...             print('Epoch %4d: %.4f' % (e, c))
Epoch    0: 12.2230
Epoch   50: 8.3876
Epoch  100: 6.5721
Epoch  150: 5.6844
Epoch  200: 5.2269
Epoch  250: 4.9725
Epoch  300: 4.8169
Epoch  350: 4.7119
Epoch  400: 4.6347
Epoch  450: 4.5742
             
&gt;&gt;&gt; plt.plot(training_costs)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The code generates the<a id="calibre_link-2374" class="calibre1"></a> following graph that shows the training costs after each epoch:</p><div class="mediaobject"><img src="images/00316.jpeg" alt="Building a regression model" class="calibre11" /></div><p class="calibre12"> </p></div></div>

<div id="calibre_link-578" class="calibre"><div class="book" title="Executing objects in a TensorFlow graph using their names" id="calibre_link-409"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2375"><a id="calibre_link-2376" class="calibre1"></a>Executing objects in a TensorFlow graph using their names</h1></div></div></div><p class="calibre8">Executing variables and operators <a id="calibre_link-2377" class="calibre1"></a>by their names is very useful in many scenarios. For example, we may develop a <a id="calibre_link-2378" class="calibre1"></a>model in a separate module; and thus the variables are not available in a different Python scope according to Python scoping rules. However, if we have a graph, we can execute the nodes of the graph using their names in the graph.</p><p class="calibre8">This can be done easily by changing the <code class="email">sess.run</code> method from the previous code example, using the variable name of the <span class="strong"><strong class="calibre2">cost</strong></span> in the graph rather than the Python variable <code class="email">cost</code> by changing <code class="email">sess.run([cost, train_op], ...)</code> to <code class="email">sess.run(['cost:0', 'train_op'], ...)</code>.</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; n_epochs = 500
&gt;&gt;&gt; training_costs = []
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     ## first, run the variables initializer
...     sess.run(tf.global_variables_initializer())
...     
...     ## train the model for n_eopchs
...     for e in range(n_epochs):
...         c, _ = sess.run(['cost:0', 'train_op'], 
...                         feed_dict={'tf_x:0':x_train,
...                                    'tf_y:0':y_train})
...         training_costs.append(c)
...         if e%50 == 0:
...             print('Epoch {:4d} : {:.4f}'
...                     .format(e, c))</pre></div><p class="calibre8">Notice that we are evaluating the cost by its name, which is <code class="email">'cost:0'</code>, and executing the train operator by its name: <code class="email">'train_op'</code>. Also, in <code class="email">feed_dict</code>, instead of using <code class="email">tf_x: x_train</code>, we are using <code class="email">'tf_x:0': x_train</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2379" class="calibre1"></a>Note</h3><p class="calibre8">If we pay attention to the names of the tensors, we will notice that TensorFlow adds a suffix <code class="email">':0'</code> to the name of the tensors.</p><p class="calibre8">However, the names of operators do not have any suffix like that. When a tensor with a given name, such as <code class="email">name='my_tensor'</code>, is created, TensorFlow appends <code class="email">':0'</code>; so the name of this tensor will be <code class="email">'my_tensor:0'</code>.</p><p class="calibre8">Then, if we try to create another tensor with the same name in the same graph, TensorFlow will append <code class="email">'_1:0'</code> and so on to the name; therefore, the future tensors will be named <code class="email">'my_tensor_1:0'</code>, <code class="email">'my_tensor_2:0'</code>, and so on. This naming assumes that we are not trying to reuse the already created tensor.</p></div></div></div>

<div id="calibre_link-583" class="calibre"><div class="book" title="Saving and restoring a model in TensorFlow"><div class="book" id="calibre_link-410"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2380"><a id="calibre_link-2381" class="calibre1"></a>Saving and restoring a model in TensorFlow</h1></div></div></div><p class="calibre8">In the <a id="calibre_link-2382" class="calibre1"></a>previous section, we <a id="calibre_link-2383" class="calibre1"></a>built a graph and<a id="calibre_link-2384" class="calibre1"></a> trained it. How about doing the actual prediction on the held out test set? The problem is <a id="calibre_link-2385" class="calibre1"></a>that we did not save the model parameters; so, once the execution of the preceding statements are finished and we exit the <code class="email">tf.Session</code> environment, all the variables and their allocated memories are freed.</p><p class="calibre8">One solution is to train a model, and as soon as the training is finished, we can feed it our test set. However, this is not a good approach since deep neural network models are typically trained over multiple hours, days, or even weeks.</p><p class="calibre8">The best<a id="calibre_link-2386" class="calibre1"></a> approach is to save <a id="calibre_link-2387" class="calibre1"></a>the trained model for future use. For this purpose, we need to add a new node to the graph, an instance of the <code class="email">tf.train.Saver</code> class, which we call <code class="email">saver</code>.</p><p class="calibre8">In the following statement, we <a id="calibre_link-2388" class="calibre1"></a>can add more nodes to a particular graph. In this case, we are adding <code class="email">saver</code> to the graph <code class="email">g</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with g.as_default():
...     saver = tf.train.Saver()</pre></div><p class="calibre8">Next, we can retrain the model with an <a id="calibre_link-2389" class="calibre1"></a>additional call to <code class="email">saver.save()</code> to save the model as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; n_epochs = 500
&gt;&gt;&gt; training_costs = []
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     sess.run(tf.global_variables_initializer())
...     
...     ## train the model for n_epochs
...     for e in range(n_epochs):
...         c, _ = sess.run([cost, train_op],
...                         feed_dict={tf_x: x_train,
...                                    tf_y: y_train})
...         training_costs.append(c)
...         if not e % 50:
...             print('Epoch %4d: %.4f' % (e, c))
...
...     saver.save(sess, './trained-model')</pre></div><p class="calibre8">As a result of this new statement, three files are created with extensions <code class="email">.data</code>, <code class="email">.index</code>, and <code class="email">.meta</code>. TensorFlow uses Protocol Buffers (<a class="calibre1" href="https://developers.google.com/protocol-buffers/">https://developers.google.com/protocol-buffers/</a>), which is a language-agnostic way, for serializing structured data.</p><p class="calibre8">Restoring a trained model requires two steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Rebuild the graph that has the same nodes and names as the saved model.</li><li class="listitem" value="2">Restore the saved variables in a new <code class="email">tf.Session</code> environment.</li></ol><div class="calibre13"></div></div><p class="calibre8">For the first step, we can<a id="calibre_link-2390" class="calibre1"></a> run the<a id="calibre_link-2391" class="calibre1"></a> statements, as we did in the first place, to build the graph <code class="email">g</code>. But there is a much easier way to do this. Note that all of the information regarding the graph is<a id="calibre_link-2392" class="calibre1"></a> saved as metadata<a id="calibre_link-2393" class="calibre1"></a> in the file with the <code class="email">.meta</code> extension. Using the following code, we rebuild the graph by importing it from the meta file:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session() as sess:
...     new_saver = tf.train.import_meta_graph(
...                            './trained-model.meta')</pre></div><p class="calibre8">The <code class="email">tf.train.import_meta_graph</code> function recreates the graph that is saved in the <code class="email">'./trained-model.meta'</code> file. After recreating the graph, we can use the <code class="email">new_saver</code> object to restore the parameters of the model in that session and execute it. The complete code to run the model on a test set is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; g2 = tf.Graph()
&gt;&gt;&gt; with tf.Session(graph=g2) as sess:
...     new_saver = tf.train.import_meta_graph(
...         './trained-model.meta')
...     new_saver.restore(sess, './trained-model')
...     
...     y_pred = sess.run('y_hat:0',
...                       feed_dict={'tf_x:0': x_test})</pre></div><p class="calibre8">Note that we evaluated the <span class="strong"><img src="images/00448.jpeg" alt="Saving and restoring a model in TensorFlow" class="calibre14" /></span> tensor by its name that was given previously: <code class="email">'y_hat:0'</code>. Also, we needed to feed the values for the <code class="email">tf_x</code> placeholder, which is also done by its name: <code class="email">'tf_x:0'</code>. In this case, there is no need to feed the values for the true <span class="strong"><em class="calibre9">y</em></span> values. This is because executing the <code class="email">y_hat</code> node does not depend on <code class="email">tf_y</code> in the computation graph that we built.</p><p class="calibre8">Now, let's visualize the predictions, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; 
&gt;&gt;&gt; x_arr = np.arange(-2, 4, 0.1)
&gt;&gt;&gt; 
&gt;&gt;&gt; g2 = tf.Graph()
&gt;&gt;&gt; with tf.Session(graph=g2) as sess:
...     new_saver = tf.train.import_meta_graph(
...         './trained-model.meta')
...     new_saver.restore(sess, './trained-model')
...     
...     y_arr = sess.run('y_hat:0',
...                       feed_dict={'tf_x:0' : x_arr})
&gt;&gt;&gt;
&gt;&gt;&gt; plt.figure()
&gt;&gt;&gt; plt.plot(x_train, y_train, 'bo')
&gt;&gt;&gt; plt.plot(x_test, y_test, 'bo', alpha=0.3)
&gt;&gt;&gt; plt.plot(x_arr, y_arr.T[:, 0], '-r', lw=3)
&gt;&gt;&gt; plt.show()</pre></div><p class="calibre8">The result is shown in the following figure, where both the training data and test data are displayed:</p><div class="mediaobject"><img src="images/00210.jpeg" alt="Saving and restoring a model in TensorFlow" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Saving and restoring a <a id="calibre_link-2394" class="calibre1"></a>model is very often <a id="calibre_link-2395" class="calibre1"></a>used during the training stage of large models as well. Since the training stage of large models can take several hours to days, we can break the <a id="calibre_link-2396" class="calibre1"></a>training phase into<a id="calibre_link-2397" class="calibre1"></a> smaller tasks. For example, if the intended number of epochs is 100, we can break it into 25 tasks, where each task would run four epochs one after the other. For this purpose, we can save the trained model and restore it in the next task.</p></div></div>

<div id="calibre_link-589" class="calibre"><div class="book" title="Transforming Tensors as multidimensional data arrays" id="calibre_link-411"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2398"><a id="calibre_link-2399" class="calibre1"></a>Transforming Tensors as multidimensional data arrays</h1></div></div></div><p class="calibre8">In this section, we explore a<a id="calibre_link-2400" class="calibre1"></a> selection of <a id="calibre_link-2401" class="calibre1"></a>operators that can be used to transform tensors. Note that some of these operators work very similar to NumPy array transformations. However, when we are dealing with tensors with ranks higher than 2, we need to be careful in using such transformations, for example, the transpose of a tensor.</p><p class="calibre8">First, as in NumPy, we can use the attribute <code class="email">arr.shape</code> to get the shape of a NumPy array. In TensorFlow, we use the <code class="email">tf.get_shape</code> function instead:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     arr = np.array([[1., 2., 3., 3.5],
...                     [4., 5., 6., 6.5],
...                     [7., 8., 9., 9.5]])
...     T1 = tf.constant(arr, name='T1')
...     print(T1)
...     s = T1.get_shape()
...     print('Shape of T1 is', s)
...     T2 = tf.Variable(tf.random_normal(
...         shape=s))
...     print(T2)
...     T3 = tf.Variable(tf.random_normal(
...         shape=(s.as_list()[0],)))
...     print(T3)</pre></div><p class="calibre8">The output of<a id="calibre_link-2402" class="calibre1"></a> the previous code <a id="calibre_link-2403" class="calibre1"></a>example is as follows:</p><div class="informalexample"><pre class="programlisting">Tensor("T1:0", shape=(3, 4), dtype=float64)
Shape of T1 is (3, 4)
&lt;tf.Variable 'Variable:0' shape=(3, 4) dtype=float32_ref&gt;
&lt;tf.Variable 'Variable_1:0' shape=(3,) dtype=float32_ref&gt;</pre></div><p class="calibre8">Notice that we used <code class="email">s</code> to create <code class="email">T2</code>, but we cannot slice or index <code class="email">s</code> for creating <code class="email">T3</code>. Therefore, we converted <code class="email">s</code> into a regular Python list by <code class="email">s.as_list()</code> and then used the usual indexing conventions.</p><p class="calibre8">Now, let's see how we can reshape tensors. Recall that in NumPy, we can use <code class="email">np.reshape</code> or <code class="email">arr.reshape</code> for this purpose. In TensorFlow, we use the function <code class="email">tf.reshape</code> to reshape a tensor. As is the case for NumPy, one dimension can be set to <code class="email">-1</code> so that the size of the new dimension will be inferred based on the total size of the array and the other remaining dimensions that are specified.</p><p class="calibre8">In the following code, we reshape the tensor <code class="email">T1</code> to <code class="email">T4</code> and <code class="email">T5</code>, both of which have rank 3:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with g.as_default():
...     T4 = tf.reshape(T1, shape=[1, 1, -1],
...                     name='T4')
...     print(T4)
...     T5 = tf.reshape(T1, shape=[1, 3, -1],
...                     name='T5')
...     print(T5)</pre></div><p class="calibre8">The output is as follows:</p><div class="informalexample"><pre class="programlisting">Tensor("T4:0", shape=(1, 1, 12), dtype=float64)
Tensor("T5:0", shape=(1, 3, 4), dtype=float64)</pre></div><p class="calibre8">Next, let's print the elements of <code class="email">T4</code> and <code class="email">T5</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph = g) as sess:
...     print(sess.run(T4))
...     print()
...     print(sess.run(T5))

[[[ 1.   2.   3.   3.5  4.   5.   6.   6.5  7.   8.   9.   9.5]]]

[[[ 1.   2.   3.   3.5]
  [ 4.   5.   6.   6.5]
  [ 7.   8.   9.   9.5]]]</pre></div><p class="calibre8">As we know, there<a id="calibre_link-2404" class="calibre1"></a> are three ways to<a id="calibre_link-2405" class="calibre1"></a> transpose an array in NumPy: <code class="email">arr.T</code>, <code class="email">arr.transpose()</code>, and <code class="email">np.transpose(arr)</code>. In TensorFlow, we use the <code class="email">tf.transpose</code> function instead, and in addition to a regular transpose operation, we can change the order of dimensions in any way we want by specifying the order in <code class="email">perm=[...]</code>. Here's an example:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with g.as_default():
...     T6 = tf.transpose(T5, perm=[2, 1, 0],
...                     name='T6')
...     print(T6)
...     T7 = tf.transpose(T5, perm=[0, 2, 1],
...                     name='T7')
...     print(T7)

Tensor("T6:0", shape=(4, 3, 1), dtype=float64)
Tensor("T7:0", shape=(1, 4, 3), dtype=float64)</pre></div><p class="calibre8">Next, we can also split a tensor into a list of subtensors using the <code class="email">tf.split</code> function, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with g.as_default():
...     t5_splt = tf.split(T5,
...                        num_or_size_splits=2,
...                        axis=2, name='T8')
...     print(t5_splt)

[&lt;tf.Tensor 'T8:0' shape=(1, 3, 2) dtype=float64&gt;,
 &lt;tf.Tensor 'T8:1' shape=(1, 3, 2) dtype=float64&gt;]</pre></div><p class="calibre8">Here, it's important to note that the output is not a tensor object anymore; rather, it's a list of tensors. The name of these subtensors are <code class="email">'T8:0'</code> and <code class="email">'T8:1'</code>.</p><p class="calibre8">Lastly, another useful<a id="calibre_link-2406" class="calibre1"></a> transformation is the<a id="calibre_link-2407" class="calibre1"></a> concatenation of multiple tensors. If we have a list of tensors with the same shape and <code class="email">dtype</code>, we can combine them into one big tensor using the <code class="email">tf.concat</code> function. An example is given in the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     t1 = tf.ones(shape=(5, 1),
...                  dtype=tf.float32, name='t1')
...     t2 = tf.zeros(shape=(5, 1),
...                  dtype=tf.float32, name='t2')
...     print(t1)
...     print(t2)
&gt;&gt;&gt; with g.as_default():
...     t3 = tf.concat([t1, t2], axis=0, name='t3')
...     print(t3)
...     t4 = tf.concat([t1, t2], axis=1, name='t4')
...     print(t4)
    
Tensor("t1:0", shape=(5, 1), dtype=float32)
Tensor("t2:0", shape=(5, 1), dtype=float32)

Tensor("t3:0", shape=(10, 1), dtype=float32)
Tensor("t4:0", shape=(5, 2), dtype=float32)</pre></div><p class="calibre8">Let's print the values of these concatenated tensors:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     print(t3.eval())
...     print()
...     print(t4.eval())
    
[[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 0.]
 [ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]

[[ 1.  0.]
 [ 1.  0.]
 [ 1.  0.]
 [ 1.  0.]
 [ 1.  0.]]</pre></div></div></div>

<div id="calibre_link-511" class="calibre"><div class="book" title="Utilizing control flow mechanics in building graphs"><div class="book" id="calibre_link-77"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2408"><a id="calibre_link-2409" class="calibre1"></a>Utilizing control flow mechanics in building graphs</h1></div></div></div><p class="calibre8">Now let's <a id="calibre_link-2410" class="calibre1"></a>learn about an interesting <a id="calibre_link-2411" class="calibre1"></a>TensorFlow mechanic. TensorFlow provides a mechanism for making decisions when building a graph. However, there are some subtle differences when we use Python's control flow statements compared to TensorFlow's control flow functions, when constructing computation graphs.</p><p class="calibre8">To illustrate these differences with some simple code examples, let's consider implementing the following equation in TensorFlow:</p><div class="mediaobject"><img src="images/00497.jpeg" alt="Utilizing control flow mechanics in building graphs" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the following code, we may naively use Python's <code class="email">if</code> statement to build a graph that corresponds to the preceding equation:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; x, y = 1.0, 2.0
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     tf_x = tf.placeholder(dtype=tf.float32,
...                           shape=None, name='tf_x')
...     tf_y = tf.placeholder(dtype=tf.float32,
...                           shape=None, name='tf_y')
...     if x &lt; y:
...         res = tf.add(tf_x, tf_y, name='result_add')
...     else:
...         res = tf.subtract(tf_x, tf_y, name='result_sub')
...         
...     print('Object:', res)
&gt;&gt;&gt;         
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     print('x &lt; y: %s -&gt; Result:' % (x &lt; y),
...           res.eval(feed_dict={'tf_x:0': x,
...                               'tf_y:0': y}))
...     x, y = 2.0, 1.0
...     print('x &lt; y: %s -&gt; Result:' % (x &lt; y),
...           res.eval(feed_dict={'tf_x:0': x,
...                               'tf_y:0': y}))</pre></div><p class="calibre8">The result of this code will be as follows:</p><div class="informalexample"><pre class="programlisting">Object: Tensor("result_add:0", dtype=float32)
x &lt; y: True -&gt; Result: 3.0
x &lt; y: False -&gt; Result: 3.0</pre></div><p class="calibre8">As you can see, the<a id="calibre_link-2412" class="calibre1"></a> <code class="email">res</code> object is a <a id="calibre_link-2413" class="calibre1"></a>tensor named <code class="email">'result_add:0'</code>. It is very important to understand that in the previous mechanism, the computation graph has only one branch associated with the addition operator, and the subtract operator has not been called.</p><p class="calibre8">The TensorFlow computation graph is static, which means that once the computation graph is built, it remains unchanged during the execution process. So, even when we change the values of <code class="email">x</code> and <code class="email">y</code> and feed the new values to the graph, these new tensors will go through the same path in the graph. Therefore, in both cases, we see the same output <code class="email">3.0</code> for <code class="email">x=2</code>, <code class="email">y=1</code> and for <code class="email">x=1</code>, <code class="email">y=2</code>.</p><p class="calibre8">Now, let's use the <a id="calibre_link-2414" class="calibre1"></a>control flow mechanics in <a id="calibre_link-2415" class="calibre1"></a>TensorFlow. In the following code, we implement the previous equation using the <code class="email">tf.cond</code> function instead of Python's <code class="email">if</code> statement:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; x, y = 1.0, 2.0
&gt;&gt;&gt;
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     tf_x = tf.placeholder(dtype=tf.float32,
...                           shape=None, name='tf_x')
...     tf_y = tf.placeholder(dtype=tf.float32,
...                           shape=None, name='tf_y')
...     res = tf.cond(tf_x &lt; tf_y,
...                   lambda: tf.add(tf_x, tf_y,
...                                  name='result_add'),
...                   lambda: tf.subtract(tf_x, tf_y,
...                                  name='result_sub'))
...     print('Object:', res)
...         
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     print('x &lt; y: %s -&gt; Result:' % (x &lt; y),
...           res.eval(feed_dict={'tf_x:0': x,
...                               'tf_y:0': y}))
...     x, y = 2.0, 1.0
...     print('x &lt; y: %s -&gt; Result:' % (x &lt; y),
...           res.eval(feed_dict={'tf_x:0': x,
...                               'tf_y:0': y}))</pre></div><p class="calibre8">The result will be as follows:</p><div class="informalexample"><pre class="programlisting">Object: Tensor("cond/Merge:0", dtype=float32)
x &lt; y: True -&gt; Result: 3.0
x &lt; y: False -&gt; Result: 1.0</pre></div><p class="calibre8">Here, we can see that the <code class="email">res</code> object is named <code class="email">"cond/Merge:0"</code>. In this case, the computation graph has two branches with a mechanism to decide which branch to follow at execution time. Therefore, when <code class="email">x=2</code>, <code class="email">y=1</code>, it follows the addition branch and the output will be <code class="email">3.0</code>, while for <code class="email">x=1</code>, <code class="email">y=2</code>, the subtraction branch is pursued and the result will be <code class="email">1.0</code>.</p><p class="calibre8">The following figure contrasts the differences in the computation graph of the previous implementation using the python <code class="email">if</code> statement versus TensorFlow's <code class="email">tf.cond</code> function;</p><div class="mediaobject"><img src="images/00184.jpeg" alt="Utilizing control flow mechanics in building graphs" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In<a id="calibre_link-2416" class="calibre1"></a> addition to <code class="email">tf.cond</code>, TensorFlow <a id="calibre_link-2417" class="calibre1"></a>offers several other control flow operators, such as <code class="email">tf.case</code> and <code class="email">tf.while_loop</code>. For instance, <code class="email">tf.case</code> is the TensorFlow control flow equivalent to a Python <code class="email">ifâ¦else</code> statement. Consider the following Python expression:</p><div class="informalexample"><pre class="programlisting">if (x &lt; y):
    result = 1
else:
    result = 0</pre></div><p class="calibre8">The <code class="email">tf.case</code> equivalent to the previous statement for conditional execution in a TensorFlow graph would then be implemented as follows:</p><div class="informalexample"><pre class="programlisting">f1 = lambda: tf.constant(1)
f2 = lambda: tf.constant(0)
result = tf.case([(tf.less(x, y), f1)], default=f2)</pre></div><p class="calibre8">Similarly, we can add a <code class="email">while</code> loop to a TensorFlow graph that increments the <code class="email">i</code> variable by 1 until a threshold value (<code class="email">threshold</code>) is reached, as follows:</p><div class="informalexample"><pre class="programlisting">i = tf.constant(0)
threshold = 100
c = lambda i: tf.less(i, 100)
b = lambda i: tf.add(i, 1)
r = tf.while_loop(cond=c, body=b, loop_vars=[i])</pre></div><p class="calibre8">You can of course check out the official documentation for more information on the various control flow operators: <a class="calibre1" href="https://www.tensorflow.org/api_guides/python/control_flow_ops">https://www.tensorflow.org/api_guides/python/control_flow_ops</a>.</p><p class="calibre8">You may have noticed that these computation graphs are built by TensorBoard, so now is a great time to take a good look at TensorBoard in the next section.</p></div></div>

<div id="calibre_link-524" class="calibre">
<div id="calibre_link-2418" class="calibre10"></div><div class="book" title="Visualizing the graph with TensorBoard"><div class="book" id="calibre_link-181"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2419"><a id="calibre_link-2420" class="calibre1"></a>Visualizing the graph with TensorBoard</h1></div></div></div><p class="calibre8">A great feature of <a id="calibre_link-2421" class="calibre1"></a>TensorFlow is <a id="calibre_link-2422" class="calibre1"></a>TensorBoard, which is a module for visualizing the graph as well as visualizing the learning of a model. Visualizing the graph allows us to see the connection between nodes, explore their dependencies, and debug the model if needed.</p><p class="calibre8">So let's visualize a network that we've already built, one which consists of a generator and a classifier part. We'll repeat some code that we previously used for defining the helper functions. So, revisit the <span class="strong"><em class="calibre9">Reusing variables</em></span> section earlier in this chapter, for the function definitions of <code class="email">build_generator</code> and <code class="email">build_classifier</code>. Using these two helper functions, we will build the graph as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; batch_size=64
&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt;
&gt;&gt;&gt; with g.as_default():
...     tf_X = tf.placeholder(shape=(batch_size, 100),
...                           dtype=tf.float32,
...                           name='tf_X')
...
...     ## build the generator
...     with tf.variable_scope('generator'):
...         gen_out1 = build_generator(data=tf_X,
...                                    n_hidden=50)
...     
...     ## build the classifier
...     with tf.variable_scope('classifier') as scope:
...         ## classifier for the original data:
...         cls_out1 = build_classifier(data=tf_X,
...                                     labels=tf.ones(
...                                        shape=batch_size))
...         
...         ## reuse the classifier for generated data
...         scope.reuse_variables()
...         cls_out2 = build_classifier(data=gen_out1[1],
...                                     labels=tf.zeros(
...                                         shape=batch_size))</pre></div><p class="calibre8">Note that no changes were needed so far for building the graph. So after building the graph, its visualization is straightforward. The following lines of code export the graph for visualization purposes:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     sess.run(tf.global_variables_initializer())
...     
...     file_writer = tf.summary.FileWriter(
...                              logdir='./logs/', graph=g)</pre></div><p class="calibre8">This will create a new directory: <code class="email">logs/</code>. Now, we just need to run the following command in a Linux or macOS Terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">tensorboard --logdir logs/</strong></span>
</pre></div><p class="calibre8">This command will print a message, which is a URL address. You can try launching TensorBoard by copying the link, for example, <code class="email">http://localhost:6006/#graphs</code>, and pasting it into your browser's address bar. You should see the graph that corresponds to this model, as shown in the following figure:</p><div class="mediaobject"><img src="images/00507.jpeg" alt="Visualizing the graph with TensorBoard" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The large <a id="calibre_link-2423" class="calibre1"></a>rectangular boxes indicate <a id="calibre_link-2424" class="calibre1"></a>the two subnetworks that we built: generator and classifier. Since we used the <code class="email">tf.variable_scope</code> function when we built this graph, all the components of each of these subnetworks are grouped into those rectangular boxes, as shown in the previous figure.</p><p class="calibre8">We can <a id="calibre_link-2425" class="calibre1"></a>expand these boxes to explore their <a id="calibre_link-2426" class="calibre1"></a>details: using your mouse, click on the plus sign on the top-right corner of these boxes to expand them. Doing this, we can see the details of the generator subnetwork, as shown in the following figure:</p><div class="mediaobject"><img src="images/00518.jpeg" alt="Visualizing the graph with TensorBoard" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">By exploring this graph, we can easily see that the generator has two weight tensors, named <code class="email">w1</code> and <code class="email">w2</code>. Next, let's expand the classifier subnetwork, as shown in the following figure:</p><div class="mediaobject"><img src="images/00535.jpeg" alt="Visualizing the graph with TensorBoard" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As you can see<a id="calibre_link-2427" class="calibre1"></a> in this figure, the <a id="calibre_link-2428" class="calibre1"></a>classifier has two sources of input, where one input comes from the <code class="email">tf_X</code> placeholder and the other one is in fact the output of the generator subnetwork.</p></div></div>

<div id="calibre_link-539" class="calibre">
<div class="book" title="Visualizing the graph with TensorBoard">
<div class="book" title="Extending your TensorBoard experience"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2429"><a id="calibre_link-412" class="calibre1"></a>Extending your TensorBoard experience</h2></div></div></div><p class="calibre8">As an interesting exercise, we <a id="calibre_link-2430" class="calibre1"></a>suggest you use TensorBoard to visualize the different graphs we implemented throughout this chapter. For example, you could use similar steps for building the graphs, and then add extra lines for their visualization. You can also make graphs for the control flow section, which will show you the difference between graphs made by the Python <code class="email">if</code> statement and the <code class="email">tf.cond</code> function.</p><p class="calibre8">For more information and examples for graph visualization, visit the official TensorFlow tutorials page at <a class="calibre1" href="https://www.tensorflow.org/get_started/graph_viz">https://www.tensorflow.org/get_started/graph_viz</a>.</p></div></div></div>

<div id="calibre_link-561" class="calibre"><div class="book" title="Summary" id="calibre_link-413"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2431"><a id="calibre_link-2432" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, we covered in detail the key features and concepts of TensorFlow. We started with discussing TensorFlow's main features and advantages, and key TensorFlow concepts such as ranks and tensors. We then looked at TensorFlow's computation graphs, and discussed how to launch a graph in a session environment, and you learned about placeholders and variables. We then saw different ways to evaluate tensors and execute operators, using Python variables or by referring to them via their name in the graph.</p><p class="calibre8">We went further to explore some of the essential TensorFlow operators and functions for transforming tensors, such as <code class="email">tf.transpose</code>, <code class="email">tf.reshape</code>, <code class="email">tf.split</code>, and <code class="email">tf.concat</code>. Finally, we saw how to visualize a TensorFlow computation graph using TensorBoard. Visualizing computation graphs using this module can be very useful, especially when we are debugging complex models.</p><p class="calibre8">In the next chapter, we'll make use of this library to implement an advanced image classifier: a <span class="strong"><strong class="calibre2">Convolutional Neural Network</strong></span> (<span class="strong"><strong class="calibre2">CNN</strong></span>). CNNs are powerful models and have shown great performance in image classification and computer vision. We'll cover the basic operations in CNNs, and we'll implement deep convolutional networks for image classification using TensorFlow.</p></div></div>

<div id="calibre_link-591" class="calibre">
<div id="calibre_link-2433" class="calibre10"></div><div class="book" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks"><div class="book" id="calibre_link-20"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2434"><a id="calibre_link-2435" class="calibre1"></a>Chapter&nbsp;15.&nbsp;Classifying Images with Deep Convolutional Neural Networks</h1></div></div></div><p class="calibre8">In the previous chapter, we looked in depth at different aspects of the TensorFlow API, became familiar with tensors, naming variables, and operators, and learned how to work with variable scopes. In this chapter, we'll now learn about <span class="strong"><strong class="calibre2">Convolutional Neural Networks</strong></span> (<span class="strong"><strong class="calibre2">CNNs</strong></span>), and how we can implement CNNs in TensorFlow. We'll also take an interesting journey in this chapter as we apply this type of deep neural network architecture to image classification. </p><p class="calibre8">So we'll start by discussing the basic building blocks of CNNs, using a bottom-up approach. Then we'll take a deeper dive into the CNN architecture and how to implement deep CNNs in TensorFlow. Along the way we'll be covering the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Understanding convolution operations in one and two dimensions</li><li class="listitem">Learning about the building blocks of CNN architectures</li><li class="listitem">Implementing deep convolutional neural networks in TensorFlow</li></ul></div></div></div>

<div id="calibre_link-603" class="calibre">
<div class="book" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks">
<div class="book" title="Building blocks of convolutional neural networks"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2436"><a id="calibre_link-414" class="calibre1"></a>Building blocks of convolutional neural networks</h1></div></div></div><p class="calibre8">Convolutional<a id="calibre_link-2437" class="calibre1"></a> neural networks, or CNNs, are a family of models that were inspired by how the visual cortex of human brain works when recognizing objects. </p><p class="calibre8">The development of CNNs goes back to the 1990's, when Yann LeCun and his colleagues proposed a novel neural network architecture for classifying handwritten digits from images (<span class="strong"><em class="calibre9">Handwritten Digit Recognition with a Back-Propagation Network</em></span>, <span class="strong"><em class="calibre9">Y LeCun, and others</em></span>, <span class="strong"><em class="calibre9">1989</em></span>, published at <span class="strong"><em class="calibre9">Neural Information Processing Systems.(NIPS)</em></span> conference). </p><p class="calibre8">Due to the outstanding performance of CNNs for image classification tasks, they have gained a lot of attention and this led to tremendous improvements in machine learning and computer vision applications.</p><p class="calibre8">In the following<a id="calibre_link-2438" class="calibre1"></a> sections, we next see how CNNs are used as feature extraction engines, and then we'll delve into the theoretical definition of convolution and computing convolution in one and two dimensions.</p></div></div></div>

<div id="calibre_link-616" class="calibre">
<div class="book" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks">
<div class="book" title="Building blocks of convolutional neural networks">
<div class="book" title="Understanding CNNs and learning feature hierarchies"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2439"><a id="calibre_link-415" class="calibre1"></a>Understanding CNNs and learning feature hierarchies</h2></div></div></div><p class="calibre8">Successfully <a id="calibre_link-2440" class="calibre1"></a>extracting <span class="strong"><strong class="calibre2">salient (relevant) features</strong></span> is key to the performance of any machine learning algorithm, of course, and traditional machine learning models rely on input features that may come from a domain expert, or are based on computational feature extraction techniques. Neural networks are able to automatically learn the features from raw data that are most useful for a particular task. For this reason, it's common to consider a neural network as a feature extraction engine: the early layers (those right after the input layer)<a id="calibre_link-2441" class="calibre1"></a> extract <span class="strong"><strong class="calibre2">low-level features</strong></span>. </p><p class="calibre8">Multilayer neural networks, and in particular, deep convolutional neural networks, construct a <a id="calibre_link-2442" class="calibre1"></a>so-called <span class="strong"><strong class="calibre2">feature hierarchy</strong></span> by combining the low-level features in a layer-wise fashion to form high-level features. For example, if we're dealing with images, then low-level features, such as edges and blobs, are extracted from the earlier layers, which are combined together to form high-level features &ndash; as object shapes like a building, a car, or a dog. </p><p class="calibre8">As you can see in the following image, a CNN<a id="calibre_link-2443" class="calibre1"></a> computes <span class="strong"><strong class="calibre2">feature maps</strong></span> from an input image, where each element comes from a local patch of pixels in the input image:</p><div class="mediaobject"><img src="images/00547.jpeg" alt="Understanding CNNs and learning feature hierarchies" class="calibre11" /><div class="caption"><p class="calibre28">(Photo by Alexander Dummer on Unsplash)</p></div></div><p class="calibre12"> </p><p class="calibre8">This local patch of pixels is referred to as the<a id="calibre_link-2444" class="calibre1"></a> <span class="strong"><strong class="calibre2">local receptive field</strong></span>. CNNs will usually perform very well for image-related tasks, and that's largely due to two important ideas:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Sparse-connectivity</strong></span>: A <a id="calibre_link-2445" class="calibre1"></a>single element in the feature map is connected to only a small patch of pixels. (This is very different from connecting to the whole input image, in the case of perceptrons. You may find it useful to look back and compare how we implemented a fully connected network that connected to the whole image, in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch.</em></span>)</li><li class="listitem"><span class="strong"><strong class="calibre2">Parameter-sharing</strong></span>: The same<a id="calibre_link-2446" class="calibre1"></a> weights are used for different patches of the input image.</li></ul></div><p class="calibre8">As a direct consequence of these two ideas, the number of weights (parameters) in the network decreases dramatically, and we see an improvement in the ability to capture <span class="strong"><strong class="calibre2">salient</strong></span> features. Intuitively, it makes sense that nearby pixels are probably more relevant to each other than pixels that are far away from each other.</p><p class="calibre8">Typically, CNNs are composed of several <span class="strong"><strong class="calibre2">Convolutional</strong></span> (<span class="strong"><strong class="calibre2">conv</strong></span>) layers and subsampling (also known as <span class="strong"><strong class="calibre2">Pooling</strong></span> (<span class="strong"><strong class="calibre2">P</strong></span>)) layers that are followed by one or more <span class="strong"><strong class="calibre2">Fully Connected</strong></span> (<span class="strong"><strong class="calibre2">FC</strong></span>) layers at the end. The fully connected layers are essentially a multilayer perceptron, where every input unit <span class="strong"><em class="calibre9">i</em></span> is connected to every output unit <span class="strong"><em class="calibre9">j</em></span> with weight <span class="strong"><img src="images/00455.jpeg" alt="Understanding CNNs and learning feature hierarchies" class="calibre14" /></span> (which we learned about in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>).</p><p class="calibre8">Please note that subsampling layers, commonly known <a id="calibre_link-2447" class="calibre1"></a>as <span class="strong"><strong class="calibre2">pooling layers</strong></span>, do not have any learnable parameters; for instance, there are no weights or bias units in pooling layers. However, both convolution and fully connected layers have such weights and biases. </p><p class="calibre8">In the following sections, we'll study convolutional and pooling layers in more detail and see how they work. To understand how convolution operations work, let's start with a convolution in one dimension before working through the typical two-dimensional cases as applications for two-dimensional images later.</p></div></div></div></div>

<div id="calibre_link-633" class="calibre">
<div class="book" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks">
<div class="book" title="Building blocks of convolutional neural networks">
<div class="book" title="Performing discrete convolutions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2448"><a id="calibre_link-416" class="calibre1"></a>Performing discrete convolutions</h2></div></div></div><p class="calibre8">A <span class="strong"><strong class="calibre2">discrete convolution</strong></span> (or simply <span class="strong"><strong class="calibre2">convolution</strong></span>) is a <a id="calibre_link-2449" class="calibre1"></a>fundamental operation in a CNN. Therefore, it's important to understand how this operation works. In this section, we'll learn the mathematical definition and discuss some of the <span class="strong"><strong class="calibre2">naive</strong></span> algorithms<a id="calibre_link-2450" class="calibre1"></a> to compute convolutions of two one-dimensional vectors or two two-dimensional matrices. </p><p class="calibre8">Please note that this <a id="calibre_link-2451" class="calibre1"></a>description is solely for understanding how a convolution works. Indeed, much more efficient implementations of convolutional operations already exist in packages such as TensorFlow, as we will see later in this chapter.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2452" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Mathematical notation</strong></span>
</p><p class="calibre8">In this chapter, we will use subscripts to denote the size of a multidimensional array; for example, <span class="strong"><img src="images/00560.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span> is a two-dimensional array of size <span class="strong"><img src="images/00574.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span>. We use brackets <span class="strong"><img src="images/00592.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span> to denote the indexing of a multidimensional array. For example, <span class="strong"><img src="images/00664.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span> means the element at index <span class="strong"><img src="images/00606.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span> of matrix <span class="strong"><img src="images/00620.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span>. Furthermore, note that we use a special symbol <span class="strong"><img src="images/00632.jpeg" alt="Performing discrete convolutions" class="calibre14" /></span> to denote the convolution operation between two vectors or matrices, which is not to be confused with the multiplication operator <span class="strong"><em class="calibre9">*</em></span> in Python.</p></div><div class="book" title="Performing a discrete convolution in one dimension"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-417" class="calibre1"></a>Performing a discrete convolution in one dimension</h3></div></div></div><p class="calibre8">Let's start with<a id="calibre_link-2453" class="calibre1"></a> some basic definitions and <a id="calibre_link-2454" class="calibre1"></a>notations we are going to use. A discrete convolution for two one-dimensional vectors <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">w</strong></span> is denoted by <span class="strong"><img src="images/00913.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span>, in which vector <span class="strong"><strong class="calibre2">x</strong></span> is our input (sometimes <a id="calibre_link-2455" class="calibre1"></a>called <span class="strong"><strong class="calibre2">signal</strong></span>) and <span class="strong"><strong class="calibre2">w</strong></span> is called<a id="calibre_link-2456" class="calibre1"></a> the <span class="strong"><strong class="calibre2">filter</strong></span> <a id="calibre_link-2457" class="calibre1"></a>or <span class="strong"><strong class="calibre2">kernel</strong></span>. A discrete convolution is mathematically defined as follows:</p><div class="mediaobject"><img src="images/00652.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, the brackets [] are used to denote the indexing for vector elements. The index <span class="strong"><em class="calibre9">i</em></span> runs through each element of the output vector <span class="strong"><strong class="calibre2">y</strong></span>. There are two odd things in the preceding formula that we need to clarify: <span class="strong"><img src="images/00669.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> to <span class="strong"><img src="images/00690.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> indices and negative indexing for <span class="strong"><strong class="calibre2">x</strong></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2458" class="calibre1"></a>Tip</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Cross-correlation</strong></span>
</p><p class="calibre8">Cross-correlation (or simply correlation) between<a id="calibre_link-2459" class="calibre1"></a> an input vector and a filter is denoted by <span class="strong"><img src="images/00707.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> and is very much like a sibling for a convolution with a small difference; the difference is that in cross-correlation, the multiplication is performed in the same direction. Therefore, it is not required to rotate the filter matrix <span class="strong"><strong class="calibre2">w</strong></span> in each dimension. Mathematically, cross-correlation is defined as follows:</p><div class="mediaobject1"><img src="images/00709.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The same rules for padding and stride may be applied to cross-correlation as well.</p></div><p class="calibre8">The first issue where the<a id="calibre_link-2460" class="calibre1"></a> sum runs through indices from <span class="strong"><img src="images/00669.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> to <span class="strong"><img src="images/00690.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> seems odd mainly because in machine learning applications, we always <a id="calibre_link-2461" class="calibre1"></a>deal with finite feature vectors. For example, if <span class="strong"><strong class="calibre2">x</strong></span> has 10 features with indices <span class="strong"><img src="images/00723.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span>, then indices <span class="strong"><img src="images/00736.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> and <span class="strong"><img src="images/00748.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> are out of bounds for <span class="strong"><strong class="calibre2">x</strong></span>. Therefore, to correctly compute the summation shown in the preceding formula, it is assumed that <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">w</strong></span> are filled with zeros. This will result in an output vector <span class="strong"><strong class="calibre2">y</strong></span> that also has infinite size with lots of zeros as well. Since this is not useful in practical situations, <span class="strong"><strong class="calibre2">x</strong></span> is padded only with a finite number of zeros.</p><p class="calibre8">This process is called <span class="strong"><strong class="calibre2">zero-padding</strong></span>
<a id="calibre_link-2462" class="calibre1"></a> or<a id="calibre_link-2463" class="calibre1"></a> simply <span class="strong"><strong class="calibre2">padding</strong></span>. Here, the number of zeros padded on each side is denoted by <span class="strong"><em class="calibre9">p</em></span>. An example padding of a one-dimensional vector <span class="strong"><strong class="calibre2">x</strong></span> is shown in the following figure:</p><div class="mediaobject"><img src="images/00761.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Let's assume that the <a id="calibre_link-2464" class="calibre1"></a>original input <span class="strong"><strong class="calibre2">x</strong></span> and filter <span class="strong"><strong class="calibre2">w</strong></span> have <span class="strong"><em class="calibre9">n</em></span> and <span class="strong"><em class="calibre9">m</em></span> elements, respectively, where <span class="strong"><img src="images/00766.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span>. Therefore, the padded vector <span class="strong"><img src="images/00781.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> has size <span class="strong"><em class="calibre9">n + 2p</em></span>. Then, the practical formula for computing a discrete convolution will change<a id="calibre_link-2465" class="calibre1"></a> to the following:</p><div class="mediaobject"><img src="images/00793.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Now that we have solved the infinite index issue, the second issue is indexing <span class="strong"><strong class="calibre2">x</strong></span> with <span class="strong"><em class="calibre9">i + m - k</em></span>. The important point to notice here is that <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">w</strong></span> are indexed in different directions in this summation. For this reason, we can flip one of those vectors, <span class="strong"><strong class="calibre2">x</strong></span> or <span class="strong"><strong class="calibre2">w</strong></span>, after they are padded. Then, we can simply compute their dot product.</p><p class="calibre8">Let's assume we flip the filter <span class="strong"><strong class="calibre2">w</strong></span> to get the rotated filter <span class="strong"><img src="images/00804.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span>. Then, the dot product <span class="strong"><img src="images/00683.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> is computed to get one element <span class="strong"><img src="images/00826.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span>, where <span class="strong"><img src="images/00841.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> is a patch of <span class="strong"><strong class="calibre2">x</strong></span> with size <span class="strong"><em class="calibre9">m</em></span>.</p><p class="calibre8">This operation is repeated like in a sliding window approach to get all the output elements. The following figure provides an example with <span class="strong"><strong class="calibre2">x</strong></span> = (3,2,1,7,1,2,5,4) and <span class="strong"><img src="images/00854.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> so that the first three output elements are computed:</p><div class="mediaobject"><img src="images/00862.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">You can see in the preceding<a id="calibre_link-2466" class="calibre1"></a> example that the padding size is zero (<span class="strong"><em class="calibre9">p = 0</em></span>). Notice that the rotated filter <span class="strong"><img src="images/00804.jpeg" alt="Performing a discrete convolution in one dimension" class="calibre14" /></span> is shifted by two cells each time we shift. This <a id="calibre_link-2467" class="calibre1"></a>
<span class="strong"><strong class="calibre2">shift</strong></span> is another hyperparameter of a convolution, the <span class="strong"><strong class="calibre2">stride</strong></span> <span class="strong"><em class="calibre9">s</em></span>. In this example, the stride is two, <span class="strong"><em class="calibre9">s = 2</em></span>. Note that the stride has to be a positive number smaller than the size of the input vector. We'll talk more about padding and strides in the next section!</p></div><div class="book" title="The effect of zero-padding in a convolution"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-418" class="calibre1"></a>The effect of zero-padding in a convolution</h3></div></div></div><p class="calibre8">So far here, we've used zero-padding in <a id="calibre_link-2468" class="calibre1"></a>convolutions to compute finite-sized output vectors. Technically, padding can be applied with any <span class="strong"><img src="images/00878.jpeg" alt="The effect of zero-padding in a convolution" class="calibre14" /></span>. Depending on the choice <span class="strong"><em class="calibre9">p</em></span>, boundary cells may be treated differently than the cells located in the middle of <span class="strong"><strong class="calibre2">x</strong></span>.</p><p class="calibre8">Now consider an example where <span class="strong"><em class="calibre9">n = 5, m = 3</em></span>. Then, <span class="strong"><em class="calibre9">p = 0</em></span>, <span class="strong"><strong class="calibre2">x</strong></span>[0] is only used in computing one output element (for instance, <span class="strong"><strong class="calibre2">y</strong></span>[0]), while <span class="strong"><strong class="calibre2">x</strong></span>[1] is used in the computation of two output elements (for instance, <span class="strong"><strong class="calibre2">y</strong></span>[0] and <span class="strong"><strong class="calibre2">y</strong></span>[1]). So, you can see that this different treatment of elements of <span class="strong"><em class="calibre9">x</em></span> can artificially put more emphasis on the middle element, <span class="strong"><strong class="calibre2">x</strong></span>[2], since it has appeared in most computations. We can avoid this issue if we choose <span class="strong"><em class="calibre9">p = 2</em></span>, in which case, each element of <span class="strong"><em class="calibre9">x</em></span> will be involved in computing three elements of <span class="strong"><strong class="calibre2">y</strong></span>.</p><p class="calibre8">Furthermore, the size of the output <span class="strong"><strong class="calibre2">y</strong></span> also depends on the choice of the padding strategy we use. There are three modes of padding that are commonly used in practice: <span class="strong"><strong class="calibre2">full</strong></span>, <span class="strong"><strong class="calibre2">same</strong></span>, and <span class="strong"><strong class="calibre2">valid</strong></span>:</p><div class="book"><ul class="itemizedlist"><li class="listitem">In the <span class="strong"><strong class="calibre2">full</strong></span> mode, the<a id="calibre_link-2469" class="calibre1"></a> padding parameter <span class="strong"><em class="calibre9">p</em></span> is set to <span class="strong"><em class="calibre9">p = m - 1</em></span>. Full padding increases the dimensions of the output; thus, it is rarely used in convolutional neural network architectures.</li><li class="listitem"><span class="strong"><strong class="calibre2">Same</strong></span> padding is<a id="calibre_link-2470" class="calibre1"></a> usually used if you want to have the size of the output the same as the input vector <span class="strong"><strong class="calibre2">x</strong></span>. In this case, the padding parameter <span class="strong"><em class="calibre9">p</em></span> is computed according to the filter size, along with the requirement that the input size and output size are the same.</li><li class="listitem">Finally, computing a convolution in the <span class="strong"><strong class="calibre2">valid</strong></span> mode<a id="calibre_link-2471" class="calibre1"></a> refers to the case where <span class="strong"><em class="calibre9">p = 0</em></span> (no padding).</li></ul></div><p class="calibre8">The following figure <a id="calibre_link-2472" class="calibre1"></a>illustrates the three different padding modes for a simple 5 x 5 pixel input with a kernel size of 3 x 3 and a stride of 1:</p><div class="mediaobject"><img src="images/00897.jpeg" alt="The effect of zero-padding in a convolution" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The most commonly used padding mode in convolutional neural networks is <span class="strong"><strong class="calibre2">same</strong></span> padding. One of its advantages over the other padding modes is that same padding preserves the height and width of the input images or tensors, which makes designing a network architecture more convenient.</p><p class="calibre8">One big disadvantage of the <span class="strong"><strong class="calibre2">valid</strong></span> padding versus <span class="strong"><strong class="calibre2">full</strong></span> and <span class="strong"><strong class="calibre2">same</strong></span> padding, for example, is that the volume of the tensors would decrease substantially in neural networks with many layers, which can be detrimental to the network performance.</p><p class="calibre8">In practice, it is <a id="calibre_link-2473" class="calibre1"></a>recommended that you preserve the spatial size using same padding for the convolutional layers and decrease the spatial size via pooling layers instead. As for the full padding, its size results in an output larger than the input size. Full padding is usually used in signal processing applications where it is important to minimize boundary effects. However, in deep learning context, boundary effect is not usually an issue, so we rarely see full padding.</p></div><div class="book" title="Determining the size of the convolution output"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-419" class="calibre1"></a>Determining the size of the convolution output</h3></div></div></div><p class="calibre8">The output size of a <a id="calibre_link-2474" class="calibre1"></a>convolution is determined by the total number of times that we shift the filter <span class="strong"><strong class="calibre2">w</strong></span> along the input vector. Let's assume that the input vector has size <span class="strong"><em class="calibre9">n</em></span> and the filter is of size <span class="strong"><em class="calibre9">m</em></span>. Then, the size of the output resulting from <span class="strong"><img src="images/00906.jpeg" alt="Determining the size of the convolution output" class="calibre14" /></span> with padding <span class="strong"><em class="calibre9">p</em></span> and stride <span class="strong"><em class="calibre9">s</em></span> is determined as follows:</p><div class="mediaobject"><img src="images/00914.jpeg" alt="Determining the size of the convolution output" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00935.jpeg" alt="Determining the size of the convolution output" class="calibre14" /></span> denotes the floor operation:</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2475" class="calibre1"></a>Tip</h3><p class="calibre8">The floor operation returns the largest integer that is equal or smaller to the input, for example:</p><div class="mediaobject1"><img src="images/00953.jpeg" alt="Determining the size of the convolution output" class="calibre11" /></div><p class="calibre12"> </p></div><p class="calibre8">Consider the following two cases:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Compute the output size for an input vector of size 10 with a convolution kernel of size 5, padding 2, and stride 1:<div class="mediaobject"><img src="images/00473.jpeg" alt="Determining the size of the convolution output" class="calibre11" /></div><p class="calibre26"> </p><p class="calibre16">(Note that in this case, the output size turns out to be the same as the input; therefore, we conclude this as <span class="strong"><strong class="calibre2">mode='same'</strong></span>)</p></li><li class="listitem">How can the output size change for the same input vector, but have a kernel of size 3, and stride 2?<div class="mediaobject"><img src="images/00483.jpeg" alt="Determining the size of the convolution output" class="calibre11" /></div><p class="calibre26"> </p></li></ul></div><p class="calibre8">If you are interested to learn more about the size of the convolution output, we recommend the manuscript <span class="strong"><em class="calibre9">A guide to convolution arithmetic for deep learning</em></span>, <span class="strong"><em class="calibre9">Vincent Dumoulin and Francesco Visin</em></span>, <span class="strong"><em class="calibre9">2016</em></span>, which is freely available at <a class="calibre1" href="https://arxiv.org/abs/1603.07285">https://arxiv.org/abs/1603.07285</a>.</p><p class="calibre8">Finally, in order to <a id="calibre_link-2476" class="calibre1"></a>learn how to compute convolutions in one dimension, a naÃ¯ve implementation is shown in the following code block, and the results are compared with the <code class="email">numpy.convolve</code> function. The code is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; def conv1d(x, w, p=0, s=1):
...     w_rot = np.array(w[::-1])
...     x_padded = np.array(x)
...     if p &gt; 0:
...         zero_pad = np.zeros(shape=p)
...         x_padded = np.concatenate([zero_pad, 
...                                    x_padded, 
...                                    zero_pad])
...     res = []
...     for i in range(0, int(len(x)/s),s):
...         res.append(np.sum(x_padded[i:i+w_rot.shape[0]] *
...                            w_rot))
...     return np.array(res)

&gt;&gt;&gt; ## Testing:
&gt;&gt;&gt; x = [1, 3, 2, 4, 5, 6, 1, 3]
&gt;&gt;&gt; w = [1, 0, 3, 1, 2]

&gt;&gt;&gt; print('Conv1d Implementation:', 
... conv1d(x, w, p=2, s=1))
Conv1d Implementation: [  5. 14. 16. 26. 24. 34. 19. 22.]

&gt;&gt;&gt; print('Numpy Results:', 
... np.convolve(x, w, mode='same'))
Numpy Results: [ 5 14 16 26 24 34 19 22]</pre></div><p class="calibre8">So far, here, we have explored the convolution in 1D. We started with 1D case to make the concepts easier to understand. In the next section, we will extend this to two dimensions.</p></div><div class="book" title="Performing a discrete convolution in 2D"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-420" class="calibre1"></a>Performing a discrete convolution in 2D</h3></div></div></div><p class="calibre8">The concepts you learned in the <a id="calibre_link-2477" class="calibre1"></a>previous sections are <a id="calibre_link-2478" class="calibre1"></a>easily extendible to two dimensions. When we deal with two-dimensional input, such as a matrix <span class="strong"><img src="images/00468.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span> and the filter matrix <span class="strong"><img src="images/00496.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>, where <span class="strong"><img src="images/00505.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span> and <span class="strong"><img src="images/00432.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>, then the matrix <span class="strong"><img src="images/00517.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span> is the result of 2D convolution of <span class="strong"><strong class="calibre2">X</strong></span> with <span class="strong"><strong class="calibre2">W</strong></span>. This is mathematically defined as follows:</p><div class="mediaobject"><img src="images/00534.jpeg" alt="Performing a discrete convolution in 2D" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Notice that if you omit one of the dimensions, the remaining formula is exactly the same as the one we used previously to compute the convolution in 1D. In fact, all the previously mentioned techniques, such as zero-padding, rotating the filter matrix, and the use of strides, are also applicable to 2D convolutions, provided that they are extended to both the dimensions independently. The following example illustrates the computation of a 2D convolution between an input matrix <span class="strong"><img src="images/00546.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>, a kernel matrix <span class="strong"><img src="images/00556.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>, padding <span class="strong"><img src="images/00566.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>, and stride <span class="strong"><img src="images/00573.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>. According to the specified padding, one layer of zeros are padded on each side of the input matrix, which results in the padded matrix <span class="strong"><img src="images/00588.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span>, as follows:</p><div class="mediaobject"><img src="images/00601.jpeg" alt="Performing a discrete convolution in 2D" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">With the preceding filter, the rotated filter will be:</p><div class="mediaobject"><img src="images/00605.jpeg" alt="Performing a discrete convolution in 2D" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that this rotation is <span class="strong"><em class="calibre9">not</em></span> the same as the transpose matrix. To get the rotated filter in NumPy, we can write <code class="email">W_rot=W[::-1,::-1]</code>. Next, we can shift the rotated filter matrix along the padded input matrix <span class="strong"><img src="images/00619.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span> like a sliding window and compute the sum of the element-wise product, which is denoted by the <span class="strong"><img src="images/00631.jpeg" alt="Performing a discrete convolution in 2D" class="calibre14" /></span> operator in the following figure:</p><div class="mediaobject"><img src="images/00646.jpeg" alt="Performing a discrete convolution in 2D" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The result will be the 2 x 2 matrix <span class="strong"><strong class="calibre2">Y</strong></span>.</p><p class="calibre8">Let's also implement the 2D<a id="calibre_link-2479" class="calibre1"></a> convolution<a id="calibre_link-2480" class="calibre1"></a> according to the <span class="strong"><strong class="calibre2">naÃ¯ve</strong></span> algorithm described. The <code class="email">scipy.signal</code> package provides a way to compute 2D convolution via the <code class="email">scipy.signal.convolve2d</code> function:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import scipy.signal

&gt;&gt;&gt; def conv2d(X, W, p=(0, 0), s=(1, 1)):
...     W_rot = np.array(W)[::-1,::-1]
...     X_orig = np.array(X)
...     n1 = X_orig.shape[0] + 2*p[0]
...     n2 = X_orig.shape[1] + 2*p[1]
...     X_padded = np.zeros(shape=(n1, n2))
...     X_padded[p[0]:p[0]+X_orig.shape[0], 
...              p[1]:p[1]+X_orig.shape[1]] = X_orig
...
...     res = []
...     for i in range(0, int((X_padded.shape[0] - \
...                            W_rot.shape[0])/s[0])+1, s[0]):
...         res.append([])
...         for j in range(0, int((X_padded.shape[1] - \
...                                W_rot.shape[1])/s[1])+1, s[1]):
...             X_sub = X_padded[i:i+W_rot.shape[0],
...                              j:j+W_rot.shape[1]]
...             res[-1].append(np.sum(X_sub * W_rot))
...     return(np.array(res))
    
&gt;&gt;&gt; X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]
&gt;&gt;&gt; W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]

&gt;&gt;&gt; print('Conv2d Implementation:\n',
...       conv2d(X, W, p=(1, 1), s=(1, 1)))
Conv2d Implementation: 
 [[ 11.  25.  32.  13.]
 [ 19.  25.  24.  13.]
 [ 13.  28.  25.  17.]
 [ 11.  17.  14.   9.]]


&gt;&gt;&gt; print('SciPy Results:\n', 
...       scipy.signal.convolve2d(X, W, mode='same'))
SciPy Results:         
 [[11 25 32 13]
 [19 25 24 13]
 [13 28 25 17]
 [11 17 14  9]]</pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2481" class="calibre1"></a>Tip</h3><p class="calibre8">We provided a naÃ¯ve<a id="calibre_link-2482" class="calibre1"></a> implementation to <a id="calibre_link-2483" class="calibre1"></a>compute a 2D convolution for the purpose of understanding the concepts. However, this implementation is very inefficient in terms of memory requirements and computational complexity. Therefore, it should not be used in real-world neural network applications. </p><p class="calibre8">In recent years, much more efficient algorithms have been developed that use the Fourier transformation for computing convolutions. It is also important to note that in the context of neural networks, the size of a convolution kernel is usually much smaller than the size of the input image. For example, modern CNNs usually <a id="calibre_link-2484" class="calibre1"></a>use kernel sizes such as 1 x 1, 3 x 3, or 5 x 5, for which efficient algorithms have been designed that can carry out the convolutional operations much more efficiently, such<a id="calibre_link-2485" class="calibre1"></a> as the <span class="strong"><strong class="calibre2">Winograd's Minimal Filtering</strong></span> algorithm. These <a id="calibre_link-2486" class="calibre1"></a>algorithms are beyond the scope of this book, but if you are interested to learn more, you can read the manuscript: <span class="strong"><em class="calibre9">Fast Algorithms for Convolutional Neural Networks</em></span>, <span class="strong"><em class="calibre9">Andrew Lavin and Scott Gray</em></span>, <span class="strong"><em class="calibre9">2015</em></span>, which is freely available at (<a class="calibre1" href="https://arxiv.org/abs/1509.09308">https://arxiv.org/abs/1509.09308</a>).</p></div><p class="calibre8">In the next section, we will discuss subsampling, which is another important operation often used in CNNs.</p></div></div></div></div></div>

<div id="calibre_link-652" class="calibre">
<div class="book" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks">
<div class="book" title="Building blocks of convolutional neural networks">
<div class="book" title="Subsampling"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2487"><a id="calibre_link-421" class="calibre1"></a>Subsampling</h2></div></div></div><p class="calibre8">Subsampling is<a id="calibre_link-2488" class="calibre1"></a> typically applied in two forms of pooling<a id="calibre_link-2489" class="calibre1"></a> operations in convolutional neural networks: <span class="strong"><strong class="calibre2">max-pooling</strong></span>
<a id="calibre_link-2490" class="calibre1"></a> and <span class="strong"><strong class="calibre2">mean-pooling</strong></span> (also <a id="calibre_link-2491" class="calibre1"></a>known as <span class="strong"><strong class="calibre2">average-pooling</strong></span>). The pooling layer is usually denoted by <span class="strong"><img src="images/00224.jpeg" alt="Subsampling" class="calibre14" /></span>. Here, the subscript determines the size of the neighborhood (the number of adjacent pixels in each dimension), where the max or mean operation is performed. We refer to such a <a id="calibre_link-2492" class="calibre1"></a>neighborhood as the <span class="strong"><strong class="calibre2">pooling size</strong></span>.</p><p class="calibre8">The operation is described in the following figure. Here, max-pooling takes the maximum value from a neighborhood of pixels, and mean-pooling computes their average:</p><div class="mediaobject"><img src="images/00668.jpeg" alt="Subsampling" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The advantage of pooling<a id="calibre_link-2493" class="calibre1"></a> is twofold:</p><div class="book"><ul class="itemizedlist"><li class="listitem">
Pooling (max-pooling) introduces some sort of local invariance. This means that small changes in a local neighborhood do not change the result of max-pooling. Therefore, it helps generate features that are more robust to noise in the input data. See the following example that shows max-pooling of two different input matrices <span class="strong"><img src="images/00688.jpeg" alt="Subsampling" class="calibre14" /></span> and <span class="strong"><img src="images/00706.jpeg" alt="Subsampling" class="calibre14" /></span> results in the same output:
<div class="mediaobject"><img src="images/00442.jpeg" alt="Subsampling" class="calibre11" /></div><p class="calibre26"> </p></li><li class="listitem">Pooling <a id="calibre_link-2494" class="calibre1"></a>decreases the size of features, which results in higher computational efficiency. Furthermore, reducing the number of features may reduce the degree of overfitting as well.<div class="note" title="Note"><h3 class="title2"><a id="calibre_link-2495" class="calibre1"></a>Note</h3><p class="calibre8">Traditionally, pooling is assumed to be nonoverlapping. Pooling is typically performed on nonoverlapping neighborhoods, which can be done by setting the stride parameter equal to the pooling size. For example, a nonoverlapping pooling layer <span class="strong"><img src="images/00722.jpeg" alt="Subsampling" class="calibre14" /></span> requires a stride parameter <span class="strong"><img src="images/00735.jpeg" alt="Subsampling" class="calibre14" /></span>.</p><p class="calibre8">On the other hand, overlapping pooling occurs if the stride is smaller than pooling size. An example where overlapping pooling is used in a convolutional network is described in <span class="strong"><em class="calibre9">ImageNet Classification with Deep Convolutional Neural Networks</em></span>, <span class="strong"><em class="calibre9">A. Krizhevsky, I. Sutskever, and G. Hinton</em></span>, <span class="strong"><em class="calibre9">2012</em></span>, which is freely available as a manuscript at <a class="calibre1" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a>.</p></div></li></ul></div></div></div></div></div>

<div id="calibre_link-28" class="calibre">
<div id="calibre_link-2496" class="calibre10"></div><div class="book" title="Putting everything together to build a CNN"><div class="book" id="calibre_link-74"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2497"><a id="calibre_link-2498" class="calibre1"></a>Putting everything together to build a CNN</h1></div></div></div><p class="calibre8">So far, we've learned about the<a id="calibre_link-2499" class="calibre1"></a> basic building blocks of convolutional neural networks. The concepts illustrated in this chapter are not really more difficult than traditional multilayer neural networks. Intuitively, we can say that the most important operation in a traditional neural network is the matrix-vector multiplication. </p><p class="calibre8">For instance, we use matrix-vector multiplications to pre-activations (or net input) as in <span class="strong"><img src="images/00747.jpeg" alt="Putting everything together to build a CNN" class="calibre14" /></span>. Here, <span class="strong"><strong class="calibre2">x</strong></span> is a column vector representing pixels, and <span class="strong"><strong class="calibre2">W</strong></span> is the weight matrix connecting the pixel inputs to each hidden unit. In a convolutional neural network, this operation is replaced by a convolution operation, as in <span class="strong"><img src="images/00760.jpeg" alt="Putting everything together to build a CNN" class="calibre14" /></span>, where <span class="strong"><strong class="calibre2">X</strong></span> is a matrix representing the pixels in a height x width arrangement. In both cases, the pre-activations are passed to an activation function to obtain the activation of a hidden unit <span class="strong"><img src="images/00765.jpeg" alt="Putting everything together to build a CNN" class="calibre14" /></span>, where <span class="strong"><img src="images/00777.jpeg" alt="Putting everything together to build a CNN" class="calibre14" /></span> is the activation function. Furthermore, recall that subsampling is another building block of a convolutional neural network, which may appear in the form of pooling, as we described in the previous section.</p></div></div>

<div id="calibre_link-475" class="calibre">
<div class="book" title="Putting everything together to build a CNN">
<div class="book" title="Working with multiple input or color channels"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2500"><a id="calibre_link-422" class="calibre1"></a>Working with multiple input or color channels</h2></div></div></div><p class="calibre8">An input sample to a <a id="calibre_link-2501" class="calibre1"></a>convolutional layer may contain one or more 2D arrays or matrices with dimensions <span class="strong"><img src="images/00792.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> (for example, the image height and width in pixels). These <span class="strong"><img src="images/00792.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> matrices are called <span class="strong"><strong class="calibre2">channels</strong></span>. Therefore, using multiple channels as input to a convolutional layer requires us to use a rank-3 tensor or a three-dimensional array: <span class="strong"><img src="images/00803.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>, where <span class="strong"><img src="images/00814.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> is the number of input channels.</p><p class="calibre8">For example, let's consider images as<a id="calibre_link-2502" class="calibre1"></a> input to the first layer of a CNN. If the image is colored and uses the RGB color mode, then <span class="strong"><img src="images/00830.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> (for the red, green, and blue color channels in RGB). However, if the image is in grayscale, then we have <span class="strong"><img src="images/00837.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> because there is only one channel with the grayscale pixel intensity values.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2503" class="calibre1"></a>Tip</h3><p class="calibre8">When we work with images, we can read images into NumPy arrays using the <code class="email">'uint8'</code> (unsinged 8-bit integer) data type to reduce memory usage compared to 16-bit, 32-bit, or 64-bit integer types, for example. Unsigned 8-bit integers take values in the range [0, 255], which are sufficient to store the pixel information in RGB images, which also take values in the same range.</p><p class="calibre8">Next, let's look at an example of how we can read in an image into our Python session using SciPy. However, please note that reading images with SciPy requires that you have the <span class="strong"><strong class="calibre2">Python Imaging Library</strong></span> (<span class="strong"><strong class="calibre2">PIL</strong></span>)<a id="calibre_link-2504" class="calibre1"></a> package installed. We can install Pillow (<a class="calibre1" href="https://python-pillow.org">https://python-pillow.org</a>), a more user-friendly fork of PIL, to satisfy those requirements, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">pip install pillow</strong></span>
</pre></div><p class="calibre8">Once Pillow is installed, we can use the <code class="email">imread</code> function from the <code class="email">scipy.misc</code> module to read an RGB image (this example image is located in the code bundle folder that is provided with this chapter at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition/tree/master/code/ch15">https://github.com/rasbt/python-machine-learning-book-2nd-edition/tree/master/code/ch15</a>):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import scipy.misc
&gt;&gt;&gt; img = scipy.misc.imread('./example-image.png',
...                         mode='RGB')
&gt;&gt;&gt; print('Image shape:', img.shape)
Image shape: (252, 221, 3)
&gt;&gt;&gt; print('Number of channels:', img.shape[2])
Number of channels: 3
&gt;&gt;&gt; print('Image data type:', img.dtype)
Image data type: uint8
&gt;&gt;&gt; print(img[100:102, 100:102, :])
 [[[179 134 110]
  [182 136 112]]

 [[180 135 111]
  [182 137 113]]]</pre></div></div><p class="calibre8">Now that we have <a id="calibre_link-2505" class="calibre1"></a>familiarized ourselves with the structure of input data, the next question is how can we incorporate multiple input channels in the convolution operation that we discussed in the previous sections?</p><p class="calibre8">The answer is very simple: we perform the convolution operation for each channel separately and then add the results together using the matrix summation. The convolution associated with each channel (<span class="strong"><em class="calibre9">c</em></span>) has its own kernel matrix as <span class="strong"><img src="images/00853.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>. The total pre-activation result is computed in the following formula:</p><div class="mediaobject"><img src="images/00232.jpeg" alt="Working with multiple input or color channels" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The final result, <span class="strong"><strong class="calibre2">h</strong></span>, is<a id="calibre_link-2506" class="calibre1"></a> called a <span class="strong"><strong class="calibre2">feature map</strong></span>. Usually, a convolutional layer of a CNN has more than one feature map. If we use multiple feature maps, the kernel tensor becomes<a id="calibre_link-2507" class="calibre1"></a> four-dimensional: <span class="strong"><img src="images/00877.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>. Here, width x height is the kernel size, <span class="strong"><img src="images/00814.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> is the number of input channels, and <span class="strong"><img src="images/00896.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> is the number of output feature maps. So, now let's include the number of output feature maps in the preceding formula and update it as follows:</p><div class="mediaobject"><img src="images/00905.jpeg" alt="Working with multiple input or color channels" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To conclude our discussion of computing convolutions in the context of neural networks, let's look at the example in the following figure that shows a convolutional layer, followed by a pooling layer. </p><p class="calibre8">In this example, there are three input channels. The kernel tensor is four-dimensional. Each kernel matrix is denoted as <span class="strong"><img src="images/00444.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>, and there are three of them, one for each input channel. Furthermore, there are five such kernels, accounting for five output feature maps. Finally, there is a <a id="calibre_link-2508" class="calibre1"></a>pooling layer for subsampling the feature maps, as shown in the following figure:</p><div class="mediaobject"><img src="images/00934.jpeg" alt="Working with multiple input or color channels" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">How many trainable parameters exist in the preceding example?</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2509" class="calibre1"></a>Tip</h3><p class="calibre8">To illustrate the advantages of<a id="calibre_link-2510" class="calibre1"></a> convolution, <span class="strong"><strong class="calibre2">parameter-sharing</strong></span> and <span class="strong"><strong class="calibre2">sparse-connectivity</strong></span>, let's work through an example. The convolutional layer in the <a id="calibre_link-2511" class="calibre1"></a>network shown in the preceding figure is a four-dimensional tensor. So, there are <span class="strong"><img src="images/00952.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> parameters associated with the kernel. Furthermore, there is a bias vector for each output feature map of the convolutional layer. Thus, the size of the bias vector is 5. Pooling layers do not have any (trainable) parameters; therefore, we can write the following:</p><div class="mediaobject1"><img src="images/00478.jpeg" alt="Working with multiple input or color channels" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">If input tensor is of size <span class="strong"><img src="images/00482.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>, assuming that the convolution is performed with <span class="strong"><strong class="calibre2">mode='same'</strong></span>, then the output feature maps would be of size <span class="strong"><img src="images/00467.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>.</p><p class="calibre8">Note that this number is much smaller than the case if we wanted to have a fully connected layer instead of the convolution layer. In the case of a fully connected layer, the number of parameters for the weight matrix to reach the same number of output units would have been as follows:</p><div class="mediaobject1"><img src="images/00038.jpeg" alt="Working with multiple input or color channels" class="calibre11" /></div><p class="calibre12"> </p></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2512" class="calibre1"></a>Tip</h3><p class="calibre8">Given that <span class="strong"><img src="images/00811.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span> and <span class="strong"><img src="images/00875.jpeg" alt="Working with multiple input or color channels" class="calibre14" /></span>, we can see that the difference in the number of trainable parameters is huge.</p></div><p class="calibre8">In the next section, we will talk about how to regularize a neural network.</p></div></div></div>

<div id="calibre_link-95" class="calibre">
<div class="book" title="Putting everything together to build a CNN">
<div class="book" title="Regularizing a neural network with dropout"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2513"><a id="calibre_link-423" class="calibre1"></a>Regularizing a neural network with dropout</h2></div></div></div><p class="calibre8">Choosing the size of a <a id="calibre_link-2514" class="calibre1"></a>network, whether we are dealing<a id="calibre_link-2515" class="calibre1"></a> with a traditional (fully connected) neural network or a CNN, has always been a challenging problem. For instance, the size of a weight matrix and the number of layers need to be tuned to achieve a reasonably good performance. </p><p class="calibre8">The <span class="strong"><strong class="calibre2">capacity</strong></span> of a network refers to the level of complexity of the function that it can learn. Small networks, networks with a relatively small number of parameters, have a low capacity and are therefore likely to be <span class="strong"><strong class="calibre2">under fit</strong></span>, resulting in poor performance since they cannot learn the underlying structure of complex datasets. </p><p class="calibre8">Yet, very large networks may more easily <a id="calibre_link-2516" class="calibre1"></a>result in <span class="strong"><strong class="calibre2">overfitting</strong></span>, where the network will memorize the training data and do extremely well on the training set while achieving poor performance on the held-out test set. When we deal with real-world machine learning problems, we do not know how large the network should be <span class="strong"><strong class="calibre2">a priori</strong></span>.</p><p class="calibre8">One way to address this problem is to build a network with a relatively large capacity (in practice, we want to choose a capacity that is slightly larger than necessary) to do well on the training set. Then, to prevent overfitting, we can apply one or multiple regularization schemes to achieve good generalization performance on new data, such as the held-out test set. A popular choice for regularization is L2 regularization, which we discussed previously in this book.</p><p class="calibre8">In recent years, another <a id="calibre_link-2517" class="calibre1"></a>popular regularization technique called <span class="strong"><strong class="calibre2">dropout</strong></span> has emerged that works amazingly well for regularizing (deep) neural networks (<span class="strong"><em class="calibre9">Dropout: a simple way to prevent neural networks from overfitting</em></span>, <span class="strong"><em class="calibre9">Nitish Srivastava and. others,</em></span> <span class="strong"><em class="calibre9">Journal of Machine Learning Research 15.1</em></span>, pages 1929-1958, <span class="strong"><em class="calibre9">2014</em></span>, <a class="calibre1" href="http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf">http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf</a>). </p><p class="calibre8">Intuitively, dropout can be <a id="calibre_link-2518" class="calibre1"></a>considered as the consensus (averaging) of an ensemble of models. In ensemble learning, we train several models independently. During prediction, we then use the consensus of all the trained models. However, both training several models and collecting and averaging the output of multiple models is computationally expensive. Here, dropout offers a workaround with an efficient way to train many models at once and compute their average predictions at test or prediction time.</p><p class="calibre8">Dropout is usually applied to the hidden units of higher layers. During the training phase of a neural network, a fraction of the hidden units is <span class="strong"><strong class="calibre2">randomly</strong></span> dropped at every iteration with probability <span class="strong"><img src="images/00947.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span> (or the keep probability <span class="strong"><img src="images/00070.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span>).</p><p class="calibre8">This dropout probability is determined by the user and the common choice is <span class="strong"><img src="images/00093.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span>, as discussed in the previously mentioned article by <span class="strong"><em class="calibre9">Nitish Srivastava and others</em></span>, <span class="strong"><em class="calibre9">2014</em></span>. When dropping a certain fraction of input neurons, the weights associated with the remaining neurons are rescaled to account for the missing (dropped) neurons. </p><p class="calibre8">The effect of this random dropout forces the network to learn a redundant representation of the data. Therefore, the network cannot rely on an activation of any set of hidden units since they may be turned off at any time during training and is forced to learn more general and robust patterns from the data. </p><p class="calibre8">This random dropout can effectively prevent overfitting. The following figure shows an example of applying dropout with probability <span class="strong"><img src="images/00093.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span> during the training phase, thereby half of the neurons become inactive randomly. However, during prediction, all neurons will contribute to computing the pre-activations of the next layer.</p><div class="mediaobject"><img src="images/00150.jpeg" alt="Regularizing a neural network with dropout" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As shown here, one<a id="calibre_link-2519" class="calibre1"></a> important point to remember is that units may drop randomly during training only, while for the evaluation phase, all the hidden units <a id="calibre_link-2520" class="calibre1"></a>must be active (for instance, <span class="strong"><img src="images/00208.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span> or <span class="strong"><img src="images/00116.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span>). To ensure that the overall activations are on the same scale during training and prediction, the activations of the active neurons have to be scaled appropriately (for example, by halving the activation if the dropout probability was set to <span class="strong"><img src="images/00093.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span>).</p><p class="calibre8">However, since it is inconvenient to always scale activations when we make predictions in practice, TensorFlow and other tools scale the activations during training (for example, by doubling the activations if the dropout probability was set to <span class="strong"><img src="images/00093.jpeg" alt="Regularizing a neural network with dropout" class="calibre14" /></span>). </p><p class="calibre8">So, what is the relationship between dropout and ensemble learning? Since we drop different hidden neurons at each iteration, effectively we are training different models. When all these models are finally trained, we set the keep probability to 1 and use all the hidden units. This means we are taking the average activation from all the hidden units.</p></div></div></div>

<div id="calibre_link-128" class="calibre">
<div id="calibre_link-2521" class="calibre10"></div><div class="book" title="Implementing a deep convolutional neural network using TensorFlow"><div class="book" id="calibre_link-79"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2522"><a id="calibre_link-2523" class="calibre1"></a>Implementing a deep convolutional neural network using TensorFlow</h1></div></div></div><p class="calibre8">In <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, you <a id="calibre_link-2524" class="calibre1"></a>may recall <a id="calibre_link-2525" class="calibre1"></a>that we implemented a multilayer neural network for handwritten digit recognition problems, using different API levels of TensorFlow. You may also recall that we achieved about 97 percent accuracy. </p><p class="calibre8">So now, we want to<a id="calibre_link-2526" class="calibre1"></a> implement a CNN<a id="calibre_link-2527" class="calibre1"></a> to solve this same problem and see its predictive power in classifying handwritten digits. Note that the fully connected layers that we saw in the <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span> were able to perform well on this problem. However, in some applications, such as reading bank account numbers from handwritten digits, even tiny mistakes can be very costly. Therefore, it is crucial to reduce this error as much as possible.</p></div></div>

<div id="calibre_link-153" class="calibre">
<div class="book" title="Implementing a deep convolutional neural network using TensorFlow">
<div class="book" title="The multilayer CNN architecture"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2528"><a id="calibre_link-424" class="calibre1"></a>The multilayer CNN architecture</h2></div></div></div><p class="calibre8">The architecture of the network that we <a id="calibre_link-2529" class="calibre1"></a>are going to implement is shown in the following figure. The input is 28 x 28 grayscale images. Considering the number of channels (which is 1 for grayscale images) and a batch of input images, the input tensor's dimensions will be batchsize x 28 x 28 x 1. </p><p class="calibre8">The input data goes through two convolutional layers that have a kernel size of 5 x 5. The first convolution has 32 output feature maps, and the second one has 64 output feature maps. Each convolution layer is followed by a subsampling layer in the form of a max-pooling operation.</p><p class="calibre8">Then a fully-connected layer passes the output to a second fully-connected layer, which acts as the final <span class="strong"><em class="calibre9">softmax</em></span> output layer. The architecture of the network that we are going to implement is shown in the following figure:</p><div class="mediaobject"><img src="images/00128.jpeg" alt="The multilayer CNN architecture" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The dimensions of the tensors in each layer are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Input</strong></span>: <span class="strong"><img src="images/00145.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li><li class="listitem"><span class="strong"><strong class="calibre2">Conv_1</strong></span>: <span class="strong"><img src="images/00417.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li><li class="listitem"><span class="strong"><strong class="calibre2">Pooling_1</strong></span>: <span class="strong"><img src="images/00166.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li><li class="listitem"><span class="strong"><strong class="calibre2">Conv_2</strong></span>: <span class="strong"><img src="images/00175.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li><li class="listitem"><span class="strong"><strong class="calibre2">Pooling_2</strong></span>: <span class="strong"><img src="images/00191.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li><li class="listitem"><span class="strong"><strong class="calibre2">FC_1</strong></span>: <span class="strong"><img src="images/00204.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li><li class="listitem"><span class="strong"><strong class="calibre2">FC_2 and softmax layer</strong></span>: <span class="strong"><img src="images/00212.jpeg" alt="The multilayer CNN architecture" class="calibre14" /></span></li></ul></div><p class="calibre8">We'll implement this network<a id="calibre_link-2530" class="calibre1"></a> using two APIs: the low-level TensorFlow API and the TensorFlow Layers API. But first, let's define some helper functions at the beginning of the next section.</p></div></div></div>

<div id="calibre_link-171" class="calibre">
<div class="book" title="Implementing a deep convolutional neural network using TensorFlow">
<div class="book" title="Loading and preprocessing the data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2531"><a id="calibre_link-425" class="calibre1"></a>Loading and preprocessing the data</h2></div></div></div><p class="calibre8">If you'll recall <a id="calibre_link-2532" class="calibre1"></a>again from <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, we used a function called <code class="email">load_mnist</code> to<a id="calibre_link-2533" class="calibre1"></a> read the MNIST handwritten digit dataset. Now we need to repeat the same procedure here as well, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; #### Loading the data
&gt;&gt;&gt; X_data, y_data = load_mnist('./mnist/', kind='train')
&gt;&gt;&gt; print('Rows: {},  Columns: {}'.format(
...             X_data.shape[0], X_data.shape[1]))
&gt;&gt;&gt; X_test, y_test = load_mnist('./mnist/', kind='t10k')
&gt;&gt;&gt; print('Rows: {},  Columns: {}'.format(
...             X_test.shape[0], X_test.shape[1]))

&gt;&gt;&gt; X_train, y_train = X_data[:50000,:], y_data[:50000]
&gt;&gt;&gt; X_valid, y_valid = X_data[50000:,:], y_data[50000:]

&gt;&gt;&gt; print('Training:   ', X_train.shape, y_train.shape)
&gt;&gt;&gt; print('Validation: ', X_valid.shape, y_valid.shape)
&gt;&gt;&gt; print('Test Set:   ', X_test.shape, y_test.shape)</pre></div><p class="calibre8">We are splitting the data into a training, a validation, and a test sets. The following result shows the shape of each set:</p><div class="informalexample"><pre class="programlisting">Rows: 60000,  Columns: 784
Rows: 10000,  Columns: 784
Training:    (50000, 784) (50000,)
Validation:  (10000, 784) (10000,)
Test Set:    (10000, 784) (10000,)</pre></div><p class="calibre8">After we've loaded the data, we need a function for iterating through mini-batches of data, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def batch_generator(X, y, batch_size=64, 
...                     shuffle=False, random_seed=None):
...     
...     idx = np.arange(y.shape[0])
...     
...     if shuffle:
...         rng = np.random.RandomState(random_seed)
...         rng.shuffle(idx)
...         X = X[idx]
...         y = y[idx]
    
...     for i in range(0, X.shape[0], batch_size):
...         yield (X[i:i+batch_size, :], y[i:i+batch_size])</pre></div><p class="calibre8">This function returns a generator with a tuple for a match of samples, for instance, data <span class="strong"><em class="calibre9">X</em></span> and labels <span class="strong"><em class="calibre9">y</em></span>. We then need to normalize the data (mean centering and division by the standard deviation) for better training performance and convergence. </p><p class="calibre8">We compute the mean of each feature using the training data (<code class="email">X_train</code>) and calculate the standard deviation across all features. The reason why we don't compute the standard deviation for each feature individually is because some features (pixel positions) in image datasets such as MNIST have a constant value of 255 across all images corresponding to white pixels in a grayscale image.</p><p class="calibre8">A constant value <a id="calibre_link-2534" class="calibre1"></a>across all samples indicates no<a id="calibre_link-2535" class="calibre1"></a> variation, and therefore, the standard deviation of those features will be zero, and a result would yield the division-by-zero error, which is why we compute the standard deviation from the <code class="email">X_train</code> array using <code class="email">np.std</code> without specifying an <code class="email">axis</code> argument:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; mean_vals = np.mean(X_train, axis=0)
&gt;&gt;&gt; std_val = np.std(X_train)

&gt;&gt;&gt; X_train_centered = (X_train - mean_vals)/std_val
&gt;&gt;&gt; X_valid_centered = (X_valid - mean_vals)/std_val
&gt;&gt;&gt; X_test_centered = (X_test - mean_vals)/std_val</pre></div><p class="calibre8">Now we are ready to implement the CNN we just described. We will proceed by implementing the CNN model in TensorFlow.</p></div></div></div>

<div id="calibre_link-194" class="calibre">
<div class="book" title="Implementing a deep convolutional neural network using TensorFlow">
<div class="book" title="Implementing a CNN in the TensorFlow low-level API"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2536"><a id="calibre_link-426" class="calibre1"></a>Implementing a CNN in the TensorFlow low-level API</h2></div></div></div><p class="calibre8">For implementing a<a id="calibre_link-2537" class="calibre1"></a> CNN<a id="calibre_link-2538" class="calibre1"></a> in TensorFlow, first we define two wrapper functions to make the process of building the network simpler: a wrapper function for a convolutional layer and a function for building a fully connected layer. </p><p class="calibre8">The <a id="calibre_link-2539" class="calibre1"></a>first function for a convolution<a id="calibre_link-2540" class="calibre1"></a> layer is as follows:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf
import numpy as np

def conv_layer(input_tensor, name,
               kernel_size, n_output_channels, 
               padding_mode='SAME', strides=(1, 1, 1, 1)):
    with tf.variable_scope(name):
        ## get n_input_channels:
        ##   input tensor shape: 
        ##   [batch x width x height x channels_in]
        input_shape = input_tensor.get_shape().as_list()
        n_input_channels = input_shape[-1] 

        weights_shape = list(kernel_size) + \
                        [n_input_channels, n_output_channels]

        weights = tf.get_variable(name='_weights',
                                  shape=weights_shape)
        print(weights)
        biases = tf.get_variable(name='_biases',
                                 initializer=tf.zeros(
                                     shape=[n_output_channels]))
        print(biases)
        conv = tf.nn.conv2d(input=input_tensor, 
                            filter=weights,
                            strides=strides, 
                            padding=padding_mode)
        print(conv)
        conv = tf.nn.bias_add(conv, biases, 
                              name='net_pre-activation')
        print(conv)
        conv = tf.nn.relu(conv, name='activation')
        print(conv)
        
        return conv</pre></div><p class="calibre8">This wrapper function will do all the necessary work for building a convolutional layer, including defining the weights, biases, initializing them, and the convolution operation using the <code class="email">tf.nn.conv2d</code> function. There are four required arguments:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">input_tensor</code>: The tensor given as input to the convolutional layer</li><li class="listitem"><code class="email">name</code>: The name of the layer, which is used as the scope name</li><li class="listitem"><code class="email">kernel_size</code>: The dimensions of the kernel tensor provided as a tuple or list</li><li class="listitem"><code class="email">n_output_channels</code>: The number of output feature maps</li></ul></div><p class="calibre8">Notice that the <a id="calibre_link-2541" class="calibre1"></a>weights are<a id="calibre_link-2542" class="calibre1"></a> initialized using the Xavier (or Glorot) initialization method by default when using tf.get_variable (we discussed the Xavier/Glorot initialization scheme in <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper: The Mechanics of TensorFlow</em></span>), while the biases are initialized to zeros using the <code class="email">tf.zeros</code> function. The net pre-activations are passed to the ReLU activation function. We can print the operations and TensorFlow graph nodes to see the shape and type of tensors. Let's test this function with a simple input by defining a placeholder, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])
...     conv_layer(x, name='convtest', 
...                kernel_size=(3, 3), 
...                n_output_channels=32)
&gt;&gt;&gt;     
&gt;&gt;&gt; del g, x

&lt;tf.Variable 'convtest/_weights:0' shape=(3, 3, 1, 32) dtype=float32_ref&gt;
&lt;tf.Variable 'convtest/_biases:0' shape=(32,) dtype=float32_ref&gt;
Tensor("convtest/Conv2D:0", shape=(?, 28, 28, 32), dtype=float32)
Tensor("convtest/net_pre-activaiton:0", shape=(?, 28, 28, 32), dtype=float32)
Tensor("convtest/activation:0", shape=(?, 28, 28, 32), dtype=float32)</pre></div><p class="calibre8">The next wrapper function is for defining our fully connected layers:</p><div class="informalexample"><pre class="programlisting">def fc_layer(input_tensor, name, 
             n_output_units, activation_fn=None):
    with tf.variable_scope(name):
        input_shape = input_tensor.get_shape().as_list()[1:]
        n_input_units = np.prod(input_shape)
        if len(input_shape) &gt; 1:
            input_tensor = tf.reshape(input_tensor, 
                                      shape=(-1, n_input_units))

        weights_shape = [n_input_units, n_output_units]
        weights = tf.get_variable(name='_weights',
                                  shape=weights_shape)
        print(weights)
        biases = tf.get_variable(name='_biases',
                                 initializer=tf.zeros(
                                     shape=[n_output_units]))
        print(biases)
        layer = tf.matmul(input_tensor, weights)
        print(layer)
        layer = tf.nn.bias_add(layer, biases,
                              name='net_pre-activaiton')
        print(layer)
        if activation_fn is None:
            return layer
        
        layer = activation_fn(layer, name='activation')
        print(layer)
        return layer</pre></div><p class="calibre8">The <a id="calibre_link-2543" class="calibre1"></a>wrapper <a id="calibre_link-2544" class="calibre1"></a>function <code class="email">fc_layer</code> also builds the weights and biases, initializes them similar to the <code class="email">conv_layer</code> function, and then performs a matrix multiplication using the <code class="email">tf.matmul</code> function. The <code class="email">fc_layer</code> function has three required arguments:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">input_tensor</code>: The input tensor</li><li class="listitem"><code class="email">name</code>: The name of the layer, which is used as the scope name</li><li class="listitem"><code class="email">n_output_units</code>: The number of output units</li></ul></div><p class="calibre8">We can test this function for a simple input tensor as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; g = tf.Graph()
&gt;&gt;&gt; with g.as_default():
...     x = tf.placeholder(tf.float32, 
...                        shape=[None, 28, 28, 1])
...     fc_layer(x, name='fctest', n_output_units=32, 
...              activation_fn=tf.nn.relu)
&gt;&gt;&gt; 
&gt;&gt;&gt; del g, x
&lt;tf.Variable 'fctest/_weights:0' shape=(784, 32) dtype=float32_ref&gt;
&lt;tf.Variable 'fctest/_biases:0' shape=(32,) dtype=float32_ref&gt;
Tensor("fctest/MatMul:0", shape=(?, 32), dtype=float32)
Tensor("fctest/net_pre-activaiton:0", shape=(?, 32), dtype=float32)
Tensor("fctest/activation:0", shape=(?, 32), dtype=float32)</pre></div><p class="calibre8">The behavior of this function is a bit different for the two fully connected layers in our model. The first fully connected layer gets its input right after a convolutional layer; therefore, the input is still a 4D tensor. For the second fully connected layer, we need to flatten the input tensor using the <code class="email">tf.reshape</code> function. Furthermore, the net pre-activations from the first FC layer are passed to the ReLU activation function, but the second one corresponds to the <code class="email">logits</code>, and therefore, a linear activation must be used.</p><p class="calibre8">Now we can <a id="calibre_link-2545" class="calibre1"></a>utilize <a id="calibre_link-2546" class="calibre1"></a>these wrapper functions to build the whole convolutional network. We define a function called <code class="email">build_cnn</code> to handle the building of the CNN model, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def build_cnn():
    ## Placeholders for X and y:
    tf_x = tf.placeholder(tf.float32, shape=[None, 784],
                          name='tf_x')
    tf_y = tf.placeholder(tf.int32, shape=[None],
                          name='tf_y')

    # reshape x to a 4D tensor: 
    # [batchsize, width, height, 1]
    tf_x_image = tf.reshape(tf_x, shape=[-1, 28, 28, 1],
                            name='tf_x_reshaped')
    ## One-hot encoding:
    tf_y_onehot = tf.one_hot(indices=tf_y, depth=10,
                             dtype=tf.float32,
                             name='tf_y_onehot')

    ## 1st layer: Conv_1
    print('\nBuilding 1st layer:')
    h1 = conv_layer(tf_x_image, name='conv_1',
                    kernel_size=(5, 5), 
                    padding_mode='VALID',
                    n_output_channels=32)
    ## MaxPooling
    h1_pool = tf.nn.max_pool(h1, 
                             ksize=[1, 2, 2, 1],
                             strides=[1, 2, 2, 1], 
                             padding='SAME')
    ## 2n layer: Conv_2
    print('\nBuilding 2nd layer:')
    h2 = conv_layer(h1_pool, name='conv_2', 
                    kernel_size=(5, 5), 
                    padding_mode='VALID',
                    n_output_channels=64)
    ## MaxPooling 
    h2_pool = tf.nn.max_pool(h2, 
                             ksize=[1, 2, 2, 1],
                             strides=[1, 2, 2, 1], 
                             padding='SAME')

    ## 3rd layer: Fully Connected
    print('\nBuilding 3rd layer:')
    h3 = fc_layer(h2_pool, name='fc_3',
                  n_output_units=1024, 
                  activation_fn=tf.nn.relu)

    ## Dropout
    keep_prob = tf.placeholder(tf.float32, name='fc_keep_prob')
    h3_drop = tf.nn.dropout(h3, keep_prob=keep_prob, 
                            name='dropout_layer')

    ## 4th layer: Fully Connected (linear activation)
    print('\nBuilding 4th layer:')
    h4 = fc_layer(h3_drop, name='fc_4',
                  n_output_units=10, 
                  activation_fn=None)

    ## Prediction
    predictions = {
        'probabilities': tf.nn.softmax(h4, name='probabilities'),
        'labels': tf.cast(tf.argmax(h4, axis=1), tf.int32,
                           name='labels')
    }
    
    ## Visualize the graph with TensorBoard:

    ## Loss Function and Optimization
    cross_entropy_loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(
            logits=h4, labels=tf_y_onehot),
        name='cross_entropy_loss')

    ## Optimizer:
    optimizer = tf.train.AdamOptimizer(learning_rate)
    optimizer = optimizer.minimize(cross_entropy_loss,
                                   name='train_op')
    ## Computing the prediction accuracy
    correct_predictions = tf.equal(
        predictions['labels'], 
        tf_y, name='correct_preds')

    accuracy = tf.reduce_mean(
        tf.cast(correct_predictions, tf.float32),
        name='accuracy')</pre></div><p class="calibre8">In order to get <a id="calibre_link-2547" class="calibre1"></a>stable results, we <a id="calibre_link-2548" class="calibre1"></a>need to use a random seed for both NumPy and TensorFlow. Setting the TensorFlow random seed can be done at the graph level by placing the <code class="email">tf.set_random_seed</code> function within the graph scope, which we will see later. The following figure shows the TensorFlow graph related to our multilayer CNN as visualized by TensorBoard:</p><div class="mediaobject"><img src="images/00225.jpeg" alt="Implementing a CNN in the TensorFlow low-level API" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2549" class="calibre1"></a>Note</h3><p class="calibre8">Note that in this implementation, we used the <code class="email">tf.train.AdamOptimizer</code> function for training the CNN model. The Adam optimizer is a robust gradient-based optimization method suited for nonconvex optimization and machine learning problems. Two popular optimization methods inspired Adam: <code class="email">RMSProp</code> and <code class="email">AdaGrad</code>.</p><p class="calibre8">The key advantage of Adam is in the choice of update step size derived from the running average of gradient moments. Please feel free to read more about the Adam optimizer in the manuscript, <span class="strong"><em class="calibre9">Adam: A Method for Stochastic Optimization</em></span>, <span class="strong"><em class="calibre9">Diederik P. Kingma and Jimmy Lei Ba</em></span>, <span class="strong"><em class="calibre9">2014</em></span>. The article if freely available at <a class="calibre1" href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>.</p></div><p class="calibre8">Furthermore, we<a id="calibre_link-2550" class="calibre1"></a> will define <a id="calibre_link-2551" class="calibre1"></a>four other functions: <code class="email">save</code> and <code class="email">load</code> for saving and loading checkpoints of the trained model, <code class="email">train</code> for training the model using <code class="email">training_set</code>, and <code class="email">predict</code> to get prediction probabilities or prediction labels of the test data. The code for these functions is as follows:</p><div class="informalexample"><pre class="programlisting">def save(saver, sess, epoch, path='./model/'):
    if not os.path.isdir(path):
        os.makedirs(path)
    print('Saving model in %s' % path)
    saver.save(sess, os.path.join(path,'cnn-model.ckpt'),
               global_step=epoch)

def load(saver, sess, path, epoch):
    print('Loading model from %s' % path)
    saver.restore(sess, os.path.join(
            path, 'cnn-model.ckpt-%d' % epoch))

def train(sess, training_set, validation_set=None,
          initialize=True, epochs=20, shuffle=True,
          dropout=0.5, random_seed=None):

    X_data = np.array(training_set[0])
    y_data = np.array(training_set[1])
    training_loss = []

    ## initialize variables
    if initialize:
        sess.run(tf.global_variables_initializer())

    np.random.seed(random_seed) # for shuflling in batch_generator
    for epoch in range(1, epochs+1):
        batch_gen = batch_generator(
                        X_data, y_data, 
                        shuffle=shuffle)
        avg_loss = 0.0
        for i,(batch_x,batch_y) in enumerate(batch_gen):
            feed = {'tf_x:0': batch_x, 
                    'tf_y:0': batch_y, 
                    'fc_keep_prob:0': dropout}
            loss, _ = sess.run(
                    ['cross_entropy_loss:0', 'train_op'],
                    feed_dict=feed)
            avg_loss += loss

        training_loss.append(avg_loss / (i+1))
        print('Epoch %02d Training Avg. Loss: %7.3f' % (
            epoch, avg_loss), end=' ')
        if validation_set is not None:
            feed = {'tf_x:0': validation_set[0],
                    'tf_y:0': validation_set[1],
                    'fc_keep_prob:0': 1.0}
            valid_acc = sess.run('accuracy:0', feed_dict=feed)
            print(' Validation Acc: %7.3f' % valid_acc)
        else:
            print()

def predict(sess, X_test, return_proba=False):
    feed = {'tf_x:0': X_test, 
            'fc_keep_prob:0': 1.0}
    if return_proba:
        return sess.run('probabilities:0', feed_dict=feed)
    else:
        return sess.run('labels:0', feed_dict=feed)</pre></div><p class="calibre8">Now we can <a id="calibre_link-2552" class="calibre1"></a>create a TensorFlow <a id="calibre_link-2553" class="calibre1"></a>graph object, set the graph-level random seed, and build the CNN model in that graph, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;<code class="email">&gt;&gt; </code>## Define hyperparameters
&gt;<code class="email">&gt;&gt; </code>learning_rate = 1e-4
&gt;<code class="email">&gt;&gt; </code>random_seed = 123
&gt;<code class="email">&gt;&gt;</code>
&gt;<code class="email">&gt;&gt;</code>
&gt;<code class="email">&gt;&gt; </code>## create a graph
&gt;<code class="email">&gt;&gt; </code>g = tf.Graph()
&gt;<code class="email">&gt;&gt; </code>with g.as_default():
...     tf.set_random_seed(random_seed)
...     ## build the graph
...     build_cnn()
...
...     ## saver:
...     saver = tf.train.Saver()</pre></div><p class="calibre8">Note that in the preceding code, after we built the model by calling the <code class="email">build_cnn</code> function, we created a saver object from the <code class="email">tf.train.Saver</code> class for saving and restoring trained models, as we saw in <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span>.</p><p class="calibre8">The next step is to train our CNN model. For this, we need to create a TensorFlow session to launch the graph; then, we call the <code class="email">train</code> function. To train the model for the first time, we have to initialize all the variables in the network. </p><p class="calibre8">For this purpose, we<a id="calibre_link-2554" class="calibre1"></a> have defined<a id="calibre_link-2555" class="calibre1"></a> an argument named <code class="email">initialize</code> that will take care of the initialization. When <code class="email">initialize=True</code>, we will execute <code class="email">tf.global_variables_initializer</code> through <code class="email">session.run</code>. This initialization step should be avoided in case you want to train additional epochs; for example, you can restore an already trained model and train further for additional 10 epochs. The code for training the model for the first time is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## create a TF session 
&gt;&gt;&gt; ## and train the CNN model
&gt;&gt;&gt;
&gt;&gt;&gt; with tf.Session(graph=g) as sess:
...     train(sess, 
...           training_set=(X_train_centered, y_train), 
...           validation_set=(X_valid_centered, y_valid), 
...           initialize=True,
...           random_seed=123)
...     save(saver, sess, epoch=20)

Epoch 01 Training Avg. Loss: 272.772  Validation Acc:   0.973
Epoch 02 Training Avg. Loss:  76.053  Validation Acc:   0.981
Epoch 03 Training Avg. Loss:  51.309  Validation Acc:   0.984
Epoch 04 Training Avg. Loss:  39.740  Validation Acc:   0.986
Epoch 05 Training Avg. Loss:  31.508  Validation Acc:   0.987
...
Epoch 19 Training Avg. Loss:   5.386  Validation Acc:   0.991
Epoch 20 Training Avg. Loss:   3.965  Validation Acc:   0.992
Saving model in ./model/</pre></div><p class="calibre8">After the 20 epochs are finished, we save the trained model for future use so that we do not have to retrain the model every time, and therefore, save computational time. The following code shows how to<a id="calibre_link-2556" class="calibre1"></a> restore a saved model. We delete the graph <code class="email">g</code>, then create a new graph <code class="email">g2</code>, and reload the trained<a id="calibre_link-2557" class="calibre1"></a> model to do prediction on the test set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ### Calculate prediction accuracy
&gt;&gt;&gt; ### on test set
&gt;&gt;&gt; ### restoring the saved model
&gt;&gt;&gt;
&gt;&gt;&gt; del g
&gt;&gt;&gt;
&gt;&gt;&gt; ## create a new graph 
&gt;&gt;&gt; ## and build the model
&gt;&gt;&gt; g2 = tf.Graph()
&gt;&gt;&gt; with g2.as_default():
...     tf.set_random_seed(random_seed)
...     ## build the graph
...     build_cnn()
...
...     ## saver:
...     saver = tf.train.Saver()
&gt;&gt;&gt; 
&gt;&gt;&gt; ## create a new session 
&gt;&gt;&gt; ## and restore the model
&gt;&gt;&gt; with tf.Session(graph=g2) as sess:
...     load(saver, sess, 
...          epoch=20, path='./model/')
...     
...     preds = predict(sess, X_test_centered, 
...                     return_proba=False)
...
...     print('Test Accuracy: %.3f%%' % (100*
                np.sum(preds == y_test)/len(y_test)))

Building 1st layer: 
..
Building 2nd layer: 
..
Building 3rd layer:
..
Building 4th layer:
..
Test Accuracy: 99.310%</pre></div><p class="calibre8">The output contains several extra lines from the <code class="email">print</code> statements in the <code class="email">build_cnn</code> function, but they are not shown here for brevity. As you can see, the prediction accuracy on the test set is already better than what we achieved using the multilayer perceptron in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>. </p><p class="calibre8">Please, make sure you use <code class="email">X_test_centered</code>, which is the preprocessed version of the test data; you will get lower accuracy if you try using <code class="email">X_test</code> instead.</p><p class="calibre8">Now, let's look at <a id="calibre_link-2558" class="calibre1"></a>the predicted labels<a id="calibre_link-2559" class="calibre1"></a> as well as their probabilities on the first 10 test samples. We already have the predictions stored in <code class="email">preds</code>; however, in order to have more practice in using the session and launching the graph, we repeat those steps here:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## run the prediction on 
&gt;&gt;&gt; ##  some test samples
&gt;&gt;&gt; np.set_printoptions(precision=2, suppress=True)
&gt;&gt;&gt;
&gt;&gt;&gt; with tf.Session(graph=g2) as sess:
...     load(saver, sess, 
...          epoch=20, path='./model/')
...         
...     print(predict(sess, X_test_centered[:10], 
...               return_proba=False))
...     
...     print(predict(sess, X_test_centered[:10], 
...                   return_proba=True))

Loading model from ./model/
INFO:tensorflow:Restoring parameters from ./model/cnn-model.ckpt-20
[7 2 1 0 4 1 4 9 5 9]
[[ 0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  ]
 [ 0.    0.    1.    0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    1.    0.    0.    0.    0.    0.    0.    0.    0.  ]
 [ 1.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    1.    0.    0.    0.    0.    0.  ]
 [ 0.    1.    0.    0.    0.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    1.    0.    0.    0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]
 [ 0.    0.    0.    0.    0.    0.99  0.01  0.    0.    0.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]</pre></div><p class="calibre8">Finally, let's see how we can train the model further to reach a total of 40 epochs. Since, we have already trained 20 epochs from the initialized weights and biases. We can save time by restoring the already trained model and continue training for 20 additional epochs. This will be very easy to do with our setup. We need to call the <code class="email">train</code> function again, but this time, we set <code class="email">initialize=False</code> to avoid the initialization step. The code is as follows:</p><div class="informalexample"><pre class="programlisting">## continue training for 20 more epochs
## without re-initializing :: initialize=False
## create a new session 
## and restore the model
with tf.Session(graph=g2) as sess:
    load(saver, sess, 
         epoch=20, path='./model/')
    
    train(sess,
          training_set=(X_train_centered, y_train), 
          validation_set=(X_valid_centered, y_valid),
          initialize=False,
          epochs=20,
          random_seed=123)
        
    save(saver, sess, epoch=40, path='./model/')
    
    preds = predict(sess, X_test_centered, 
                    return_proba=False)
    
    print('Test Accuracy: %.3f%%' % (100*
                np.sum(preds == y_test)/len(y_test)))</pre></div><p class="calibre8">The result shows that <a id="calibre_link-2560" class="calibre1"></a>training for 20 additional <a id="calibre_link-2561" class="calibre1"></a>epochs slightly improved the performance to get 99.37 percent prediction accuracy on the test set.</p><p class="calibre8">In this section, we saw how to implement a multilayer convolutional neural network in the low-level TensorFlow API. In the next section, we'll now implement the same network but we'll use the TensorFlow Layers API.</p></div></div></div>

<div id="calibre_link-484" class="calibre">
<div class="book" title="Implementing a deep convolutional neural network using TensorFlow">
<div class="book" title="Implementing a CNN in the TensorFlow Layers API"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2562"><a id="calibre_link-427" class="calibre1"></a>Implementing a CNN in the TensorFlow Layers API</h2></div></div></div><p class="calibre8">For the implementation in the <a id="calibre_link-2563" class="calibre1"></a>TensorFlow Layers<a id="calibre_link-2564" class="calibre1"></a> API, we need to repeat the same process of loading the data and preprocessing steps to get <code class="email">X_train_centered</code>, <code class="email">X_valid_centered</code>, and <code class="email">X_test_centered</code>. Then, we can implement the model in a new class, as follows:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf
import numpy as np


class ConvNN(object):
    def __init__(self, batchsize=64,
                 epochs=20, learning_rate=1e-4, 
                 dropout_rate=0.5,
                 shuffle=True, random_seed=None):
        np.random.seed(random_seed)
        self.batchsize = batchsize
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.dropout_rate = dropout_rate
        self.shuffle = shuffle
                
        g = tf.Graph()
        with g.as_default():
            ## set random-seed:
            tf.set_random_seed(random_seed)
            
            ## build the network:
            self.build()

            ## initializer
            self.init_op = \
                tf.global_variables_initializer()

            ## saver
            self.saver = tf.train.Saver()
            
        ## create a session
        self.sess = tf.Session(graph=g)
                
    def build(self):
        
        ## Placeholders for X and y:
        tf_x = tf.placeholder(tf.float32, 
                              shape=[None, 784],
                              name='tf_x')
        tf_y = tf.placeholder(tf.int32, 
                              shape=[None],
                              name='tf_y')
        is_train = tf.placeholder(tf.bool, 
                              shape=(),
                              name='is_train')

        ## reshape x to a 4D tensor: 
        ##  [batchsize, width, height, 1]
        tf_x_image = tf.reshape(tf_x, shape=[-1, 28, 28, 1],
                              name='input_x_2dimages')
        ## One-hot encoding:
        tf_y_onehot = tf.one_hot(indices=tf_y, depth=10,
                                 dtype=tf.float32,
                                 name='input_y_onehot')

        ## 1st layer: Conv_1
        h1 = tf.layers.conv2d(tf_x_image, 
                              kernel_size=(5, 5), 
                              filters=32, 
                              activation=tf.nn.relu)
        ## MaxPooling
        h1_pool = tf.layers.max_pooling2d(h1, 
                              pool_size=(2, 2), 
                              strides=(2, 2))
        ## 2n layer: Conv_2
        h2 = tf.layers.conv2d(h1_pool, kernel_size=(5, 5), 
                              filters=64, 
                              activation=tf.nn.relu)
        ## MaxPooling 
        h2_pool = tf.layers.max_pooling2d(h2, 
                              pool_size=(2, 2), 
                              strides=(2, 2))

        ## 3rd layer: Fully Connected
        input_shape = h2_pool.get_shape().as_list()
        n_input_units = np.prod(input_shape[1:])
        h2_pool_flat = tf.reshape(h2_pool, 
                              shape=[-1, n_input_units])
        h3 = tf.layers.dense(h2_pool_flat, 1024, 
                             activation=tf.nn.relu)

        ## Dropout
        h3_drop = tf.layers.dropout(h3, 
                              rate=self.dropout_rate,
                              training=is_train)
        
        ## 4th layer: Fully Connected (linear activation)
        h4 = tf.layers.dense(h3_drop, 10, 
                             activation=None)

        ## Prediction
        predictions = {
            'probabilities': tf.nn.softmax(h4, 
                              name='probabilities'),
            'labels': tf.cast(tf.argmax(h4, axis=1), 
                              tf.int32, name='labels')
        }
        
        ## Loss Function and Optimization
        cross_entropy_loss = tf.reduce_mean(
            tf.nn.softmax_cross_entropy_with_logits(
                logits=h4, labels=tf_y_onehot),
            name='cross_entropy_loss')
        
        ## Optimizer:
        optimizer = tf.train.AdamOptimizer(self.learning_rate)
        optimizer = optimizer.minimize(cross_entropy_loss,
                              name='train_op')

        ## Finding accuracy
        correct_predictions = tf.equal(
            predictions['labels'], 
            tf_y, name='correct_preds')
        
        accuracy = tf.reduce_mean(
            tf.cast(correct_predictions, tf.float32),
            name='accuracy')

    def save(self, epoch, path='./tflayers-model/'):
        if not os.path.isdir(path):
            os.makedirs(path)
        print('Saving model in %s' % path)
        self.saver.save(self.sess, 
                        os.path.join(path, 'model.ckpt'),
                        global_step=epoch)
        
    def load(self, epoch, path):
        print('Loading model from %s' % path)
        self.saver.restore(self.sess,
             os.path.join(path, 'model.ckpt-%d' % epoch))
        
    def train(self, training_set, 
              validation_set=None,
              initialize=True):
        ## initialize variables
        if initialize:
            self.sess.run(self.init_op)

        self.train_cost_ = []
        X_data = np.array(training_set[0])
        y_data = np.array(training_set[1])

        for epoch in range(1, self.epochs+1):
            batch_gen = \
                batch_generator(X_data, y_data, 
                              shuffle=self.shuffle)
            avg_loss = 0.0
            for i, (batch_x,batch_y) in \
                enumerate(batch_gen):
                feed = {'tf_x:0': batch_x, 
                        'tf_y:0': batch_y,
                        'is_train:0': True} ## for dropout
                loss, _ = self.sess.run(
                        ['cross_entropy_loss:0', 'train_op'], 
                        feed_dict=feed)
                avg_loss += loss
                
            print('Epoch %02d: Training Avg. Loss: '
                  '%7.3f' % (epoch, avg_loss), end=' ')
            if validation_set is not None:
                feed = {'tf_x:0': batch_x, 
                        'tf_y:0': batch_y,
                        'is_train:0' : False} ## for dropout
                valid_acc = self.sess.run('accuracy:0',
                        feed_dict=feed)
                print('Validation Acc: %7.3f' % valid_acc)
            else:
                print()
                    
    def predict(self, X_test, return_proba=False):
        feed = {'tf_x:0' : X_test,
                'is_train:0' : False} ## for dropout
        if return_proba:
            return self.sess.run('probabilities:0',
                                 feed_dict=feed)
        else:
            return self.sess.run('labels:0',
                                 feed_dict=feed)</pre></div><p class="calibre8">The structure of this class is very similar to the previous section with the low-level TensorFlow API. The class has a constructor that sets the training parameters, creates a graph <code class="email">g</code>, and builds the model. Besides the constructor, there are five major methods:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">.build</code>: Builds the model</li><li class="listitem"><code class="email">.save</code>: To save a trained model</li><li class="listitem"><code class="email">.load</code>: To restore a saved model</li><li class="listitem"><code class="email">.train</code>: Trains the model</li><li class="listitem"><code class="email">.predict</code>: To do prediction on a test set</li></ul></div><p class="calibre8">Similar to the implementation in the previous section, we've used a dropout layer after the first fully connected layer. In the previous implementation that used the low-level TensorFlow API, we used the <code class="email">tf.nn.dropout</code> function, but here we used <code class="email">tf.layers.dropout</code>, which is a wrapper for the <code class="email">tf.nn.dropout</code> function. There are two major differences between these two functions that we need to be careful about:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">tf.nn.dropout</code>: This has an argument called <code class="email">keep_prob</code> that indicates the probability of keeping the units, while <code class="email">tf.layers.dropout</code> has a <code class="email">rate</code> parameter, which is the rate of dropping units&mdash;therefore <code class="email">rate = 1 - keep_prob</code>.</li><li class="listitem">In the <code class="email">tf.nn.dropout</code> function, we fed the <code class="email">keep_prob</code> parameter using a <a id="calibre_link-2565" class="calibre1"></a>placeholder so that during the training, we will use <code class="email">keep_prob=0.5</code>. Then, during the inference (or prediction) mode, we used <code class="email">keep_prob=1</code>. However, in <code class="email">tf.layers.dropout</code>, the value of <code class="email">rate</code> is<a id="calibre_link-2566" class="calibre1"></a> provided upon the creation of the dropout layer in the graph, and we cannot change it during the training or the inference modes. Instead, we need to provide a Boolean argument called <code class="email">training</code> to determine whether we need to apply dropout or not. This can be done using a placeholder of type <code class="email">tf.bool</code>, which we will feed with the value <code class="email">True</code> during the training mode and <code class="email">False</code> during the inference mode.</li></ul></div><p class="calibre8">We can create an instance of the <code class="email">ConvNN</code> class, train it for 20 epochs, and save the model. The code for this is as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; cnn = ConvNN(random_seed=123)
&gt;&gt;&gt; 
&gt;&gt;&gt; ## train the model
&gt;&gt;&gt; cnn.train(training_set=(X_train_centered, y_train), 
...           validation_set=(X_valid_centered, y_valid),
...           initialize=True)
&gt;&gt;&gt; cnn.save(epoch=20)</pre></div><p class="calibre8">After the training is finished, the model can be used to do prediction on the test dataset, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; del cnn
&gt;&gt;&gt; 
&gt;&gt;&gt; cnn2 = ConvNN(random_seed=123)
&gt;&gt;&gt; cnn2.load(epoch=20, path='./tflayers-model/')
&gt;&gt;&gt; 
&gt;&gt;&gt; print(cnn2.predict(X_test_centered[:10, :]))

Loading model from ./tflayers-model/
INFO:tensorflow:Restoring parameters from ./tflayers-model/model.ckpt-20
[7 2 1 0 4 1 4 9 5 9]</pre></div><p class="calibre8">Finally, we can measure the accuracy of the test dataset as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; preds = cnn2.predict(X_test_centered)
&gt;&gt;&gt; 
&gt;&gt;&gt; print('Test Accuracy: %.2f%%' % (100*
...       np.sum(y_test == preds)/len(y_test)))

Test Accuracy: 99.32%</pre></div><p class="calibre8">The obtained prediction accuracy is 99.32 percent, which means there are only 68 misclassified test samples!</p><p class="calibre8">This<a id="calibre_link-2567" class="calibre1"></a> concludes our discussion<a id="calibre_link-2568" class="calibre1"></a> on implementing convolutional neural networks using the TensorFlow low-level API and TensorFlow Layers API. We defined some wrapper functions for the first implementation using the low-level API. The second implementation was more straightforward since we could use the <code class="email">tf.layers.conv2d</code> and <code class="email">tf.layers.dense</code> functions to build the convolutional and the fully connected layers.</p></div></div></div>

<div id="calibre_link-512" class="calibre"><div class="book" title="Summary" id="calibre_link-428"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2569"><a id="calibre_link-2570" class="calibre1"></a>Summary</h1></div></div></div><p class="calibre8">In this chapter, we learned about CNNs, or convolutional neural networks, and explored the building blocks that form different CNN architectures. We started by defining the convolution operation, then we learned about its fundamentals by discussing 1D as well as 2D implementations. </p><p class="calibre8">We also covered subsampling by discussing two forms of pooling operations: max-pooling and average-pooling. Then, putting all these blocks together, we built a deep convolutional neural network and implemented it using the TensorFlow core API as well as the TensorFlow <span class="strong"><strong class="calibre2">Layers</strong></span> API to apply CNNs for image classification.</p><p class="calibre8">In the next chapter, we'll move on to <span class="strong"><strong class="calibre2">Recurrent Neural Networks</strong></span> (<span class="strong"><strong class="calibre2">RNN</strong></span>). RNNs are used for learning the structure of sequence data, and they have some fascinating applications, including language translation and image captioning!</p></div></div>

<div id="calibre_link-525" class="calibre">
<div id="calibre_link-2571" class="calibre10"></div><div class="book" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" id="calibre_link-44"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2572"><a id="calibre_link-2573" class="calibre1"></a>Chapter&nbsp;16.&nbsp;Modeling Sequential Data Using Recurrent Neural Networks</h1></div></div></div><p class="calibre8">In the previous chapter, we focused on <span class="strong"><strong class="calibre2">Convolutional Neural Networks</strong></span> (<span class="strong"><strong class="calibre2">CNNs</strong></span>) for image classification. In this chapter, we will explore <span class="strong"><strong class="calibre2">Recurrent Neural Networks</strong></span> (<span class="strong"><strong class="calibre2">RNNs</strong></span>) and see their application in modeling sequential data and a specific subset of sequential data&mdash;time-series data. As an overview, in this chapter, we will cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Introducing sequential data</li><li class="listitem">RNNs for modeling sequences</li><li class="listitem"><span class="strong"><strong class="calibre2">Long Short-Term Memory</strong></span> (<span class="strong"><strong class="calibre2">LSTM</strong></span>)</li><li class="listitem"><span class="strong"><strong class="calibre2">Truncated Backpropagation Through Time</strong></span> (<span class="strong"><strong class="calibre2">T-BPTT</strong></span>)</li><li class="listitem">Implementing a multilayer RNN for sequence modeling in TensorFlow</li><li class="listitem">Project one &ndash; RNN sentiment analysis of the IMDb movie review dataset</li><li class="listitem">Project two &ndash; RNN character-level language modeling with LSTM cells, using text data from Shakespeare's Hamlet</li><li class="listitem">Using gradient clipping to avoid exploding gradients</li></ul></div><p class="calibre8">Since this chapter is the last in our <span class="strong"><em class="calibre9">Python Machine Learning</em></span> journey, we'll conclude with a summary of what we've learned about RNNs, and an overview of all the machine learning and deep learning topics that led us to RNNs across the journey of the book. We'll then sign off by sharing with you links to some of our favorite people and initiatives in this wonderful field so that you can continue your journey into machine learning and deep learning.</p></div></div>

<div id="calibre_link-540" class="calibre">
<div class="book" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" id="calibre_link-2574">
<div class="book" title="Introducing sequential data"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2575"><a id="calibre_link-429" class="calibre1"></a>Introducing sequential data</h1></div></div></div><p class="calibre8">Let's begin our <a id="calibre_link-2576" class="calibre1"></a>discussion of RNNs by looking at the nature of sequential data, more commonly known as <span class="strong"><strong class="calibre2">sequences</strong></span>. We'll take a look at the unique properties of sequences that <a id="calibre_link-2577" class="calibre1"></a>make them different from other kinds of data. We'll then see how we can represent sequential data, and explore the various categories of models for sequential data, which are based on the input and output of a model. This will help us explore the relationship between RNNs and sequences a little bit later on in the chapter.</p></div></div></div>

<div id="calibre_link-562" class="calibre">
<div class="book" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" id="calibre_link-2578">
<div class="book" title="Introducing sequential data">
<div class="book" title="Modeling sequential data â order matters"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2579"><a id="calibre_link-430" class="calibre1"></a>Modeling sequential data &ndash; order matters</h2></div></div></div><p class="calibre8">What makes<a id="calibre_link-2580" class="calibre1"></a> sequences unique, from other data types, is that elements in a sequence appear in a certain order, and are not independent of each other.</p><p class="calibre8">If you recall from <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>,<span class="strong"><em class="calibre9"> Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we discussed that typical machine learning algorithms for supervised learning assume that the input <a id="calibre_link-2581" class="calibre1"></a>data is <span class="strong"><strong class="calibre2">Independent and Identically Distributed</strong></span> (<span class="strong"><strong class="calibre2">IID</strong></span>). For example, if we have <span class="strong"><em class="calibre9">n</em></span> data samples, <span class="strong"><img src="images/00818.jpeg" alt="Modeling sequential data â order matters" class="calibre14" /></span>, the order in which we use the data for training our machine learning algorithm does not matter.</p><p class="calibre8">However, this assumption is not valid anymore when we deal with sequences&mdash;by definition, order matters.</p></div></div></div></div>

<div id="calibre_link-169" class="calibre">
<div class="book" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" id="calibre_link-2582">
<div class="book" title="Introducing sequential data">
<div class="book" title="Representing sequences"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2583"><a id="calibre_link-431" class="calibre1"></a>Representing sequences</h2></div></div></div><p class="calibre8">We've established that sequences<a id="calibre_link-2584" class="calibre1"></a> are a nonindependent order in our input data; we next need to find ways to leverage this valuable information in our machine learning model.</p><p class="calibre8">Throughout this chapter, we will represent sequences as <span class="strong"><img src="images/00882.jpeg" alt="Representing sequences" class="calibre14" /></span>. The superscript indices indicate the order of the instances, and the length of the sequence is <span class="strong"><em class="calibre9">T</em></span>. For a sensible example of sequences, consider time-series data, where each sample point <span class="strong"><img src="images/00956.jpeg" alt="Representing sequences" class="calibre14" /></span> belongs to a particular time <span class="strong"><em class="calibre9">t</em></span>.</p><p class="calibre8">The following figure shows an example of time-series data where both <span class="strong"><em class="calibre9">x</em></span>'s and <span class="strong"><em class="calibre9">y</em></span>'s naturally follow the order according to their time axis; therefore, both <span class="strong"><em class="calibre9">x</em></span>'s and <span class="strong"><em class="calibre9">y</em></span>'s are sequences:</p><div class="mediaobject"><img src="images/00273.jpeg" alt="Representing sequences" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The standard neural network models that we have covered so far, such as MLPs and CNNs, are not capable of handling <span class="strong"><em class="calibre9">the order</em></span> of input samples. Intuitively, one can say that such models do not have a <span class="strong"><em class="calibre9">memory</em></span> of the past seen samples. For instance, the samples are passed through the feedforward and backpropagation steps, and the weights are updated independent of the order in which the sample is processed.</p><p class="calibre8">RNNs, by contrast, are designed for modeling sequences and are capable of remembering past information and processing new events accordingly.</p></div></div></div></div>

<div id="calibre_link-192" class="calibre">
<div class="book" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" id="calibre_link-2585">
<div class="book" title="Introducing sequential data">
<div class="book" title="The different categories of sequence modeling"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2586"><a id="calibre_link-432" class="calibre1"></a>The different categories of sequence modeling</h2></div></div></div><p class="calibre8">Sequence modeling has <a id="calibre_link-2587" class="calibre1"></a>many fascinating applications, such as language translation (perhaps from English to German), image captioning, and text generation.</p><p class="calibre8">However, we need to understand the different types of sequence modeling tasks to develop an appropriate model. The following figure, based on the explanations in the excellent article <span class="strong"><em class="calibre9">The Unreasonable Effectiveness of Recurrent Neural Networks</em></span> by Andrej Karpathy (<a class="calibre1" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a>), shows several different relationship categories of input and output data:</p><div class="mediaobject"><img src="images/00286.jpeg" alt="The different categories of sequence modeling" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">So, let's consider the input and output data here. If neither the input or output data represents sequences, then we are dealing with standard data, and we can use any of the previous methods to model such data. But if either the input or output is a sequence, the data will form one of the following three different categories:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Many-to-one</strong></span>: The <a id="calibre_link-2588" class="calibre1"></a>input data is a sequence, but the output is a fixed-size vector, not a sequence. For example, in sentiment analysis, the input is text-based and the output is a class label.</li><li class="listitem"><span class="strong"><strong class="calibre2">One-to-many</strong></span>: The <a id="calibre_link-2589" class="calibre1"></a>input data is in standard format, not a sequence, but the output is a sequence. An example of this category is image captioning&mdash;the input is an image; the output is an English phrase.</li><li class="listitem"><span class="strong"><strong class="calibre2">Many-to-many</strong></span>: Both<a id="calibre_link-2590" class="calibre1"></a> the input and output arrays are sequences. This category can be further divided based on whether the input and output are synchronized or not. An example of a <span class="strong"><strong class="calibre2">synchronized</strong></span> many-to-many modeling task is video classification, where each frame in a video is labeled. An example of a <span class="strong"><strong class="calibre2">delayed</strong></span> many-to-many would be translating a language into another. For instance, an entire English sentence must be read and processed by a machine before producing its translation into German.</li></ul></div><p class="calibre8">Now, since we know about the categories of sequence modeling, we can move forward to discuss the structure of an RNN.</p></div></div></div></div>

<div id="calibre_link-152" class="calibre">
<div id="calibre_link-2591" class="calibre10"></div><div class="book" title="RNNs for modeling sequences"><div class="book" id="calibre_link-4"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2592"><a id="calibre_link-2593" class="calibre1"></a>RNNs for modeling sequences</h1></div></div></div><p class="calibre8">In this section, now that we<a id="calibre_link-2594" class="calibre1"></a> understand sequences, we can look at the foundations of RNNs. We'll start by introducing the typical structure of an RNN, and we'll see how the data flows through it with one or more hidden layers. We'll then examine how the neuron activations are computed in a typical RNN. This will create a context for us to discuss the common challenges in training RNNs, and explore the modern solution to these challenges&mdash;LSTM.</p></div></div>

<div id="calibre_link-514" class="calibre">
<div class="book" title="RNNs for modeling sequences">
<div class="book" title="Understanding the structure and flow of an RNN"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2595"><a id="calibre_link-433" class="calibre1"></a>Understanding the structure and flow of an RNN</h2></div></div></div><p class="calibre8">Let's start by introducing the <a id="calibre_link-2596" class="calibre1"></a>architecture of an RNN. The following figure shows a standard feedforward neural network and an RNN, in a side by side for comparison:</p><div class="mediaobject"><img src="images/00151.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Both of these networks have only <a id="calibre_link-2597" class="calibre1"></a>one hidden layer. In this representation, the units are not displayed, but we assume that the input layer (<span class="strong"><strong class="calibre2">x</strong></span>), hidden layer (<span class="strong"><strong class="calibre2">h</strong></span>), and output layer (<span class="strong"><strong class="calibre2">y</strong></span>) are vectors which contain many units.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2598" class="calibre1"></a>Note</h3><p class="calibre8">This generic RNN architecture could correspond to the two sequence modeling categories where the input is a sequence. Thus, it could be either many-to-many if we consider <span class="strong"><img src="images/00209.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> as the final output, or it could be many-to-one if, for example, we only use the last element of <span class="strong"><img src="images/00209.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> as the final output.</p><p class="calibre8">Later, we will see how the output sequence <span class="strong"><img src="images/00209.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> can be converted into standard, nonsequential output.</p></div><p class="calibre8">In a standard feedforward network, information flows from the input to the hidden layer, and then from the hidden layer to the output layer. On the other hand, in a recurrent network, the hidden layer gets its input from both the input layer and the hidden layer from the previous time step.</p><p class="calibre8">The flow of information in adjacent time steps in the hidden layer allows the network to have a memory of past events. This flow of information is usually displayed as a loop, also<a id="calibre_link-2599" class="calibre1"></a> known as a <span class="strong"><strong class="calibre2">recurrent edge</strong></span> in graph notation, which is how this general architecture got its name.</p><p class="calibre8">In the following figure, the single hidden<a id="calibre_link-2600" class="calibre1"></a> layer network and the multilayer network illustrate two contrasting architectures:</p><div class="mediaobject"><img src="images/00307.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In order to examine the architecture of RNNs and the flow of information, a compact representation with a recurrent edge can be unfolded, which you can see in the preceding figure.</p><p class="calibre8">As we know, each hidden unit in a standard neural network receives only one input&mdash;the net preactivation associated with the input layer. Now, in contrast, each hidden unit in an RNN receives two <span class="strong"><em class="calibre9">distinct</em></span> sets of input&mdash;the preactivation from the input layer and the activation of the same hidden layer from the previous time step t-1.</p><p class="calibre8">At the first time step <span class="strong"><em class="calibre9">t = 0</em></span>, the hidden units are initialized to zeros or small random values. Then, at a time step where t &gt; 0, the hidden units get their input from the data point at the current time <span class="strong"><img src="images/00956.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> and the previous values of hidden units at <span class="strong"><em class="calibre9">t - 1</em></span>, indicated as <span class="strong"><img src="images/00317.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span>.</p><p class="calibre8">Similarly, in the case of a <a id="calibre_link-2601" class="calibre1"></a>multilayer RNN, we can summarize the information flow as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><img src="images/00366.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span>
: Here, the hidden layer is represented as <span class="strong"><img src="images/00418.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> and gets its input from the data point <span class="strong"><img src="images/00956.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> and the hidden values in the same layer, but the previous time step <span class="strong"><img src="images/00349.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span></li><li class="listitem"><span class="strong"><img src="images/00357.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span>: The second hidden layer, <span class="strong"><img src="images/00370.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span> receives its inputs from the hidden units from the layer below at the current time step (<span class="strong"><img src="images/00418.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span>) and its own hidden values from the previous time step <span class="strong"><img src="images/00635.jpeg" alt="Understanding the structure and flow of an RNN" class="calibre14" /></span></li></ul></div></div></div></div>

<div id="calibre_link-529" class="calibre">
<div class="book" title="RNNs for modeling sequences">
<div class="book" title="Computing activations in an RNN"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2602"><a id="calibre_link-434" class="calibre1"></a>Computing activations in an RNN</h2></div></div></div><p class="calibre8">Now that we understand the structure and general flow of <a id="calibre_link-2603" class="calibre1"></a>information in an RNN, let's get more specific and <a id="calibre_link-2604" class="calibre1"></a>compute the actual activations of the hidden layers as well as the output layer. For simplicity, we'll consider just a single hidden layer; however, the same concept applies to multilayer RNNs.</p><p class="calibre8">Each directed edge (the connections between boxes) in the representation of an RNN that we just looked at is associated with a weight matrix. Those weights do not depend on time <span class="strong"><em class="calibre9">t</em></span>; therefore, they are shared across the time axis. The different weight matrices in a single layer RNN are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><img src="images/00387.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> : The weight matrix between the input <span class="strong"><img src="images/00956.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> and the hidden layer <span class="strong"><strong class="calibre2">h</strong></span></li><li class="listitem"><span class="strong"><img src="images/00398.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> : The weight matrix associated with the recurrent edge
</li><li class="listitem"><span class="strong"><img src="images/00408.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span>: The weight matrix between the hidden layer and output layer
</li></ul></div><p class="calibre8">You can see these weight matrices in the following figure:</p><div class="mediaobject"><img src="images/00424.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In certain <a id="calibre_link-2605" class="calibre1"></a>implementations, you<a id="calibre_link-2606" class="calibre1"></a> may observe that weight matrices <span class="strong"><img src="images/00387.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> and <span class="strong"><img src="images/00398.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> are concatenated to a combined matrix <span class="strong"><img src="images/00958.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span>. Later on, we'll make use of this notation as well.</p><p class="calibre8">Computing the activations is very similar to standard multilayer perceptrons and other types of feedforward neural networks. For the hidden layer, the net input <span class="strong"><img src="images/00445.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> (preactivation) is computed through a linear combination. That is, we compute the sum of the multiplications of the weight matrices with the corresponding vectors and add the bias unit&mdash;<span class="strong"><img src="images/00626.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span>. Then, the activations of the hidden units at the time step <span class="strong"><em class="calibre9">t</em></span> are calculated as follows:</p><div class="mediaobject"><img src="images/00019.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00570.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> is the bias vector for the hidden units and <span class="strong"><img src="images/00494.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> is the activation function of the hidden layer.</p><p class="calibre8">In case you want to use the concatenated weight matrix <span class="strong"><img src="images/00503.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span>, the formula for computing hidden units will change as follows:</p><div class="mediaobject"><img src="images/00858.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Once the activations of hidden units at the current time step are computed, then the activations of output units will be computed as follows:</p><div class="mediaobject"><img src="images/00928.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">To help clarify <a id="calibre_link-2607" class="calibre1"></a>this further, the <a id="calibre_link-2608" class="calibre1"></a>following figure shows the process of computing these activations with both formulations:</p><div class="mediaobject"><img src="images/00528.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2609" class="calibre1"></a>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Training RNNs using BPTT</strong></span>
</p><p class="calibre8">The <a id="calibre_link-2610" class="calibre1"></a>learning algorithm for <a id="calibre_link-2611" class="calibre1"></a>RNNs was introduced in 1990s <span class="strong"><em class="calibre9">Backpropagation Through Time: What It Does and How to Do It</em></span> (<span class="strong"><em class="calibre9">Paul Werbos</em></span>, <span class="strong"><em class="calibre9">Proceedings of IEEE</em></span>, 78(10):1550-1560, <span class="strong"><em class="calibre9">1990</em></span>). </p><p class="calibre8">The derivation of the gradients might be a bit complicated, but the basic idea is that the overall loss <span class="strong"><em class="calibre9">L</em></span> is the sum of all the loss functions at times <span class="strong"><img src="images/00541.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> to <span class="strong"><img src="images/00554.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span>:</p><div class="mediaobject1"><img src="images/00561.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Since the loss at time <span class="strong"><img src="images/00571.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> is dependent on the hidden units at all previous time steps <span class="strong"><img src="images/00571.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span>, the gradient will be computed as follows:</p><div class="mediaobject1"><img src="images/00586.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Here, <span class="strong"><img src="images/00596.jpeg" alt="Computing activations in an RNN" class="calibre14" /></span> is computed as a multiplication of adjacent time steps:</p><div class="mediaobject1"><img src="images/00405.jpeg" alt="Computing activations in an RNN" class="calibre11" /></div><p class="calibre12"> </p></div></div></div></div>

<div id="calibre_link-546" class="calibre">
<div class="book" title="RNNs for modeling sequences">
<div class="book" title="The challenges of learning long-range interactions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2612"><a id="calibre_link-435" class="calibre1"></a>The challenges of learning long-range interactions</h2></div></div></div><p class="calibre8">Backpropagation<a id="calibre_link-2613" class="calibre1"></a> through time, or BPTT, which we briefly mentioned in the previous information box, introduces some new challenges.</p><p class="calibre8">Because of the multiplicative factor <span class="strong"><img src="images/00617.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> in the computing gradients of a loss function, the so-called <span class="strong"><strong class="calibre2">vanishing</strong></span> or <span class="strong"><strong class="calibre2">exploding</strong></span> gradient problem arises. This problem is explained through the examples in the following figure, which shows an RNN with only one hidden unit for simplicity:</p><div class="mediaobject"><img src="images/00629.jpeg" alt="The challenges of learning long-range interactions" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Basically, <span class="strong"><img src="images/00617.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> has <span class="strong"><img src="images/00644.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> multiplications; therefore, multiplying the <span class="strong"><em class="calibre9">w</em></span> weight <span class="strong"><img src="images/00644.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> times results in a factor&mdash;<span class="strong"><img src="images/00655.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span>. As a result, if <span class="strong"><img src="images/00682.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span>, this factor becomes very small when <span class="strong"><img src="images/00644.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> is large. On the other hand, if the weight of the recurrent edge is <span class="strong"><img src="images/00686.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span>, then <span class="strong"><img src="images/00655.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> becomes very large when <span class="strong"><img src="images/00644.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> is large. Note that large <span class="strong"><img src="images/00644.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span> refers to long-range dependencies.</p><p class="calibre8">Intuitively, we can see <a id="calibre_link-2614" class="calibre1"></a>that a naÃ¯ve solution to avoid vanishing or exploding gradient can be accomplished by ensuring <span class="strong"><img src="images/00704.jpeg" alt="The challenges of learning long-range interactions" class="calibre14" /></span>. If you are interested and would like to investigate this in more detail, I encourage you to read <span class="strong"><em class="calibre9">On the difficulty of training recurrent neural networks</em></span> by <span class="strong"><em class="calibre9">R. Pascanu</em></span>, <span class="strong"><em class="calibre9">T. Mikolov</em></span>, and <span class="strong"><em class="calibre9">Y. Bengio</em></span>, <span class="strong"><em class="calibre9">2012</em></span> (<a class="calibre1" href="https://arxiv.org/pdf/1211.5063.pdf">https://arxiv.org/pdf/1211.5063.pdf</a>).</p><p class="calibre8">In practice, there are two solutions to this problem:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Truncated backpropagation through time (TBPTT)</li><li class="listitem">Long short-term memory (LSTM)</li></ul></div><p class="calibre8">TBPTT clips the gradients above a given threshold. While TBPTT can solve the exploding gradient problem, the truncation limits the number of steps that the gradient can effectively flow back and properly update the weights.</p><p class="calibre8">On the other hand, LSTM, designed in 1997 by Hochreiter and Schmidhuber, has been more successful in modeling long-range sequences by overcoming the vanishing gradient problem. Let's discuss LSTM in more detail.</p></div></div></div>

<div id="calibre_link-572" class="calibre">
<div class="book" title="RNNs for modeling sequences">
<div class="book" title="LSTM units"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2615"><a id="calibre_link-436" class="calibre1"></a>LSTM units</h2></div></div></div><p class="calibre8">LSTMs were first<a id="calibre_link-2616" class="calibre1"></a> introduced to overcome the vanishing gradient problem (<span class="strong"><em class="calibre9">Long Short-Term Memory</em></span>, <span class="strong"><em class="calibre9">S. Hochreiter</em></span> and <span class="strong"><em class="calibre9">J. Schmidhuber</em></span>, <span class="strong"><em class="calibre9">Neural Computation</em></span>, 9(8): 1735-1780, <span class="strong"><em class="calibre9">1997</em></span>). The building block of an<a id="calibre_link-2617" class="calibre1"></a> LSTM is a <span class="strong"><strong class="calibre2">memory cell</strong></span>, which essentially represents the hidden layer.</p><p class="calibre8">In each memory cell, there is a recurrent edge that has the desirable weight <span class="strong"><img src="images/00715.jpeg" alt="LSTM units" class="calibre14" /></span>, as we discussed previously, to overcome the vanishing and exploding gradient problems. The values associated with this <a id="calibre_link-2618" class="calibre1"></a>recurrent edge is called <span class="strong"><strong class="calibre2">cell state</strong></span>. The unfolded structure of a modern LSTM cell is shown in the following figure:</p><div class="mediaobject"><img src="images/00726.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Notice that the cell state from the previous time step, <span class="strong"><img src="images/00730.jpeg" alt="LSTM units" class="calibre14" /></span>, is modified to get the cell state at the current time step, <span class="strong"><img src="images/00745.jpeg" alt="LSTM units" class="calibre14" /></span>, without being multiplied directly with any weight factor.</p><p class="calibre8">The flow of information in this memory cell is controlled by some units of computation that we'll describe here. In the<a id="calibre_link-2619" class="calibre1"></a> previous figure, <span class="strong"><img src="images/00758.jpeg" alt="LSTM units" class="calibre14" /></span> refers to the <span class="strong"><strong class="calibre2">element-wise product</strong></span> (element-wise multiplication) and <span class="strong"><img src="images/00772.jpeg" alt="LSTM units" class="calibre14" /></span> means <span class="strong"><strong class="calibre2">element-wise summation</strong></span> (element-wise addition). Furthermore, <span class="strong"><img src="images/00956.jpeg" alt="LSTM units" class="calibre14" /></span> refers to <a id="calibre_link-2620" class="calibre1"></a>the input data at time <span class="strong"><em class="calibre9">t</em></span>, and <span class="strong"><img src="images/00317.jpeg" alt="LSTM units" class="calibre14" /></span> indicates the hidden units at time <span class="strong"><img src="images/00775.jpeg" alt="LSTM units" class="calibre14" /></span>.</p><p class="calibre8">Four boxes are indicated with an activation function, either the sigmoid function (<span class="strong"><img src="images/00787.jpeg" alt="LSTM units" class="calibre14" /></span>) or hyperbolic tangent (tanh), and a set of weights; these boxes apply linear combination by performing matrix-vector multiplications on their input. These units of computation with sigmoid activation functions, whose output units are passed through <span class="strong"><img src="images/00758.jpeg" alt="LSTM units" class="calibre14" /></span>, are <a id="calibre_link-2621" class="calibre1"></a>called <span class="strong"><strong class="calibre2">gates</strong></span>.</p><p class="calibre8">In an LSTM cell, there are three different types of gates, known as the forget gate, the input gate, and the output gate:</p><div class="book"><ul class="itemizedlist"><li class="listitem">
The <span class="strong"><strong class="calibre2">forget gate</strong></span> (<span class="strong"><img src="images/00801.jpeg" alt="LSTM units" class="calibre14" /></span>) allows the <a id="calibre_link-2622" class="calibre1"></a>memory cell to reset the cell state without growing indefinitely. In fact, the forget gate decides which information is allowed to go through and which information to suppress. Now, <span class="strong"><img src="images/00801.jpeg" alt="LSTM units" class="calibre14" /></span> is computed as follows:
<div class="mediaobject"><img src="images/00812.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre26"> </p>Note that the forget gate was not part of the original LSTM cell; it was added a few years later to improve the original model (<span class="strong"><em class="calibre9">Learning to Forget: Continual Prediction with LSTM</em></span>, <span class="strong"><em class="calibre9">F. Gers</em></span>, <span class="strong"><em class="calibre9">J. Schmidhuber</em></span>, and <span class="strong"><em class="calibre9">F. Cummins</em></span>, <span class="strong"><em class="calibre9">Neural Computation 12</em></span>, 2451-2471, 2000).</li><li class="listitem">
The <span class="strong"><strong class="calibre2">input gate</strong></span> (<span class="strong"><img src="images/00824.jpeg" alt="LSTM units" class="calibre14" /></span>) and<a id="calibre_link-2623" class="calibre1"></a> input node (<span class="strong"><img src="images/00835.jpeg" alt="LSTM units" class="calibre14" /></span>) are responsible for updating the cell state. They are computed as follows:
<div class="mediaobject"><img src="images/00848.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre26"> </p><div class="mediaobject"><img src="images/00868.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre26"> </p>The cell state at time <span class="strong"><em class="calibre9">t</em></span> is computed as follows:<div class="mediaobject"><img src="images/00684.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre26"> </p></li><li class="listitem">
The <span class="strong"><strong class="calibre2">output gate</strong></span> (<span class="strong"><img src="images/00894.jpeg" alt="LSTM units" class="calibre14" /></span>) decides<a id="calibre_link-2624" class="calibre1"></a> how to update the values of hidden units:
<div class="mediaobject"><img src="images/00903.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre26"> </p></li></ul></div><p class="calibre8">Given this, the hidden units at the current time step are computed as follows:</p><div class="mediaobject"><img src="images/00917.jpeg" alt="LSTM units" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">The structure of an LSTM cell and its underlying computations might seem too complex. However, the good news is that TensorFlow has already implemented everything in wrapper functions that allows us to define our LSTM cells easily. We'll see the real application of LSTMs in action when we use TensorFlow later in this chapter.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2625" class="calibre1"></a>Note</h3><p class="calibre8">We have introduced LSTMs in this section, which provide a basic approach for modeling long-range dependencies in sequences. Yet, it is important to note that there are many variations of LSTMs described in literature (<span class="strong"><em class="calibre9">An Empirical Exploration of Recurrent Network Architectures</em></span>, <span class="strong"><em class="calibre9">Rafal Jozefowicz</em></span>, <span class="strong"><em class="calibre9">Wojciech Zaremba</em></span>, and <span class="strong"><em class="calibre9">Ilya Sutskever</em></span>, <span class="strong"><em class="calibre9">Proceedings of ICML</em></span>, 2342-2350, <span class="strong"><em class="calibre9">2015</em></span>).</p><p class="calibre8">Also, worth noting is a <a id="calibre_link-2626" class="calibre1"></a>more recent approach, called <span class="strong"><strong class="calibre2">Gated Recurrent Unit</strong></span> (<span class="strong"><strong class="calibre2">GRU</strong></span>), which was proposed in 2014. GRUs have a simpler architecture than LSTMs; therefore, they are computationally more efficient while their performance in some tasks, such as polyphonic music modeling, is comparable to LSTMs. If you are interested in learning more about these modern RNN architectures, refer to the paper, <span class="strong"><em class="calibre9">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</em></span> by <span class="strong"><em class="calibre9">Junyoung Chung and others 2014</em></span> (<a class="calibre1" href="https://arxiv.org/pdf/1412.3555v1.pdf">https://arxiv.org/pdf/1412.3555v1.pdf</a>).</p></div></div></div></div>

<div id="calibre_link-595" class="calibre"><div class="book" title="Implementing a multilayer RNN for sequence modeling in TensorFlow" id="calibre_link-437"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2627"><a id="calibre_link-2628" class="calibre1"></a>Implementing a multilayer RNN for sequence modeling in TensorFlow</h1></div></div></div><p class="calibre8">Now that we introduced the underlying theory behind RNNs, we are ready to move on to the more practical part to implement RNNs in TensorFlow. During the rest of this chapter, we will apply RNNs <a id="calibre_link-2629" class="calibre1"></a>to two common problems tasks:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Sentiment analysis</li><li class="listitem" value="2">Language modeling</li></ol><div class="calibre13"></div></div><p class="calibre8">These two projects, which we'll build together in the following pages, are both fascinating but also quite involved. Thus, instead of providing all the code all at once, we will break the implementation up into several steps and discuss the code in detail. If you like to have a big picture overview and see all the code at once before diving into the discussion, we recommend you to take a look at the code implementation first, which you can view at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch16/ch16.ipynb">https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch16/ch16.ipynb</a>.</p><p class="calibre8">Note, before we start coding in this chapter, that since we're using a very modern build of TensorFlow, we'll be using code from the <code class="email">contrib</code> submodule of TensorFlow's Python API, in the <a id="calibre_link-2630" class="calibre1"></a>latest version of TensorFlow (1.3.0) from August 2017. These <code class="email">contrib</code> functions and classes, as well as their documentation references used in this chapter, may change in the future versions of TensorFlow, or they may be integrated into the <code class="email">tf.nn</code> submodule. We therefore advise you to keep an eye on the TensorFlow API documentation (<a class="calibre1" href="https://www.tensorflow.org/api_docs/python/">https://www.tensorflow.org/api_docs/python/</a>) to be updated with the latest version details, in particular, if you have any problems using the <code class="email">tf.contrib</code> code described in this chapter.</p></div></div>

<div id="calibre_link-607" class="calibre">
<div id="calibre_link-2631" class="calibre10"></div><div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs"><div class="book" id="calibre_link-142"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2632"><a id="calibre_link-2633" class="calibre1"></a>Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</h1></div></div></div><p class="calibre8">You may recall from <a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span>, that sentiment analysis is concerned with analyzing the expressed opinion of a sentence or a text document. In this section and the following subsections, we will implement a<a id="calibre_link-2634" class="calibre1"></a> multilayer RNN for sentiment analysis using a many-to-one architecture.</p><p class="calibre8">In the next section, we will implement a many-to-many RNN for an application language modeling. While the chosen examples are purposefully simple to introduce the main concepts of RNNs, language modeling has a wide range of interesting applications such as building chatbot &mdash; giving computers the ability to directly talk and interact with a human.</p></div></div>

<div id="calibre_link-623" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="Preparing the data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2635"><a id="calibre_link-438" class="calibre1"></a>Preparing the data</h2></div></div></div><p class="calibre8">In the preprocessing<a id="calibre_link-2636" class="calibre1"></a> steps in <a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span>, we created a clean dataset named <code class="email">movie_data.csv</code>, which we'll use again now. So, first let's import the necessary modules and read the data into a <code class="email">DataFrame</code> pandas, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pyprind
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from string import punctuation
&gt;&gt;&gt; import re
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; df = pd.read_csv('movie_data.csv', encoding='utf-8')</pre></div><p class="calibre8">Recall that this <code class="email">df</code> data frame has two columns, namely <code class="email">'review'</code> and <code class="email">'sentiment'</code>, where <code class="email">'review'</code> contains the text of movie reviews and <code class="email">'sentiment'</code> contains the <code class="email">0</code> or <code class="email">1</code> labels. The text component of these movie reviews are sequences of words; therefore, we want to build an RNN model to process the words in each sequence, and at the end, classify the entire sequence to <code class="email">0</code> or <code class="email">1</code> classes.</p><p class="calibre8">To prepare the data for input to a neural network, we need to encode it into numeric values. To do this, we first find the unique words in the entire dataset, which can be done using sets in Python. However, I found that using sets for finding unique words in such a large dataset is not efficient. A more efficient way is to use <code class="email">Counter</code> from the collections package. If you want to learn more about <code class="email">Counter</code>, refer to its documentation at <a class="calibre1" href="https://docs.python.org/3/library/collections.html#collections.Counter">https://docs.python.org/3/library/collections.html#collections.Counter</a>.</p><p class="calibre8">In the following code, we will <a id="calibre_link-2637" class="calibre1"></a>define a <code class="email">counts</code> object from the <code class="email">Counter</code> class that collects the counts of occurrence of each unique word in the text. Note that in this particular application (and in contrast to the bag-of-words model), we are only interested in the set of unique words and won't require the word counts, which are created as a side product.</p><p class="calibre8">Then, we create a mapping in the form of a dictionary that maps each unique word, in our dataset, to a unique integer number. We call this dictionary <code class="email">word_to_int</code>, which can be used to convert the entire text of a review into a list of numbers. The unique words are sorted based on their counts, but any arbitrary order can be used without affecting the final results. This process of converting a text into a list of integers is performed using the following code:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## Preprocessing the data:
&gt;&gt;&gt; ## Separate words and
&gt;&gt;&gt; ## count each word's occurrence
&gt;&gt;&gt;
&gt;&gt;&gt; from collections import Counter

&gt;&gt;&gt; counts = Counter()
&gt;&gt;&gt; pbar = pyprind.ProgBar(len(df['review']), \
...                        title='Counting words occurrences')
&gt;&gt;&gt; for i,review in enumerate(df['review']):
...     text = ''.join([c if c not in punctuation else ' '+c+' ' \
...                     for c in review]).lower()
...     df.loc[i,'review'] = text
...     pbar.update()
...     counts.update(text.split())
&gt;&gt;&gt;
&gt;&gt;&gt; ## Create a mapping
&gt;&gt;&gt; ## Map each unique word to an integer
&gt;&gt;&gt; word_counts = sorted(counts, key=counts.get, reverse=True)
&gt;&gt;&gt; print(word_counts[:5])
&gt;&gt;&gt; word_to_int = {word: ii for ii, word in \
...                enumerate(word_counts, 1)}
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; mapped_reviews = []
&gt;&gt;&gt; pbar = pyprind.ProgBar(len(df['review']), \
...                        title='Map reviews to ints')
&gt;&gt;&gt; for review in df['review']:
...     mapped_reviews.append([word_to_int[word] \
...                           for word in review.split()])
...     pbar.update()</pre></div><p class="calibre8">So far, we've converted sequences of words into sequences of integers. However, there is one issue that we still need to solve&mdash;the sequences currently have different lengths. In order to generate input data that is compatible with our RNN architecture, we will need to make sure that all the sequences have the same length.</p><p class="calibre8">For this purpose, we <a id="calibre_link-2638" class="calibre1"></a>define a parameter called <code class="email">sequence_length</code> that we set to <code class="email">200</code>. Sequences that have fewer than 200 words will be left-padded with zeros. Vice versa, sequences that are longer than 200 words are cut such that only the last 200 corresponding words will be used. We can implement this preprocessing step in two steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Create a matrix of zeros, where each row corresponds to a sequence of size 200.</li><li class="listitem" value="2">Fill the index of words in each sequence from the right-hand side of the matrix. Thus, if a sequence has a length of 150, the first 50 elements of the corresponding row will stay zero.</li></ol><div class="calibre13"></div></div><p class="calibre8">These two steps are shown in the following figure, for a small example with eight sequences of sizes 4, 12, 8, 11, 7, 3, 10, and 13:</p><div class="mediaobject"><img src="images/00938.jpeg" alt="Preparing the data" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Note that <code class="email">sequence_length</code> is, in fact, a hyperparameter and can be tuned for optimal performance. Due to <a id="calibre_link-2639" class="calibre1"></a>page limitations, we did not optimize this hyperparameter further, but we encourage you to try this with different values for <code class="email">sequence_length</code>, such as 50, 100, 200, 250, and 300.</p><p class="calibre8">Check out the following code for the implementation of these steps to create sequences of the same length:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; ## Define same-length sequences
&gt;&gt;&gt; ## if sequence length &lt; 200: left-pad with zeros
&gt;&gt;&gt; ## if sequence length &gt; 200: use the last 200 elements
&gt;&gt;&gt;
&gt;&gt;&gt; sequence_length = 200  ## (Known as T in our RNN formulas)
&gt;&gt;&gt; sequences = np.zeros((len(mapped_reviews), sequence_length),
...                       dtype=int)
&gt;&gt;&gt;
&gt;&gt;&gt; for i, row in enumerate(mapped_reviews):
...     review_arr = np.array(row)
...     sequences[i, -len(row):] = review_arr[-sequence_length:]</pre></div><p class="calibre8">After we preprocess the<a id="calibre_link-2640" class="calibre1"></a> dataset, we can proceed with splitting the data into separate training and test sets. Since the dataset was already shuffled, we can simply take the first half of the dataset for training and the second half for testing, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; X_train = sequences[:25000,:]
&gt;&gt;&gt; y_train = df.loc[:25000, 'sentiment'].values
&gt;&gt;&gt; X_test = sequences[25000:,:]
&gt;&gt;&gt; y_test = df.loc[25000:, 'sentiment'].values</pre></div><p class="calibre8">Now if we want to separate the dataset for cross-validation, we can further split the second half of the data further to generate a smaller test set and a validation set for hyperparameter optimization.</p><p class="calibre8">Finally, we define a helper function that breaks a given dataset (which could be a training set or test set) into chunks and returns a<a id="calibre_link-2641" class="calibre1"></a> generator to iterate through these chunks (also known as <span class="strong"><strong class="calibre2">mini-batches</strong></span>):</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; np.random.seed(123) # for reproducibility

&gt;&gt;&gt; ## Define a function to generate mini-batches:
&gt;&gt;&gt; def create_batch_generator(x, y=None, batch_size=64):
...     n_batches = len(x)//batch_size
...     x = x[:n_batches*batch_size]
...     if y is not None:
...         y = y[:n_batches*batch_size]
...     for ii in range(0, len(x), batch_size):
...         if y is not None:
...             yield x[ii:ii+batch_size], y[ii:ii+batch_size]
...         else:
...             yield x[ii:ii+batch_size]</pre></div><p class="calibre8">Using generators, as we've done in this code, is a very useful technique for handling memory limitations. This is the recommended approach for splitting the dataset into mini-batches for training a neural network, rather than creating all the data splits upfront and keeping them in memory during training.</p></div></div></div>

<div id="calibre_link-641" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="Embedding"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2642"><a id="calibre_link-439" class="calibre1"></a>Embedding</h2></div></div></div><p class="calibre8">During the data preparation in the previous step, we generated sequences of the same length. The elements of these sequences were integer numbers that corresponded to the <span class="strong"><em class="calibre9">indices</em></span> of unique words.</p><p class="calibre8">These word indices can be converted into input features in several different ways. One naÃ¯ve way is to apply one-hot encoding to convert indices into vectors of zeros and ones. Then, each word will be mapped to a vector whose size is the number of unique words in the entire dataset. Given that the number of unique words (the size of the vocabulary) can be in the order of 20,000, which will also be the number of our input features, a model trained on such features may suffer from the <span class="strong"><strong class="calibre2">curse of dimensionality</strong></span>. Furthermore, these features are very sparse, since all are zero except one.</p><p class="calibre8">A more elegant way is to map each word to a vector of fixed size with real-valued elements (not necessarily integers). In contrast to the one-hot encoded vectors, we can use finite-sized vectors to represent an infinite number of real numbers (in theory, we can extract infinite real numbers from a given interval, for example [-1, 1]). </p><p class="calibre8">This is the idea <a id="calibre_link-2643" class="calibre1"></a>behind the so-called <span class="strong"><strong class="calibre2">embedding</strong></span>, which is a feature-learning technique that we can utilize here to automatically learn the salient features to represent the words in our dataset. Given the number of unique words <span class="strong"><em class="calibre9">unique_words</em></span>, we can choose the size of the embedding vectors to be much smaller than the number of unique words (<span class="strong"><em class="calibre9">embedding_size &lt;&lt; unique_words</em></span>) to represent the entire vocabulary as input features.</p><p class="calibre8">The advantages of <a id="calibre_link-2644" class="calibre1"></a>embedding over one-hot encoding are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">A reduction in the dimensionality of the feature space to decrease the effect of the curse of dimensionality</li><li class="listitem">The extraction of salient features since the embedding layer in a neural network is trainable</li></ul></div><p class="calibre8">The following schematic representation shows how embedding works by mapping vocabulary indices to a trainable <a id="calibre_link-2645" class="calibre1"></a>embedding matrix:</p><div class="mediaobject"><img src="images/00950.jpeg" alt="Embedding" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">TensorFlow implements an efficient function, <code class="email">tf.nn.embedding_lookup</code>, that maps each integer that corresponds to a unique word, to a row of this trainable matrix. For example, integer 1 is mapped to the first row, integer 2 is mapped to the second row, and so on. Then, given a sequence of integers, such as <span class="strong"><em class="calibre9">&lt;0, 5, 3, 4, 19, 2â¦&gt;</em></span>, we need to look up the corresponding rows for each element of this sequence.</p><p class="calibre8">Now let's see how we can create an embedding layer in practice. If we have <code class="email">tf_x</code> as the input layer where the corresponding vocabulary indices are fed with type <code class="email">tf.int32</code>, then creating an embedding layer can be done in two steps, as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">
We start by creating a matrix of size <span class="strong"><img src="images/00476.jpeg" alt="Embedding" class="calibre14" /></span> as a tensor variable, which we call <code class="email">embedding</code>, and we initialize its elements randomly with floats between [-1, 1]:
<div class="informalexample"><pre class="programlisting">embedding = tf.Variable(
                tf.random_uniform(
                    shape=(n_words, embedding_size),
                    minval=-1, maxval=1)
            )</pre></div></li><li class="listitem" value="2">Then, we use the <code class="email">tf.nn.embedding_lookup</code> function to look up the row in the embedding matrix associated with each element of <code class="email">tf_x</code>:<div class="informalexample"><pre class="programlisting">embed_x = tf.nn.embedding_lookup(embedding, tf_x)</pre></div></li></ol><div class="calibre13"></div></div><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2646" class="calibre1"></a>Note</h3><p class="calibre8">As you may have observed in these steps, to create an embedding layer, the <code class="email">tf.nn.embedding_lookup</code> function requires two arguments: the embedding tensor and the lookup IDs.</p><p class="calibre8">The <code class="email">tf.nn.embedding_lookup</code> function has a few optional arguments that allow you to tweak the behavior of the embedding layer, such as applying L2 normalization. Feel free to read more about this function from its official documentation at <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup">https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup</a>.</p></div></div></div></div>

<div id="calibre_link-0" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="Building an RNN model"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2647"><a id="calibre_link-440" class="calibre1"></a>Building an RNN model</h2></div></div></div><p class="calibre8">Now we're ready to build an <a id="calibre_link-2648" class="calibre1"></a>RNN model. We'll implement a <code class="email">SentimentRNN</code> class that has the following methods:</p><div class="book"><ul class="itemizedlist"><li class="listitem">A constructor to set all the model parameters and then create a computation graph and call the <code class="email">self.build</code> method to build the multilayer RNN model.</li><li class="listitem">A <code class="email">build</code> method that declares three placeholders for input data, input labels, and the keep-probability for the dropout configuration of the hidden layer. After declaring these, it creates an embedding layer, and builds the multilayer RNN using the embedded representation as input.</li><li class="listitem">A <code class="email">train</code> method that creates a TensorFlow session for launching the computation graph, iterates through the mini-batches of data, and runs for a fixed number of epochs, to minimize the cost function defined in the graph. This method also saves the model after 10 epochs for checkpointing.</li><li class="listitem">A <code class="email">predict</code> method that creates a new session, restores the last checkpoint saved during the training process, and carries out the predictions for the test data.</li></ul></div><p class="calibre8">In the following code, we'll see the implementation of this class and its methods broken into separate code sections.</p></div></div></div>

<div id="calibre_link-46" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="The SentimentRNN class constructor"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2649"><a id="calibre_link-441" class="calibre1"></a>The SentimentRNN class constructor</h2></div></div></div><p class="calibre8">Let's start with the <a id="calibre_link-2650" class="calibre1"></a>constructor of our <code class="email">SentimentRNN</code> class, which we'll code as follows:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf

class SentimentRNN(object):
    def __init__(self, n_words, seq_len=200,
                 lstm_size=256, num_layers=1, batch_size=64,
                 learning_rate=0.0001, embed_size=200):
        self.n_words = n_words
        self.seq_len = seq_len
        self.lstm_size = lstm_size  ## number of hidden units
        self.num_layers = num_layers
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.embed_size = embed_size

        self.g = tf.Graph()
        with self.g.as_default():
            tf.set_random_seed(123)
            self.build()
            self.saver = tf.train.Saver()
            self.init_op = tf.global_variables_initializer()</pre></div><p class="calibre8">Here, the <code class="email">n_words</code> parameter must be set equal to the number of unique words (plus 1 since we use zero to fill sequences whose size is less than 200) and it's used while creating the embedding layer along with the <code class="email">embed_size</code> hyperparameter. Meanwhile, the <code class="email">seq_len</code> variable must be set according to the length of the sequences that were created in the preprocessing steps we went through previously. Note that <code class="email">lstm_size</code> is another hyperparameter that we've used here, and it determines the number of hidden units in each RNN layer.</p></div></div></div>

<div id="calibre_link-64" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="The build method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2651"><a id="calibre_link-442" class="calibre1"></a>The build method</h2></div></div></div><p class="calibre8">Next, let's discuss the <code class="email">build</code> method <a id="calibre_link-2652" class="calibre1"></a>for our <code class="email">SentimentRNN</code> class. This is the longest and most critical method in our sequence, so we'll be going through it in plenty of detail. First, we'll look at the code in full, so we can see everything together, and then we'll analyze each of its main parts:</p><div class="informalexample"><pre class="programlisting">    def build(self):
        ## Define the placeholders
        tf_x = tf.placeholder(tf.int32,
                    shape=(self.batch_size, self.seq_len),
                    name='tf_x')
        tf_y = tf.placeholder(tf.float32,
                    shape=(self.batch_size),
                    name='tf_y')
        tf_keepprob = tf.placeholder(tf.float32,
                    name='tf_keepprob')

        ## Create the embedding layer
        embedding = tf.Variable(
                    tf.random_uniform(
                        (self.n_words, self.embed_size),
                        minval=-1, maxval=1),
                    name='embedding')
        embed_x = tf.nn.embedding_lookup(
                    embedding, tf_x,
                    name='embeded_x')

        ## Define LSTM cell and stack them together
        cells = tf.contrib.rnn.MultiRNNCell(
                [tf.contrib.rnn.DropoutWrapper(
                   tf.contrib.rnn.BasicLSTMCell(self.lstm_size),
                   output_keep_prob=tf_keepprob)
                 for i in range(self.num_layers)])

        ## Define the initial state:
        self.initial_state = cells.zero_state(
                 self.batch_size, tf.float32)
        print('  &lt;&lt; initial state &gt;&gt; ', self.initial_state)

        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(
                 cells, embed_x,
                 initial_state=self.initial_state)

        ## Note: lstm_outputs shape:
        ##  [batch_size, max_time, cells.output_size]
        print('\n  &lt;&lt; lstm_output   &gt;&gt; ', lstm_outputs)
        print('\n  &lt;&lt; final state   &gt;&gt; ', self.final_state)

        logits = tf.layers.dense(
                 inputs=lstm_outputs[:, -1],
                 units=1, activation=None,
                 name='logits')
        
        logits = tf.squeeze(logits, name='logits_squeezed')
        print ('\n  &lt;&lt; logits        &gt;&gt; ', logits)
        
        y_proba = tf.nn.sigmoid(logits, name='probabilities')
        predictions = {
            'probabilities': y_proba,
            'labels' : tf.cast(tf.round(y_proba), tf.int32,
                 name='labels')
        }
        print('\n  &lt;&lt; predictions   &gt;&gt; ', predictions)

        ## Define the cost function
        cost = tf.reduce_mean(
                 tf.nn.sigmoid_cross_entropy_with_logits(
                 labels=tf_y, logits=logits),
                 name='cost')
        
        ## Define the optimizer
        optimizer = tf.train.AdamOptimizer(self.learning_rate)
        train_op = optimizer.minimize(cost, name='train_op')</pre></div><p class="calibre8">So first of all in our <code class="email">build</code> method <a id="calibre_link-2653" class="calibre1"></a>here, we created three placeholders, namely <code class="email">tf_x</code>, <code class="email">tf_y</code>, and <code class="email">tf_keepprob</code>, which we need for feeding the input data. Then we added the embedding layer, which builds the embedded representation <code class="email">embed_x</code>, as we discussed earlier.</p><p class="calibre8">Next, in our <code class="email">build</code> method, we built the RNN network with LSTM cells. We did this in three steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, we defined the multilayer RNN cells.</li><li class="listitem" value="2">Next, we defined the initial state for these cells.</li><li class="listitem" value="3">Finally, we created an RNN specified by the RNN cells and their initial states.</li></ol><div class="calibre13"></div></div><p class="calibre8">Let's break these three steps out in detail in the following three sections, so we can examine in depth how we built the RNN network in our <code class="email">build</code> method.</p><div class="book" title="Step 1 â defining multilayer RNN cells"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-443" class="calibre1"></a>Step 1 &ndash; defining multilayer RNN cells</h3></div></div></div><p class="calibre8">To examine<a id="calibre_link-2654" class="calibre1"></a> how we coded our <code class="email">build</code> method to build the RNN network, the first step was to define our multilayer RNN cells.</p><p class="calibre8">Fortunately, TensorFlow has a very nice wrapper class to define LSTM cells&mdash;the <code class="email">BasicLSTMCell</code> class&mdash;which can be stacked together to form a multilayer RNN using the <code class="email">MultiRNNCell</code> wrapper class. The process of stacking RNN cells with a dropout has three nested steps; these three nested steps can be described from inside out as follows:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, create the RNN cells using <code class="email">tf.contrib.rnn.BasicLSTMCell</code>.</li><li class="listitem" value="2">Apply the dropout to the RNN cells using <code class="email">tf.contrib.rnn.DropoutWrapper</code>.</li><li class="listitem" value="3">Make a list of such cells according to the desired number of RNN layers and pass this list to <code class="email">tf.contrib.rnn.MultiRNNCell</code>.</li></ol><div class="calibre13"></div></div><p class="calibre8">In our <code class="email">build</code> method code, this list is created using Python list comprehension. Note that for a single layer, this list has only one cell.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2655" class="calibre1"></a>Note</h3><p class="calibre8">You <a id="calibre_link-2656" class="calibre1"></a>can read<a id="calibre_link-2657" class="calibre1"></a> more about these<a id="calibre_link-2658" class="calibre1"></a> functions at the following links:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">tf.contrib.rnn.BasicLSTMCell</code>:<a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell">https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell</a></li><li class="listitem"><code class="email">tf.contrib.rnn.DropoutWrapper</code>: <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper">https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper</a></li><li class="listitem"><code class="email">tf.contrib.rnn.MultiRNNCell</code>: <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell">https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell</a></li></ul></div></div></div><div class="book" title="Step 2 â defining the initial states for the RNN cells"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-444" class="calibre1"></a>Step 2 &ndash; defining the initial states for the RNN cells</h3></div></div></div><p class="calibre8">The second step that our <code class="email">build</code> method takes to build the<a id="calibre_link-2659" class="calibre1"></a> RNN network was to define the initial states for the RNN cells.</p><p class="calibre8">You'll recall from the architecture of LSTM cells, there are three types of inputs in an LSTM cell&mdash;input data <span class="strong"><img src="images/00956.jpeg" alt="Step 2 â defining the initial states for the RNN cells" class="calibre14" /></span>, activations of hidden units from the previous time step <span class="strong"><img src="images/00317.jpeg" alt="Step 2 â defining the initial states for the RNN cells" class="calibre14" /></span>, and the cell state from the previous time step <span class="strong"><img src="images/00730.jpeg" alt="Step 2 â defining the initial states for the RNN cells" class="calibre14" /></span>.</p><p class="calibre8">So, in our<code class="email"> build</code> method implementation, <span class="strong"><img src="images/00956.jpeg" alt="Step 2 â defining the initial states for the RNN cells" class="calibre14" /></span> is the embedded <code class="email">embed_x</code> data tensor. However, when we evaluate the <code class="email">cells</code>, we also need to specify the previous state of the cells. So, when we start processing a new input sequence, we initialize the cell states to zero state; then after each time step, we need to store the updated state of the cells to use for the next time step.</p><p class="calibre8">Once our multilayer <a id="calibre_link-2660" class="calibre1"></a>RNN object is defined (<code class="email">cells</code> in our implementation), we define its initial state in our <code class="email">build</code> method using the <code class="email">cells.zero_state</code> method.</p></div><div class="book" title="Step 3 â creating the RNN using the RNN cells and their states"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="calibre_link-445" class="calibre1"></a>Step 3 &ndash; creating the RNN using the RNN cells and their states</h3></div></div></div><p class="calibre8">The third step to creating the<a id="calibre_link-2661" class="calibre1"></a> RNN in our <code class="email">build</code> method, used the <code class="email">tf.nn.dynamic_rnn</code> function to pull together all our components.</p><p class="calibre8">The <code class="email">tf.nn.dynamic_rnn</code> function therefore pulls the embedded data, the RNN cells, and their initial states, and creates a pipeline for them according to the unrolled architecture of LSTM cells.</p><p class="calibre8">The <code class="email">tf.nn.dynamic_rnn</code> function returns a tuple containing the activations of the RNN cells, <code class="email">outputs</code>; and their final states, <code class="email">state</code>. The output is a three-dimensional tensor with this shape&mdash;<code class="email">(batch_size, num_steps, lstm_size)</code>. We pass <code class="email">outputs</code> to a fully connected layer to get <code class="email">logits</code> and we store the final state to use as the initial state of the next mini-batch of data.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="calibre_link-2662" class="calibre1"></a>Note</h3><p class="calibre8">Feel free to read <a id="calibre_link-2663" class="calibre1"></a>more about the <code class="email">tf.nn.dynamic_rnn</code> function at its official documentation page at <a class="calibre1" href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a>.</p></div><p class="calibre8">Finally, in our <code class="email">build</code> method, after setting up the RNN components of the network, the cost function and optimization schemes can be defined like any other neural network.</p></div></div></div></div>

<div id="calibre_link-104" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="The train method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2664"><a id="calibre_link-446" class="calibre1"></a>The train method</h2></div></div></div><p class="calibre8">The next method in our <code class="email">SentimentRNN</code> class is <code class="email">train</code>. This method call is quite similar to the train methods we created in <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span> and <a class="calibre1" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks" href="#calibre_link-20">Chapter 15</a>, <span class="strong"><em class="calibre9">Classifying Images with Deep Convolutional Neural Networks</em></span> except that we have an additional tensor, <code class="email">state</code>, that we feed into our network.</p><p class="calibre8">The following code shows the implementation of the <code class="email">train</code> method:</p><div class="informalexample"><pre class="programlisting">    def train(self, X_train, y_train, num_epochs):
        with tf.Session(graph=self.g) as sess:
            sess.run(self.init_op)
            iteration = 1
            for epoch in range(num_epochs):
                state = sess.run(self.initial_state)
                
                for batch_x, batch_y in create_batch_generator(
                            X_train, y_train, self.batch_size):
                    feed = {'tf_x:0': batch_x,
                            'tf_y:0': batch_y,
                            'tf_keepprob:0': 0.5,
                            self.initial_state : state}
                    loss, _, state = sess.run(
                            ['cost:0', 'train_op',
                             self.final_state],
                             feed_dict=feed)

                    if iteration % 20 == 0:
                        print("Epoch: %d/%d Iteration: %d "
                              "| Train loss: %.5f" % (
                               epoch + 1, num_epochs,
                               iteration, loss))

                    iteration +=1
                if (epoch+1)%10 == 0:
                    self.saver.save(sess,
                        "model/sentiment-%d.ckpt" % epoch)</pre></div><p class="calibre8">In this implementation of our <code class="email">train</code> method, at the beginning of each epoch, we start from the zero states of<a id="calibre_link-2665" class="calibre1"></a> RNN cells as our current state. Running each mini-batch of data is performed by feeding the current state along with the data <code class="email">batch_x</code> and their labels <code class="email">batch_y</code>. Upon finishing the execution of a mini-batch, we update the state to be the final state, which is returned by the <code class="email">tf.nn.dynamic_rnn</code> function. This updated state will be used toward execution of the next mini-batch. This process is repeated and the current state is updated throughout the epoch.</p></div></div></div>

<div id="calibre_link-139" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="The predict method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2666"><a id="calibre_link-447" class="calibre1"></a>The predict method</h2></div></div></div><p class="calibre8">Finally, the last method in <a id="calibre_link-2667" class="calibre1"></a>our <code class="email">SentimentRNN</code> class is the <code class="email">predict</code> method, which keeps updating the current state similar to the <code class="email">train</code> method, shown in the following code:</p><div class="informalexample"><pre class="programlisting">    def predict(self, X_data, return_proba=False):
        preds = []
        with tf.Session(graph = self.g) as sess:
            self.saver.restore(
                sess, tf.train.latest_checkpoint('./model/'))
            test_state = sess.run(self.initial_state)
            for ii, batch_x in enumerate(
                create_batch_generator(
                    X_data, None, batch_size=self.batch_size), 1):
                feed = {'tf_x:0' : batch_x,
                        'tf_keepprob:0' : 1.0,
                        self.initial_state : test_state}
                if return_proba:
                    pred, test_state = sess.run(
                        ['probabilities:0', self.final_state],
                        feed_dict=feed)
                else:
                    pred, test_state = sess.run(
                        ['labels:0', self.final_state],
                        feed_dict=feed)
                    
                preds.append(pred)
                
        return np.concatenate(preds)</pre></div></div></div></div>

<div id="calibre_link-158" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="Instantiating the SentimentRNN class"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2668"><a id="calibre_link-448" class="calibre1"></a>Instantiating the SentimentRNN class</h2></div></div></div><p class="calibre8">We've now coded and <a id="calibre_link-2669" class="calibre1"></a>examined all four parts of our <code class="email">SentimentRNN </code>class, which were the class constructor, the <code class="email">build </code>method, the <code class="email">train</code> method, and the <code class="email">predict</code> method.</p><p class="calibre8">We are now ready to create an object of the class <code class="email">SentimentRNN</code>, with parameters as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; n_words = max(list(word_to_int.values())) + 1
&gt;&gt;&gt;
&gt;&gt;&gt; rnn = SentimentRNN(n_words=n_words,
...                    seq_len=sequence_length,
...                    embed_size=256,
...                    lstm_size=128,
...                    num_layers=1,
...                    batch_size=100,
...                    learning_rate=0.001)</pre></div><p class="calibre8">Notice here that we use <code class="email">num_layers=1</code> to use a single RNN layer. Although our implementation allows us to create multilayer RNNs, by setting <code class="email">num_layers</code> greater than 1. Here we should <a id="calibre_link-2670" class="calibre1"></a>consider the small size of our dataset, and that a single RNN layer may generalize better to unseen data, since it is less likely to overfit the training data.</p></div></div></div>

<div id="calibre_link-179" class="calibre">
<div class="book" title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs">
<div class="book" title="Training and optimizing the sentiment analysis RNN model"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2671"><a id="calibre_link-449" class="calibre1"></a>Training and optimizing the sentiment analysis RNN model</h2></div></div></div><p class="calibre8">Next, we can train the <a id="calibre_link-2672" class="calibre1"></a>RNN model by calling the <code class="email">rnn.train</code> function. In the following code, we train the<a id="calibre_link-2673" class="calibre1"></a> model for <code class="email">40</code> epochs using the input from <code class="email">X_train</code> and the corresponding class labels stored in <code class="email">y_train</code>:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; rnn.train(X_train, y_train, num_epochs=40)
Epoch: 1/40 Iteration: 20 | Train loss: 0.70637
Epoch: 1/40 Iteration: 40 | Train loss: 0.60539
Epoch: 1/40 Iteration: 60 | Train loss: 0.66977
Epoch: 1/40 Iteration: 80 | Train loss: 0.51997
...</pre></div><p class="calibre8">The trained model is saved using TensorFlow's checkpointing system, which we discussed in <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span>. Now, we can use the trained model for predicting the class labels on the test set, as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; preds = rnn.predict(X_test)
&gt;&gt;&gt; y_true = y_test[:len(preds)]
&gt;&gt;&gt; print('Test Acc.: %.3f' % (
...     np.sum(preds == y_true) / len(y_true)))</pre></div><p class="calibre8">The result will show an accuracy of 86 percent. Given the small size of this dataset, this is comparable to the test prediction accuracy obtained in <a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span>.</p><p class="calibre8">We can optimize this further by <a id="calibre_link-2674" class="calibre1"></a>changing the hyperparameters of the model, such as <code class="email">lstm_size</code>, <code class="email">seq_len</code>, and <code class="email">embed_size</code>, to achieve better generalization performance. However, for hyperparameter <a id="calibre_link-2675" class="calibre1"></a>tuning, it is recommended that we create a separate validation set and that we don't repeatedly use the test set for evaluation to avoid introducing bias through test data leakage, which we discussed in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>.</p><p class="calibre8">Also, if you're interested in the prediction probabilities on the test set rather than the class labels, then you can set <code class="email">return_proba=True</code> as follows:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; proba = rnn.predict(X_test, return_proba=True)</pre></div><p class="calibre8">So this was our first RNN model for sentiment analysis. We'll now go further and create an RNN for character-by-character language modeling in TensorFlow, as another popular application of sequence modeling.</p></div></div></div>

<div id="calibre_link-466" class="calibre">
<div id="calibre_link-2676" class="calibre10"></div><div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow"><div class="book" id="calibre_link-69"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2677"><a id="calibre_link-2678" class="calibre1"></a>Project two &ndash; implementing an RNN for character-level language modeling in TensorFlow</h1></div></div></div><p class="calibre8">Language modeling is a <a id="calibre_link-2679" class="calibre1"></a>fascinating application that enables machines to perform human-language-related tasks, such as <a id="calibre_link-2680" class="calibre1"></a>generating English sentences. One of the interesting efforts in this area is the work done by Sutskever, Martens, and Hinton (<span class="strong"><em class="calibre9">Generating Text with Recurrent Neural Networks</em></span>, <span class="strong"><em class="calibre9">Ilya Sutskever</em></span>, <span class="strong"><em class="calibre9">James Martens</em></span>, and <span class="strong"><em class="calibre9">Geoffrey E. Hinton</em></span>, <span class="strong"><em class="calibre9">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</em></span>, <span class="strong"><em class="calibre9">2011</em></span> <a class="calibre1" href="https://pdfs.semanticscholar.org/93c2/0e38c85b69fc2d2eb314b3c1217913f7db11.pdf">https://pdfs.semanticscholar.org/93c2/0e38c85b69fc2d2eb314b3c1217913f7db11.pdf</a>).</p><p class="calibre8">In the model that we'll build now, the input is a text document, and our goal is to develop a model that can generate new text similar to the input document. Examples of such an input can be a book or a computer program in a specific programming language.</p><p class="calibre8">In character-level language modeling, the input is broken down into a sequence of characters that are fed into our network one character at a time. The network will process each new character in conjunction with the memory of the previously seen characters to predict the next character. The following figure shows an example of character-level language modeling:</p><div class="mediaobject"><img src="images/00486.jpeg" alt="Project two â implementing an RNN for character-level language modeling in TensorFlow" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">We can break this<a id="calibre_link-2681" class="calibre1"></a> implementation down into three separate steps&mdash;preparing the data, building the RNN model, and performing next-character prediction and sampling to generate new text.</p><p class="calibre8">If you recall from the previous sections of this chapter, we mentioned the exploding gradient problem. In this application, we'll also get a chance to play with a gradient clipping technique to avoid this exploding gradient problem.</p></div></div>

<div id="calibre_link-497" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="Preparing the data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2682"><a id="calibre_link-450" class="calibre1"></a>Preparing the data</h2></div></div></div><p class="calibre8">In this section, we prepare<a id="calibre_link-2683" class="calibre1"></a> the data for<a id="calibre_link-2684" class="calibre1"></a> character-level language modeling.</p><p class="calibre8">To get the input data, visit the Project Gutenberg website at <a class="calibre1" href="https://www.gutenberg.org/">https://www.gutenberg.org/</a>, which provides thousands of free e-books. For our example, we can get the book <span class="strong"><em class="calibre9">The Tragedie of Hamlet</em></span> by William Shakespeare in plain text format from <a class="calibre1" href="http://www.gutenberg.org/cache/epub/2265/pg2265.txt">http://www.gutenberg.org/cache/epub/2265/pg2265.txt</a>.</p><p class="calibre8">Note that this link will directly take you to the download page. If you are using macOS or a Linux operating system, you can download the file with the following command in the Terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">curl http://www.gutenberg.org/cache/epub/2265/pg2265.txt &gt; pg2265.txt</strong></span>
</pre></div><p class="calibre8">If this resource becomes unavailable in future, a copy of this text is also included in  this chapter's code directory in the book's code repository at <a class="calibre1" href="https://github.com/rasbt/python-machine-learning-book-2nd-edition">https://github.com/rasbt/python-machine-learning-book-2nd-edition</a>.</p><p class="calibre8">Once we have some data, we can read it into a Python session as plain text. In the following code, the <a id="calibre_link-2685" class="calibre1"></a>Python variable <code class="email">chars</code> represents the set of <span class="strong"><em class="calibre9">unique</em></span> characters observed in this text. We then create a <a id="calibre_link-2686" class="calibre1"></a>dictionary that maps each character to an integer, <code class="email">char2int</code>, and a dictionary that performs reverse mapping, for instance, mapping integers to those unique characters&mdash;<code class="email">int2char</code>. Using the <code class="email">char2int</code> dictionary, we convert the text into a NumPy array of integers. The following figure shows an example of converting characters into integers and the reverse for the words <code class="email">"Hello"</code> and <code class="email">"world"</code>:</p><div class="mediaobject"><img src="images/00465.jpeg" alt="Preparing the data" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">This code reads the text from the downloaded link, removes the beginning portion of the text that contains some legal description of the Gutenberg project, and then constructs the dictionaries based on the text:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; ## Reading and processing text
&gt;&gt;&gt; with open('pg2265.txt', 'r', encoding='utf-8') as f:
...     text=f.read()
&gt;&gt;&gt; text = text[15858:]
&gt;&gt;&gt; chars = set(text)
&gt;&gt;&gt; char2int = {ch:i for i,ch in enumerate(chars)}
&gt;&gt;&gt; int2char = dict(enumerate(chars))
&gt;&gt;&gt; text_ints = np.array([char2int[ch] for ch in text],
...                      dtype=np.int32)</pre></div><p class="calibre8">Now, we should reshape the data into batches of sequences, the most important step in preparing data. As we know, the goal is to predict the next character based on the sequence of characters that we have observed so far. Therefore, we shift the input (<span class="strong"><strong class="calibre2">x</strong></span>) and output (<span class="strong"><strong class="calibre2">y</strong></span>) of the neural <a id="calibre_link-2687" class="calibre1"></a>network by one<a id="calibre_link-2688" class="calibre1"></a> character. The following figure shows the preprocessing steps, starting from a text corpus to generating data arrays for <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">y</strong></span>:</p><div class="mediaobject"><img src="images/00887.jpeg" alt="Preparing the data" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">As you can see in this figure, the training arrays <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">y</strong></span> have the same shapes or dimensions, where the number of rows is equal to the <span class="strong"><em class="calibre9">batch size</em></span> and the number of columns is <span class="strong"><img src="images/00960.jpeg" alt="Preparing the data" class="calibre14" /></span>.</p><p class="calibre8">Given the input array <code class="email">data</code> that contains the integers that correspond to the characters in the text corpus, the following function will generate <code class="email">x</code> and <code class="email">y</code> with the same structure shown in the previous figure:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def reshape_data(sequence, batch_size, num_steps):
...     tot_batch_length = batch_size * num_steps
...     num_batches = int(len(sequence) / tot_batch_length)
...     if num_batches*tot_batch_length + 1 &gt; len(sequence):
...         num_batches = num_batches - 1
...     ## Truncate the sequence at the end to get rid of
...     ## remaining charcaters that do not make a full batch
...     x = sequence[0: num_batches*tot_batch_length]
...     y = sequence[1: num_batches*tot_batch_length + 1]
...     ## Split x &amp; y into a list batches of sequences:
...     x_batch_splits = np.split(x, batch_size)
...     y_batch_splits = np.split(y, batch_size)
...     ## Stack the batches together
...     ## batch_size x tot_batch_length
...     x = np.stack(x_batch_splits)
...     y = np.stack(y_batch_splits)
...     
...     return x, y</pre></div><p class="calibre8">The <a id="calibre_link-2689" class="calibre1"></a>next step is to split the <a id="calibre_link-2690" class="calibre1"></a>arrays <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">y</strong></span> into mini-batches where each row is a sequence with length equal to the <span class="strong"><em class="calibre9">number of steps</em></span>. The process of splitting the data array <span class="strong"><strong class="calibre2">x</strong></span> is shown in the following figure:</p><div class="mediaobject"><img src="images/00053.jpeg" alt="Preparing the data" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">In the following code, we define a function named <code class="email">create_batch_generator</code> that splits the data arrays <span class="strong"><strong class="calibre2">x</strong></span> and <span class="strong"><strong class="calibre2">y</strong></span>, as shown in the previous figure, and outputs a batch generator. Later, we will use this generator to iterate through the mini-batches during the training of our network:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; def create_batch_generator(data_x, data_y, num_steps):
...     batch_size, tot_batch_length = data_x.shape
...     num_batches = int(tot_batch_length/num_steps)
...     for b in range(num_batches):
...         yield (data_x[:, b*num_steps:(b+1)*num_steps],
...                data_y[:, b*num_steps:(b+1)*num_steps])</pre></div><p class="calibre8">At this point, we've <a id="calibre_link-2691" class="calibre1"></a>now completed the <a id="calibre_link-2692" class="calibre1"></a>data preprocessing steps, and we have the data in the proper format. In the next section, we'll implement the RNN model for character-level language modeling.</p></div></div></div>

<div id="calibre_link-515" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="Building a character-level RNN model"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2693"><a id="calibre_link-451" class="calibre1"></a>Building a character-level RNN model</h2></div></div></div><p class="calibre8">To build a<a id="calibre_link-2694" class="calibre1"></a> character-level neural network, we'll implement a class called <code class="email">CharRNN</code> that constructs the graph of the RNN in order to predict the next character, after observing a given sequence of characters. From the classification perspective, the number of classes is the total number of unique characters that exists in the text corpus. The <code class="email">CharRNN</code> class has four methods, as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">A constructor that sets up the learning parameters, creates a computation graph, and calls the <code class="email">build</code> method to construct the graph based on the sampling mode versus the training mode.</li><li class="listitem">A <code class="email">build</code> method that defines the placeholders for feeding the data, constructs the RNN using LSTM cells, and defines the output of the network, the cost function, and the optimizer.</li><li class="listitem">A <code class="email">train</code> method to iterate through the mini-batches and train the network for the specified number of epochs.</li><li class="listitem">A <code class="email">sample</code> method to start from a given string, calculate the probabilities for the next character, and choose a character randomly according to these probabilities. This process will be repeated, and the sampled characters will be concatenated together to form a string. Once the size of this string reaches the specified length, it will return the string.</li></ul></div><p class="calibre8">We'll break these four methods into separate code sections and explain each one. Note that implementing the RNN part of this model is very similar to the implementation in the <span class="strong"><em class="calibre9">Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</em></span> section. So, we'll skip the description of building the RNN components here.</p></div></div></div>

<div id="calibre_link-532" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="The constructor"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2695"><a id="calibre_link-452" class="calibre1"></a>The constructor</h2></div></div></div><p class="calibre8">In contrast to our <a id="calibre_link-2696" class="calibre1"></a>previous implementation for sentiment analysis, where the same computation graph was used for both training and prediction modes, this time our computation graph is going to be different for the training versus the sampling mode.</p><p class="calibre8">Therefore we need to add a new Boolean type argument to the constructor, to determine whether we're building the model for the training mode or the sampling mode. The following code shows the implementation of the constructor enclosed in the class definition:</p><div class="informalexample"><pre class="programlisting">import tensorflow as tf
import os

class CharRNN(object):
    def __init__(self, num_classes, batch_size=64,
                 num_steps=100, lstm_size=128,
                 num_layers=1, learning_rate=0.001,
                 keep_prob=0.5, grad_clip=5,
                 sampling=False):
        self.num_classes = num_classes
        self.batch_size = batch_size
        self.num_steps = num_steps
        self.lstm_size = lstm_size
        self.num_layers = num_layers
        self.learning_rate = learning_rate
        self.keep_prob = keep_prob
        self.grad_clip = grad_clip
        
        self.g = tf.Graph()
        with self.g.as_default():
            tf.set_random_seed(123)

            self.build(sampling=sampling)

            self.saver = tf.train.Saver()

            self.init_op = tf.global_variables_initializer()</pre></div><p class="calibre8">As we planned earlier, the Boolean <code class="email">sampling</code> argument is used to determine whether the instance of <code class="email">CharRNN</code> is for building the graph in the training mode (<code class="email">sampling=False</code>) or the sampling mode (<code class="email">sampling=True</code>).</p><p class="calibre8">In addition to the <code class="email">sampling</code> argument, we've introduced a new argument called <code class="email">grad_clip</code>, which is used for clipping the gradients to avoid the exploding gradient problem that we mentioned earlier.</p><p class="calibre8">Then, similar to the previous implementation, the constructor creates a computation graph, sets the graph-level random seed for consistent output, and builds the graph by calling the <code class="email">build</code> method.</p></div></div></div>

<div id="calibre_link-548" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="The build method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2697"><a id="calibre_link-453" class="calibre1"></a>The build method</h2></div></div></div><p class="calibre8">The next <a id="calibre_link-2698" class="calibre1"></a>method of the <code class="email">CharRNN</code> class is <code class="email">build</code>, which is very similar to the <code class="email">build</code> method in the <span class="strong"><em class="calibre9">Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</em></span> section, except for some minor differences. The <code class="email">build</code> method first defines two local variables, <code class="email">batch_size</code> and <code class="email">num_steps</code>, based on the mode, as follows:</p><div class="mediaobject"><img src="images/00094.jpeg" alt="The build method" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">Recall that in the sentiment analysis implementation, we used an embedding layer to create a salient representation for the unique words in the dataset. In contrast, here we are using the one-hot encoding scheme for both <span class="strong"><em class="calibre9">x</em></span> and <span class="strong"><em class="calibre9">y</em></span> with <code class="email">depth=num_classes</code>, where <code class="email">num_classes</code> is in fact the total number of characters in the text corpus.</p><p class="calibre8">Building a multilayer RNN component of the model is exactly the same as in our sentiment analysis implementation, using the <code class="email">tf.nn.dynamic_rnn</code> function. However, <code class="email">outputs</code> from the <code class="email">tf.nn.dynamic_rnn</code> function is a three-dimensional tensor with this shape&mdash;<code class="email">batch_size, num_steps, lstm_size</code>. Next, this tensor will be reshaped into a two-dimensional tensor with the <code class="email">batch_size*num_steps, lstm_size</code> shape, which is passed to the <code class="email">tf.layers.dense </code>function to make a fully connected layer and obtain <code class="email">logits</code> (net inputs). Finally, the probabilities for the next batch of characters are obtained and the cost function is defined. In addition, here, we apply gradient clipping using the <code class="email">tf.clip_by_global_norm</code> function to avoid the exploding gradient problem.</p><p class="calibre8">The following <a id="calibre_link-2699" class="calibre1"></a>code shows the implementation of what we've just described for our new <code class="email">build</code> method:</p><div class="informalexample"><pre class="programlisting">    def build(self, sampling):
        if sampling == True:
            batch_size, num_steps = 1, 1
        else:
            batch_size = self.batch_size
            num_steps = self.num_steps

        tf_x = tf.placeholder(tf.int32,
                              shape=[batch_size, num_steps],
                              name='tf_x')
        tf_y = tf.placeholder(tf.int32,
                              shape=[batch_size, num_steps],
                              name='tf_y')
        tf_keepprob = tf.placeholder(tf.float32,
                              name='tf_keepprob')

        # One-hot encoding:
        x_onehot = tf.one_hot(tf_x, depth=self.num_classes)
        y_onehot = tf.one_hot(tf_y, depth=self.num_classes)

        ### Build the multi-layer RNN cells
        cells = tf.contrib.rnn.MultiRNNCell(
            [tf.contrib.rnn.DropoutWrapper(
                tf.contrib.rnn.BasicLSTMCell(self.lstm_size),
                output_keep_prob=tf_keepprob)
            for _ in range(self.num_layers)])
        
        ## Define the initial state
        self.initial_state = cells.zero_state(
                    batch_size, tf.float32)

        ## Run each sequence step through the RNN
        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(
                    cells, x_onehot,
                    initial_state=self.initial_state)
        
        print('  &lt;&lt; lstm_outputs  &gt;&gt;', lstm_outputs)

        seq_output_reshaped = tf.reshape(
                    lstm_outputs,
                    shape=[-1, self.lstm_size],
                    name='seq_output_reshaped')

        logits = tf.layers.dense(
                    inputs=seq_output_reshaped,
                    units=self.num_classes,
                    activation=None,
                    name='logits')

        proba = tf.nn.softmax(
                    logits,
                    name='probabilities')

        y_reshaped = tf.reshape(
                    y_onehot,
                    shape=[-1, self.num_classes],
                    name='y_reshaped')
        cost = tf.reduce_mean(
                    tf.nn.softmax_cross_entropy_with_logits(
                        logits=logits,
                        labels=y_reshaped),
                    name='cost')

        # Gradient clipping to avoid "exploding gradients"
        tvars = tf.trainable_variables()
        grads, _ = tf.clip_by_global_norm(
                    tf.gradients(cost, tvars),
                    self.grad_clip)
        optimizer = tf.train.AdamOptimizer(self.learning_rate)
        train_op = optimizer.apply_gradients(
                    zip(grads, tvars),
                    name='train_op')</pre></div></div></div></div>

<div id="calibre_link-575" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="The train method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2700"><a id="calibre_link-454" class="calibre1"></a>The train method</h2></div></div></div><p class="calibre8">The next method <a id="calibre_link-2701" class="calibre1"></a>of the <code class="email">CharRNN</code> class is the <code class="email">train</code> method, which is very similar to the <code class="email">train</code> method described in the <span class="strong"><em class="calibre9">Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</em></span> section. Here is the <code class="email">train</code> method code, which will look very familiar to the sentiment analysis version we built earlier in this chapter:</p><div class="informalexample"><pre class="programlisting">    def train(self, train_x, train_y,
              num_epochs, ckpt_dir='./model/'):
        ## Create the checkpoint directory
        ## if it does not exists
        if not os.path.exists(ckpt_dir):
            os.mkdir(ckpt_dir)
            
        with tf.Session(graph=self.g) as sess:
            sess.run(self.init_op)

            n_batches = int(train_x.shape[1]/self.num_steps)
            iterations = n_batches * num_epochs
            for epoch in range(num_epochs):

                # Train network
                new_state = sess.run(self.initial_state)
                loss = 0
                ## Mini-batch generator:
                bgen = create_batch_generator(
                        train_x, train_y, self.num_steps)
                for b, (batch_x, batch_y) in enumerate(bgen, 1):
                    iteration = epoch*n_batches + b
                    
                    feed = {'tf_x:0': batch_x,
                            'tf_y:0': batch_y,
                            'tf_keepprob:0' : self.keep_prob,
                            self.initial_state : new_state}
                    batch_cost, _, new_state = sess.run(
                            ['cost:0', 'train_op',
                                self.final_state],
                            feed_dict=feed)
                    if iteration % 10 == 0:
                        print('Epoch %d/%d Iteration %d'
                              '| Training loss: %.4f' % (
                              epoch + 1, num_epochs,
                              iteration, batch_cost))

                ## Save the trained model
                self.saver.save(
                        sess, os.path.join(
                            ckpt_dir, 'language_modeling.ckpt'))</pre></div></div></div></div>

<div id="calibre_link-598" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="The sample method"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2702"><a id="calibre_link-455" class="calibre1"></a>The sample method</h2></div></div></div><p class="calibre8">The final <a id="calibre_link-2703" class="calibre1"></a>method in our <code class="email">CharRNN</code> class is the <code class="email">sample</code> method. The behavior of this <code class="email">sample</code> method is similar to that of the <code class="email">predict</code> method that we implemented in the <span class="strong"><em class="calibre9">Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</em></span> section. However, the difference here is that we calculate the probabilities for the next character from an observed sequence&mdash;<code class="email">observed_seq</code>. Then, these probabilities are passed to a function named <code class="email">get_top_char</code>, which randomly selects one character according to the obtained probabilities.</p><p class="calibre8">Initially, the observed sequence starts from <code class="email">starter_seq</code>, which is provided as an argument. When new characters are sampled according to their predicted probabilities, they are appended to the observed sequence, and the new observed sequence is used for predicting the next character.</p><p class="calibre8">The implementation of the <code class="email">sample</code> method is as follows:</p><div class="informalexample"><pre class="programlisting">    def sample(self, output_length,
               ckpt_dir, starter_seq="The "):
        observed_seq = [ch for ch in starter_seq]
        with tf.Session(graph=self.g) as sess:
            self.saver.restore(
                sess,
                tf.train.latest_checkpoint(ckpt_dir))
            ## 1: run the model using the starter sequence
            new_state = sess.run(self.initial_state)
            for ch in starter_seq:
                x = np.zeros((1, 1))
                x[0, 0] = char2int[ch]
                feed = {'tf_x:0': x,
                        'tf_keepprob:0': 1.0,
                        self.initial_state: new_state}
                proba, new_state = sess.run(
                        ['probabilities:0', self.final_state],
                        feed_dict=feed)

            ch_id = get_top_char(proba, len(chars))
            observed_seq.append(int2char[ch_id])
            
            ## 2: run the model using the updated observed_seq
            for i in range(output_length):
                x[0,0] = ch_id
                feed = {'tf_x:0': x,
                        'tf_keepprob:0': 1.0,
                        self.initial_state: new_state}
                proba, new_state = sess.run(
                        ['probabilities:0', self.final_state],
                        feed_dict=feed)

                ch_id = get_top_char(proba, len(chars))
                observed_seq.append(int2char[ch_id])

        return ''.join(observed_seq)</pre></div><p class="calibre8">So here, the <code class="email">sample</code> method calls the <code class="email">get_top_char</code> function to choose a character ID randomly (<code class="email">ch_id</code>) according to the obtained probabilities.</p><p class="calibre8">In this <code class="email">get_top_char</code> function, the probabilities are first sorted, then the <code class="email">top_n</code> probabilities are passed to the <code class="email">numpy.random.choice</code> function to randomly select one out of these top probabilities. The implementation of the <code class="email">get_top_char</code> function is as follows:</p><div class="informalexample"><pre class="programlisting">def get_top_char(probas, char_size, top_n=5):
    p = np.squeeze(probas)
    p[np.argsort(p)[:-top_n]] = 0.0
    p = p / np.sum(p)
    ch_id = np.random.choice(char_size, 1, p=p)[0]
    return ch_id</pre></div><p class="calibre8">Note, of course, that <a id="calibre_link-2704" class="calibre1"></a>this function should be defined <span class="strong"><em class="calibre9">before</em></span> the definition of the <code class="email">CharRNN</code> class; we've explained it in this order here so that we can explain the concepts in order. Browse through the code notebook that accompanies this chapter to get a better overview of the order in which the functions are defined.</p></div></div></div>

<div id="calibre_link-610" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="Creating and training the CharRNN Model"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2705"><a id="calibre_link-456" class="calibre1"></a>Creating and training the CharRNN Model</h2></div></div></div><p class="calibre8">Now we're ready to create an instance<a id="calibre_link-2706" class="calibre1"></a> of the <code class="email">CharRNN</code> class to build the RNN model, and to train it with the following<a id="calibre_link-2707" class="calibre1"></a> configurations:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; batch_size = 64
&gt;&gt;&gt; num_steps = 100
&gt;&gt;&gt; train_x, train_y = reshape_data(text_ints,
...                                 batch_size,
...                                 num_steps)
&gt;&gt;&gt;
&gt;&gt;&gt; rnn = CharRNN(num_classes=len(chars), batch_size=batch_size)
&gt;&gt;&gt; rnn.train(train_x, train_y,
...           num_epochs=100,
...           ckpt_dir='./model-100/')</pre></div><p class="calibre8">The trained model will be saved in a directory called <code class="email">./model-100/</code> so that we can reload it later for prediction or for continuing the training.</p></div></div></div>

<div id="calibre_link-626" class="calibre">
<div class="book" title="Project two â implementing an RNN for character-level language modeling in TensorFlow">
<div class="book" title="The CharRNN model in the sampling mode"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_link-2708"><a id="calibre_link-457" class="calibre1"></a>The CharRNN model in the sampling mode</h2></div></div></div><p class="calibre8">Next up, we can <a id="calibre_link-2709" class="calibre1"></a>create a new instance of the <code class="email">CharRNN</code> class in the sampling mode by specifying that <code class="email">sampling=True</code>. We'll call the <code class="email">sample</code> method to load the saved model in the <code class="email">./model-100/</code> folder, and generate a sequence of 500 characters:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; del rnn
&gt;&gt;&gt;
&gt;&gt;&gt; np.random.seed(123)
&gt;&gt;&gt; rnn = CharRNN(len(chars), sampling=True)
&gt;&gt;&gt; print(rnn.sample(ckpt_dir='./model-100/',
...                  output_length=500))</pre></div><p class="calibre8">The generated text will look like the following:</p><div class="mediaobject"><img src="images/00152.jpeg" alt="The CharRNN model in the sampling mode" class="calibre11" /></div><p class="calibre12"> </p><p class="calibre8">You can see that in the resulting output, that some English words are mostly preserved. It's also important to note that this is from an old English text; therefore, some words in the original text may be unfamiliar. To get a better result, we would need to train the model for higher number of epochs. Feel free to repeat this with a much larger document and train the model for more epochs.</p></div></div></div>

<div id="calibre_link-642" class="calibre"><div class="book" title="Chapter and book summary"><div class="book" id="calibre_link-458"><div class="book"><div class="book"><h1 class="title" id="calibre_link-2710"><a id="calibre_link-2711" class="calibre1"></a>Chapter and book summary</h1></div></div></div><p class="calibre8">We hope you enjoyed this last chapter of <span class="strong"><em class="calibre9">Python Machine Learning</em></span> and our exciting tour of machine learning and deep learning. Through the journey of this book, we've covered the essential topics that this field has to offer, and you should now be well equipped to put those techniques into action to solve real-world problems.</p><p class="calibre8">We started our journey with a brief overview of the different types of learning tasks: supervised learning, reinforcement learning, and unsupervised learning. We then discussed several different learning algorithms that you can use for classification, starting with simple single-layer neural networks in <a class="calibre1" title="ChapterÂ 2.Â Training Simple Machine Learning Algorithms for Classification" href="#calibre_link-19">Chapter 2</a>, <span class="strong"><em class="calibre9">Training Simple Machine Learning Algorithms for Classification</em></span>.</p><p class="calibre8">We continued to discuss advanced classification algorithms in <a class="calibre1" title="ChapterÂ 3.Â A Tour of Machine Learning Classifiers Using scikit-learn" href="#calibre_link-30">Chapter 3</a>, <span class="strong"><em class="calibre9">A Tour of Machine Learning Classifiers Using scikit-learn</em></span>, and we learned about the most important aspects of a machine learning pipeline in <a class="calibre1" title="ChapterÂ 4.Â Building Good Training Sets â Data Preprocessing" href="#calibre_link-36">Chapter 4</a>, <span class="strong"><em class="calibre9">Building Good Training Sets &ndash; Data Preprocessing</em></span> and <a class="calibre1" title="ChapterÂ 5.Â Compressing Data via Dimensionality Reduction" href="#calibre_link-26">Chapter 5</a>, <span class="strong"><em class="calibre9">Compressing Data via Dimensionality Reduction</em></span>. </p><p class="calibre8">Remember that even the most advanced algorithm is limited by the information in the training data that it gets to learn from. So in <a class="calibre1" title="ChapterÂ 6.Â Learning Best Practices for Model Evaluation and Hyperparameter Tuning" href="#calibre_link-37">Chapter 6</a>, <span class="strong"><em class="calibre9">Learning Best Practices for Model Evaluation and Hyperparameter Tuning</em></span>, we learned about the best practices to build and evaluate predictive models, which is another important aspect in machine learning applications. </p><p class="calibre8">If one single learning algorithm does not achieve the performance we desire, it can be sometimes helpful to create an ensemble of experts to make a prediction. We explored this in <a class="calibre1" title="ChapterÂ 7.Â Combining Different Models for Ensemble Learning" href="#calibre_link-38">Chapter 7</a>, <span class="strong"><em class="calibre9">Combining Different Models for Ensemble Learning</em></span>.</p><p class="calibre8">Then in <a class="calibre1" title="ChapterÂ 8.Â Applying Machine Learning to Sentiment Analysis" href="#calibre_link-39">Chapter 8</a>, <span class="strong"><em class="calibre9">Applying Machine Learning to Sentiment Analysis</em></span>, we applied machine learning to analyze one of the most popular and interesting forms of data in the modern age that's dominated by social media platforms on the internet&mdash;text documents.</p><p class="calibre8">Next, we reminded ourselves that machine learning techniques are not limited to offline data analysis, and in <a class="calibre1" title="ChapterÂ 9.Â Embedding a Machine Learning Model into a Web Application" href="#calibre_link-40">Chapter 9</a>, <span class="strong"><em class="calibre9">Embedding a Machine Learning Model into a Web Application</em></span>, we saw how to embed a machine learning model into a web application to share it with the outside world.</p><p class="calibre8">For the most part, our focus was on algorithms for classification, which is probably the most popular application of machine learning. However, this is not where our journey ended! In <a class="calibre1" title="ChapterÂ 10.Â Predicting Continuous Target Variables with Regression Analysis" href="#calibre_link-41">Chapter 10</a>, <span class="strong"><em class="calibre9">Predicting Continuous Target Variables with Regression Analysis</em></span>, we explored several algorithms for regression analysis to predict continuous valued output values.</p><p class="calibre8">Another exciting subfield of machine learning is clustering analysis, which can help us find hidden structures in the data, even if our training data does not come with the right answers to learn from. We worked with this in <a class="calibre1" title="ChapterÂ 11.Â Working with Unlabeled Data â Clustering Analysis" href="#calibre_link-42">Chapter 11</a>, <span class="strong"><em class="calibre9">Working with Unlabeled Data &ndash; Clustering Analysis</em></span>.</p><p class="calibre8">We then shifted our attention to one of one of the most exciting algorithms in the whole machine learning field&mdash;artificial neural networks. We started by implementing a multilayer perceptron from scratch with NumPy in <a class="calibre1" title="ChapterÂ 12.Â Implementing a Multilayer Artificial Neural Network from Scratch" href="#calibre_link-10">Chapter 12</a>, <span class="strong"><em class="calibre9">Implementing a Multilayer Artificial Neural Network from Scratch</em></span>.</p><p class="calibre8">The power of TensorFlow became obvious in <a class="calibre1" title="ChapterÂ 13.Â Parallelizing Neural Network Training with TensorFlow" href="#calibre_link-16">Chapter 13</a>, <span class="strong"><em class="calibre9">Parallelizing Neural Network Training with TensorFlow</em></span>, where we used TensorFlow to facilitate the process of building neural network models and make use of GPUs to make the training of multilayer neural networks more efficient.</p><p class="calibre8">We delved deeper into the mechanics of TensorFlow in <a class="calibre1" title="ChapterÂ 14.Â Going Deeper â The Mechanics of TensorFlow" href="#calibre_link-43">Chapter 14</a>, <span class="strong"><em class="calibre9">Going Deeper &ndash; The Mechanics of TensorFlow</em></span>, and discussed the different aspects and mechanics of TensorFlow, including variables and operators in a TensorFlow computation graph, variable scopes, launching graphs, and different ways of executing nodes.</p><p class="calibre8">In <a class="calibre1" title="ChapterÂ 15.Â Classifying Images with Deep Convolutional Neural Networks" href="#calibre_link-20">Chapter 15</a>, <span class="strong"><em class="calibre9">Classifying Images with Deep Convolutional Neural Networks</em></span>, we dived into convolutional neural networks, which are widely used in computer vision at the moment, due to their great performance in image classification tasks.</p><p class="calibre8">Finally, here in <a class="calibre1" title="ChapterÂ 16.Â Modeling Sequential Data Using Recurrent Neural Networks" href="#calibre_link-44">Chapter 16</a>, <span class="strong"><em class="calibre9">Modeling Sequential Data Using Recurrent Neural Networks</em></span>, we learned about sequence modeling using RNNs. While a comprehensive study of deep learning is well beyond the scope of this book, we hope that we've kindled your interest enough to follow the most recent advancements in this field of deep learning.</p><p class="calibre8">If you're considering a career in machine learning, or you just want to keep up to date with the current advancements in this field, I can recommend to you the works of the following leading experts in the machine learning field:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Geoffry Hinton (<a class="calibre1" href="http://www.cs.toronto.edu/~hinton/">http://www.cs.toronto.edu/~hinton/</a>) </li><li class="listitem">Andrew Ng (<a class="calibre1" href="http://www.andrewng.org/">http://www.andrewng.org/</a>)</li><li class="listitem">Yann LeCun (<a class="calibre1" href="http://yann.lecun.com">http://yann.lecun.com</a>)</li><li class="listitem">Juergen Schmidhuber (<a class="calibre1" href="http://people.idsia.ch/~juergen/">http://people.idsia.ch/~juergen/</a>)</li><li class="listitem">Yoshua Bengio (<a class="calibre1" href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/">http://www.iro.umontreal.ca/~bengioy/yoshua_en/</a>)</li></ul></div><p class="calibre8">Just to name a few!</p><p class="calibre8">And of course, don't hesitate to join the scikit-learn, TensorFlow, and Keras mailing lists to participate in interesting discussions around these libraries and machine learning in general. Lastly, you can find out what we, the authors, are up at <a class="calibre1" href="http://sebastianraschka.com">http://sebastianraschka.com</a> and <a class="calibre1" href="http://vahidmirjalili.com">http://vahidmirjalili.com</a>. You're always welcome to contact us if you have any questions about this book, or need some general tips about machine learning.</p></div></div>

<div id="calibre_link-1" class="calibre">
<div id="calibre_link-459" class="calibre10"></div><div id="calibre_link-2712" class="book">
      <h1 class="title" id="calibre_link-2713">Index</h1>
      <h2 class="title1">A</h2>
      <ul class="itemizedlist"><li class="listitem">accuracy / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li>
        <li class="listitem">activation functions<ul class="calibre29"><li class="listitem">selecting, for multilayer networks / <a title="Choosing activation functions for multilayer networks" class="calibre1" href="#calibre_link-3">Choosing activation functions for multilayer networks</a></li></ul></li>
        <li class="listitem">activations<ul class="calibre29"><li class="listitem">computing, in RNN / <a title="Computing activations in an RNN" class="calibre1" href="#calibre_link-4">Computing activations in an RNN</a></li></ul></li>
        <li class="listitem">AdaBoost<ul class="calibre29"><li class="listitem">applying, scikit-learn used / <a title="Applying AdaBoost using scikit-learn" class="calibre1" href="#calibre_link-5">Applying AdaBoost using scikit-learn</a></li></ul></li>
        <li class="listitem">AdaBoost (Adaptive Boosting)<ul class="calibre29"><li class="listitem">weak learners, leveraging via / <a title="Leveraging weak learners via adaptive boosting" class="calibre1" href="#calibre_link-5">Leveraging weak learners via adaptive boosting</a></li></ul></li>
        <li class="listitem">Adaline<ul class="calibre29"><li class="listitem">implementing, in Python / <a title="Implementing Adaline in Python" class="calibre1" href="#calibre_link-6">Implementing Adaline in Python</a></li></ul> / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a></li>
        <li class="listitem">Adaline implementation<ul class="calibre29"><li class="listitem">converting, into algotithm for logistic regression / <a title="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre1" href="#calibre_link-8">Converting an Adaline implementation into an algorithm for logistic regression</a></li></ul></li>
        <li class="listitem">ADAptive Linear NEuron (Adaline) / <a title="Solving regression for regression parameters with gradient descent" class="calibre1" href="#calibre_link-9">Solving regression for regression parameters with gradient descent</a></li>
        <li class="listitem">ADAptive LInear NEuron (Adaline) / <a title="Adaptive linear neurons and the convergence of learning" class="calibre1" href="#calibre_link-6">Adaptive linear neurons and the convergence of learning</a></li>
        <li class="listitem">ADAptive LInear NEuron (Adaline) algorithm / <a title="Single-layer neural network recap" class="calibre1" href="#calibre_link-10">Single-layer neural network recap</a></li>
        <li class="listitem">advanced techniques for nonlinear dimensionality reduction, scikit-learn<ul class="calibre29"><li class="listitem">reference / <a title="Kernel principal component analysis in scikit-learn" class="calibre1" href="#calibre_link-11">Kernel principal component analysis in scikit-learn</a></li></ul></li>
        <li class="listitem">agglomerative clustering<ul class="calibre29"><li class="listitem">applying, via scikit-learn / <a title="Applying agglomerative clustering via scikit-learn" class="calibre1" href="#calibre_link-12">Applying agglomerative clustering via scikit-learn</a></li></ul></li>
        <li class="listitem">AI winter<ul class="calibre29"><li class="listitem">reference / <a title="Modeling complex functions with artificial neural networks" class="calibre1" href="#calibre_link-10">Modeling complex functions with artificial neural networks</a></li></ul></li>
        <li class="listitem">algorithm<ul class="calibre29"><li class="listitem">selecting, with nested cross-validation / <a title="Algorithm selection with nested cross-validation" class="calibre1" href="#calibre_link-13">Algorithm selection with nested cross-validation</a></li></ul></li>
        <li class="listitem">algorithms<ul class="calibre29"><li class="listitem">debugging, with learning curves / <a title="Debugging algorithms with learning and validation curves" class="calibre1" href="#calibre_link-14">Debugging algorithms with learning and validation curves</a></li><li class="listitem">debugging, with validation curves / <a title="Debugging algorithms with learning and validation curves" class="calibre1" href="#calibre_link-14">Debugging algorithms with learning and validation curves</a></li></ul></li>
        <li class="listitem">Anaconda installer<ul class="calibre29"><li class="listitem">download link / <a title="Using the Anaconda Python distribution and package manager" class="calibre1" href="#calibre_link-15">Using the Anaconda Python distribution and package manager</a></li></ul></li>
        <li class="listitem">Anaconda Python distribution<ul class="calibre29"><li class="listitem">using / <a title="Using the Anaconda Python distribution and package manager" class="calibre1" href="#calibre_link-15">Using the Anaconda Python distribution and package manager</a></li></ul></li>
        <li class="listitem">array structures<ul class="calibre29"><li class="listitem">working with / <a title="Working with array structures" class="calibre1" href="#calibre_link-16">Working with array structures</a></li></ul></li>
        <li class="listitem">Artificial Intelligence (AI)<ul class="calibre29"><li class="listitem">about / <a title="Building intelligent machines to transform data into knowledge" class="calibre1" href="#calibre_link-17">Building intelligent machines to transform data into knowledge</a></li></ul> / <a title="Modeling complex functions with artificial neural networks" class="calibre1" href="#calibre_link-10">Modeling complex functions with artificial neural networks</a></li>
        <li class="listitem">artificial neural network<ul class="calibre29"><li class="listitem">training / <a title="Training an artificial neural network" class="calibre1" href="#calibre_link-18">Training an artificial neural network</a></li></ul></li>
        <li class="listitem">artificial neural networks<ul class="calibre29"><li class="listitem">complex functions, modeling with / <a title="Modeling complex functions with artificial neural networks" class="calibre1" href="#calibre_link-10">Modeling complex functions with artificial neural networks</a></li></ul></li>
        <li class="listitem">artificial neurons / <a title="Artificial neurons â a brief glimpse into the early history of machine learning" class="calibre1" href="#calibre_link-19">Artificial neurons &ndash; a brief glimpse into the early history of machine learning</a>, <a title="The formal definition of an artificial neuron" class="calibre1" href="#calibre_link-19">The formal definition of an artificial neuron</a></li>
        <li class="listitem">automatic differentiation / <a title="Developing your intuition for backpropagation" class="calibre1" href="#calibre_link-18">Developing your intuition for backpropagation</a></li>
        <li class="listitem">average-pooling / <a title="Subsampling" class="calibre1" href="#calibre_link-20">Subsampling</a></li>
        <li class="listitem">average linkage / <a title="Grouping clusters in bottom-up fashion" class="calibre1" href="#calibre_link-12">Grouping clusters in bottom-up fashion</a></li>
      </ul></div>
  </div>

<div id="calibre_link-48" class="calibre">
<div id="calibre_link-2714" class="book">
<h2 class="title1" id="calibre_link-2715">B</h2>
      <ul class="itemizedlist"><li class="listitem">backpropagation<ul class="calibre29"><li class="listitem">intuition, developing for / <a title="Developing your intuition for backpropagation" class="calibre1" href="#calibre_link-18">Developing your intuition for backpropagation</a></li><li class="listitem">neural networks, training via / <a title="Training neural networks via backpropagation" class="calibre1" href="#calibre_link-18">Training neural networks via backpropagation</a></li></ul></li>
        <li class="listitem">bag-of-words model<ul class="calibre29"><li class="listitem">about / <a title="Introducing the bag-of-words model" class="calibre1" href="#calibre_link-49">Introducing the bag-of-words model</a></li></ul></li>
        <li class="listitem">bagging / <a title="Evaluating and tuning the ensemble classifier" class="calibre1" href="#calibre_link-50">Evaluating and tuning the ensemble classifier</a>, <a title="Bagging â building an ensemble of classifiers from bootstrap samples" class="calibre1" href="#calibre_link-51">Bagging &ndash; building an ensemble of classifiers from bootstrap samples</a><ul class="calibre29"><li class="listitem">applying, for sample classification in Wine dataset / <a title="Applying bagging to classify samples in the Wine dataset" class="calibre1" href="#calibre_link-51">Applying bagging to classify samples in the Wine dataset</a></li></ul></li>
        <li class="listitem">bagging classifier<ul class="calibre29"><li class="listitem">working / <a title="Bagging in a nutshell" class="calibre1" href="#calibre_link-51">Bagging in a nutshell</a></li></ul></li>
        <li class="listitem">Basic Linear Algebra Subprograms (BLAS) / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li>
        <li class="listitem">batch gradient descent / <a title="Minimizing cost functions with gradient descent" class="calibre1" href="#calibre_link-6">Minimizing cost functions with gradient descent</a>, <a title="Large-scale machine learning and stochastic gradient descent" class="calibre1" href="#calibre_link-6">Large-scale machine learning and stochastic gradient descent</a></li>
        <li class="listitem">best-fitting / <a title="Implementing an ordinary least squares linear regression model" class="calibre1" href="#calibre_link-9">Implementing an ordinary least squares linear regression model</a></li>
        <li class="listitem">bias problems<ul class="calibre29"><li class="listitem">diagnosing, with learning curves / <a title="Diagnosing bias and variance problems with learning curves" class="calibre1" href="#calibre_link-14">Diagnosing bias and variance problems with learning curves</a></li></ul></li>
        <li class="listitem">bias unit / <a title="The formal definition of an artificial neuron" class="calibre1" href="#calibre_link-19">The formal definition of an artificial neuron</a></li>
        <li class="listitem">bias units<ul class="calibre29"><li class="listitem">about / <a title="Introducing the multilayer neural network architecture" class="calibre1" href="#calibre_link-10">Introducing the multilayer neural network architecture</a></li></ul></li>
        <li class="listitem">binomial coefficient / <a title="Learning with ensembles" class="calibre1" href="#calibre_link-38">Learning with ensembles</a></li>
        <li class="listitem">boosting<ul class="calibre29"><li class="listitem">working / <a title="How boosting works" class="calibre1" href="#calibre_link-5">How boosting works</a></li></ul></li>
        <li class="listitem">border point / <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li>
        <li class="listitem">bottom-up fashion<ul class="calibre29"><li class="listitem">clusters, grouping in / <a title="Grouping clusters in bottom-up fashion" class="calibre1" href="#calibre_link-12">Grouping clusters in bottom-up fashion</a></li></ul></li>
        <li class="listitem">BPTT<ul class="calibre29"><li class="listitem">used, for training RNN / <a title="Computing activations in an RNN" class="calibre1" href="#calibre_link-4">Computing activations in an RNN</a></li></ul></li>
        <li class="listitem">Breast Cancer Wisconsin dataset<ul class="calibre29"><li class="listitem">loading / <a title="Loading the Breast Cancer Wisconsin dataset" class="calibre1" href="#calibre_link-37">Loading the Breast Cancer Wisconsin dataset</a></li><li class="listitem">reference / <a title="Loading the Breast Cancer Wisconsin dataset" class="calibre1" href="#calibre_link-37">Loading the Breast Cancer Wisconsin dataset</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-66" class="calibre">
<div id="calibre_link-2716" class="book">
<h2 class="title1" id="calibre_link-2717">C</h2>
      <ul class="itemizedlist"><li class="listitem">calculus<ul class="calibre29"><li class="listitem">reference / <a title="Developing your intuition for backpropagation" class="calibre1" href="#calibre_link-18">Developing your intuition for backpropagation</a></li></ul></li>
        <li class="listitem">Cascading Style Sheet (CSS) / <a title="Adding style via CSS" class="calibre1" href="#calibre_link-67">Adding style via CSS</a></li>
        <li class="listitem">categorical data<ul class="calibre29"><li class="listitem">handling / <a title="Handling categorical data" class="calibre1" href="#calibre_link-68">Handling categorical data</a></li><li class="listitem">example dataset, creating / <a title="Creating an example dataset" class="calibre1" href="#calibre_link-68">Creating an example dataset</a></li></ul></li>
        <li class="listitem">categories, sequence modeling<ul class="calibre29"><li class="listitem">many-to-one / <a title="The different categories of sequence modeling" class="calibre1" href="#calibre_link-44">The different categories of sequence modeling</a></li><li class="listitem">one-to-many / <a title="The different categories of sequence modeling" class="calibre1" href="#calibre_link-44">The different categories of sequence modeling</a></li><li class="listitem">many-to-many / <a title="The different categories of sequence modeling" class="calibre1" href="#calibre_link-44">The different categories of sequence modeling</a></li></ul></li>
        <li class="listitem">cell state / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
        <li class="listitem">centroid / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">character-level language modeling<ul class="calibre29"><li class="listitem">data, preparing for / <a title="Preparing the data" class="calibre1" href="#calibre_link-69">Preparing the data</a></li></ul></li>
        <li class="listitem">character-level RNN model
<ul class="calibre29"><li class="listitem">building / <a title="Building a character-level RNN model" class="calibre1" href="#calibre_link-69">Building a character-level RNN model</a></li><li class="listitem">constructor / <a title="The constructor" class="calibre1" href="#calibre_link-69">The constructor</a></li><li class="listitem">build method / <a title="The build method" class="calibre1" href="#calibre_link-69">The build method</a></li><li class="listitem">train method / <a title="The train method" class="calibre1" href="#calibre_link-69">The train method</a></li><li class="listitem">sample method / <a title="The sample method" class="calibre1" href="#calibre_link-69">The sample method</a></li></ul></li>
        <li class="listitem">CharRNN model<ul class="calibre29"><li class="listitem">in sampling mode / <a title="The CharRNN model in the sampling mode" class="calibre1" href="#calibre_link-69">The CharRNN model in the sampling mode</a></li></ul></li>
        <li class="listitem">CharRNN Model<ul class="calibre29"><li class="listitem">creating / <a title="Creating and training the CharRNN Model" class="calibre1" href="#calibre_link-69">Creating and training the CharRNN Model</a></li><li class="listitem">training / <a title="Creating and training the CharRNN Model" class="calibre1" href="#calibre_link-69">Creating and training the CharRNN Model</a></li></ul></li>
        <li class="listitem">classfication<ul class="calibre29"><li class="listitem">class labels, predicting / <a title="Classification for predicting class labels" class="calibre1" href="#calibre_link-70">Classification for predicting class labels</a></li></ul></li>
        <li class="listitem">classification algorithm<ul class="calibre29"><li class="listitem">selecting / <a title="Choosing a classification algorithm" class="calibre1" href="#calibre_link-30">Choosing a classification algorithm</a></li></ul></li>
        <li class="listitem">classification error / <a title="Maximizing information gain â getting the most bang for your buck" class="calibre1" href="#calibre_link-71">Maximizing information gain &ndash; getting the most bang for your buck</a></li>
        <li class="listitem">classification model<ul class="calibre29"><li class="listitem">precision, optimizing of / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li><li class="listitem">recall, optimizing of / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li></ul></li>
        <li class="listitem">classification task<ul class="calibre29"><li class="listitem">about / <a title="Making predictions about the future with supervised learning" class="calibre1" href="#calibre_link-70">Making predictions about the future with supervised learning</a></li></ul></li>
        <li class="listitem">classifiers<ul class="calibre29"><li class="listitem">combining, via majority vote / <a title="Combining classifiers via majority vote" class="calibre1" href="#calibre_link-50">Combining classifiers via majority vote</a></li></ul></li>
        <li class="listitem">class imbalance<ul class="calibre29"><li class="listitem">dealing with / <a title="Dealing with class imbalance" class="calibre1" href="#calibre_link-72">Dealing with class imbalance</a></li></ul></li>
        <li class="listitem">class labels<ul class="calibre29"><li class="listitem">encoding / <a title="Encoding class labels" class="calibre1" href="#calibre_link-68">Encoding class labels</a></li></ul></li>
        <li class="listitem">class probabilities<ul class="calibre29"><li class="listitem">modeling, via logistic regression / <a title="Modeling class probabilities via logistic regression" class="calibre1" href="#calibre_link-8">Modeling class probabilities via logistic regression</a></li><li class="listitem">estimating, in multi-class classification / <a title="Estimating class probabilities in multiclass classification via the softmax function" class="calibre1" href="#calibre_link-3">Estimating class probabilities in multiclass classification via the softmax function</a></li></ul></li>
        <li class="listitem">cluster cohesion / <a title="Quantifying the quality of clustering via silhouette plots" class="calibre1" href="#calibre_link-42">Quantifying the quality of clustering via silhouette plots</a></li>
        <li class="listitem">cluster inertia / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">clustering<ul class="calibre29"><li class="listitem">about / <a title="Finding subgroups with clustering" class="calibre1" href="#calibre_link-70">Finding subgroups with clustering</a></li><li class="listitem">subgroups, finding with / <a title="Finding subgroups with clustering" class="calibre1" href="#calibre_link-70">Finding subgroups with clustering</a></li></ul></li>
        <li class="listitem">clusters<ul class="calibre29"><li class="listitem">about / <a title="Finding subgroups with clustering" class="calibre1" href="#calibre_link-70">Finding subgroups with clustering</a></li><li class="listitem">organizing, as hierarchical tree / <a title="Organizing clusters as a hierarchical tree" class="calibre1" href="#calibre_link-12">Organizing clusters as a hierarchical tree</a></li><li class="listitem">grouping, in bottom-up fashion / <a title="Grouping clusters in bottom-up fashion" class="calibre1" href="#calibre_link-12">Grouping clusters in bottom-up fashion</a></li></ul></li>
        <li class="listitem">cluster separation / <a title="Quantifying the quality of clustering via silhouette plots" class="calibre1" href="#calibre_link-42">Quantifying the quality of clustering via silhouette plots</a></li>
        <li class="listitem">coefficient of determination / <a title="Evaluating the performance of linear regression models" class="calibre1" href="#calibre_link-73">Evaluating the performance of linear regression models</a></li>
        <li class="listitem">coefficient of regression<ul class="calibre29"><li class="listitem">estimating, via scikit-learn / <a title="Estimating coefficient of a regression model via scikit-learn" class="calibre1" href="#calibre_link-9">Estimating coefficient of a regression model via scikit-learn</a></li></ul></li>
        <li class="listitem">color channels<ul class="calibre29"><li class="listitem">working with / <a title="Working with multiple input or color channels" class="calibre1" href="#calibre_link-74">Working with multiple input or color channels</a></li></ul></li>
        <li class="listitem">Comma-separated Values (CSV) / <a title="Identifying missing values in tabular data" class="calibre1" href="#calibre_link-36">Identifying missing values in tabular data</a></li>
        <li class="listitem">complete linkage / <a title="Grouping clusters in bottom-up fashion" class="calibre1" href="#calibre_link-12">Grouping clusters in bottom-up fashion</a></li>
        <li class="listitem">complex functions<ul class="calibre29"><li class="listitem">modeling, with artificial neural networks / <a title="Modeling complex functions with artificial neural networks" class="calibre1" href="#calibre_link-10">Modeling complex functions with artificial neural networks</a></li></ul></li>
        <li class="listitem">computation graphs, TensorFlow / <a title="Understanding TensorFlow&apos;s computation graphs" class="calibre1" href="#calibre_link-75">Understanding TensorFlow's computation graphs</a></li>
        <li class="listitem">Computer Vision and Pattern Recognition (CVPR) / <a title="Modeling complex functions with artificial neural networks" class="calibre1" href="#calibre_link-10">Modeling complex functions with artificial neural networks</a></li>
        <li class="listitem">concentric circles separation example / <a title="Example 2 â separating concentric circles" class="calibre1" href="#calibre_link-11">Example 2 &ndash; separating concentric circles</a></li>
        <li class="listitem">conditional probabilities / <a title="Logistic regression intuition and conditional probabilities" class="calibre1" href="#calibre_link-8">Logistic regression intuition and conditional probabilities</a></li>
        <li class="listitem">confusion matrix<ul class="calibre29"><li class="listitem">reading / <a title="Reading a confusion matrix" class="calibre1" href="#calibre_link-2">Reading a confusion matrix</a></li></ul></li>
        <li class="listitem">contrib module, Keras<ul class="calibre29"><li class="listitem">reference / <a title="Developing a multilayer neural network with Keras" class="calibre1" href="#calibre_link-76">Developing a multilayer neural network with Keras</a></li></ul></li>
        <li class="listitem">control flow mechanics<ul class="calibre29"><li class="listitem">used, for building graphs / <a title="Utilizing control flow mechanics in building graphs" class="calibre1" href="#calibre_link-77">Utilizing control flow mechanics in building graphs</a></li></ul></li>
        <li class="listitem">convergence<ul class="calibre29"><li class="listitem">in neural networks / <a title="About the convergence in neural networks" class="calibre1" href="#calibre_link-78">About the convergence in neural networks</a></li></ul></li>
        <li class="listitem">convolutional neural network<ul class="calibre29"><li class="listitem">implementing, in TensorFlow low-level API / <a title="Implementing a CNN in the TensorFlow low-level API" class="calibre1" href="#calibre_link-79">Implementing a CNN in the TensorFlow low-level API</a></li><li class="listitem">implementing, in TensorFlow layers API / <a title="Implementing a CNN in the TensorFlow Layers API" class="calibre1" href="#calibre_link-79">Implementing a CNN in the TensorFlow Layers API</a></li></ul></li>
        <li class="listitem">convolutional neural networks<ul class="calibre29"><li class="listitem">building blocks / <a title="Building blocks of convolutional neural networks" class="calibre1" href="#calibre_link-20">Building blocks of convolutional neural networks</a></li><li class="listitem">sparse-connectivity / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li><li class="listitem">parameter-sharing / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li><li class="listitem">implementation / <a title="Putting everything together to build a CNN" class="calibre1" href="#calibre_link-74">Putting everything together to build a CNN</a></li></ul></li>
        <li class="listitem">convolution output<ul class="calibre29"><li class="listitem">size, determining of / <a title="Determining the size of the convolution output" class="calibre1" href="#calibre_link-20">Determining the size of the convolution output</a></li></ul></li>
        <li class="listitem">core point / <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li>
        <li class="listitem">correlation matrix<ul class="calibre29"><li class="listitem">used, for viewing relationships / <a title="Looking at relationships using a correlation matrix" class="calibre1" href="#calibre_link-80">Looking at relationships using a correlation matrix</a></li></ul></li>
        <li class="listitem">cost functions<ul class="calibre29"><li class="listitem">minimizing, with gradient descent / <a title="Minimizing cost functions with gradient descent" class="calibre1" href="#calibre_link-6">Minimizing cost functions with gradient descent</a></li></ul></li>
        <li class="listitem">cross-correlation / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li>
        <li class="listitem">curse of dimensionality / <a title="K-nearest neighbors â a lazy learning algorithm" class="calibre1" href="#calibre_link-81">K-nearest neighbors &ndash; a lazy learning algorithm</a>, <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a>, <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li>
        <li class="listitem">curve<ul class="calibre29"><li class="listitem">linear regression model, turning into / <a title="Turning a linear regression model into a curve â polynomial regression" class="calibre1" href="#calibre_link-83">Turning a linear regression model into a curve &ndash; polynomial regression</a></li></ul></li>
        <li class="listitem">cut-off parameter / <a title="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre1" href="#calibre_link-84">Using the kernel trick to find separating hyperplanes in high-dimensional space</a></li>
      </ul></div>
  </div>

<div id="calibre_link-106" class="calibre">
<div id="calibre_link-2718" class="book">
<h2 class="title1" id="calibre_link-2719">D</h2>
      <ul class="itemizedlist"><li class="listitem">data<ul class="calibre29"><li class="listitem">preparing, for character-level language modeling / <a title="Preparing the data" class="calibre1" href="#calibre_link-69">Preparing the data</a></li></ul></li>
        <li class="listitem">data frame<ul class="calibre29"><li class="listitem">Housing dataset, loading into / <a title="Loading the Housing dataset into a data frame" class="calibre1" href="#calibre_link-80">Loading the Housing dataset into a data frame</a></li></ul></li>
        <li class="listitem">data points<ul class="calibre29"><li class="listitem">projecting / <a title="Projecting new data points" class="calibre1" href="#calibre_link-11">Projecting new data points</a></li></ul></li>
        <li class="listitem">dataset<ul class="calibre29"><li class="listitem">partitioning, into training set / <a title="Partitioning a dataset into separate training and test sets" class="calibre1" href="#calibre_link-107">Partitioning a dataset into separate training and test sets</a></li><li class="listitem">partitioning, into test set / <a title="Partitioning a dataset into separate training and test sets" class="calibre1" href="#calibre_link-107">Partitioning a dataset into separate training and test sets</a></li></ul></li>
        <li class="listitem">data storage<ul class="calibre29"><li class="listitem">SQLite database, setting up for / <a title="Setting up an SQLite database for data storage" class="calibre1" href="#calibre_link-108">Setting up an SQLite database for data storage</a></li></ul></li>
        <li class="listitem">decision regions / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a></li>
        <li class="listitem">decision tree<ul class="calibre29"><li class="listitem">building / <a title="Building a decision tree" class="calibre1" href="#calibre_link-71">Building a decision tree</a></li></ul></li>
        <li class="listitem">decision tree learning / <a title="Decision tree learning" class="calibre1" href="#calibre_link-71">Decision tree learning</a><ul class="calibre29"><li class="listitem">information gain, maximizing / <a title="Maximizing information gain â getting the most bang for your buck" class="calibre1" href="#calibre_link-71">Maximizing information gain &ndash; getting the most bang for your buck</a></li></ul></li>
        <li class="listitem">decision tree regression / <a title="Decision tree regression" class="calibre1" href="#calibre_link-109">Decision tree regression</a></li>
        <li class="listitem">deep artificial neural network<ul class="calibre29"><li class="listitem">about / <a title="Introducing the multilayer neural network architecture" class="calibre1" href="#calibre_link-10">Introducing the multilayer neural network architecture</a></li></ul></li>
        <li class="listitem">deep convolutional neural network<ul class="calibre29"><li class="listitem">implementing, TensorFlow used / <a title="Implementing a deep convolutional neural network using TensorFlow" class="calibre1" href="#calibre_link-79">Implementing a deep convolutional neural network using TensorFlow</a></li><li class="listitem">data, loading / <a title="Loading and preprocessing the data" class="calibre1" href="#calibre_link-79">Loading and preprocessing the data</a></li><li class="listitem">data, preprocessing / <a title="Loading and preprocessing the data" class="calibre1" href="#calibre_link-79">Loading and preprocessing the data</a></li></ul></li>
        <li class="listitem">deep learning<ul class="calibre29"><li class="listitem">about / <a title="Introducing the multilayer neural network architecture" class="calibre1" href="#calibre_link-10">Introducing the multilayer neural network architecture</a></li></ul></li>
        <li class="listitem">dendrograms / <a title="Organizing clusters as a hierarchical tree" class="calibre1" href="#calibre_link-12">Organizing clusters as a hierarchical tree</a><ul class="calibre29"><li class="listitem">attaching, to heat map / <a title="Attaching dendrograms to a heat map" class="calibre1" href="#calibre_link-12">Attaching dendrograms to a heat map</a></li></ul></li>
        <li class="listitem">density-based clustering / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">density-based spatial clustering of applications with noise (DBSCAN)<ul class="calibre29"><li class="listitem">regions of high density, locating via / <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li></ul></li>
        <li class="listitem">dimensionality reduction<ul class="calibre29"><li class="listitem">about / <a title="Dimensionality reduction for data compression" class="calibre1" href="#calibre_link-70">Dimensionality reduction for data compression</a>, <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li><li class="listitem">for data compression / <a title="Dimensionality reduction for data compression" class="calibre1" href="#calibre_link-70">Dimensionality reduction for data compression</a></li></ul></li>
        <li class="listitem">discrete convolution<ul class="calibre29"><li class="listitem">performing / <a title="Performing discrete convolutions" class="calibre1" href="#calibre_link-20">Performing discrete convolutions</a></li><li class="listitem">performing, in one dimension / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li><li class="listitem">performing, in two dimensions / <a title="Performing a discrete convolution in 2D" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in 2D</a></li></ul></li>
        <li class="listitem">distance matrix<ul class="calibre29"><li class="listitem">hierarchical clustering, performing on / <a title="Performing hierarchical clustering on a distance matrix" class="calibre1" href="#calibre_link-12">Performing hierarchical clustering on a distance matrix</a></li></ul></li>
        <li class="listitem">document classification<ul class="calibre29"><li class="listitem">logistic regression model, training for / <a title="Training a logistic regression model for document classification" class="calibre1" href="#calibre_link-110">Training a logistic regression model for document classification</a></li></ul></li>
        <li class="listitem">documents<ul class="calibre29"><li class="listitem">processing, into tokens / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li></ul></li>
        <li class="listitem">dropout<ul class="calibre29"><li class="listitem">neural network, regularizing with / <a title="Regularizing a neural network with dropout" class="calibre1" href="#calibre_link-74">Regularizing a neural network with dropout</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-140" class="calibre">
<div id="calibre_link-2720" class="book">
<h2 class="title1" id="calibre_link-2721">E</h2>
      <ul class="itemizedlist"><li class="listitem">eigenvalues / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li>
        <li class="listitem">eigenvectors<ul class="calibre29"><li class="listitem">obtaining / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li></ul></li>
        <li class="listitem">Elastic Net / <a title="Using regularized methods for regression" class="calibre1" href="#calibre_link-141">Using regularized methods for regression</a></li>
        <li class="listitem">elbow method / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a><ul class="calibre29"><li class="listitem">used, for finding optimal number of clusters / <a title="Using the elbow method to find the optimal number of clusters" class="calibre1" href="#calibre_link-42">Using the elbow method to find the optimal number of clusters</a></li></ul></li>
        <li class="listitem">element-wise product / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
        <li class="listitem">element-wise summation / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
        <li class="listitem">embedding / <a title="Embedding" class="calibre1" href="#calibre_link-142">Embedding</a><ul class="calibre29"><li class="listitem">advantages / <a title="Embedding" class="calibre1" href="#calibre_link-142">Embedding</a></li><li class="listitem">about / <a title="Embedding" class="calibre1" href="#calibre_link-142">Embedding</a></li></ul></li>
        <li class="listitem">Endianness <ul class="calibre29"><li class="listitem">reference / <a title="Obtaining the MNIST dataset" class="calibre1" href="#calibre_link-143">Obtaining the MNIST dataset</a></li></ul></li>
        <li class="listitem">ensemble classifier<ul class="calibre29"><li class="listitem">evaluating / <a title="Evaluating and tuning the ensemble classifier" class="calibre1" href="#calibre_link-50">Evaluating and tuning the ensemble classifier</a></li><li class="listitem">tuning / <a title="Evaluating and tuning the ensemble classifier" class="calibre1" href="#calibre_link-50">Evaluating and tuning the ensemble classifier</a></li></ul></li>
        <li class="listitem">ensemble methods<ul class="calibre29"><li class="listitem">about / <a title="Learning with ensembles" class="calibre1" href="#calibre_link-38">Learning with ensembles</a></li></ul></li>
        <li class="listitem">ensembles<ul class="calibre29"><li class="listitem">learning with / <a title="Learning with ensembles" class="calibre1" href="#calibre_link-38">Learning with ensembles</a></li></ul></li>
        <li class="listitem">entropy / <a title="Maximizing information gain â getting the most bang for your buck" class="calibre1" href="#calibre_link-71">Maximizing information gain &ndash; getting the most bang for your buck</a></li>
        <li class="listitem">epochs / <a title="The perceptron learning rule" class="calibre1" href="#calibre_link-19">The perceptron learning rule</a></li>
        <li class="listitem">error / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li>
        <li class="listitem">estimators, and transformers<ul class="calibre29"><li class="listitem">combining, in pipeline / <a title="Combining transformers and estimators in a pipeline" class="calibre1" href="#calibre_link-37">Combining transformers and estimators in a pipeline</a></li></ul></li>
        <li class="listitem">exhaustive search algorithms / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li>
        <li class="listitem">Expectation-Maximization (EM) algorithm <ul class="calibre29"><li class="listitem">about / <a title="LDA with scikit-learn" class="calibre1" href="#calibre_link-144">LDA with scikit-learn</a></li><li class="listitem">reference / <a title="LDA with scikit-learn" class="calibre1" href="#calibre_link-144">LDA with scikit-learn</a></li></ul></li>
        <li class="listitem">explained variance<ul class="calibre29"><li class="listitem">about / <a title="Total and explained variance" class="calibre1" href="#calibre_link-26">Total and explained variance</a></li></ul></li>
        <li class="listitem">explanatory variable / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">Exploratory data analysis (EDA) / <a title="Visualizing the important characteristics of a dataset" class="calibre1" href="#calibre_link-80">Visualizing the important characteristics of a dataset</a></li>
      </ul></div>
  </div>

<div id="calibre_link-159" class="calibre">
<div id="calibre_link-2722" class="book">
<h2 class="title1" id="calibre_link-2723">F</h2>
      <ul class="itemizedlist"><li class="listitem">False negative (FN) / <a title="Reading a confusion matrix" class="calibre1" href="#calibre_link-2">Reading a confusion matrix</a></li>
        <li class="listitem">False positive (FP) / <a title="Reading a confusion matrix" class="calibre1" href="#calibre_link-2">Reading a confusion matrix</a></li>
        <li class="listitem">False Positive Rate (FPR) / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li>
        <li class="listitem">feature extraction<ul class="calibre29"><li class="listitem">about / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li></ul></li>
        <li class="listitem">feature hierarchy / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li>
        <li class="listitem">feature importance<ul class="calibre29"><li class="listitem">assessing, with random forests / <a title="Assessing feature importance with random forests" class="calibre1" href="#calibre_link-160">Assessing feature importance with random forests</a></li></ul></li>
        <li class="listitem">feature maps / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a>, <a title="Working with multiple input or color channels" class="calibre1" href="#calibre_link-74">Working with multiple input or color channels</a></li>
        <li class="listitem">features<ul class="calibre29"><li class="listitem">eliminating, with missing values / <a title="Eliminating samples or features with missing values" class="calibre1" href="#calibre_link-36">Eliminating samples or features with missing values</a></li></ul></li>
        <li class="listitem">feature scaling<ul class="calibre29"><li class="listitem">gradient descent, improving through / <a title="Improving gradient descent through feature scaling" class="calibre1" href="#calibre_link-6">Improving gradient descent through feature scaling</a></li><li class="listitem">about / <a title="Bringing features onto the same scale" class="calibre1" href="#calibre_link-161">Bringing features onto the same scale</a></li></ul></li>
        <li class="listitem">feature selection<ul class="calibre29"><li class="listitem">about / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li></ul></li>
        <li class="listitem">feature space<ul class="calibre29"><li class="listitem">samples, projecting onto / <a title="Projecting samples onto the new feature space" class="calibre1" href="#calibre_link-162">Projecting samples onto the new feature space</a></li></ul></li>
        <li class="listitem">feature transformation / <a title="Feature transformation" class="calibre1" href="#calibre_link-26">Feature transformation</a></li>
        <li class="listitem">feature vectors<ul class="calibre29"><li class="listitem">words, transforming into / <a title="Transforming words into feature vectors" class="calibre1" href="#calibre_link-49">Transforming words into feature vectors</a></li></ul></li>
        <li class="listitem">feedforward / <a title="Activating a neural network via forward propagation" class="calibre1" href="#calibre_link-10">Activating a neural network via forward propagation</a></li>
        <li class="listitem">filter / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li>
        <li class="listitem">fitted scikit-learn estimators<ul class="calibre29"><li class="listitem">serializing / <a title="Serializing fitted scikit-learn estimators" class="calibre1" href="#calibre_link-40">Serializing fitted scikit-learn estimators</a></li></ul></li>
        <li class="listitem">Flask<ul class="calibre29"><li class="listitem">web application, developing with / <a title="Developing a web application with Flask" class="calibre1" href="#calibre_link-67">Developing a web application with Flask</a></li><li class="listitem">about / <a title="Developing a web application with Flask" class="calibre1" href="#calibre_link-67">Developing a web application with Flask</a></li><li class="listitem">reference / <a title="Developing a web application with Flask" class="calibre1" href="#calibre_link-67">Developing a web application with Flask</a></li></ul></li>
        <li class="listitem">Flask web application<ul class="calibre29"><li class="listitem">creating / <a title="Our first Flask web application" class="calibre1" href="#calibre_link-67">Our first Flask web application</a></li><li class="listitem">form validation / <a title="Form validation and rendering" class="calibre1" href="#calibre_link-67">Form validation and rendering</a></li><li class="listitem">rendering / <a title="Form validation and rendering" class="calibre1" href="#calibre_link-67">Form validation and rendering</a></li><li class="listitem">directory structure, setting up / <a title="Setting up the directory structure" class="calibre1" href="#calibre_link-67">Setting up the directory structure</a></li><li class="listitem">Jinja2 templating engine, used for implementing macro / <a title="Implementing a macro using the Jinja2 templating engine" class="calibre1" href="#calibre_link-67">Implementing a macro using the Jinja2 templating engine</a></li><li class="listitem">style, adding via CSS / <a title="Adding style via CSS" class="calibre1" href="#calibre_link-67">Adding style via CSS</a></li><li class="listitem">result page, creating / <a title="Creating the result page" class="calibre1" href="#calibre_link-67">Creating the result page</a></li></ul></li>
        <li class="listitem">forward propagation<ul class="calibre29"><li class="listitem">neural network, activating via / <a title="Activating a neural network via forward propagation" class="calibre1" href="#calibre_link-10">Activating a neural network via forward propagation</a></li></ul></li>
        <li class="listitem">fuzzifier / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li>
        <li class="listitem">fuzziness coefficient / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li>
        <li class="listitem">fuzzy C-means (FCM) algorithm / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li>
        <li class="listitem">fuzzy clustering / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li>
        <li class="listitem">fuzzy k-means / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li>
      </ul></div>
  </div>

<div id="calibre_link-180" class="calibre">
<div id="calibre_link-2724" class="book">
<h2 class="title1" id="calibre_link-2725">G</h2>
      <ul class="itemizedlist"><li class="listitem">1-gram model / <a title="Transforming words into feature vectors" class="calibre1" href="#calibre_link-49">Transforming words into feature vectors</a></li>
        <li class="listitem">Gated Recurrent Unit (GRU) / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
        <li class="listitem">gates / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
        <li class="listitem">Gaussian kernel / <a title="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre1" href="#calibre_link-84">Using the kernel trick to find separating hyperplanes in high-dimensional space</a></li>
        <li class="listitem">geometric interpretation<ul class="calibre29"><li class="listitem">of L2 regularization / <a title="A geometric interpretation of L2 regularization" class="calibre1" href="#calibre_link-82">A geometric interpretation of L2 regularization</a></li></ul></li>
        <li class="listitem">Gini impurity / <a title="Maximizing information gain â getting the most bang for your buck" class="calibre1" href="#calibre_link-71">Maximizing information gain &ndash; getting the most bang for your buck</a></li>
        <li class="listitem">Global Interpreter Lock (GIL)<ul class="calibre29"><li class="listitem">about / <a title="TensorFlow and training performance" class="calibre1" href="#calibre_link-16">TensorFlow and training performance</a></li></ul></li>
        <li class="listitem">Google Developers portal<ul class="calibre29"><li class="listitem">reference / <a title="Cleaning text data" class="calibre1" href="#calibre_link-49">Cleaning text data</a></li></ul></li>
        <li class="listitem">gradient descent / <a title="Minimizing cost functions with gradient descent" class="calibre1" href="#calibre_link-6">Minimizing cost functions with gradient descent</a><ul class="calibre29"><li class="listitem">cost functions, minimizing with / <a title="Minimizing cost functions with gradient descent" class="calibre1" href="#calibre_link-6">Minimizing cost functions with gradient descent</a></li><li class="listitem">improving, through feature scaling / <a title="Improving gradient descent through feature scaling" class="calibre1" href="#calibre_link-6">Improving gradient descent through feature scaling</a></li><li class="listitem">regression for regression parameters, solving with / <a title="Solving regression for regression parameters with gradient descent" class="calibre1" href="#calibre_link-9">Solving regression for regression parameters with gradient descent</a></li></ul></li>
        <li class="listitem">gradient descent (GD) / <a title="Solving regression for regression parameters with gradient descent" class="calibre1" href="#calibre_link-9">Solving regression for regression parameters with gradient descent</a></li>
        <li class="listitem">gradient descent learning algorithm<ul class="calibre29"><li class="listitem">for logistic regression / <a title="Converting an Adaline implementation into an algorithm for logistic regression" class="calibre1" href="#calibre_link-8">Converting an Adaline implementation into an algorithm for logistic regression</a></li></ul></li>
        <li class="listitem">gradient descent optimization algorithm / <a title="Bringing features onto the same scale" class="calibre1" href="#calibre_link-161">Bringing features onto the same scale</a></li>
        <li class="listitem">graph<ul class="calibre29"><li class="listitem">visualizing, with TensorBoard / <a title="Visualizing the graph with TensorBoard" class="calibre1" href="#calibre_link-181">Visualizing the graph with TensorBoard</a></li></ul></li>
        <li class="listitem">graph-based clustering / <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li>
        <li class="listitem">Graphical Processing Units (GPUs) / <a title="A few last words about the neural network implementation" class="calibre1" href="#calibre_link-182">A few last words about the neural network implementation</a></li>
        <li class="listitem">graphs<ul class="calibre29"><li class="listitem">building, control flow mechanics used / <a title="Utilizing control flow mechanics in building graphs" class="calibre1" href="#calibre_link-77">Utilizing control flow mechanics in building graphs</a></li></ul></li>
        <li class="listitem">Greedy algorithms / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li>
        <li class="listitem">grid search<ul class="calibre29"><li class="listitem">machine leaning models, fine-tuning via / <a title="Fine-tuning machine learning models via grid search" class="calibre1" href="#calibre_link-13">Fine-tuning machine learning models via grid search</a></li><li class="listitem">about / <a title="Fine-tuning machine learning models via grid search" class="calibre1" href="#calibre_link-13">Fine-tuning machine learning models via grid search</a></li><li class="listitem">hyperparameters, tuning via / <a title="Tuning hyperparameters via grid search" class="calibre1" href="#calibre_link-13">Tuning hyperparameters via grid search</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-467" class="calibre">
<div id="calibre_link-2726" class="book">
<h2 class="title1" id="calibre_link-2727">H</h2>
      <ul class="itemizedlist"><li class="listitem">half-moon shapes separation example / <a title="Example 1 â separating half-moon shapes" class="calibre1" href="#calibre_link-11">Example 1 &ndash; separating half-moon shapes</a></li>
        <li class="listitem">handwritten digits<ul class="calibre29"><li class="listitem">classifying / <a title="Classifying handwritten digits" class="calibre1" href="#calibre_link-143">Classifying handwritten digits</a></li></ul></li>
        <li class="listitem">hard clustering<ul class="calibre29"><li class="listitem">versus soft clustering / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li></ul></li>
        <li class="listitem">heat map<ul class="calibre29"><li class="listitem">dendrograms, attaching to / <a title="Attaching dendrograms to a heat map" class="calibre1" href="#calibre_link-12">Attaching dendrograms to a heat map</a></li></ul></li>
        <li class="listitem">hidden structures<ul class="calibre29"><li class="listitem">discovering, with unsupervised learning / <a title="Discovering hidden structures with unsupervised learning" class="calibre1" href="#calibre_link-70">Discovering hidden structures with unsupervised learning</a></li></ul></li>
        <li class="listitem">hierarchical clustering / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a><ul class="calibre29"><li class="listitem">agglomerative / <a title="Organizing clusters as a hierarchical tree" class="calibre1" href="#calibre_link-12">Organizing clusters as a hierarchical tree</a></li><li class="listitem">divisive / <a title="Organizing clusters as a hierarchical tree" class="calibre1" href="#calibre_link-12">Organizing clusters as a hierarchical tree</a></li><li class="listitem">performing, on distance matrix / <a title="Performing hierarchical clustering on a distance matrix" class="calibre1" href="#calibre_link-12">Performing hierarchical clustering on a distance matrix</a></li></ul></li>
        <li class="listitem">hierarchical tree<ul class="calibre29"><li class="listitem">clusters, organizing as / <a title="Organizing clusters as a hierarchical tree" class="calibre1" href="#calibre_link-12">Organizing clusters as a hierarchical tree</a></li></ul></li>
        <li class="listitem">high-level TensorFlow APIs<ul class="calibre29"><li class="listitem">neural networks, training with / <a title="Training neural networks efficiently with high-level TensorFlow APIs" class="calibre1" href="#calibre_link-76">Training neural networks efficiently with high-level TensorFlow APIs</a></li></ul></li>
        <li class="listitem">holdout cross-validation / <a title="Using k-fold cross-validation to assess model performance" class="calibre1" href="#calibre_link-300">Using k-fold cross-validation to assess model performance</a></li>
        <li class="listitem">holdout method / <a title="The holdout method" class="calibre1" href="#calibre_link-300">The holdout method</a></li>
        <li class="listitem">Housing dataset<ul class="calibre29"><li class="listitem">exploring / <a title="Exploring the Housing dataset" class="calibre1" href="#calibre_link-80">Exploring the Housing dataset</a></li><li class="listitem">download link / <a title="Exploring the Housing dataset" class="calibre1" href="#calibre_link-80">Exploring the Housing dataset</a></li><li class="listitem">loadng, into data frame / <a title="Loading the Housing dataset into a data frame" class="calibre1" href="#calibre_link-80">Loading the Housing dataset into a data frame</a></li><li class="listitem">characteristics, visualizing / <a title="Visualizing the important characteristics of a dataset" class="calibre1" href="#calibre_link-80">Visualizing the important characteristics of a dataset</a></li><li class="listitem">nonlinear relationships, modeling in / <a title="Modeling nonlinear relationships in the Housing dataset" class="calibre1" href="#calibre_link-83">Modeling nonlinear relationships in the Housing dataset</a></li></ul></li>
        <li class="listitem">hyperbolic tangent<ul class="calibre29"><li class="listitem">about / <a title="Broadening the output spectrum using a hyperbolic tangent" class="calibre1" href="#calibre_link-3">Broadening the output spectrum using a hyperbolic tangent</a></li><li class="listitem">used, for broadening output spectrum / <a title="Broadening the output spectrum using a hyperbolic tangent" class="calibre1" href="#calibre_link-3">Broadening the output spectrum using a hyperbolic tangent</a></li></ul></li>
        <li class="listitem">hyperparameters<ul class="calibre29"><li class="listitem">about / <a title="Fine-tuning machine learning models via grid search" class="calibre1" href="#calibre_link-13">Fine-tuning machine learning models via grid search</a></li><li class="listitem">tuning, via grid search / <a title="Tuning hyperparameters via grid search" class="calibre1" href="#calibre_link-13">Tuning hyperparameters via grid search</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-499" class="calibre">
<div id="calibre_link-2728" class="book">
<h2 class="title1" id="calibre_link-2729">I</h2>
      <ul class="itemizedlist"><li class="listitem">imbalanced-learn<ul class="calibre29"><li class="listitem">reference / <a title="Dealing with class imbalance" class="calibre1" href="#calibre_link-72">Dealing with class imbalance</a></li></ul></li>
        <li class="listitem">IMDb movie review data<ul class="calibre29"><li class="listitem">preparing, for text processing / <a title="Preparing the IMDb movie review data for text processing" class="calibre1" href="#calibre_link-39">Preparing the IMDb movie review data for text processing</a></li></ul></li>
        <li class="listitem">impurity measure / <a title="Maximizing information gain â getting the most bang for your buck" class="calibre1" href="#calibre_link-71">Maximizing information gain &ndash; getting the most bang for your buck</a></li>
        <li class="listitem">Independent and Identically Distributed (IID) / <a title="Modeling sequential data â order matters" class="calibre1" href="#calibre_link-44">Modeling sequential data &ndash; order matters</a></li>
        <li class="listitem">Information Gain (IG) / <a title="Decision tree regression" class="calibre1" href="#calibre_link-109">Decision tree regression</a></li>
        <li class="listitem">information gain (IG) / <a title="Decision tree learning" class="calibre1" href="#calibre_link-71">Decision tree learning</a></li>
        <li class="listitem">inliers / <a title="Fitting a robust regression model using RANSAC" class="calibre1" href="#calibre_link-357">Fitting a robust regression model using RANSAC</a></li>
        <li class="listitem">instance-based learning / <a title="K-nearest neighbors â a lazy learning algorithm" class="calibre1" href="#calibre_link-81">K-nearest neighbors &ndash; a lazy learning algorithm</a></li>
        <li class="listitem">interactive problems<ul class="calibre29"><li class="listitem">solving, with reinforcement learning / <a title="Solving interactive problems with reinforcement learning" class="calibre1" href="#calibre_link-70">Solving interactive problems with reinforcement learning</a></li></ul></li>
        <li class="listitem">Iris dataset<ul class="calibre29"><li class="listitem">perceptron model, training on / <a title="Training a perceptron model on the Iris dataset" class="calibre1" href="#calibre_link-52">Training a perceptron model on the Iris dataset</a></li></ul> / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a></li>
        <li class="listitem">Iris flower dataset / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a></li>
      </ul></div>
  </div>

<div id="calibre_link-518" class="calibre">
<div id="calibre_link-2730" class="book">
<h2 class="title1" id="calibre_link-2731">J</h2>
      <ul class="itemizedlist"><li class="listitem">Jinja2<ul class="calibre29"><li class="listitem">reference / <a title="Implementing a macro using the Jinja2 templating engine" class="calibre1" href="#calibre_link-67">Implementing a macro using the Jinja2 templating engine</a></li></ul></li>
        <li class="listitem">joblib<ul class="calibre29"><li class="listitem">reference / <a title="Serializing fitted scikit-learn estimators" class="calibre1" href="#calibre_link-40">Serializing fitted scikit-learn estimators</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-533" class="calibre">
<div id="calibre_link-2732" class="book">
<h2 class="title1" id="calibre_link-2733">K</h2>
      <ul class="itemizedlist"><li class="listitem">k-fold cross-validation / <a title="Using k-fold cross-validation to assess model performance" class="calibre1" href="#calibre_link-300">Using k-fold cross-validation to assess model performance</a><ul class="calibre29"><li class="listitem">used, for assessing model performance / <a title="Using k-fold cross-validation to assess model performance" class="calibre1" href="#calibre_link-300">Using k-fold cross-validation to assess model performance</a></li><li class="listitem">about / <a title="K-fold cross-validation" class="calibre1" href="#calibre_link-300">K-fold cross-validation</a></li></ul></li>
        <li class="listitem">k-means<ul class="calibre29"><li class="listitem">used, for grouping objects by similarity / <a title="Grouping objects by similarity using k-means" class="calibre1" href="#calibre_link-42">Grouping objects by similarity using k-means</a></li></ul></li>
        <li class="listitem">k-means++ / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a><ul class="calibre29"><li class="listitem">initial cluster centroids, placing / <a title="A smarter way of placing the initial cluster centroids using k-means++" class="calibre1" href="#calibre_link-42">A smarter way of placing the initial cluster centroids using k-means++</a></li></ul></li>
        <li class="listitem">k-means clustering<ul class="calibre29"><li class="listitem">with scikit-learn / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li></ul></li>
        <li class="listitem">k-nearest neighbor (KNN) / <a title="K-nearest neighbors â a lazy learning algorithm" class="calibre1" href="#calibre_link-81">K-nearest neighbors &ndash; a lazy learning algorithm</a></li>
        <li class="listitem">k-nearest neighbors (KNN) algorithm / <a title="Bringing features onto the same scale" class="calibre1" href="#calibre_link-161">Bringing features onto the same scale</a></li>
        <li class="listitem">Keras<ul class="calibre29"><li class="listitem">reference / <a title="A few last words about the neural network implementation" class="calibre1" href="#calibre_link-182">A few last words about the neural network implementation</a>, <a title="Training neural networks efficiently with high-level TensorFlow APIs" class="calibre1" href="#calibre_link-76">Training neural networks efficiently with high-level TensorFlow APIs</a>, <a title="Developing a multilayer neural network with Keras" class="calibre1" href="#calibre_link-76">Developing a multilayer neural network with Keras</a></li><li class="listitem">multilayer neural network, developing / <a title="Developing a multilayer neural network with Keras" class="calibre1" href="#calibre_link-76">Developing a multilayer neural network with Keras</a></li></ul></li>
        <li class="listitem">kernel / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li>
        <li class="listitem">kernel function / <a title="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre1" href="#calibre_link-84">Using the kernel trick to find separating hyperplanes in high-dimensional space</a></li>
        <li class="listitem">kernel functions / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li>
        <li class="listitem">kernel methods<ul class="calibre29"><li class="listitem">for linearly inseparable data / <a title="Kernel methods for linearly inseparable data" class="calibre1" href="#calibre_link-84">Kernel methods for linearly inseparable data</a></li></ul></li>
        <li class="listitem">kernel principal component analysis<ul class="calibre29"><li class="listitem">using, for nonlinear mappings / <a title="Using kernel principal component analysis for nonlinear mappings" class="calibre1" href="#calibre_link-11">Using kernel principal component analysis for nonlinear mappings</a></li><li class="listitem">implementing, in Python / <a title="Implementing a kernel principal component analysis in Python" class="calibre1" href="#calibre_link-11">Implementing a kernel principal component analysis in Python</a></li><li class="listitem">in scikit-learn / <a title="Kernel principal component analysis in scikit-learn" class="calibre1" href="#calibre_link-11">Kernel principal component analysis in scikit-learn</a></li></ul></li>
        <li class="listitem">kernels<ul class="calibre29"><li class="listitem">polynomial kernel / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li><li class="listitem">hyperbolic tangent (sigmoid) kernel / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li><li class="listitem">Radial Basis Function (RBF) kernel / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li></ul></li>
        <li class="listitem">kernel SVM<ul class="calibre29"><li class="listitem">used, for solving non-linear problems / <a title="Solving nonlinear problems using a kernel SVM" class="calibre1" href="#calibre_link-84">Solving nonlinear problems using a kernel SVM</a></li></ul></li>
        <li class="listitem">kernel trick / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a><ul class="calibre29"><li class="listitem">used, for finding separating hyperplanes in high-dimensional space / <a title="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre1" href="#calibre_link-84">Using the kernel trick to find separating hyperplanes in high-dimensional space</a></li><li class="listitem">about / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li></ul></li>
        <li class="listitem">key features, TensorFlow / <a title="Key features of TensorFlow" class="calibre1" href="#calibre_link-43">Key features of TensorFlow</a></li>
      </ul></div>
  </div>

<div id="calibre_link-549" class="calibre">
<div id="calibre_link-2734" class="book">
<h2 class="title1" id="calibre_link-2735">L</h2>
      <ul class="itemizedlist"><li class="listitem">L1 regularization / <a title="L1 and L2 regularization as penalties against model complexity" class="calibre1" href="#calibre_link-82">L1 and L2 regularization as penalties against model complexity</a><ul class="calibre29"><li class="listitem">sparse solutions / <a title="Sparse solutions with L1 regularization" class="calibre1" href="#calibre_link-82">Sparse solutions with L1 regularization</a></li></ul></li>
        <li class="listitem">L2 regularization / <a title="L1 and L2 regularization as penalties against model complexity" class="calibre1" href="#calibre_link-82">L1 and L2 regularization as penalties against model complexity</a><ul class="calibre29"><li class="listitem">geometric interpretation / <a title="A geometric interpretation of L2 regularization" class="calibre1" href="#calibre_link-82">A geometric interpretation of L2 regularization</a></li></ul></li>
        <li class="listitem">Lancaster stemmer / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">language modeling / <a title="Project two â implementing an RNN for character-level language modeling in TensorFlow" class="calibre1" href="#calibre_link-69">Project two &ndash; implementing an RNN for character-level language modeling in TensorFlow</a></li>
        <li class="listitem">large-scale machine learning / <a title="Large-scale machine learning and stochastic gradient descent" class="calibre1" href="#calibre_link-6">Large-scale machine learning and stochastic gradient descent</a></li>
        <li class="listitem">Latent Dirichlet Allocation (LDA) / <a title="Topic modeling with Latent Dirichlet Allocation" class="calibre1" href="#calibre_link-144">Topic modeling with Latent Dirichlet Allocation</a><ul class="calibre29"><li class="listitem">text documents, decomposing / <a title="Decomposing text documents with LDA" class="calibre1" href="#calibre_link-144">Decomposing text documents with LDA</a></li><li class="listitem">with scikit-learn / <a title="LDA with scikit-learn" class="calibre1" href="#calibre_link-144">LDA with scikit-learn</a></li></ul></li>
        <li class="listitem">lazy learner / <a title="K-nearest neighbors â a lazy learning algorithm" class="calibre1" href="#calibre_link-81">K-nearest neighbors &ndash; a lazy learning algorithm</a></li>
        <li class="listitem">learning curves<ul class="calibre29"><li class="listitem">algorithms, debugging with / <a title="Debugging algorithms with learning and validation curves" class="calibre1" href="#calibre_link-14">Debugging algorithms with learning and validation curves</a></li><li class="listitem">used, for diagnosing bias problems / <a title="Diagnosing bias and variance problems with learning curves" class="calibre1" href="#calibre_link-14">Diagnosing bias and variance problems with learning curves</a></li><li class="listitem">used, for diagnosing variance problems / <a title="Diagnosing bias and variance problems with learning curves" class="calibre1" href="#calibre_link-14">Diagnosing bias and variance problems with learning curves</a></li></ul></li>
        <li class="listitem">learning rate / <a title="The perceptron learning rule" class="calibre1" href="#calibre_link-19">The perceptron learning rule</a></li>
        <li class="listitem">Least Absolute Shrinkage and Selection Operator (LASSO) / <a title="Using regularized methods for regression" class="calibre1" href="#calibre_link-141">Using regularized methods for regression</a></li>
        <li class="listitem">Leave-one-out cross-validation (LOOCV) method<ul class="calibre29"><li class="listitem">about / <a title="K-fold cross-validation" class="calibre1" href="#calibre_link-300">K-fold cross-validation</a></li></ul></li>
        <li class="listitem">lemmas / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">lemmatization / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">LIBLINEAR library / <a title="Estimating coefficient of a regression model via scikit-learn" class="calibre1" href="#calibre_link-9">Estimating coefficient of a regression model via scikit-learn</a></li>
        <li class="listitem">linear algebra<ul class="calibre29"><li class="listitem">reference / <a title="The formal definition of an artificial neuron" class="calibre1" href="#calibre_link-19">The formal definition of an artificial neuron</a></li></ul></li>
        <li class="listitem">Linear Algebra Package (LAPACK) / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li>
        <li class="listitem">linear discriminant analysis (LDA)<ul class="calibre29"><li class="listitem">versus principal component analysis (PCA) / <a title="Principal component analysis versus linear discriminant analysis" class="calibre1" href="#calibre_link-162">Principal component analysis versus linear discriminant analysis</a></li><li class="listitem">inner workings / <a title="The inner workings of linear discriminant analysis" class="calibre1" href="#calibre_link-162">The inner workings of linear discriminant analysis</a></li><li class="listitem">via scikit-learn / <a title="LDA via scikit-learn" class="calibre1" href="#calibre_link-162">LDA via scikit-learn</a></li></ul></li>
        <li class="listitem">linear discriminants<ul class="calibre29"><li class="listitem">selecting, for new feature subspace / <a title="Selecting linear discriminants for the new feature subspace" class="calibre1" href="#calibre_link-162">Selecting linear discriminants for the new feature subspace</a></li></ul></li>
        <li class="listitem">linear least squares / <a title="Implementing an ordinary least squares linear regression model" class="calibre1" href="#calibre_link-9">Implementing an ordinary least squares linear regression model</a></li>
        <li class="listitem">linear regression<ul class="calibre29"><li class="listitem">about / <a title="Regression for predicting continuous outcomes" class="calibre1" href="#calibre_link-70">Regression for predicting continuous outcomes</a>, <a title="Introducing linear regression" class="calibre1" href="#calibre_link-41">Introducing linear regression</a></li><li class="listitem">simple linear regression / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li><li class="listitem">multiple linear regression / <a title="Multiple linear regression" class="calibre1" href="#calibre_link-41">Multiple linear regression</a></li><li class="listitem">reference / <a title="Using regularized methods for regression" class="calibre1" href="#calibre_link-141">Using regularized methods for regression</a></li></ul></li>
        <li class="listitem">linear regression model<ul class="calibre29"><li class="listitem">turning, into curve / <a title="Turning a linear regression model into a curve â polynomial regression" class="calibre1" href="#calibre_link-83">Turning a linear regression model into a curve &ndash; polynomial regression</a></li></ul></li>
        <li class="listitem">linear regression models<ul class="calibre29"><li class="listitem">performance, evaluating of / <a title="Evaluating the performance of linear regression models" class="calibre1" href="#calibre_link-73">Evaluating the performance of linear regression models</a></li></ul></li>
        <li class="listitem">linkage matrix / <a title="Performing hierarchical clustering on a distance matrix" class="calibre1" href="#calibre_link-12">Performing hierarchical clustering on a distance matrix</a></li>
        <li class="listitem">local receptive field / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li>
        <li class="listitem">logistic cost function<ul class="calibre29"><li class="listitem">weights, learning of / <a title="Learning the weights of the logistic cost function" class="calibre1" href="#calibre_link-8">Learning the weights of the logistic cost function</a></li><li class="listitem">computing / <a title="Computing the logistic cost function" class="calibre1" href="#calibre_link-18">Computing the logistic cost function</a></li></ul></li>
        <li class="listitem">logistic function / <a title="Logistic function recap" class="calibre1" href="#calibre_link-3">Logistic function recap</a></li>
        <li class="listitem">logistic regression<ul class="calibre29"><li class="listitem">class probabilities, modeling via / <a title="Modeling class probabilities via logistic regression" class="calibre1" href="#calibre_link-8">Modeling class probabilities via logistic regression</a></li><li class="listitem">versus support vector machines / <a title="Dealing with a nonlinearly separable case using slack variables" class="calibre1" href="#calibre_link-253">Dealing with a nonlinearly separable case using slack variables</a></li></ul></li>
        <li class="listitem">logistic regression model<ul class="calibre29"><li class="listitem">training, with scikit-learn / <a title="Training a logistic regression model with scikit-learn" class="calibre1" href="#calibre_link-8">Training a logistic regression model with scikit-learn</a></li><li class="listitem">training, for document classification / <a title="Training a logistic regression model for document classification" class="calibre1" href="#calibre_link-110">Training a logistic regression model for document classification</a></li></ul></li>
        <li class="listitem">logistic sigmoid function / <a title="Logistic regression intuition and conditional probabilities" class="calibre1" href="#calibre_link-8">Logistic regression intuition and conditional probabilities</a></li>
        <li class="listitem">logit function / <a title="Logistic regression intuition and conditional probabilities" class="calibre1" href="#calibre_link-8">Logistic regression intuition and conditional probabilities</a></li>
        <li class="listitem">long-range interactions
<ul class="calibre29"><li class="listitem">learning, challenges / <a title="The challenges of learning long-range interactions" class="calibre1" href="#calibre_link-4">The challenges of learning long-range interactions</a></li></ul></li>
        <li class="listitem">low-level features / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li>
        <li class="listitem">low-level TensorFlow API<ul class="calibre29"><li class="listitem">equation, implementation / <a title="First steps with TensorFlow" class="calibre1" href="#calibre_link-16">First steps with TensorFlow</a></li><li class="listitem">used, for developing simple model / <a title="Developing a simple model with the low-level TensorFlow API" class="calibre1" href="#calibre_link-16">Developing a simple model with the low-level TensorFlow API</a></li></ul></li>
        <li class="listitem">lower status of the population (LSTAT) / <a title="Modeling nonlinear relationships in the Housing dataset" class="calibre1" href="#calibre_link-83">Modeling nonlinear relationships in the Housing dataset</a></li>
        <li class="listitem">LSTM cell<ul class="calibre29"><li class="listitem">forget gate / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li><li class="listitem">input gate / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li><li class="listitem">output gate / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li></ul></li>
        <li class="listitem">LSTM units / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
      </ul></div>
  </div>

<div id="calibre_link-576" class="calibre">
<div id="calibre_link-2736" class="book">
<h2 class="title1" id="calibre_link-2737">M</h2>
      <ul class="itemizedlist"><li class="listitem">machine learning<ul class="calibre29"><li class="listitem">types / <a title="The three different types of machine learning" class="calibre1" href="#calibre_link-70">The three different types of machine learning</a></li><li class="listitem">basic terminology / <a title="Introduction to the basic terminology and notations" class="calibre1" href="#calibre_link-228">Introduction to the basic terminology and notations</a></li><li class="listitem">notations / <a title="Introduction to the basic terminology and notations" class="calibre1" href="#calibre_link-228">Introduction to the basic terminology and notations</a></li><li class="listitem">Python, using for / <a title="Using Python for machine learning" class="calibre1" href="#calibre_link-15">Using Python for machine learning</a></li></ul></li>
        <li class="listitem">machine learning models<ul class="calibre29"><li class="listitem">fine-tuning, via grid search / <a title="Fine-tuning machine learning models via grid search" class="calibre1" href="#calibre_link-13">Fine-tuning machine learning models via grid search</a></li></ul></li>
        <li class="listitem">machine learning systems<ul class="calibre29"><li class="listitem">building, workflow / <a title="A roadmap for building machine learning systems" class="calibre1" href="#calibre_link-229">A roadmap for building machine learning systems</a></li></ul></li>
        <li class="listitem">machines<ul class="calibre29"><li class="listitem">building, for transforming data into knowledge / <a title="Building intelligent machines to transform data into knowledge" class="calibre1" href="#calibre_link-17">Building intelligent machines to transform data into knowledge</a></li></ul></li>
        <li class="listitem">majority vote<ul class="calibre29"><li class="listitem">classifiers, combining via / <a title="Combining classifiers via majority vote" class="calibre1" href="#calibre_link-50">Combining classifiers via majority vote</a></li></ul></li>
        <li class="listitem">majority voting principle<ul class="calibre29"><li class="listitem">about / <a title="Learning with ensembles" class="calibre1" href="#calibre_link-38">Learning with ensembles</a></li><li class="listitem">used, for making predictions / <a title="Using the majority voting principle to make predictions" class="calibre1" href="#calibre_link-50">Using the majority voting principle to make predictions</a></li></ul></li>
        <li class="listitem">margin / <a title="Maximum margin intuition" class="calibre1" href="#calibre_link-253">Maximum margin intuition</a></li>
        <li class="listitem">Matplotlib<ul class="calibre29"><li class="listitem">reference / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li></ul></li>
        <li class="listitem">max-pooling / <a title="Subsampling" class="calibre1" href="#calibre_link-20">Subsampling</a></li>
        <li class="listitem">maximum margin / <a title="Maximum margin intuition" class="calibre1" href="#calibre_link-253">Maximum margin intuition</a></li>
        <li class="listitem">maximum margin classification<ul class="calibre29"><li class="listitem">with support vector machines / <a title="Maximum margin classification with support vector machines" class="calibre1" href="#calibre_link-253">Maximum margin classification with support vector machines</a></li></ul></li>
        <li class="listitem">McCulloch-Pitt neuron model / <a title="Modeling complex functions with artificial neural networks" class="calibre1" href="#calibre_link-10">Modeling complex functions with artificial neural networks</a></li>
        <li class="listitem">McCullock-Pitts (MCP) neuron / <a title="Artificial neurons â a brief glimpse into the early history of machine learning" class="calibre1" href="#calibre_link-19">Artificial neurons &ndash; a brief glimpse into the early history of machine learning</a></li>
        <li class="listitem">mean-pooling / <a title="Subsampling" class="calibre1" href="#calibre_link-20">Subsampling</a></li>
        <li class="listitem">mean imputation / <a title="Imputing missing values" class="calibre1" href="#calibre_link-36">Imputing missing values</a></li>
        <li class="listitem">meaningful features<ul class="calibre29"><li class="listitem">selecting / <a title="Selecting meaningful features" class="calibre1" href="#calibre_link-82">Selecting meaningful features</a></li></ul></li>
        <li class="listitem">Mean of Squared Error (MSE) / <a title="Developing a simple model with the low-level TensorFlow API" class="calibre1" href="#calibre_link-16">Developing a simple model with the low-level TensorFlow API</a></li>
        <li class="listitem">mean squared error (MSE) / <a title="Evaluating the performance of linear regression models" class="calibre1" href="#calibre_link-73">Evaluating the performance of linear regression models</a>, <a title="Decision tree regression" class="calibre1" href="#calibre_link-109">Decision tree regression</a></li>
        <li class="listitem">Median Absolute Deviatio (MAD) / <a title="Fitting a robust regression model using RANSAC" class="calibre1" href="#calibre_link-357">Fitting a robust regression model using RANSAC</a></li>
        <li class="listitem">medoid / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">memory cell / <a title="LSTM units" class="calibre1" href="#calibre_link-4">LSTM units</a></li>
        <li class="listitem">microframework<ul class="calibre29"><li class="listitem">about / <a title="Developing a web application with Flask" class="calibre1" href="#calibre_link-67">Developing a web application with Flask</a></li></ul></li>
        <li class="listitem">min-max scaling / <a title="Bringing features onto the same scale" class="calibre1" href="#calibre_link-161">Bringing features onto the same scale</a></li>
        <li class="listitem">mini-batches / <a title="Preparing the data" class="calibre1" href="#calibre_link-142">Preparing the data</a></li>
        <li class="listitem">mini-batch learning / <a title="Large-scale machine learning and stochastic gradient descent" class="calibre1" href="#calibre_link-6">Large-scale machine learning and stochastic gradient descent</a></li>
        <li class="listitem">missing data<ul class="calibre29"><li class="listitem">dealing with / <a title="Dealing with missing data" class="calibre1" href="#calibre_link-36">Dealing with missing data</a></li></ul></li>
        <li class="listitem">missing values<ul class="calibre29"><li class="listitem">identifying, in tabular data / <a title="Identifying missing values in tabular data" class="calibre1" href="#calibre_link-36">Identifying missing values in tabular data</a></li><li class="listitem">samples, eliminating with / <a title="Eliminating samples or features with missing values" class="calibre1" href="#calibre_link-36">Eliminating samples or features with missing values</a></li><li class="listitem">features, eliminating with / <a title="Eliminating samples or features with missing values" class="calibre1" href="#calibre_link-36">Eliminating samples or features with missing values</a></li><li class="listitem">imputing / <a title="Imputing missing values" class="calibre1" href="#calibre_link-36">Imputing missing values</a></li></ul></li>
        <li class="listitem">Mixed National Institute of Standards and Technology (MNIST) dataset / <a title="Classifying handwritten digits" class="calibre1" href="#calibre_link-143">Classifying handwritten digits</a></li>
        <li class="listitem">mlxtend package<ul class="calibre29"><li class="listitem">reference / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li></ul></li>
        <li class="listitem">MNIST dataset<ul class="calibre29"><li class="listitem">obtaining / <a title="Obtaining the MNIST dataset" class="calibre1" href="#calibre_link-143">Obtaining the MNIST dataset</a></li><li class="listitem">reference / <a title="Obtaining the MNIST dataset" class="calibre1" href="#calibre_link-143">Obtaining the MNIST dataset</a></li><li class="listitem">download link / <a title="Building multilayer neural networks using TensorFlow&apos;s Layers API" class="calibre1" href="#calibre_link-76">Building multilayer neural networks using TensorFlow's Layers API</a></li></ul></li>
        <li class="listitem">model<ul class="calibre29"><li class="listitem">restoring, in TensorFlow / <a title="Saving and restoring a model in TensorFlow" class="calibre1" href="#calibre_link-410">Saving and restoring a model in TensorFlow</a></li><li class="listitem">saving, in TensorFlow / <a title="Saving and restoring a model in TensorFlow" class="calibre1" href="#calibre_link-410">Saving and restoring a model in TensorFlow</a></li></ul></li>
        <li class="listitem">model performance<ul class="calibre29"><li class="listitem">assessing, k-fold cross-validation used / <a title="Using k-fold cross-validation to assess model performance" class="calibre1" href="#calibre_link-300">Using k-fold cross-validation to assess model performance</a></li></ul></li>
        <li class="listitem">models<ul class="calibre29"><li class="listitem">evaluating / <a title="Evaluating models and predicting unseen data instances" class="calibre1" href="#calibre_link-229">Evaluating models and predicting unseen data instances</a></li></ul></li>
        <li class="listitem">model selection / <a title="The holdout method" class="calibre1" href="#calibre_link-300">The holdout method</a></li>
        <li class="listitem">movie classifier<ul class="calibre29"><li class="listitem">updating / <a title="Updating the movie classifier" class="calibre1" href="#calibre_link-344">Updating the movie classifier</a></li></ul></li>
        <li class="listitem">movie classifier application<ul class="calibre29"><li class="listitem">uploading / <a title="Uploading the movie classifier application" class="calibre1" href="#calibre_link-344">Uploading the movie classifier application</a></li></ul></li>
        <li class="listitem">movie dataset<ul class="calibre29"><li class="listitem">preprocessing, into convenient format / <a title="Preprocessing the movie dataset into more convenient format" class="calibre1" href="#calibre_link-39">Preprocessing the movie dataset into more convenient format</a></li></ul></li>
        <li class="listitem">movie review classifier, turning into web application<ul class="calibre29"><li class="listitem">about / <a title="Turning the movie review classifier into a web application" class="calibre1" href="#calibre_link-339">Turning the movie review classifier into a web application</a></li><li class="listitem">directory structure / <a title="Files and folders â looking at the directory tree" class="calibre1" href="#calibre_link-339">Files and folders &ndash; looking at the directory tree</a></li><li class="listitem">main application, implementing as app.py / <a title="Implementing the main application as app.py" class="calibre1" href="#calibre_link-339">Implementing the main application as app.py</a></li><li class="listitem">review form, setting up / <a title="Setting up the review form" class="calibre1" href="#calibre_link-339">Setting up the review form</a></li><li class="listitem">result page template, creating / <a title="Creating a results page template" class="calibre1" href="#calibre_link-339">Creating a results page template</a></li></ul></li>
        <li class="listitem">movie review dataset<ul class="calibre29"><li class="listitem">obtaining / <a title="Obtaining the movie review dataset" class="calibre1" href="#calibre_link-39">Obtaining the movie review dataset</a></li><li class="listitem">download link / <a title="Obtaining the movie review dataset" class="calibre1" href="#calibre_link-39">Obtaining the movie review dataset</a></li></ul></li>
        <li class="listitem">multi-class classification<ul class="calibre29"><li class="listitem">about / <a title="Classification for predicting class labels" class="calibre1" href="#calibre_link-70">Classification for predicting class labels</a></li><li class="listitem">class probabilities, estimating in / <a title="Estimating class probabilities in multiclass classification via the softmax function" class="calibre1" href="#calibre_link-3">Estimating class probabilities in multiclass classification via the softmax function</a></li></ul></li>
        <li class="listitem">multidimensional data arrays<ul class="calibre29"><li class="listitem">Tensors, transforming as / <a title="Transforming Tensors as multidimensional data arrays" class="calibre1" href="#calibre_link-411">Transforming Tensors as multidimensional data arrays</a></li></ul></li>
        <li class="listitem">multilayer CNN architecture / <a title="The multilayer CNN architecture" class="calibre1" href="#calibre_link-79">The multilayer CNN architecture</a></li>
        <li class="listitem">multilayer networks<ul class="calibre29"><li class="listitem">activation functions, selecting for / <a title="Choosing activation functions for multilayer networks" class="calibre1" href="#calibre_link-3">Choosing activation functions for multilayer networks</a></li></ul></li>
        <li class="listitem">multilayer neural network<ul class="calibre29"><li class="listitem">developing, Keras used / <a title="Developing a multilayer neural network with Keras" class="calibre1" href="#calibre_link-76">Developing a multilayer neural network with Keras</a></li></ul></li>
        <li class="listitem">multilayer neural network architecture<ul class="calibre29"><li class="listitem">about / <a title="Introducing the multilayer neural network architecture" class="calibre1" href="#calibre_link-10">Introducing the multilayer neural network architecture</a></li></ul></li>
        <li class="listitem">multilayer neural networks<ul class="calibre29"><li class="listitem">building, TensorFlow Layers API used / <a title="Building multilayer neural networks using TensorFlow&apos;s Layers API" class="calibre1" href="#calibre_link-76">Building multilayer neural networks using TensorFlow's Layers API</a></li></ul></li>
        <li class="listitem">multilayer perceptron<ul class="calibre29"><li class="listitem">implementing / <a title="Implementing a multilayer perceptron" class="calibre1" href="#calibre_link-143">Implementing a multilayer perceptron</a></li></ul></li>
        <li class="listitem">Multilayer Perceptron (MLP)<ul class="calibre29"><li class="listitem">about / <a title="Introducing the multilayer neural network architecture" class="calibre1" href="#calibre_link-10">Introducing the multilayer neural network architecture</a></li></ul></li>
        <li class="listitem">multilayer RNN cells<ul class="calibre29"><li class="listitem">defining / <a title="Step 1 â defining multilayer RNN cells" class="calibre1" href="#calibre_link-142">Step 1 &ndash; defining multilayer RNN cells</a></li></ul></li>
        <li class="listitem">multiple decision trees<ul class="calibre29"><li class="listitem">combining, via random forests / <a title="Combining multiple decision trees via random forests" class="calibre1" href="#calibre_link-71">Combining multiple decision trees via random forests</a></li></ul></li>
        <li class="listitem">multiple input<ul class="calibre29"><li class="listitem">working with / <a title="Working with multiple input or color channels" class="calibre1" href="#calibre_link-74">Working with multiple input or color channels</a></li></ul></li>
        <li class="listitem">multiple linear regression<ul class="calibre29"><li class="listitem">about / <a title="Multiple linear regression" class="calibre1" href="#calibre_link-41">Multiple linear regression</a></li><li class="listitem">visualizing / <a title="Multiple linear regression" class="calibre1" href="#calibre_link-41">Multiple linear regression</a></li></ul></li>
        <li class="listitem">MurmurHash3<ul class="calibre29"><li class="listitem">reference / <a title="Working with bigger data â online algorithms and out-of-core learning" class="calibre1" href="#calibre_link-328">Working with bigger data &ndash; online algorithms and out-of-core learning</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-599" class="calibre">
<div id="calibre_link-2738" class="book">
<h2 class="title1" id="calibre_link-2739">N</h2>
      <ul class="itemizedlist"><li class="listitem">n-grams / <a title="Transforming words into feature vectors" class="calibre1" href="#calibre_link-49">Transforming words into feature vectors</a></li>
        <li class="listitem">naive algorithms / <a title="Performing discrete convolutions" class="calibre1" href="#calibre_link-20">Performing discrete convolutions</a></li>
        <li class="listitem">National Institute of Standards and Technology (NIST) / <a title="Obtaining the MNIST dataset" class="calibre1" href="#calibre_link-143">Obtaining the MNIST dataset</a></li>
        <li class="listitem">Natural Language Toolkit (NLTK)<ul class="calibre29"><li class="listitem">reference / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li></ul> / <a title="Serializing fitted scikit-learn estimators" class="calibre1" href="#calibre_link-40">Serializing fitted scikit-learn estimators</a></li>
        <li class="listitem">nested cross-validation<ul class="calibre29"><li class="listitem">used, for selecting algorithm / <a title="Algorithm selection with nested cross-validation" class="calibre1" href="#calibre_link-13">Algorithm selection with nested cross-validation</a></li></ul></li>
        <li class="listitem">neural network<ul class="calibre29"><li class="listitem">activating, via forward propagation / <a title="Activating a neural network via forward propagation" class="calibre1" href="#calibre_link-10">Activating a neural network via forward propagation</a></li><li class="listitem">regularizing, with dropout / <a title="Regularizing a neural network with dropout" class="calibre1" href="#calibre_link-74">Regularizing a neural network with dropout</a></li></ul></li>
        <li class="listitem">neural networks<ul class="calibre29"><li class="listitem">training, via backpropagation / <a title="Training neural networks via backpropagation" class="calibre1" href="#calibre_link-18">Training neural networks via backpropagation</a></li><li class="listitem">training, with high-level TensorFlow APIs / <a title="Training neural networks efficiently with high-level TensorFlow APIs" class="calibre1" href="#calibre_link-76">Training neural networks efficiently with high-level TensorFlow APIs</a></li></ul></li>
        <li class="listitem">new feature subspace<ul class="calibre29"><li class="listitem">linear discriminants, selecting for / <a title="Selecting linear discriminants for the new feature subspace" class="calibre1" href="#calibre_link-162">Selecting linear discriminants for the new feature subspace</a></li></ul></li>
        <li class="listitem">noise points / <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li>
        <li class="listitem">nominal features / <a title="Nominal and ordinal features" class="calibre1" href="#calibre_link-68">Nominal and ordinal features</a><ul class="calibre29"><li class="listitem">one-hot encoding, performing on / <a title="Performing one-hot encoding on nominal features" class="calibre1" href="#calibre_link-68">Performing one-hot encoding on nominal features</a></li></ul></li>
        <li class="listitem">non-empty classes / <a title="Maximizing information gain â getting the most bang for your buck" class="calibre1" href="#calibre_link-71">Maximizing information gain &ndash; getting the most bang for your buck</a></li>
        <li class="listitem">non-linear problems<ul class="calibre29"><li class="listitem">solving, kernel SVM used / <a title="Solving nonlinear problems using a kernel SVM" class="calibre1" href="#calibre_link-84">Solving nonlinear problems using a kernel SVM</a></li></ul></li>
        <li class="listitem">nonlinearly separable case<ul class="calibre29"><li class="listitem">dealing with / <a title="Dealing with a nonlinearly separable case using slack variables" class="calibre1" href="#calibre_link-253">Dealing with a nonlinearly separable case using slack variables</a></li></ul></li>
        <li class="listitem">nonlinear mappings<ul class="calibre29"><li class="listitem">kernel principal component analysis, using for / <a title="Using kernel principal component analysis for nonlinear mappings" class="calibre1" href="#calibre_link-11">Using kernel principal component analysis for nonlinear mappings</a></li></ul></li>
        <li class="listitem">nonlinear relationships<ul class="calibre29"><li class="listitem">modeling, in Housing dataset / <a title="Modeling nonlinear relationships in the Housing dataset" class="calibre1" href="#calibre_link-83">Modeling nonlinear relationships in the Housing dataset</a></li><li class="listitem">dealing with / <a title="Dealing with nonlinear relationships using random forests" class="calibre1" href="#calibre_link-109">Dealing with nonlinear relationships using random forests</a></li></ul></li>
        <li class="listitem">nonparametric models<ul class="calibre29"><li class="listitem">versus parametric models / <a title="K-nearest neighbors â a lazy learning algorithm" class="calibre1" href="#calibre_link-81">K-nearest neighbors &ndash; a lazy learning algorithm</a></li></ul></li>
        <li class="listitem">normal equation / <a title="Estimating coefficient of a regression model via scikit-learn" class="calibre1" href="#calibre_link-9">Estimating coefficient of a regression model via scikit-learn</a></li>
        <li class="listitem">normalization / <a title="Bringing features onto the same scale" class="calibre1" href="#calibre_link-161">Bringing features onto the same scale</a></li>
        <li class="listitem">NumPy<ul class="calibre29"><li class="listitem">reference / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-464" class="calibre">
<div id="calibre_link-2740" class="book">
<h2 class="title1" id="calibre_link-2741">O</h2>
      <ul class="itemizedlist"><li class="listitem">object-oriented perceptron API / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li>
        <li class="listitem">objective function / <a title="Minimizing cost functions with gradient descent" class="calibre1" href="#calibre_link-6">Minimizing cost functions with gradient descent</a></li>
        <li class="listitem">objects<ul class="calibre29"><li class="listitem">executing, in TensorFlow graph / <a title="Executing objects in a TensorFlow graph using their names" class="calibre1" href="#calibre_link-409">Executing objects in a TensorFlow graph using their names</a></li></ul></li>
        <li class="listitem">odds ratio / <a title="Logistic regression intuition and conditional probabilities" class="calibre1" href="#calibre_link-8">Logistic regression intuition and conditional probabilities</a></li>
        <li class="listitem">offsets / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">one-hot encoding<ul class="calibre29"><li class="listitem">performing, on nominal features / <a title="Performing one-hot encoding on nominal features" class="calibre1" href="#calibre_link-68">Performing one-hot encoding on nominal features</a></li></ul></li>
        <li class="listitem">One-versus-All (OvA) classification / <a title="Scoring metrics for multiclass classification" class="calibre1" href="#calibre_link-2">Scoring metrics for multiclass classification</a></li>
        <li class="listitem">One-versus-All (OvA) technique / <a title="Training a perceptron model on the Iris dataset" class="calibre1" href="#calibre_link-52">Training a perceptron model on the Iris dataset</a></li>
        <li class="listitem">One-versus-Rest (OvR) / <a title="Training a perceptron model on the Iris dataset" class="calibre1" href="#calibre_link-52">Training a perceptron model on the Iris dataset</a>, <a title="Sparse solutions with L1 regularization" class="calibre1" href="#calibre_link-82">Sparse solutions with L1 regularization</a></li>
        <li class="listitem">One-vs.-Rest (OvR) method / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a></li>
        <li class="listitem">one dimension<ul class="calibre29"><li class="listitem">discrete convolution, performing in / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li></ul></li>
        <li class="listitem">online learning / <a title="Large-scale machine learning and stochastic gradient descent" class="calibre1" href="#calibre_link-6">Large-scale machine learning and stochastic gradient descent</a></li>
        <li class="listitem">opinion mining<ul class="calibre29"><li class="listitem">about / <a title="Preparing the IMDb movie review data for text processing" class="calibre1" href="#calibre_link-39">Preparing the IMDb movie review data for text processing</a></li></ul></li>
        <li class="listitem">ordinal features / <a title="Nominal and ordinal features" class="calibre1" href="#calibre_link-68">Nominal and ordinal features</a><ul class="calibre29"><li class="listitem">mapping / <a title="Mapping ordinal features" class="calibre1" href="#calibre_link-68">Mapping ordinal features</a></li></ul></li>
        <li class="listitem">Ordinary Least Squares (OLS) / <a title="Developing a simple model with the low-level TensorFlow API" class="calibre1" href="#calibre_link-16">Developing a simple model with the low-level TensorFlow API</a></li>
        <li class="listitem">ordinary least squares (OLS) method / <a title="Implementing an ordinary least squares linear regression model" class="calibre1" href="#calibre_link-9">Implementing an ordinary least squares linear regression model</a></li>
        <li class="listitem">ordinary least squares linear regression model<ul class="calibre29"><li class="listitem">implementing / <a title="Implementing an ordinary least squares linear regression model" class="calibre1" href="#calibre_link-9">Implementing an ordinary least squares linear regression model</a></li></ul></li>
        <li class="listitem">out-of-core learning / <a title="Working with bigger data â online algorithms and out-of-core learning" class="calibre1" href="#calibre_link-328">Working with bigger data &ndash; online algorithms and out-of-core learning</a></li>
        <li class="listitem">output spectrum<ul class="calibre29"><li class="listitem">broadening, hyperbolic tangent used / <a title="Broadening the output spectrum using a hyperbolic tangent" class="calibre1" href="#calibre_link-3">Broadening the output spectrum using a hyperbolic tangent</a></li></ul></li>
        <li class="listitem">overfitting / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a>, <a title="Tackling overfitting via regularization" class="calibre1" href="#calibre_link-8">Tackling overfitting via regularization</a><ul class="calibre29"><li class="listitem">tackling, via regularization / <a title="Tackling overfitting via regularization" class="calibre1" href="#calibre_link-8">Tackling overfitting via regularization</a></li><li class="listitem">about / <a title="Selecting meaningful features" class="calibre1" href="#calibre_link-82">Selecting meaningful features</a>, <a title="Regularizing a neural network with dropout" class="calibre1" href="#calibre_link-74">Regularizing a neural network with dropout</a></li><li class="listitem">addressing, with validation curves / <a title="Addressing over- and underfitting with validation curves" class="calibre1" href="#calibre_link-14">Addressing over- and underfitting with validation curves</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-495" class="calibre">
<div id="calibre_link-2742" class="book">
<h2 class="title1" id="calibre_link-2743">P</h2>
      <ul class="itemizedlist"><li class="listitem">packages<ul class="calibre29"><li class="listitem">installing, from Python Package Index / <a title="Installing Python and packages from the Python Package Index" class="calibre1" href="#calibre_link-15">Installing Python and packages from the Python Package Index</a></li><li class="listitem">for scientific computing / <a title="Packages for scientific computing, data science, and machine learning" class="calibre1" href="#calibre_link-15">Packages for scientific computing, data science, and machine learning</a></li><li class="listitem">for data science / <a title="Packages for scientific computing, data science, and machine learning" class="calibre1" href="#calibre_link-15">Packages for scientific computing, data science, and machine learning</a></li><li class="listitem">for machine learning / <a title="Packages for scientific computing, data science, and machine learning" class="calibre1" href="#calibre_link-15">Packages for scientific computing, data science, and machine learning</a></li></ul></li>
        <li class="listitem">padding / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li>
        <li class="listitem">padding, modes<ul class="calibre29"><li class="listitem">full / <a title="The effect of zero-padding in a convolution" class="calibre1" href="#calibre_link-20">The effect of zero-padding in a convolution</a></li><li class="listitem">same / <a title="The effect of zero-padding in a convolution" class="calibre1" href="#calibre_link-20">The effect of zero-padding in a convolution</a></li><li class="listitem">valid / <a title="The effect of zero-padding in a convolution" class="calibre1" href="#calibre_link-20">The effect of zero-padding in a convolution</a></li></ul></li>
        <li class="listitem">pandas<ul class="calibre29"><li class="listitem">reference / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li></ul></li>
        <li class="listitem">parameter-sharing / <a title="Working with multiple input or color channels" class="calibre1" href="#calibre_link-74">Working with multiple input or color channels</a></li>
        <li class="listitem">parametric models<ul class="calibre29"><li class="listitem">versus nonparametric models / <a title="K-nearest neighbors â a lazy learning algorithm" class="calibre1" href="#calibre_link-81">K-nearest neighbors &ndash; a lazy learning algorithm</a></li></ul></li>
        <li class="listitem">Pearson product-moment correlation coefficients / <a title="Looking at relationships using a correlation matrix" class="calibre1" href="#calibre_link-80">Looking at relationships using a correlation matrix</a></li>
        <li class="listitem">perceptron<ul class="calibre29"><li class="listitem">training / <a title="First steps with scikit-learn â training a perceptron" class="calibre1" href="#calibre_link-7">First steps with scikit-learn &ndash; training a perceptron</a></li></ul></li>
        <li class="listitem">perceptron learning algorithm<ul class="calibre29"><li class="listitem">implementing, in Python / <a title="Implementing a perceptron learning algorithm in Python" class="calibre1" href="#calibre_link-52">Implementing a perceptron learning algorithm in Python</a></li></ul></li>
        <li class="listitem">perceptron learning rule / <a title="The perceptron learning rule" class="calibre1" href="#calibre_link-19">The perceptron learning rule</a></li>
        <li class="listitem">perceptron model<ul class="calibre29"><li class="listitem">training, on Iris dataset / <a title="Training a perceptron model on the Iris dataset" class="calibre1" href="#calibre_link-52">Training a perceptron model on the Iris dataset</a></li></ul></li>
        <li class="listitem">performance<ul class="calibre29"><li class="listitem">evaluating, of linear regression models / <a title="Evaluating the performance of linear regression models" class="calibre1" href="#calibre_link-73">Evaluating the performance of linear regression models</a></li></ul></li>
        <li class="listitem">performance evaluation metrics / <a title="Looking at different performance evaluation metrics" class="calibre1" href="#calibre_link-2">Looking at different performance evaluation metrics</a></li>
        <li class="listitem">petal length / <a title="Using the majority voting principle to make predictions" class="calibre1" href="#calibre_link-50">Using the majority voting principle to make predictions</a></li>
        <li class="listitem">pickle module<ul class="calibre29"><li class="listitem">reference / <a title="Serializing fitted scikit-learn estimators" class="calibre1" href="#calibre_link-40">Serializing fitted scikit-learn estimators</a></li></ul></li>
        <li class="listitem">pip<ul class="calibre29"><li class="listitem">reference / <a title="Installing Python and packages from the Python Package Index" class="calibre1" href="#calibre_link-15">Installing Python and packages from the Python Package Index</a></li></ul></li>
        <li class="listitem">pipelines<ul class="calibre29"><li class="listitem">workflows, streamlining with / <a title="Streamlining workflows with pipelines" class="calibre1" href="#calibre_link-37">Streamlining workflows with pipelines</a></li><li class="listitem">transformers, combining with estimators / <a title="Combining transformers and estimators in a pipeline" class="calibre1" href="#calibre_link-37">Combining transformers and estimators in a pipeline</a></li></ul></li>
        <li class="listitem">placeholders, TensorFlow<ul class="calibre29"><li class="listitem">about / <a title="Placeholders in TensorFlow" class="calibre1" href="#calibre_link-400">Placeholders in TensorFlow</a></li><li class="listitem">defining / <a title="Defining placeholders" class="calibre1" href="#calibre_link-400">Defining placeholders</a></li><li class="listitem">feeding, with data / <a title="Feeding placeholders with data" class="calibre1" href="#calibre_link-400">Feeding placeholders with data</a></li><li class="listitem">defining, for data arrays with varying batchsizes / <a title="Defining placeholders for data arrays with varying batchsizes" class="calibre1" href="#calibre_link-400">Defining placeholders for data arrays with varying batchsizes</a></li></ul></li>
        <li class="listitem">plurality voting<ul class="calibre29"><li class="listitem">about / <a title="Learning with ensembles" class="calibre1" href="#calibre_link-38">Learning with ensembles</a></li></ul></li>
        <li class="listitem">polynomial regression / <a title="Turning a linear regression model into a curve â polynomial regression" class="calibre1" href="#calibre_link-83">Turning a linear regression model into a curve &ndash; polynomial regression</a></li>
        <li class="listitem">polynomial terms<ul class="calibre29"><li class="listitem">adding, scikit-learn used / <a title="Adding polynomial terms using scikit-learn" class="calibre1" href="#calibre_link-83">Adding polynomial terms using scikit-learn</a></li></ul></li>
        <li class="listitem">pooling<ul class="calibre29"><li class="listitem">advantage / <a title="Subsampling" class="calibre1" href="#calibre_link-20">Subsampling</a></li></ul></li>
        <li class="listitem">pooling layers / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li>
        <li class="listitem">pooling size / <a title="Subsampling" class="calibre1" href="#calibre_link-20">Subsampling</a></li>
        <li class="listitem">Porter stemmer algorithm / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">precision<ul class="calibre29"><li class="listitem">optimizing, of classification model / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li></ul></li>
        <li class="listitem">precision-recall curves<ul class="calibre29"><li class="listitem">reference / <a title="Plotting a receiver operating characteristic" class="calibre1" href="#calibre_link-2">Plotting a receiver operating characteristic</a></li></ul></li>
        <li class="listitem">predicted class label / <a title="The perceptron learning rule" class="calibre1" href="#calibre_link-19">The perceptron learning rule</a></li>
        <li class="listitem">predictions<ul class="calibre29"><li class="listitem">making, majority voting principle used / <a title="Using the majority voting principle to make predictions" class="calibre1" href="#calibre_link-50">Using the majority voting principle to make predictions</a></li></ul></li>
        <li class="listitem">predictive model<ul class="calibre29"><li class="listitem">training / <a title="Training and selecting a predictive model" class="calibre1" href="#calibre_link-229">Training and selecting a predictive model</a></li><li class="listitem">selecting / <a title="Training and selecting a predictive model" class="calibre1" href="#calibre_link-229">Training and selecting a predictive model</a></li></ul></li>
        <li class="listitem">preprocessing<ul class="calibre29"><li class="listitem">about / <a title="Preprocessing â getting data into shape" class="calibre1" href="#calibre_link-229">Preprocessing &ndash; getting data into shape</a></li></ul></li>
        <li class="listitem">Principal Component Analysis (PCA) / <a title="Combining transformers and estimators in a pipeline" class="calibre1" href="#calibre_link-37">Combining transformers and estimators in a pipeline</a></li>
        <li class="listitem">principal component analysis (PCA)<ul class="calibre29"><li class="listitem">about / <a title="The main steps behind principal component analysis" class="calibre1" href="#calibre_link-26">The main steps behind principal component analysis</a></li><li class="listitem">using / <a title="The main steps behind principal component analysis" class="calibre1" href="#calibre_link-26">The main steps behind principal component analysis</a></li><li class="listitem">extracting / <a title="Extracting the principal components step by step" class="calibre1" href="#calibre_link-26">Extracting the principal components step by step</a></li><li class="listitem">in scikit-learn / <a title="Principal component analysis in scikit-learn" class="calibre1" href="#calibre_link-26">Principal component analysis in scikit-learn</a></li><li class="listitem">versus linear discriminant analysis (LDA) / <a title="Principal component analysis versus linear discriminant analysis" class="calibre1" href="#calibre_link-162">Principal component analysis versus linear discriminant analysis</a></li></ul> / <a title="Looking at relationships using a correlation matrix" class="calibre1" href="#calibre_link-80">Looking at relationships using a correlation matrix</a></li>
        <li class="listitem">prototype-based clustering / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">prune / <a title="Decision tree learning" class="calibre1" href="#calibre_link-71">Decision tree learning</a></li>
        <li class="listitem">public server<ul class="calibre29"><li class="listitem">web application, deploying to / <a title="Deploying the web application to a public server" class="calibre1" href="#calibre_link-344">Deploying the web application to a public server</a></li></ul></li>
        <li class="listitem">Python<ul class="calibre29"><li class="listitem">about / <a title="Using Python for machine learning" class="calibre1" href="#calibre_link-15">Using Python for machine learning</a></li><li class="listitem">using, for machine learning / <a title="Using Python for machine learning" class="calibre1" href="#calibre_link-15">Using Python for machine learning</a></li><li class="listitem">reference / <a title="Installing Python and packages from the Python Package Index" class="calibre1" href="#calibre_link-15">Installing Python and packages from the Python Package Index</a></li><li class="listitem">installing / <a title="Installing Python and packages from the Python Package Index" class="calibre1" href="#calibre_link-15">Installing Python and packages from the Python Package Index</a></li><li class="listitem">perceptron learning algorithm, implementing in / <a title="Implementing a perceptron learning algorithm in Python" class="calibre1" href="#calibre_link-52">Implementing a perceptron learning algorithm in Python</a></li><li class="listitem">Adaline, implementing in / <a title="Implementing Adaline in Python" class="calibre1" href="#calibre_link-6">Implementing Adaline in Python</a></li><li class="listitem">kernel principal component analysi, implementing in / <a title="Implementing a kernel principal component analysis in Python" class="calibre1" href="#calibre_link-11">Implementing a kernel principal component analysis in Python</a></li></ul></li>
        <li class="listitem">Python 3.5, versus Python 2.7<ul class="calibre29"><li class="listitem">reference / <a title="Installing Python and packages from the Python Package Index" class="calibre1" href="#calibre_link-15">Installing Python and packages from the Python Package Index</a></li></ul></li>
        <li class="listitem">PythonAnywhere<ul class="calibre29"><li class="listitem">reference / <a title="Creating a PythonAnywhere account" class="calibre1" href="#calibre_link-344">Creating a PythonAnywhere account</a></li></ul></li>
        <li class="listitem">PythonAnywhere account<ul class="calibre29"><li class="listitem">creating / <a title="Creating a PythonAnywhere account" class="calibre1" href="#calibre_link-344">Creating a PythonAnywhere account</a></li></ul></li>
        <li class="listitem">Python Imaging Library (PIL)<ul class="calibre29"><li class="listitem">reference / <a title="Working with multiple input or color channels" class="calibre1" href="#calibre_link-74">Working with multiple input or color channels</a></li></ul></li>
        <li class="listitem">Python Package Index<ul class="calibre29"><li class="listitem">packages, installing from / <a title="Installing Python and packages from the Python Package Index" class="calibre1" href="#calibre_link-15">Installing Python and packages from the Python Package Index</a></li></ul></li>
        <li class="listitem">Python Progress Indicator (PyPrind)<ul class="calibre29"><li class="listitem">reference / <a title="Preprocessing the movie dataset into more convenient format" class="calibre1" href="#calibre_link-39">Preprocessing the movie dataset into more convenient format</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-177" class="calibre">
<div id="calibre_link-2744" class="book">
<h2 class="title1" id="calibre_link-2745">Q</h2>
      <ul class="itemizedlist"><li class="listitem">quick-start guide, Anaconda<ul class="calibre29"><li class="listitem">download link / <a title="Using the Anaconda Python distribution and package manager" class="calibre1" href="#calibre_link-15">Using the Anaconda Python distribution and package manager</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-567" class="calibre">
<div id="calibre_link-2746" class="book">
<h2 class="title1" id="calibre_link-2747">R</h2>
      <ul class="itemizedlist"><li class="listitem">Radial Basis Function (RBF) kernel<ul class="calibre29"><li class="listitem">implementing / <a title="Kernel functions and the kernel trick" class="calibre1" href="#calibre_link-11">Kernel functions and the kernel trick</a></li></ul></li>
        <li class="listitem">Radial Basis Function kernel (RBF kernel) / <a title="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre1" href="#calibre_link-84">Using the kernel trick to find separating hyperplanes in high-dimensional space</a></li>
        <li class="listitem">random forest regression / <a title="Random forest regression" class="calibre1" href="#calibre_link-109">Random forest regression</a></li>
        <li class="listitem">random forests<ul class="calibre29"><li class="listitem">multiple decision trees, combining via / <a title="Combining multiple decision trees via random forests" class="calibre1" href="#calibre_link-71">Combining multiple decision trees via random forests</a></li><li class="listitem">feature importance, assessing with / <a title="Assessing feature importance with random forests" class="calibre1" href="#calibre_link-160">Assessing feature importance with random forests</a></li><li class="listitem">used, for dealing with nonlinear relationships / <a title="Dealing with nonlinear relationships using random forests" class="calibre1" href="#calibre_link-109">Dealing with nonlinear relationships using random forests</a></li></ul></li>
        <li class="listitem">random parameter combinations<ul class="calibre29"><li class="listitem">reference / <a title="Tuning hyperparameters via grid search" class="calibre1" href="#calibre_link-13">Tuning hyperparameters via grid search</a></li></ul></li>
        <li class="listitem">RANdom SAmple Consensus (RANSAC) algorithm / <a title="Fitting a robust regression model using RANSAC" class="calibre1" href="#calibre_link-357">Fitting a robust regression model using RANSAC</a></li>
        <li class="listitem">rank<ul class="calibre29"><li class="listitem">about / <a title="TensorFlow ranks and tensors" class="calibre1" href="#calibre_link-398">TensorFlow ranks and tensors</a></li><li class="listitem">obtaining, of tensor / <a title="How to get the rank and shape of a tensor" class="calibre1" href="#calibre_link-398">How to get the rank and shape of a tensor</a></li></ul></li>
        <li class="listitem">RANSAC<ul class="calibre29"><li class="listitem">used, for fitting robust regression model / <a title="Fitting a robust regression model using RANSAC" class="calibre1" href="#calibre_link-357">Fitting a robust regression model using RANSAC</a></li></ul></li>
        <li class="listitem">raw term frequencies / <a title="Transforming words into feature vectors" class="calibre1" href="#calibre_link-49">Transforming words into feature vectors</a></li>
        <li class="listitem">recall<ul class="calibre29"><li class="listitem">optimizing, of classification model / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li></ul></li>
        <li class="listitem">receiver operating characteristic (ROC)<ul class="calibre29"><li class="listitem">plotting / <a title="Plotting a receiver operating characteristic" class="calibre1" href="#calibre_link-2">Plotting a receiver operating characteristic</a></li></ul></li>
        <li class="listitem">Receiver Operator Characteristic area under the curve (ROC AUC) / <a title="Implementing a simple majority vote classifier" class="calibre1" href="#calibre_link-50">Implementing a simple majority vote classifier</a></li>
        <li class="listitem">Rectified Linear Unit (ReLU) / <a title="Rectified linear unit activation" class="calibre1" href="#calibre_link-3">Rectified linear unit activation</a></li>
        <li class="listitem">recurrent edge / <a title="Understanding the structure and flow of an RNN" class="calibre1" href="#calibre_link-4">Understanding the structure and flow of an RNN</a></li>
        <li class="listitem">recursive backward elimination / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li>
        <li class="listitem">regression<ul class="calibre29"><li class="listitem">about / <a title="Making predictions about the future with supervised learning" class="calibre1" href="#calibre_link-70">Making predictions about the future with supervised learning</a></li><li class="listitem">continuous outcomes, predicting / <a title="Regression for predicting continuous outcomes" class="calibre1" href="#calibre_link-70">Regression for predicting continuous outcomes</a></li><li class="listitem">regularized methods, using for / <a title="Using regularized methods for regression" class="calibre1" href="#calibre_link-141">Using regularized methods for regression</a></li></ul></li>
        <li class="listitem">regression analysis<ul class="calibre29"><li class="listitem">about / <a title="Regression for predicting continuous outcomes" class="calibre1" href="#calibre_link-70">Regression for predicting continuous outcomes</a></li></ul></li>
        <li class="listitem">regression for regression parameters<ul class="calibre29"><li class="listitem">solving, with gradient descent / <a title="Solving regression for regression parameters with gradient descent" class="calibre1" href="#calibre_link-9">Solving regression for regression parameters with gradient descent</a></li></ul></li>
        <li class="listitem">regression line / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">regression model<ul class="calibre29"><li class="listitem">building / <a title="Building a regression model" class="calibre1" href="#calibre_link-408">Building a regression model</a></li></ul></li>
        <li class="listitem">regular expression (regex) library / <a title="Cleaning text data" class="calibre1" href="#calibre_link-49">Cleaning text data</a></li>
        <li class="listitem">regularization<ul class="calibre29"><li class="listitem">overfitting, tackling via / <a title="Tackling overfitting via regularization" class="calibre1" href="#calibre_link-8">Tackling overfitting via regularization</a></li></ul></li>
        <li class="listitem">regularization parameter / <a title="Tackling overfitting via regularization" class="calibre1" href="#calibre_link-8">Tackling overfitting via regularization</a></li>
        <li class="listitem">regularized methods<ul class="calibre29"><li class="listitem">using, for regression / <a title="Using regularized methods for regression" class="calibre1" href="#calibre_link-141">Using regularized methods for regression</a></li></ul></li>
        <li class="listitem">reinforcement learning<ul class="calibre29"><li class="listitem">about / <a title="The three different types of machine learning" class="calibre1" href="#calibre_link-70">The three different types of machine learning</a>, <a title="Solving interactive problems with reinforcement learning" class="calibre1" href="#calibre_link-70">Solving interactive problems with reinforcement learning</a></li><li class="listitem">interactive problems, solving / <a title="Solving interactive problems with reinforcement learning" class="calibre1" href="#calibre_link-70">Solving interactive problems with reinforcement learning</a></li></ul></li>
        <li class="listitem">re module<ul class="calibre29"><li class="listitem">reference / <a title="Cleaning text data" class="calibre1" href="#calibre_link-49">Cleaning text data</a></li></ul></li>
        <li class="listitem">residual plots / <a title="Evaluating the performance of linear regression models" class="calibre1" href="#calibre_link-73">Evaluating the performance of linear regression models</a></li>
        <li class="listitem">residuals / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">response / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">reward signal<ul class="calibre29"><li class="listitem">about / <a title="Solving interactive problems with reinforcement learning" class="calibre1" href="#calibre_link-70">Solving interactive problems with reinforcement learning</a></li></ul></li>
        <li class="listitem">Ridge Regression / <a title="Using regularized methods for regression" class="calibre1" href="#calibre_link-141">Using regularized methods for regression</a></li>
        <li class="listitem">RNN<ul class="calibre29"><li class="listitem">structure / <a title="Understanding the structure and flow of an RNN" class="calibre1" href="#calibre_link-4">Understanding the structure and flow of an RNN</a></li><li class="listitem">flow / <a title="Understanding the structure and flow of an RNN" class="calibre1" href="#calibre_link-4">Understanding the structure and flow of an RNN</a></li><li class="listitem">activations, computing / <a title="Computing activations in an RNN" class="calibre1" href="#calibre_link-4">Computing activations in an RNN</a></li><li class="listitem">training, BPTT used / <a title="Computing activations in an RNN" class="calibre1" href="#calibre_link-4">Computing activations in an RNN</a></li></ul></li>
        <li class="listitem">RNN cells<ul class="calibre29"><li class="listitem">initial states, definng for / <a title="Step 2 â defining the initial states for the RNN cells" class="calibre1" href="#calibre_link-142">Step 2 &ndash; defining the initial states for the RNN cells</a></li><li class="listitem">used, for creating RNN / <a title="Step 3 â creating the RNN using the RNN cells and their states" class="calibre1" href="#calibre_link-142">Step 3 &ndash; creating the RNN using the RNN cells and their states</a>, <a title="The train method" class="calibre1" href="#calibre_link-142">The train method</a></li></ul></li>
        <li class="listitem">RNN model<ul class="calibre29"><li class="listitem">building / <a title="Building an RNN model" class="calibre1" href="#calibre_link-142">Building an RNN model</a></li></ul></li>
        <li class="listitem">RNNs<ul class="calibre29"><li class="listitem">sequences, modeling / <a title="RNNs for modeling sequences" class="calibre1" href="#calibre_link-4">RNNs for modeling sequences</a></li></ul></li>
        <li class="listitem">robust regression model<ul class="calibre29"><li class="listitem">fitting, RANSAC used / <a title="Fitting a robust regression model using RANSAC" class="calibre1" href="#calibre_link-357">Fitting a robust regression model using RANSAC</a></li></ul></li>
        <li class="listitem">ROC Area Under the Curve (ROC AUC) / <a title="Plotting a receiver operating characteristic" class="calibre1" href="#calibre_link-2">Plotting a receiver operating characteristic</a></li>
      </ul></div>
  </div>

<div id="calibre_link-594" class="calibre">
<div id="calibre_link-2748" class="book">
<h2 class="title1" id="calibre_link-2749">S</h2>
      <ul class="itemizedlist"><li class="listitem">salient (relevant) features / <a title="Understanding CNNs and learning feature hierarchies" class="calibre1" href="#calibre_link-20">Understanding CNNs and learning feature hierarchies</a></li>
        <li class="listitem">samples<ul class="calibre29"><li class="listitem">eliminating, with missing values / <a title="Eliminating samples or features with missing values" class="calibre1" href="#calibre_link-36">Eliminating samples or features with missing values</a></li><li class="listitem">projecting, onto new feature space / <a title="Projecting samples onto the new feature space" class="calibre1" href="#calibre_link-162">Projecting samples onto the new feature space</a></li></ul></li>
        <li class="listitem">savez function<ul class="calibre29"><li class="listitem">about / <a title="Obtaining the MNIST dataset" class="calibre1" href="#calibre_link-143">Obtaining the MNIST dataset</a></li><li class="listitem">reference / <a title="Obtaining the MNIST dataset" class="calibre1" href="#calibre_link-143">Obtaining the MNIST dataset</a></li></ul></li>
        <li class="listitem">scatter matrices<ul class="calibre29"><li class="listitem">computing / <a title="Computing the scatter matrices" class="calibre1" href="#calibre_link-162">Computing the scatter matrices</a></li></ul></li>
        <li class="listitem">scikit-learn<ul class="calibre29"><li class="listitem">logistic regression model, training with / <a title="Training a logistic regression model with scikit-learn" class="calibre1" href="#calibre_link-8">Training a logistic regression model with scikit-learn</a></li><li class="listitem">alternative implementations / <a title="Alternative implementations in scikit-learn" class="calibre1" href="#calibre_link-253">Alternative implementations in scikit-learn</a></li><li class="listitem">principal component analysis (PCA) / <a title="Principal component analysis in scikit-learn" class="calibre1" href="#calibre_link-26">Principal component analysis in scikit-learn</a></li><li class="listitem">used, for applying Adaboost / <a title="Applying AdaBoost using scikit-learn" class="calibre1" href="#calibre_link-5">Applying AdaBoost using scikit-learn</a></li><li class="listitem">coefficient of regression model, estimating via / <a title="Estimating coefficient of a regression model via scikit-learn" class="calibre1" href="#calibre_link-9">Estimating coefficient of a regression model via scikit-learn</a></li><li class="listitem">used, for adding polynomial terms / <a title="Adding polynomial terms using scikit-learn" class="calibre1" href="#calibre_link-83">Adding polynomial terms using scikit-learn</a></li><li class="listitem">agglomerative clustering, applying via / <a title="Applying agglomerative clustering via scikit-learn" class="calibre1" href="#calibre_link-12">Applying agglomerative clustering via scikit-learn</a></li></ul></li>
        <li class="listitem">scikit-learn-compatible implementations, of stacking<ul class="calibre29"><li class="listitem">reference / <a title="Evaluating and tuning the ensemble classifier" class="calibre1" href="#calibre_link-50">Evaluating and tuning the ensemble classifier</a></li></ul></li>
        <li class="listitem">scikit-learn estimator API / <a title="Understanding the scikit-learn estimator API" class="calibre1" href="#calibre_link-36">Understanding the scikit-learn estimator API</a></li>
        <li class="listitem">scoring metrics<ul class="calibre29"><li class="listitem">for multiclass classification / <a title="Scoring metrics for multiclass classification" class="calibre1" href="#calibre_link-2">Scoring metrics for multiclass classification</a></li></ul></li>
        <li class="listitem">seaborn library<ul class="calibre29"><li class="listitem">reference / <a title="Visualizing the important characteristics of a dataset" class="calibre1" href="#calibre_link-80">Visualizing the important characteristics of a dataset</a></li></ul></li>
        <li class="listitem">sentiment analysis<ul class="calibre29"><li class="listitem">about / <a title="Preparing the IMDb movie review data for text processing" class="calibre1" href="#calibre_link-39">Preparing the IMDb movie review data for text processing</a></li></ul></li>
        <li class="listitem">sentiment analysis of IMDb movie reviews, with multilayer RNNs<ul class="calibre29"><li class="listitem">performing / <a title="Project one â performing sentiment analysis of IMDb movie reviews using multilayer RNNs" class="calibre1" href="#calibre_link-142">Project one &ndash; performing sentiment analysis of IMDb movie reviews using multilayer RNNs</a></li><li class="listitem">data, preparing / <a title="Preparing the data" class="calibre1" href="#calibre_link-142">Preparing the data</a></li></ul></li>
        <li class="listitem">sentiment analysis RNN model<ul class="calibre29"><li class="listitem">training / <a title="Training and optimizing the sentiment analysis RNN model" class="calibre1" href="#calibre_link-142">Training and optimizing the sentiment analysis RNN model</a></li><li class="listitem">optimizing / <a title="Training and optimizing the sentiment analysis RNN model" class="calibre1" href="#calibre_link-142">Training and optimizing the sentiment analysis RNN model</a></li></ul></li>
        <li class="listitem">SentimentRNN class<ul class="calibre29"><li class="listitem">build method / <a title="The build method" class="calibre1" href="#calibre_link-142">The build method</a></li><li class="listitem">predict method / <a title="The predict method" class="calibre1" href="#calibre_link-142">The predict method</a></li><li class="listitem">instantiating / <a title="Instantiating the SentimentRNN class" class="calibre1" href="#calibre_link-142">Instantiating the SentimentRNN class</a></li></ul></li>
        <li class="listitem">SentimentRNN class constructor / <a title="The SentimentRNN class constructor" class="calibre1" href="#calibre_link-142">The SentimentRNN class constructor</a></li>
        <li class="listitem">sepal width / <a title="Using the majority voting principle to make predictions" class="calibre1" href="#calibre_link-50">Using the majority voting principle to make predictions</a></li>
        <li class="listitem">sepal width feature axis / <a title="Decision tree learning" class="calibre1" href="#calibre_link-71">Decision tree learning</a></li>
        <li class="listitem">sequence modeling<ul class="calibre29"><li class="listitem">categories / <a title="The different categories of sequence modeling" class="calibre1" href="#calibre_link-44">The different categories of sequence modeling</a></li></ul></li>
        <li class="listitem">sequences<ul class="calibre29"><li class="listitem">about / <a title="Introducing sequential data" class="calibre1" href="#calibre_link-44">Introducing sequential data</a></li><li class="listitem">representing / <a title="Representing sequences" class="calibre1" href="#calibre_link-44">Representing sequences</a></li></ul></li>
        <li class="listitem">Sequential Backward Selection (SBS) / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li>
        <li class="listitem">sequential data<ul class="calibre29"><li class="listitem">about / <a title="Introducing sequential data" class="calibre1" href="#calibre_link-44">Introducing sequential data</a></li><li class="listitem">modeling / <a title="Modeling sequential data â order matters" class="calibre1" href="#calibre_link-44">Modeling sequential data &ndash; order matters</a></li></ul></li>
        <li class="listitem">sequential feature selection algorithms<ul class="calibre29"><li class="listitem">about / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li></ul></li>
        <li class="listitem">shape<ul class="calibre29"><li class="listitem">obtaining, of tensor / <a title="How to get the rank and shape of a tensor" class="calibre1" href="#calibre_link-398">How to get the rank and shape of a tensor</a></li></ul></li>
        <li class="listitem">sigmoid function / <a title="Logistic regression intuition and conditional probabilities" class="calibre1" href="#calibre_link-8">Logistic regression intuition and conditional probabilities</a></li>
        <li class="listitem">signal / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a></li>
        <li class="listitem">silhouette analysis / <a title="Quantifying the quality of clustering via silhouette plots" class="calibre1" href="#calibre_link-42">Quantifying the quality of clustering via silhouette plots</a></li>
        <li class="listitem">silhouette coefficient / <a title="Quantifying the quality of clustering via silhouette plots" class="calibre1" href="#calibre_link-42">Quantifying the quality of clustering via silhouette plots</a></li>
        <li class="listitem">silhouette plots / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a><ul class="calibre29"><li class="listitem">quality of clustering, quantifying via / <a title="Quantifying the quality of clustering via silhouette plots" class="calibre1" href="#calibre_link-42">Quantifying the quality of clustering via silhouette plots</a></li></ul></li>
        <li class="listitem">similarity function / <a title="Using the kernel trick to find separating hyperplanes in high-dimensional space" class="calibre1" href="#calibre_link-84">Using the kernel trick to find separating hyperplanes in high-dimensional space</a></li>
        <li class="listitem">simple linear regression<ul class="calibre29"><li class="listitem">about / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li></ul></li>
        <li class="listitem">simple majority vote classifier<ul class="calibre29"><li class="listitem">implementing / <a title="Implementing a simple majority vote classifier" class="calibre1" href="#calibre_link-50">Implementing a simple majority vote classifier</a></li></ul></li>
        <li class="listitem">simple model<ul class="calibre29"><li class="listitem">developing, with low-level TensorFlow API / <a title="Developing a simple model with the low-level TensorFlow API" class="calibre1" href="#calibre_link-16">Developing a simple model with the low-level TensorFlow API</a></li></ul></li>
        <li class="listitem">single-layer neural network / <a title="Single-layer neural network recap" class="calibre1" href="#calibre_link-10">Single-layer neural network recap</a></li>
        <li class="listitem">Single Instruction, Multiple Data (SIMD) / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li>
        <li class="listitem">single linkage / <a title="Grouping clusters in bottom-up fashion" class="calibre1" href="#calibre_link-12">Grouping clusters in bottom-up fashion</a></li>
        <li class="listitem">slack variables<ul class="calibre29"><li class="listitem">used, for dealing with nonlinearly separable case / <a title="Dealing with a nonlinearly separable case using slack variables" class="calibre1" href="#calibre_link-253">Dealing with a nonlinearly separable case using slack variables</a></li></ul></li>
        <li class="listitem">Snowball stemmer / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">soft-margin classification / <a title="Dealing with a nonlinearly separable case using slack variables" class="calibre1" href="#calibre_link-253">Dealing with a nonlinearly separable case using slack variables</a></li>
        <li class="listitem">soft clustering<ul class="calibre29"><li class="listitem">versus hard clustering / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li></ul></li>
        <li class="listitem">soft k-means / <a title="Hard versus soft clustering" class="calibre1" href="#calibre_link-42">Hard versus soft clustering</a></li>
        <li class="listitem">softmax function<ul class="calibre29"><li class="listitem">class probabilities, estimating in multi-class classification / <a title="Estimating class probabilities in multiclass classification via the softmax function" class="calibre1" href="#calibre_link-3">Estimating class probabilities in multiclass classification via the softmax function</a></li></ul></li>
        <li class="listitem">sparse-connectivity / <a title="Working with multiple input or color channels" class="calibre1" href="#calibre_link-74">Working with multiple input or color channels</a></li>
        <li class="listitem">sparse solutions<ul class="calibre29"><li class="listitem">with L1 regularization / <a title="Sparse solutions with L1 regularization" class="calibre1" href="#calibre_link-82">Sparse solutions with L1 regularization</a></li></ul></li>
        <li class="listitem">spectral clustering / <a title="Locating regions of high density via DBSCAN" class="calibre1" href="#calibre_link-53">Locating regions of high density via DBSCAN</a></li>
        <li class="listitem">SQLite<ul class="calibre29"><li class="listitem">reference / <a title="Setting up an SQLite database for data storage" class="calibre1" href="#calibre_link-108">Setting up an SQLite database for data storage</a></li></ul></li>
        <li class="listitem">sqlite3<ul class="calibre29"><li class="listitem">reference / <a title="Setting up an SQLite database for data storage" class="calibre1" href="#calibre_link-108">Setting up an SQLite database for data storage</a></li></ul></li>
        <li class="listitem">SQLite database<ul class="calibre29"><li class="listitem">setting up, for data storage / <a title="Setting up an SQLite database for data storage" class="calibre1" href="#calibre_link-108">Setting up an SQLite database for data storage</a></li></ul></li>
        <li class="listitem">SQLite Manager<ul class="calibre29"><li class="listitem">reference / <a title="Setting up an SQLite database for data storage" class="calibre1" href="#calibre_link-108">Setting up an SQLite database for data storage</a></li></ul></li>
        <li class="listitem">squared Euclidean distance / <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">stacking / <a title="Evaluating and tuning the ensemble classifier" class="calibre1" href="#calibre_link-50">Evaluating and tuning the ensemble classifier</a></li>
        <li class="listitem">standardization / <a title="Improving gradient descent through feature scaling" class="calibre1" href="#calibre_link-6">Improving gradient descent through feature scaling</a>, <a title="Bringing features onto the same scale" class="calibre1" href="#calibre_link-161">Bringing features onto the same scale</a></li>
        <li class="listitem">stochastic gradient descent / <a title="Large-scale machine learning and stochastic gradient descent" class="calibre1" href="#calibre_link-6">Large-scale machine learning and stochastic gradient descent</a>, <a title="Working with bigger data â online algorithms and out-of-core learning" class="calibre1" href="#calibre_link-328">Working with bigger data &ndash; online algorithms and out-of-core learning</a></li>
        <li class="listitem">stochastic gradient descent (SGD) / <a title="Solving regression for regression parameters with gradient descent" class="calibre1" href="#calibre_link-9">Solving regression for regression parameters with gradient descent</a></li>
        <li class="listitem">stochastic gradient descent optimization / <a title="Single-layer neural network recap" class="calibre1" href="#calibre_link-10">Single-layer neural network recap</a></li>
        <li class="listitem">stop-word removal / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">subgroups<ul class="calibre29"><li class="listitem">finding, with clustering / <a title="Finding subgroups with clustering" class="calibre1" href="#calibre_link-70">Finding subgroups with clustering</a></li></ul></li>
        <li class="listitem">subsampling / <a title="Subsampling" class="calibre1" href="#calibre_link-20">Subsampling</a></li>
        <li class="listitem">sum of squared errors (SSE) / <a title="Solving regression for regression parameters with gradient descent" class="calibre1" href="#calibre_link-9">Solving regression for regression parameters with gradient descent</a>, <a title="K-means clustering using scikit-learn" class="calibre1" href="#calibre_link-42">K-means clustering using scikit-learn</a></li>
        <li class="listitem">Sum of Squared Errors (SSE) / <a title="Minimizing cost functions with gradient descent" class="calibre1" href="#calibre_link-6">Minimizing cost functions with gradient descent</a>, <a title="A geometric interpretation of L2 regularization" class="calibre1" href="#calibre_link-82">A geometric interpretation of L2 regularization</a>, <a title="Single-layer neural network recap" class="calibre1" href="#calibre_link-10">Single-layer neural network recap</a></li>
        <li class="listitem">supervised data compression<ul class="calibre29"><li class="listitem">via linear discriminant analysis / <a title="Supervised data compression via linear discriminant analysis" class="calibre1" href="#calibre_link-162">Supervised data compression via linear discriminant analysis</a></li></ul></li>
        <li class="listitem">supervised learning<ul class="calibre29"><li class="listitem">about / <a title="The three different types of machine learning" class="calibre1" href="#calibre_link-70">The three different types of machine learning</a></li><li class="listitem">predictions, making about future / <a title="Making predictions about the future with supervised learning" class="calibre1" href="#calibre_link-70">Making predictions about the future with supervised learning</a></li></ul></li>
        <li class="listitem">Support Vector Machine (SVM) / <a title="Tuning hyperparameters via grid search" class="calibre1" href="#calibre_link-13">Tuning hyperparameters via grid search</a>, <a title="Random forest regression" class="calibre1" href="#calibre_link-109">Random forest regression</a></li>
        <li class="listitem">support vector machine (SVM) / <a title="Maximum margin classification with support vector machines" class="calibre1" href="#calibre_link-253">Maximum margin classification with support vector machines</a>, <a title="Using kernel principal component analysis for nonlinear mappings" class="calibre1" href="#calibre_link-11">Using kernel principal component analysis for nonlinear mappings</a></li>
        <li class="listitem">support vector machines<ul class="calibre29"><li class="listitem">versus logistic regression / <a title="Dealing with a nonlinearly separable case using slack variables" class="calibre1" href="#calibre_link-253">Dealing with a nonlinearly separable case using slack variables</a></li></ul></li>
        <li class="listitem">support vectors / <a title="Maximum margin classification with support vector machines" class="calibre1" href="#calibre_link-253">Maximum margin classification with support vector machines</a></li>
        <li class="listitem">SVM regressor<ul class="calibre29"><li class="listitem">reference / <a title="Random forest regression" class="calibre1" href="#calibre_link-109">Random forest regression</a></li></ul></li>
        <li class="listitem">Synthetic Minority Over-sampling Technique (SMOTE) / <a title="Dealing with class imbalance" class="calibre1" href="#calibre_link-72">Dealing with class imbalance</a></li>
      </ul></div>
  </div>

<div id="calibre_link-606" class="calibre">
<div id="calibre_link-2750" class="book">
<h2 class="title1" id="calibre_link-2751">T</h2>
      <ul class="itemizedlist"><li class="listitem">tabular data<ul class="calibre29"><li class="listitem">missing values, identifying in / <a title="Identifying missing values in tabular data" class="calibre1" href="#calibre_link-36">Identifying missing values in tabular data</a></li></ul></li>
        <li class="listitem">target variable / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">TensorBoard<ul class="calibre29"><li class="listitem">graph, visualizing / <a title="Visualizing the graph with TensorBoard" class="calibre1" href="#calibre_link-181">Visualizing the graph with TensorBoard</a></li></ul></li>
        <li class="listitem">TensorBoard experience<ul class="calibre29"><li class="listitem">extending / <a title="Extending your TensorBoard experience" class="calibre1" href="#calibre_link-181">Extending your TensorBoard experience</a></li></ul></li>
        <li class="listitem">TensorFlow<ul class="calibre29"><li class="listitem">about / <a title="TensorFlow and training performance" class="calibre1" href="#calibre_link-16">TensorFlow and training performance</a>, <a title="What is TensorFlow?" class="calibre1" href="#calibre_link-16">What is TensorFlow?</a></li><li class="listitem">training, performance / <a title="TensorFlow and training performance" class="calibre1" href="#calibre_link-16">TensorFlow and training performance</a></li><li class="listitem">learning / <a title="How we will learn TensorFlow" class="calibre1" href="#calibre_link-16">How we will learn TensorFlow</a></li><li class="listitem">first steps / <a title="First steps with TensorFlow" class="calibre1" href="#calibre_link-16">First steps with TensorFlow</a></li><li class="listitem">reference, for installation procedure / <a title="First steps with TensorFlow" class="calibre1" href="#calibre_link-16">First steps with TensorFlow</a></li><li class="listitem">array structures / <a title="Working with array structures" class="calibre1" href="#calibre_link-16">Working with array structures</a></li><li class="listitem">key features / <a title="Key features of TensorFlow" class="calibre1" href="#calibre_link-43">Key features of TensorFlow</a></li><li class="listitem">computation graph / <a title="Understanding TensorFlow&apos;s computation graphs" class="calibre1" href="#calibre_link-75">Understanding TensorFlow's computation graphs</a></li><li class="listitem">placeholders / <a title="Placeholders in TensorFlow" class="calibre1" href="#calibre_link-400">Placeholders in TensorFlow</a></li><li class="listitem">model, saving in / <a title="Saving and restoring a model in TensorFlow" class="calibre1" href="#calibre_link-410">Saving and restoring a model in TensorFlow</a></li><li class="listitem">model, restoring in / <a title="Saving and restoring a model in TensorFlow" class="calibre1" href="#calibre_link-410">Saving and restoring a model in TensorFlow</a></li><li class="listitem">used, for implementing deep convolutional neural network / <a title="Implementing a deep convolutional neural network using TensorFlow" class="calibre1" href="#calibre_link-79">Implementing a deep convolutional neural network using TensorFlow</a></li><li class="listitem">multilayer RNN, implementing for sequence modeling / <a title="Implementing a multilayer RNN for sequence modeling in TensorFlow" class="calibre1" href="#calibre_link-437">Implementing a multilayer RNN for sequence modeling in TensorFlow</a></li><li class="listitem">RNN, implementing for character-level language modeling / <a title="Project two â implementing an RNN for character-level language modeling in TensorFlow" class="calibre1" href="#calibre_link-69">Project two &ndash; implementing an RNN for character-level language modeling in TensorFlow</a></li></ul></li>
        <li class="listitem">TensorFlow functions<ul class="calibre29"><li class="listitem">reference / <a title="Working with array structures" class="calibre1" href="#calibre_link-16">Working with array structures</a></li></ul></li>
        <li class="listitem">TensorFlow graph<ul class="calibre29"><li class="listitem">objects, executing in / <a title="Executing objects in a TensorFlow graph using their names" class="calibre1" href="#calibre_link-409">Executing objects in a TensorFlow graph using their names</a></li></ul></li>
        <li class="listitem">TensorFlow layers API<ul class="calibre29"><li class="listitem">convolutional neural network, implementing in / <a title="Implementing a CNN in the TensorFlow Layers API" class="calibre1" href="#calibre_link-79">Implementing a CNN in the TensorFlow Layers API</a></li></ul></li>
        <li class="listitem">TensorFlow Layers API<ul class="calibre29"><li class="listitem">used, for building multilayer neural networks / <a title="Building multilayer neural networks using TensorFlow&apos;s Layers API" class="calibre1" href="#calibre_link-76">Building multilayer neural networks using TensorFlow's Layers API</a></li></ul></li>
        <li class="listitem">TensorFlow library<ul class="calibre29"><li class="listitem">reference / <a title="A few last words about the neural network implementation" class="calibre1" href="#calibre_link-182">A few last words about the neural network implementation</a></li></ul></li>
        <li class="listitem">TensorFlow low-level API<ul class="calibre29"><li class="listitem">convolutional neural network, implementing in / <a title="Implementing a CNN in the TensorFlow low-level API" class="calibre1" href="#calibre_link-79">Implementing a CNN in the TensorFlow low-level API</a></li></ul></li>
        <li class="listitem">TensorFlow style guide<ul class="calibre29"><li class="listitem">reference / <a title="First steps with TensorFlow" class="calibre1" href="#calibre_link-16">First steps with TensorFlow</a></li></ul></li>
        <li class="listitem">tensors / <a title="First steps with TensorFlow" class="calibre1" href="#calibre_link-16">First steps with TensorFlow</a><ul class="calibre29"><li class="listitem">about / <a title="TensorFlow ranks and tensors" class="calibre1" href="#calibre_link-398">TensorFlow ranks and tensors</a></li><li class="listitem">rank, obtaining of / <a title="How to get the rank and shape of a tensor" class="calibre1" href="#calibre_link-398">How to get the rank and shape of a tensor</a></li><li class="listitem">shape, obtaining of / <a title="How to get the rank and shape of a tensor" class="calibre1" href="#calibre_link-398">How to get the rank and shape of a tensor</a></li></ul></li>
        <li class="listitem">Tensors<ul class="calibre29"><li class="listitem">transforming, as multidimensional data arrays / <a title="Transforming Tensors as multidimensional data arrays" class="calibre1" href="#calibre_link-411">Transforming Tensors as multidimensional data arrays</a></li></ul></li>
        <li class="listitem">term frequency-inverse document frequency (tf-idf)<ul class="calibre29"><li class="listitem">word relevancy, assessing via / <a title="Assessing word relevancy via term frequency-inverse document frequency" class="calibre1" href="#calibre_link-49">Assessing word relevancy via term frequency-inverse document frequency</a></li></ul></li>
        <li class="listitem">test set<ul class="calibre29"><li class="listitem">dataset, partitioning into / <a title="Partitioning a dataset into separate training and test sets" class="calibre1" href="#calibre_link-107">Partitioning a dataset into separate training and test sets</a></li></ul></li>
        <li class="listitem">text data<ul class="calibre29"><li class="listitem">cleaning / <a title="Cleaning text data" class="calibre1" href="#calibre_link-49">Cleaning text data</a></li></ul></li>
        <li class="listitem">text documents<ul class="calibre29"><li class="listitem">decomposing, with Latent Dirichlet Allocation (LDA) / <a title="Decomposing text documents with LDA" class="calibre1" href="#calibre_link-144">Decomposing text documents with LDA</a></li></ul></li>
        <li class="listitem">text processing<ul class="calibre29"><li class="listitem">IMDb movie review data, preparing for / <a title="Preparing the IMDb movie review data for text processing" class="calibre1" href="#calibre_link-39">Preparing the IMDb movie review data for text processing</a></li></ul></li>
        <li class="listitem">tf.contrib.rnn.BasicLSTMCell function<ul class="calibre29"><li class="listitem">reference / <a title="Step 1 â defining multilayer RNN cells" class="calibre1" href="#calibre_link-142">Step 1 &ndash; defining multilayer RNN cells</a></li></ul></li>
        <li class="listitem">tf.contrib.rnn.DropoutWrapper function<ul class="calibre29"><li class="listitem">reference / <a title="Step 1 â defining multilayer RNN cells" class="calibre1" href="#calibre_link-142">Step 1 &ndash; defining multilayer RNN cells</a></li></ul></li>
        <li class="listitem">tf.contrib.rnn.MultiRNNCell function<ul class="calibre29"><li class="listitem">reference / <a title="Step 1 â defining multilayer RNN cells" class="calibre1" href="#calibre_link-142">Step 1 &ndash; defining multilayer RNN cells</a></li></ul></li>
        <li class="listitem">tf.nn.dynamic_rnn function<ul class="calibre29"><li class="listitem">reference / <a title="Step 3 â creating the RNN using the RNN cells and their states" class="calibre1" href="#calibre_link-142">Step 3 &ndash; creating the RNN using the RNN cells and their states</a></li></ul></li>
        <li class="listitem">tokens<ul class="calibre29"><li class="listitem">documents, processig into / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li></ul></li>
        <li class="listitem">topic modeling / <a title="Topic modeling with Latent Dirichlet Allocation" class="calibre1" href="#calibre_link-144">Topic modeling with Latent Dirichlet Allocation</a></li>
        <li class="listitem">total variance<ul class="calibre29"><li class="listitem">about / <a title="Total and explained variance" class="calibre1" href="#calibre_link-26">Total and explained variance</a></li></ul></li>
        <li class="listitem">training set<ul class="calibre29"><li class="listitem">dataset, partitioning into / <a title="Partitioning a dataset into separate training and test sets" class="calibre1" href="#calibre_link-107">Partitioning a dataset into separate training and test sets</a></li></ul></li>
        <li class="listitem">transformer classes / <a title="Understanding the scikit-learn estimator API" class="calibre1" href="#calibre_link-36">Understanding the scikit-learn estimator API</a></li>
        <li class="listitem">transformers, and estimators<ul class="calibre29"><li class="listitem">combining, in pipeline / <a title="Combining transformers and estimators in a pipeline" class="calibre1" href="#calibre_link-37">Combining transformers and estimators in a pipeline</a></li></ul></li>
        <li class="listitem">transpose / <a title="The formal definition of an artificial neuron" class="calibre1" href="#calibre_link-19">The formal definition of an artificial neuron</a></li>
        <li class="listitem">true class label / <a title="The perceptron learning rule" class="calibre1" href="#calibre_link-19">The perceptron learning rule</a></li>
        <li class="listitem">True negative (TN) / <a title="Reading a confusion matrix" class="calibre1" href="#calibre_link-2">Reading a confusion matrix</a></li>
        <li class="listitem">True positive (TP) / <a title="Reading a confusion matrix" class="calibre1" href="#calibre_link-2">Reading a confusion matrix</a></li>
        <li class="listitem">True Positive Rate (TPR) / <a title="Optimizing the precision and recall of a classification model" class="calibre1" href="#calibre_link-2">Optimizing the precision and recall of a classification model</a></li>
        <li class="listitem">two dimensions<ul class="calibre29"><li class="listitem">discrete convolution, performing in / <a title="Performing a discrete convolution in 2D" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in 2D</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-622" class="calibre">
<div id="calibre_link-2752" class="book">
<h2 class="title1" id="calibre_link-2753">U</h2>
      <ul class="itemizedlist"><li class="listitem">underfitting / <a title="Tackling overfitting via regularization" class="calibre1" href="#calibre_link-8">Tackling overfitting via regularization</a><ul class="calibre29"><li class="listitem">addressing, with validation curves / <a title="Addressing over- and underfitting with validation curves" class="calibre1" href="#calibre_link-14">Addressing over- and underfitting with validation curves</a></li></ul></li>
        <li class="listitem">unigram model / <a title="Transforming words into feature vectors" class="calibre1" href="#calibre_link-49">Transforming words into feature vectors</a></li>
        <li class="listitem">unit step function / <a title="The formal definition of an artificial neuron" class="calibre1" href="#calibre_link-19">The formal definition of an artificial neuron</a></li>
        <li class="listitem">univariate / <a title="Simple linear regression" class="calibre1" href="#calibre_link-41">Simple linear regression</a></li>
        <li class="listitem">unseen data instances<ul class="calibre29"><li class="listitem">predicting / <a title="Evaluating models and predicting unseen data instances" class="calibre1" href="#calibre_link-229">Evaluating models and predicting unseen data instances</a></li></ul></li>
        <li class="listitem">unsupervised classification<ul class="calibre29"><li class="listitem">about / <a title="Finding subgroups with clustering" class="calibre1" href="#calibre_link-70">Finding subgroups with clustering</a></li></ul></li>
        <li class="listitem">unsupervised dimensionality<ul class="calibre29"><li class="listitem">via principal component analysis / <a title="Unsupervised dimensionality reduction via principal component analysis" class="calibre1" href="#calibre_link-26">Unsupervised dimensionality reduction via principal component analysis</a></li></ul></li>
        <li class="listitem">unsupervised learning<ul class="calibre29"><li class="listitem">about / <a title="The three different types of machine learning" class="calibre1" href="#calibre_link-70">The three different types of machine learning</a></li><li class="listitem">hidden structures, discovering with / <a title="Discovering hidden structures with unsupervised learning" class="calibre1" href="#calibre_link-70">Discovering hidden structures with unsupervised learning</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-638" class="calibre">
<div id="calibre_link-2754" class="book">
<h2 class="title1" id="calibre_link-2755">V</h2>
      <ul class="itemizedlist"><li class="listitem">validation curves<ul class="calibre29"><li class="listitem">algorithms, debugging with / <a title="Debugging algorithms with learning and validation curves" class="calibre1" href="#calibre_link-14">Debugging algorithms with learning and validation curves</a></li><li class="listitem">used, for addressing underfitting / <a title="Addressing over- and underfitting with validation curves" class="calibre1" href="#calibre_link-14">Addressing over- and underfitting with validation curves</a></li><li class="listitem">used, for addressing overfitting / <a title="Addressing over- and underfitting with validation curves" class="calibre1" href="#calibre_link-14">Addressing over- and underfitting with validation curves</a></li></ul></li>
        <li class="listitem">validation dataset / <a title="Sequential feature selection algorithms" class="calibre1" href="#calibre_link-82">Sequential feature selection algorithms</a></li>
        <li class="listitem">variables, TensorFlow<ul class="calibre29"><li class="listitem">about / <a title="Defining placeholders for data arrays with varying batchsizes" class="calibre1" href="#calibre_link-400">Defining placeholders for data arrays with varying batchsizes</a>, <a title="Variables in TensorFlow" class="calibre1" href="#calibre_link-34">Variables in TensorFlow</a></li><li class="listitem">defining / <a title="Defining variables" class="calibre1" href="#calibre_link-34">Defining variables</a></li><li class="listitem">initializing / <a title="Initializing variables" class="calibre1" href="#calibre_link-34">Initializing variables</a></li><li class="listitem">reusing / <a title="Reusing variables" class="calibre1" href="#calibre_link-34">Reusing variables</a></li></ul></li>
        <li class="listitem">variable scope / <a title="Variable scope" class="calibre1" href="#calibre_link-34">Variable scope</a></li>
        <li class="listitem">variance problems<ul class="calibre29"><li class="listitem">diagnosing, with learning curves / <a title="Diagnosing bias and variance problems with learning curves" class="calibre1" href="#calibre_link-14">Diagnosing bias and variance problems with learning curves</a></li></ul></li>
        <li class="listitem">vectorization / <a title="An object-oriented perceptron API" class="calibre1" href="#calibre_link-52">An object-oriented perceptron API</a></li>
      </ul></div>
  </div>

<div id="calibre_link-658" class="calibre">
<div id="calibre_link-2756" class="book">
<h2 class="title1" id="calibre_link-2757">W</h2>
      <ul class="itemizedlist"><li class="listitem">Ward's linkage / <a title="Grouping clusters in bottom-up fashion" class="calibre1" href="#calibre_link-12">Grouping clusters in bottom-up fashion</a></li>
        <li class="listitem">weak learners<ul class="calibre29"><li class="listitem">leveraging, via AdaBoost (Adaptive Boosting) / <a title="Leveraging weak learners via adaptive boosting" class="calibre1" href="#calibre_link-5">Leveraging weak learners via adaptive boosting</a></li></ul></li>
        <li class="listitem">web application<ul class="calibre29"><li class="listitem">developing, with Flask / <a title="Developing a web application with Flask" class="calibre1" href="#calibre_link-67">Developing a web application with Flask</a></li><li class="listitem">deploying, to public server / <a title="Deploying the web application to a public server" class="calibre1" href="#calibre_link-344">Deploying the web application to a public server</a></li></ul></li>
        <li class="listitem">weights<ul class="calibre29"><li class="listitem">learning, of logistic cost function / <a title="Learning the weights of the logistic cost function" class="calibre1" href="#calibre_link-8">Learning the weights of the logistic cost function</a></li></ul></li>
        <li class="listitem">Wine dataset<ul class="calibre29"><li class="listitem">about / <a title="Partitioning a dataset into separate training and test sets" class="calibre1" href="#calibre_link-107">Partitioning a dataset into separate training and test sets</a></li><li class="listitem">reference / <a title="Partitioning a dataset into separate training and test sets" class="calibre1" href="#calibre_link-107">Partitioning a dataset into separate training and test sets</a></li></ul></li>
        <li class="listitem">Winograd's Minimal Filtering algorithm / <a title="Performing a discrete convolution in 2D" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in 2D</a></li>
        <li class="listitem">word relevancy<ul class="calibre29"><li class="listitem">assessing, via term frequency-inverse document frequency (tf-idf) / <a title="Assessing word relevancy via term frequency-inverse document frequency" class="calibre1" href="#calibre_link-49">Assessing word relevancy via term frequency-inverse document frequency</a></li></ul></li>
        <li class="listitem">words<ul class="calibre29"><li class="listitem">transforming, into feature vectors / <a title="Transforming words into feature vectors" class="calibre1" href="#calibre_link-49">Transforming words into feature vectors</a></li></ul></li>
        <li class="listitem">word stemming / <a title="Processing documents into tokens" class="calibre1" href="#calibre_link-49">Processing documents into tokens</a></li>
        <li class="listitem">workflows<ul class="calibre29"><li class="listitem">streamlining, with pipelines / <a title="Streamlining workflows with pipelines" class="calibre1" href="#calibre_link-37">Streamlining workflows with pipelines</a></li></ul></li>
        <li class="listitem">WTForms library<ul class="calibre29"><li class="listitem">reference / <a title="Form validation and rendering" class="calibre1" href="#calibre_link-67">Form validation and rendering</a></li></ul></li>
      </ul></div>
  </div>

<div id="calibre_link-33" class="calibre">
<div id="calibre_link-2758" class="book">
<h2 class="title1" id="calibre_link-2759">X</h2>
      <ul class="itemizedlist"><li class="listitem">5x2 cross-validation / <a title="Algorithm selection with nested cross-validation" class="calibre1" href="#calibre_link-13">Algorithm selection with nested cross-validation</a></li>
        <li class="listitem">Xavier initialization / <a title="Defining variables" class="calibre1" href="#calibre_link-34">Defining variables</a></li>
      </ul></div>
  </div>

<div id="calibre_link-498" class="calibre">
<div id="calibre_link-2760" class="book">
<h2 class="title1" id="calibre_link-2761">Z</h2>
      <ul class="itemizedlist"><li class="listitem">7Zip<ul class="calibre29"><li class="listitem">download link / <a title="Obtaining the movie review dataset" class="calibre1" href="#calibre_link-39">Obtaining the movie review dataset</a></li></ul></li>
        <li class="listitem">zero-padding / <a title="Performing a discrete convolution in one dimension" class="calibre1" href="#calibre_link-20">Performing a discrete convolution in one dimension</a><ul class="calibre29"><li class="listitem">effect, in convolution / <a title="The effect of zero-padding in a convolution" class="calibre1" href="#calibre_link-20">The effect of zero-padding in a convolution</a></li></ul></li>
      </ul></div>
  </div>

</body></html>